{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNet2_MVtecAD_Dataset",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seunghee0518/AI_python/blob/main/EfficientNet_b0_sam_MVtecAD_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## trina/ test 나눠서 학습"
      ],
      "metadata": {
        "id": "lynhGDxilbRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "torch.hub : Pytorch Hub는 연구 재현성을 촉진하도록 설계된 사전 훈련 된 모델 저장소\n",
        "nvidia_efficientnet_b4 사전 모델 가져옴\n",
        "'''\n",
        "# import torch\n",
        "# model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b4', pretrained=True)\n",
        "!pip install timm\n",
        "import timm\n",
        "model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=88)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ-ytfDpoKMH",
        "outputId": "c227fdda-307d-48fa-d08d-b78432c999e9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.5.4)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2021.10.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from pprint import pprint\n",
        "# model_names = timm.list_models(pretrained=True)\n",
        "# pprint(model_names)"
      ],
      "metadata": {
        "id": "invECZxkPTyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKXv22Yk6zus",
        "outputId": "499e3d66-9e3b-416d-b081-4cafffaa70fe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 학습 코드\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "#import timm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import transforms, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "from PIL import Image\n",
        "# from efficientnet_pytorch import EfficientNet\n",
        "# model_name = 'efficientnet-b0'  # b5\n",
        "\n",
        "# image_size = EfficientNet.get_image_size(model_name)\n",
        "# print(image_size)\n",
        "# model = EfficientNet.from_pretrained(model_name, num_classes=88)"
      ],
      "metadata": {
        "id": "Gjs-R_R5lUKg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 기본 설정\n",
        "device = torch.device('cuda')\n",
        "batch_size  = 32\n",
        "random_seed = 1234\n",
        "img_size = 224\n",
        "random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZHMCtAvlDOp",
        "outputId": "598aaa77-3737-4618-d011-0fa4eb355cfb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fb8cd4a7110>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## transforms 함수 정리\n",
        "* transforms.ToPILImage() - csv 파일로 데이터셋을 받을 경우, PIL image로 바꿔준다.\n",
        "* transforms.CenterCrop(size) - 가운데 부분을 size 크기로 자른다.\n",
        "* transforms.Grayscale(num_output_channels=1) - grayscale로 변환한다.\n",
        "* transforms.RandomAffine(degrees) - 랜덤으로 affine 변형을 한다.\n",
        "* transforms.RandomCrop(size) -이미지를 랜덤으로 아무데나 잘라 size 크기로 출력한다.\n",
        "* transforms.RandomResizedCrop(size) - 이미지 사이즈를 size로 변경한다\n",
        "* transforms.Resize(size) - 이미지 사이즈를 size로 변경한다\n",
        "* transforms.RandomRotation(degrees) 이미지를 랜덤으로 degrees 각도로 회전한다.\n",
        "* transforms.RandomResizedCrop(size, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333)) - 이미지를 랜덤으로 변형한다.\n",
        "* transforms.RandomVerticalFlip(p=0.5) - 이미지를 랜덤으로 수직으로 뒤집는다. p =0이면 뒤집지 않는다.\n",
        "* transforms.RandomHorizontalFlip(p=0.5) - 이미지를 랜덤으로 수평으로 뒤집는다.\n",
        "* transforms.ToTensor() - 이미지 데이터를 tensor로 바꿔준다.\n",
        "* transforms.Normalize(mean, std, inplace=False) - 이미지를 정규화한다."
      ],
      "metadata": {
        "id": "fTgH3bYzN7RA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 데이터 전처리 함수\n",
        "# make dataset\n",
        "#data_path = 'president/president_data'  # class 별 폴더로 나누어진 걸 가져와서 라벨도 달아준다\n",
        "# train_dataset = datasets.ImageFolder(data_path,\n",
        "#                                      transforms.Compose([\n",
        "#                                      transforms.Resize((224, 224)),\n",
        "#                                      transforms.RandomCrop(224),\n",
        "#                                      transforms.RandomRotation(90, expand=True),\n",
        "#                                      transforms.RandomVerticalFlip(),\n",
        "#                                      transforms.RandomHorizontalFlip(),\n",
        "#                                      transforms.ToTensor(), # 이미지 데이터를 tensor로 바꿔준다.\n",
        "#                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])) # Normalize는 많은 이미지의 평균, 표준편차로 정함(보통 많이 하는 값이라고함)\n",
        "\n",
        "\n",
        "### 이미지 전처리 함수 & 클래스\n",
        "## 이미지  > 넘파이 배열로 변환\n",
        "def img_load(path):\n",
        "    img = cv2.imread(path)[:,:,::-1] # Return type:\tnumpy.ndarray / 기본적으로 BGR로 불러옴, RGB 변환함\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    return img\n",
        "\n",
        "class Custom_dataset_1(Dataset): # 기본\n",
        "    def __init__(self, img_paths, labels, mode='train'):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode = mode\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.img_paths[idx]\n",
        "        img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "        img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "        ## 레이블 > 원-핫 인코딩 하기 \n",
        "        label = self.labels[idx]# (원핫인코딩 안할거면 해당 코드만 필요)\n",
        "        return img, label\n",
        "\n",
        "class Custom_dataset_2(Dataset): # 변형\n",
        "    def __init__(self, img_paths, labels, mode='train'):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode = mode\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.img_paths[idx]\n",
        "        if self.mode == 'train':\n",
        "          img = Image.fromarray(img)\n",
        "          #img = transforms.Resize((img_size, img_size))(img) # 처음 이미지 불러올때 resize 했으므로 생략\n",
        "          #img = transforms.RandomCrop(img_size)(img)\n",
        "          img = transforms.RandomRotation(90, expand=False)(img)\n",
        "          img = transforms.RandomVerticalFlip()(img)\n",
        "          img = transforms.RandomHorizontalFlip()(img)\n",
        "          img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "          img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "        if self.mode=='test':\n",
        "          img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "          img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "        ## 레이블\n",
        "        label = self.labels[idx]# (원핫인코딩 안할거면 해당 코드만 필요)\n",
        "        return img, label\n",
        "\n",
        "class Custom_dataset_3(Dataset): # 기본이미지 + 변형이미지 (train 시 2배 증량됨)\n",
        "    def __init__(self, img_paths, labels, mode='train'):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode=mode\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.mode=='train':\n",
        "          if idx < 4277: # 변경 없는 이미지\n",
        "            img = self.img_paths[idx]\n",
        "            img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "            img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "            label = self.labels[idx]\n",
        "            return img, label\n",
        "\n",
        "          else : # 랜덤 변경된 이미지 추가됨 \n",
        "            img = self.img_paths[idx]\n",
        "            img = Image.fromarray(img)\n",
        "            #img = transforms.Resize((img_size, img_size))(img) # 처음 이미지 불러올때 resize 했으므로 생략\n",
        "            #img = transforms.RandomCrop(img_size)(img)\n",
        "            img = transforms.RandomRotation(90, expand=False)(img)\n",
        "            img = transforms.RandomVerticalFlip()(img)\n",
        "            img = transforms.RandomHorizontalFlip()(img)\n",
        "            img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "            img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "            label = self.labels[idx]\n",
        "            return img, label\n",
        "\n",
        "        if self.mode=='test':\n",
        "          img = self.img_paths[idx]\n",
        "          img = transforms.ToTensor()(img)\n",
        "          img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "          label = self.labels[idx]\n",
        "          return img, label\n",
        "\n",
        "class SAM(torch.optim.Optimizer):\n",
        "    def __init__(self, params, base_optimizer, rho=0.05, **kwargs):\n",
        "        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n",
        "\n",
        "        defaults = dict(rho=rho, **kwargs)\n",
        "        super(SAM, self).__init__(params, defaults)\n",
        "\n",
        "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
        "        self.param_groups = self.base_optimizer.param_groups\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def first_step(self, zero_grad=False):\n",
        "        grad_norm = self._grad_norm()\n",
        "        for group in self.param_groups:\n",
        "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
        "\n",
        "            for p in group[\"params\"]:\n",
        "                if p.grad is None: continue\n",
        "                e_w = p.grad * scale.to(p)\n",
        "                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n",
        "                self.state[p][\"e_w\"] = e_w\n",
        "\n",
        "        if zero_grad: self.zero_grad()\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def second_step(self, zero_grad=False):\n",
        "        for group in self.param_groups:\n",
        "            for p in group[\"params\"]:\n",
        "                if p.grad is None: continue\n",
        "                p.sub_(self.state[p][\"e_w\"])  # get back to \"w\" from \"w + e(w)\"\n",
        "\n",
        "        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n",
        "\n",
        "        if zero_grad: self.zero_grad()\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure=None):\n",
        "        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n",
        "        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n",
        "\n",
        "        self.first_step(zero_grad=True)\n",
        "        closure()\n",
        "        self.second_step()\n",
        "\n",
        "    def _grad_norm(self):\n",
        "        shared_device = self.param_groups[0][\"params\"][0].device  # put everything on the same device, in case of model parallelism\n",
        "        norm = torch.norm(\n",
        "                    torch.stack([\n",
        "                        p.grad.norm(p=2).to(shared_device)\n",
        "                        for group in self.param_groups for p in group[\"params\"]\n",
        "                        if p.grad is not None\n",
        "                    ]),\n",
        "                    p=2\n",
        "               )\n",
        "        return norm"
      ],
      "metadata": {
        "id": "ORqFbwLXpSeu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 이미지 로드 및 전처리\n",
        "# 이미지 경로\n",
        "train_png = sorted(glob('/content/drive/Othercomputers/내 MacBook Pro/open/train/*.png'))\n",
        "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
        "\n",
        "#train_imgs = np.load('/content/drive/MyDrive/DACON_이상치 탐지 알고리즘 경진대회/train_imgs_224.npy')\n",
        "train_y = pd.read_csv(\"/content/drive/Othercomputers/내 MacBook Pro/open/train_df.csv\")\n",
        "\n",
        "train_labels = train_y[\"label\"] # 레이블순서는 이미지 파일 순서대로임\n",
        "\n",
        "label_unique = sorted(np.unique(train_labels))\n",
        "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))} # 오름차순으로 레이블별로 숫자 부여(0부터 시작)\n",
        "\n",
        "train_labels = [label_unique[k] for k in train_labels]\n",
        "\n",
        "# 커스텀 이미지 생성\n",
        "train_dataset = Custom_dataset_1(np.array(train_imgs), np.array(train_labels), mode='train')\n",
        "train_idx, vaild_idx = train_test_split(list(range(len(train_dataset))), stratify=train_labels, test_size=0.3, random_state=random_seed)\n",
        "\n",
        "# ## 이미지 증량 시만 사용\n",
        "# train_imgs = train_imgs + train_imgs\n",
        "# train_labels = train_labels+train_labels\n",
        "\n",
        "# train_dataset = Custom_dataset_3(np.array(train_imgs), np.array(train_labels), mode='train')\n",
        "\n",
        "### 데이터셋 분리 > 층화추출 & 테스터 데이터 비율 : 0.3, 시드 : 1234, 셔플 = True(default)\n",
        "train_idx, vaild_idx = train_test_split(list(range(len(train_dataset))), stratify=train_labels, test_size=0.3, random_state=random_seed)\n",
        "\n",
        "datasets = {} # 데이터셋을 담을 딕셔너리\n",
        "datasets['train'] = Subset(train_dataset, train_idx)\n",
        "datasets['vaild']  = Subset(train_dataset, vaild_idx)\n",
        "\n",
        "## data loader 선언\n",
        "dataloaders, batch_num = {}, {}\n",
        "dataloaders['train'] = torch.utils.data.DataLoader(datasets['train'],\n",
        "                                                  batch_size=batch_size, shuffle=True,\n",
        "                                                  num_workers=0)\n",
        "dataloaders['vaild']  = torch.utils.data.DataLoader(datasets['vaild'],\n",
        "                                                    batch_size=batch_size, shuffle=False,\n",
        "                                                    num_workers=0)\n",
        "'''\n",
        "데이터 변형 코드를 추가한 후 아래 오류코드가 나와\n",
        "Caught TypeError in DataLoader worker process 0\n",
        "DataLoader > num_workers 를 4 -> 0 로 낮춤\n",
        "'''\n",
        "\n",
        "batch_num['train'], batch_num['vaild'] = len(dataloaders['train']), len(dataloaders['vaild'])\n",
        "print('batch_size : %d,  train/vaild(데이터셋개수/배치사이즈) : %d / %d' % (batch_size, batch_num['train'],batch_num['vaild']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItvLP1Y3k-OW",
        "outputId": "60366465-0de7-47a5-81db-e2cb013e638c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4277/4277 [02:10<00:00, 32.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_size : 32,  train/vaild(데이터셋개수/배치사이즈) : 94 / 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 참고 블로그 : https://keep-steady.tistory.com/35\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "### f1 스코어 함수 \n",
        "def score_function(real, pred): # 라이브러리 > sklearn.metrics \n",
        "    score = f1_score(real, pred, average=\"macro\")\n",
        "    return score\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    #train_loss, train_acc, valid_loss, valid_acc = [], [], [], []\n",
        "    train_loss, train_acc, valid_loss, valid_acc, train_f1, valid_f1 = [], [], [], [], [], []\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))# - 1))\n",
        "        print('-' * 10)\n",
        "        train_pred=[]# 이거 추가 : f1스코어 계산\n",
        "        train_y=[]#이거 추가\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'vaild']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
        "            \n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device) # device = torch.device('cuda')\n",
        "                labels = labels.to(device) # device = torch.device('cuda')\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # # backward + optimize only if in training phase\n",
        "                    # if phase == 'train':\n",
        "                    #     loss.backward()\n",
        "                    #     optimizer.step()\n",
        "\n",
        "                    # backward + optimize only if in training phase + sam\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.first_step(zero_grad=True)\n",
        "                        criterion(model(inputs), labels).backward()\n",
        "                        optimizer.second_step(zero_grad=True)\n",
        "\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                num_cnt += len(labels)\n",
        "\n",
        "                train_pred += preds.detach().cpu().numpy().tolist() #이거 추가\n",
        "                train_y += labels.detach().cpu().data.numpy().tolist() #이거 추가\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "            \n",
        "            epoch_loss = float(running_loss / num_cnt)\n",
        "            epoch_acc  = float((running_corrects.double() / num_cnt).cpu()*100)\n",
        "            f1 = score_function(train_y,  train_pred) # score_function or f1_score\n",
        "\n",
        "            if phase == 'train':\n",
        "                train_loss.append(epoch_loss)\n",
        "                train_acc.append(epoch_acc)\n",
        "                train_f1.append(f1)\n",
        "            else:\n",
        "                valid_loss.append(epoch_loss)\n",
        "                valid_acc.append(epoch_acc)\n",
        "                valid_f1.append(f1)\n",
        "\n",
        "            print('{} Loss: {:.5f} Acc: {:.5f} macro-f1: {:.5f}'.format(phase, epoch_loss, epoch_acc, f1))\n",
        "           \n",
        "            # deep copy the model(최적모델 저장)\n",
        "            if phase == 'vaild' and epoch_acc > best_acc:\n",
        "                best_idx = epoch\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "#                 best_model_wts = copy.deepcopy(model.module.state_dict())\n",
        "                print('==> best model saved - %d / %.1f'%(best_idx, best_acc))\n",
        "        # 한 에포크마다 실행 시간 출력하기(누적 시간으로 출력됨)\n",
        "        time_elapsed = time.time() - since\n",
        "        print('each epochs training time : {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "        print('\\n')\n",
        "\n",
        "        # 한 에포크마다 필요없는 메모리 지우기 : 지우기 효과는 아직 확인 못해봄\n",
        "        try:      \n",
        "          gc.collect() # cpu 비움\n",
        "          torch.cuda.empty_cache() # gpu 비움\n",
        "        except:\n",
        "          pass\n",
        "          \n",
        "    ## 학습 마무리 후\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best valid Acc: %d - %.1f' %(best_idx, best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    '''\n",
        "    한 에포크 마다 저장된 최적의 모델 가중치로 조정 후 다음 에포크가 돌아감\n",
        "    '''\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    torch.save(model.state_dict(), 'president_model.pt')\n",
        "    print('model saved')\n",
        "    return model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc, train_f1, valid_f1\n",
        "\n",
        "# 설정\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # set gpu\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer_ft = optim.SGD(model.parameters(), \n",
        "#                          lr = 0.05,\n",
        "#                          momentum=0.9,\n",
        "#                          weight_decay=1e-4)\n",
        "\n",
        "# lmbda = lambda epoch: 0.98739\n",
        "# exp_lr_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer_ft, lr_lambda=lmbda)\n",
        "\n",
        "## 변경된 옵티마이저\n",
        "base_optimizer = torch.optim.SGD\n",
        "optimizer_ft = SAM(model.parameters(), base_optimizer, lr=0.001, momentum=0.9)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer_ft,\n",
        "                                                step_size = 5,\n",
        "                                                gamma = 0.75)\n",
        "\n",
        "\n",
        "\n",
        "# 사전학습된 가중치와 모델을 가져와 데이터셋으로 추가 모델 학습\n",
        "model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc, train_f1, valid_f1 = train_model(model, criterion, optimizer_ft, lr_scheduler, num_epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDNj4Yarkx-R",
        "outputId": "2e8971c2-ace9-4268-c89e-48a51b7f32f6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/100\n",
            "----------\n",
            "train Loss: 4.16823 Acc: 18.81056 macro-f1: 0.04672\n",
            "vaild Loss: 3.70072 Acc: 60.74766 macro-f1: 0.07023\n",
            "==> best model saved - 0 / 60.7\n",
            "each epochs training time : 1m 27s\n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "----------\n",
            "train Loss: 3.16580 Acc: 76.54527 macro-f1: 0.13826\n",
            "vaild Loss: 2.57698 Acc: 83.25545 macro-f1: 0.14092\n",
            "==> best model saved - 1 / 83.3\n",
            "each epochs training time : 2m 56s\n",
            "\n",
            "\n",
            "Epoch 2/100\n",
            "----------\n",
            "train Loss: 1.89886 Acc: 83.22753 macro-f1: 0.14436\n",
            "vaild Loss: 1.37255 Acc: 83.41121 macro-f1: 0.14447\n",
            "==> best model saved - 2 / 83.4\n",
            "each epochs training time : 4m 27s\n",
            "\n",
            "\n",
            "Epoch 3/100\n",
            "----------\n",
            "train Loss: 1.32399 Acc: 83.76211 macro-f1: 0.14903\n",
            "vaild Loss: 1.20302 Acc: 84.73520 macro-f1: 0.15180\n",
            "==> best model saved - 3 / 84.7\n",
            "each epochs training time : 5m 60s\n",
            "\n",
            "\n",
            "Epoch 4/100\n",
            "----------\n",
            "train Loss: 1.19166 Acc: 84.73104 macro-f1: 0.15569\n",
            "vaild Loss: 1.11746 Acc: 84.81308 macro-f1: 0.15586\n",
            "==> best model saved - 4 / 84.8\n",
            "each epochs training time : 7m 32s\n",
            "\n",
            "\n",
            "Epoch 5/100\n",
            "----------\n",
            "train Loss: 1.11764 Acc: 84.86468 macro-f1: 0.15603\n",
            "vaild Loss: 1.07834 Acc: 84.81308 macro-f1: 0.15610\n",
            "each epochs training time : 9m 5s\n",
            "\n",
            "\n",
            "Epoch 6/100\n",
            "----------\n",
            "train Loss: 1.07751 Acc: 84.73104 macro-f1: 0.15579\n",
            "vaild Loss: 1.04445 Acc: 84.81308 macro-f1: 0.15593\n",
            "each epochs training time : 10m 38s\n",
            "\n",
            "\n",
            "Epoch 7/100\n",
            "----------\n",
            "train Loss: 1.04259 Acc: 84.86468 macro-f1: 0.15605\n",
            "vaild Loss: 1.01677 Acc: 84.81308 macro-f1: 0.15611\n",
            "each epochs training time : 12m 11s\n",
            "\n",
            "\n",
            "Epoch 8/100\n",
            "----------\n",
            "train Loss: 1.01612 Acc: 84.83127 macro-f1: 0.15599\n",
            "vaild Loss: 0.99280 Acc: 84.81308 macro-f1: 0.15607\n",
            "each epochs training time : 13m 44s\n",
            "\n",
            "\n",
            "Epoch 9/100\n",
            "----------\n",
            "train Loss: 0.99531 Acc: 84.86468 macro-f1: 0.15594\n",
            "vaild Loss: 0.96798 Acc: 84.81308 macro-f1: 0.15604\n",
            "each epochs training time : 15m 17s\n",
            "\n",
            "\n",
            "Epoch 10/100\n",
            "----------\n",
            "train Loss: 0.96733 Acc: 84.83127 macro-f1: 0.15599\n",
            "vaild Loss: 0.94408 Acc: 84.81308 macro-f1: 0.15607\n",
            "each epochs training time : 16m 50s\n",
            "\n",
            "\n",
            "Epoch 11/100\n",
            "----------\n",
            "train Loss: 0.93819 Acc: 84.86468 macro-f1: 0.15605\n",
            "vaild Loss: 0.92853 Acc: 84.81308 macro-f1: 0.15612\n",
            "each epochs training time : 18m 23s\n",
            "\n",
            "\n",
            "Epoch 12/100\n",
            "----------\n",
            "train Loss: 0.92490 Acc: 84.86468 macro-f1: 0.15605\n",
            "vaild Loss: 0.91357 Acc: 84.81308 macro-f1: 0.15611\n",
            "each epochs training time : 19m 56s\n",
            "\n",
            "\n",
            "Epoch 13/100\n",
            "----------\n",
            "train Loss: 0.91946 Acc: 84.86468 macro-f1: 0.15604\n",
            "vaild Loss: 0.91023 Acc: 84.81308 macro-f1: 0.15611\n",
            "each epochs training time : 21m 29s\n",
            "\n",
            "\n",
            "Epoch 14/100\n",
            "----------\n",
            "train Loss: 0.88653 Acc: 84.86468 macro-f1: 0.15604\n",
            "vaild Loss: 0.87474 Acc: 84.81308 macro-f1: 0.15611\n",
            "each epochs training time : 23m 1s\n",
            "\n",
            "\n",
            "Epoch 15/100\n",
            "----------\n",
            "train Loss: 0.87895 Acc: 84.86468 macro-f1: 0.15604\n",
            "vaild Loss: 0.86912 Acc: 84.81308 macro-f1: 0.15611\n",
            "each epochs training time : 24m 34s\n",
            "\n",
            "\n",
            "Epoch 16/100\n",
            "----------\n",
            "train Loss: 0.85746 Acc: 84.86468 macro-f1: 0.15597\n",
            "vaild Loss: 0.85499 Acc: 84.81308 macro-f1: 0.15606\n",
            "each epochs training time : 26m 7s\n",
            "\n",
            "\n",
            "Epoch 17/100\n",
            "----------\n",
            "train Loss: 0.85275 Acc: 84.86468 macro-f1: 0.15604\n",
            "vaild Loss: 0.84909 Acc: 84.81308 macro-f1: 0.15611\n",
            "each epochs training time : 27m 40s\n",
            "\n",
            "\n",
            "Epoch 18/100\n",
            "----------\n",
            "train Loss: 0.84082 Acc: 84.89810 macro-f1: 0.15891\n",
            "vaild Loss: 0.82714 Acc: 84.81308 macro-f1: 0.15822\n",
            "each epochs training time : 29m 13s\n",
            "\n",
            "\n",
            "Epoch 19/100\n",
            "----------\n",
            "train Loss: 0.82016 Acc: 84.93151 macro-f1: 0.16148\n",
            "vaild Loss: 0.81812 Acc: 84.81308 macro-f1: 0.15999\n",
            "each epochs training time : 30m 46s\n",
            "\n",
            "\n",
            "Epoch 20/100\n",
            "----------\n",
            "train Loss: 0.80088 Acc: 84.86468 macro-f1: 0.15606\n",
            "vaild Loss: 0.83045 Acc: 84.81308 macro-f1: 0.15609\n",
            "each epochs training time : 32m 19s\n",
            "\n",
            "\n",
            "Epoch 21/100\n",
            "----------\n",
            "train Loss: 0.78792 Acc: 84.89810 macro-f1: 0.16134\n",
            "vaild Loss: 0.79242 Acc: 84.81308 macro-f1: 0.15987\n",
            "each epochs training time : 33m 52s\n",
            "\n",
            "\n",
            "Epoch 22/100\n",
            "----------\n",
            "train Loss: 0.79321 Acc: 84.89810 macro-f1: 0.15862\n",
            "vaild Loss: 0.78420 Acc: 84.81308 macro-f1: 0.15791\n",
            "each epochs training time : 35m 25s\n",
            "\n",
            "\n",
            "Epoch 23/100\n",
            "----------\n",
            "train Loss: 0.77932 Acc: 85.06515 macro-f1: 0.17095\n",
            "vaild Loss: 0.78004 Acc: 84.81308 macro-f1: 0.16670\n",
            "each epochs training time : 36m 58s\n",
            "\n",
            "\n",
            "Epoch 24/100\n",
            "----------\n",
            "train Loss: 0.75936 Acc: 84.86468 macro-f1: 0.15608\n",
            "vaild Loss: 0.76529 Acc: 84.81308 macro-f1: 0.15615\n",
            "each epochs training time : 38m 31s\n",
            "\n",
            "\n",
            "Epoch 25/100\n",
            "----------\n",
            "train Loss: 0.75579 Acc: 84.89810 macro-f1: 0.16644\n",
            "vaild Loss: 0.77015 Acc: 84.89097 macro-f1: 0.16567\n",
            "==> best model saved - 25 / 84.9\n",
            "each epochs training time : 40m 4s\n",
            "\n",
            "\n",
            "Epoch 26/100\n",
            "----------\n",
            "train Loss: 0.74523 Acc: 84.99833 macro-f1: 0.16554\n",
            "vaild Loss: 0.75136 Acc: 84.96885 macro-f1: 0.16625\n",
            "==> best model saved - 26 / 85.0\n",
            "each epochs training time : 41m 37s\n",
            "\n",
            "\n",
            "Epoch 27/100\n",
            "----------\n",
            "train Loss: 0.75320 Acc: 85.03174 macro-f1: 0.16751\n",
            "vaild Loss: 0.75876 Acc: 85.20249 macro-f1: 0.17136\n",
            "==> best model saved - 27 / 85.2\n",
            "each epochs training time : 43m 10s\n",
            "\n",
            "\n",
            "Epoch 28/100\n",
            "----------\n",
            "train Loss: 0.74620 Acc: 85.06515 macro-f1: 0.17143\n",
            "vaild Loss: 0.74546 Acc: 84.89097 macro-f1: 0.16867\n",
            "each epochs training time : 44m 43s\n",
            "\n",
            "\n",
            "Epoch 29/100\n",
            "----------\n",
            "train Loss: 0.71806 Acc: 84.99833 macro-f1: 0.16498\n",
            "vaild Loss: 0.73422 Acc: 84.89097 macro-f1: 0.16417\n",
            "each epochs training time : 46m 15s\n",
            "\n",
            "\n",
            "Epoch 30/100\n",
            "----------\n",
            "train Loss: 0.70932 Acc: 85.16539 macro-f1: 0.17595\n",
            "vaild Loss: 0.72643 Acc: 84.96885 macro-f1: 0.17375\n",
            "each epochs training time : 47m 48s\n",
            "\n",
            "\n",
            "Epoch 31/100\n",
            "----------\n",
            "train Loss: 0.70628 Acc: 85.03174 macro-f1: 0.16865\n",
            "vaild Loss: 0.72473 Acc: 85.20249 macro-f1: 0.17196\n",
            "each epochs training time : 49m 21s\n",
            "\n",
            "\n",
            "Epoch 32/100\n",
            "----------\n",
            "train Loss: 0.69817 Acc: 85.09856 macro-f1: 0.17367\n",
            "vaild Loss: 0.71521 Acc: 85.28037 macro-f1: 0.17723\n",
            "==> best model saved - 32 / 85.3\n",
            "each epochs training time : 50m 54s\n",
            "\n",
            "\n",
            "Epoch 33/100\n",
            "----------\n",
            "train Loss: 0.69757 Acc: 85.13197 macro-f1: 0.17701\n",
            "vaild Loss: 0.71391 Acc: 85.04673 macro-f1: 0.17466\n",
            "each epochs training time : 52m 26s\n",
            "\n",
            "\n",
            "Epoch 34/100\n",
            "----------\n",
            "train Loss: 0.68117 Acc: 85.13197 macro-f1: 0.17557\n",
            "vaild Loss: 0.69351 Acc: 85.04673 macro-f1: 0.17476\n",
            "each epochs training time : 53m 59s\n",
            "\n",
            "\n",
            "Epoch 35/100\n",
            "----------\n",
            "train Loss: 0.69331 Acc: 85.16539 macro-f1: 0.17758\n",
            "vaild Loss: 0.69967 Acc: 85.04673 macro-f1: 0.17607\n",
            "each epochs training time : 55m 32s\n",
            "\n",
            "\n",
            "Epoch 36/100\n",
            "----------\n",
            "train Loss: 0.67889 Acc: 85.26562 macro-f1: 0.18628\n",
            "vaild Loss: 0.69331 Acc: 84.96885 macro-f1: 0.18056\n",
            "each epochs training time : 57m 4s\n",
            "\n",
            "\n",
            "Epoch 37/100\n",
            "----------\n",
            "train Loss: 0.67814 Acc: 85.16539 macro-f1: 0.17727\n",
            "vaild Loss: 0.69541 Acc: 84.96885 macro-f1: 0.17465\n",
            "each epochs training time : 58m 37s\n",
            "\n",
            "\n",
            "Epoch 38/100\n",
            "----------\n",
            "train Loss: 0.66249 Acc: 85.29903 macro-f1: 0.18471\n",
            "vaild Loss: 0.68977 Acc: 85.04673 macro-f1: 0.18049\n",
            "each epochs training time : 60m 10s\n",
            "\n",
            "\n",
            "Epoch 39/100\n",
            "----------\n",
            "train Loss: 0.67093 Acc: 85.13197 macro-f1: 0.17317\n",
            "vaild Loss: 0.68684 Acc: 85.20249 macro-f1: 0.17392\n",
            "each epochs training time : 61m 43s\n",
            "\n",
            "\n",
            "Epoch 40/100\n",
            "----------\n",
            "train Loss: 0.65954 Acc: 85.29903 macro-f1: 0.19357\n",
            "vaild Loss: 0.67843 Acc: 85.28037 macro-f1: 0.19123\n",
            "each epochs training time : 63m 15s\n",
            "\n",
            "\n",
            "Epoch 41/100\n",
            "----------\n",
            "train Loss: 0.66551 Acc: 85.16539 macro-f1: 0.17892\n",
            "vaild Loss: 0.68715 Acc: 85.12461 macro-f1: 0.17662\n",
            "each epochs training time : 64m 48s\n",
            "\n",
            "\n",
            "Epoch 42/100\n",
            "----------\n",
            "train Loss: 0.66321 Acc: 85.39926 macro-f1: 0.19323\n",
            "vaild Loss: 0.67787 Acc: 85.28037 macro-f1: 0.18937\n",
            "each epochs training time : 66m 21s\n",
            "\n",
            "\n",
            "Epoch 43/100\n",
            "----------\n",
            "train Loss: 0.65671 Acc: 85.26562 macro-f1: 0.18321\n",
            "vaild Loss: 0.67638 Acc: 85.20249 macro-f1: 0.18180\n",
            "each epochs training time : 67m 54s\n",
            "\n",
            "\n",
            "Epoch 44/100\n",
            "----------\n",
            "train Loss: 0.65446 Acc: 85.43268 macro-f1: 0.19353\n",
            "vaild Loss: 0.67984 Acc: 85.20249 macro-f1: 0.18951\n",
            "each epochs training time : 69m 26s\n",
            "\n",
            "\n",
            "Epoch 45/100\n",
            "----------\n",
            "train Loss: 0.64959 Acc: 85.36585 macro-f1: 0.19108\n",
            "vaild Loss: 0.67587 Acc: 85.35826 macro-f1: 0.19173\n",
            "==> best model saved - 45 / 85.4\n",
            "each epochs training time : 70m 59s\n",
            "\n",
            "\n",
            "Epoch 46/100\n",
            "----------\n",
            "train Loss: 0.65046 Acc: 85.39926 macro-f1: 0.19456\n",
            "vaild Loss: 0.67104 Acc: 85.28037 macro-f1: 0.19096\n",
            "each epochs training time : 72m 32s\n",
            "\n",
            "\n",
            "Epoch 47/100\n",
            "----------\n",
            "train Loss: 0.64997 Acc: 85.43268 macro-f1: 0.19407\n",
            "vaild Loss: 0.67087 Acc: 85.35826 macro-f1: 0.19248\n",
            "each epochs training time : 74m 5s\n",
            "\n",
            "\n",
            "Epoch 48/100\n",
            "----------\n",
            "train Loss: 0.64158 Acc: 85.36585 macro-f1: 0.19027\n",
            "vaild Loss: 0.66831 Acc: 85.35826 macro-f1: 0.18720\n",
            "each epochs training time : 75m 37s\n",
            "\n",
            "\n",
            "Epoch 49/100\n",
            "----------\n",
            "train Loss: 0.63970 Acc: 85.29903 macro-f1: 0.18301\n",
            "vaild Loss: 0.66374 Acc: 85.28037 macro-f1: 0.18206\n",
            "each epochs training time : 77m 10s\n",
            "\n",
            "\n",
            "Epoch 50/100\n",
            "----------\n",
            "train Loss: 0.63778 Acc: 85.36585 macro-f1: 0.18909\n",
            "vaild Loss: 0.65623 Acc: 85.28037 macro-f1: 0.18604\n",
            "each epochs training time : 78m 43s\n",
            "\n",
            "\n",
            "Epoch 51/100\n",
            "----------\n",
            "train Loss: 0.63308 Acc: 85.39926 macro-f1: 0.19154\n",
            "vaild Loss: 0.65929 Acc: 85.28037 macro-f1: 0.18869\n",
            "each epochs training time : 80m 15s\n",
            "\n",
            "\n",
            "Epoch 52/100\n",
            "----------\n",
            "train Loss: 0.63931 Acc: 85.43268 macro-f1: 0.19735\n",
            "vaild Loss: 0.65507 Acc: 85.12461 macro-f1: 0.19283\n",
            "each epochs training time : 81m 48s\n",
            "\n",
            "\n",
            "Epoch 53/100\n",
            "----------\n",
            "train Loss: 0.62829 Acc: 85.49950 macro-f1: 0.19747\n",
            "vaild Loss: 0.65689 Acc: 85.28037 macro-f1: 0.19235\n",
            "each epochs training time : 83m 21s\n",
            "\n",
            "\n",
            "Epoch 54/100\n",
            "----------\n",
            "train Loss: 0.62694 Acc: 85.43268 macro-f1: 0.19317\n",
            "vaild Loss: 0.65932 Acc: 85.28037 macro-f1: 0.18982\n",
            "each epochs training time : 84m 54s\n",
            "\n",
            "\n",
            "Epoch 55/100\n",
            "----------\n",
            "train Loss: 0.63677 Acc: 85.43268 macro-f1: 0.19230\n",
            "vaild Loss: 0.67016 Acc: 85.43614 macro-f1: 0.19156\n",
            "==> best model saved - 55 / 85.4\n",
            "each epochs training time : 86m 26s\n",
            "\n",
            "\n",
            "Epoch 56/100\n",
            "----------\n",
            "train Loss: 0.63721 Acc: 85.36585 macro-f1: 0.19540\n",
            "vaild Loss: 0.65660 Acc: 85.35826 macro-f1: 0.19317\n",
            "each epochs training time : 87m 59s\n",
            "\n",
            "\n",
            "Epoch 57/100\n",
            "----------\n",
            "train Loss: 0.65073 Acc: 85.43268 macro-f1: 0.20277\n",
            "vaild Loss: 0.65343 Acc: 85.35826 macro-f1: 0.19952\n",
            "each epochs training time : 89m 31s\n",
            "\n",
            "\n",
            "Epoch 58/100\n",
            "----------\n",
            "train Loss: 0.61840 Acc: 85.59973 macro-f1: 0.20761\n",
            "vaild Loss: 0.64938 Acc: 85.35826 macro-f1: 0.20203\n",
            "each epochs training time : 91m 4s\n",
            "\n",
            "\n",
            "Epoch 59/100\n",
            "----------\n",
            "train Loss: 0.62624 Acc: 85.53291 macro-f1: 0.19481\n",
            "vaild Loss: 0.65557 Acc: 85.35826 macro-f1: 0.19099\n",
            "each epochs training time : 92m 37s\n",
            "\n",
            "\n",
            "Epoch 60/100\n",
            "----------\n",
            "train Loss: 0.64326 Acc: 85.39926 macro-f1: 0.19543\n",
            "vaild Loss: 0.64827 Acc: 85.35826 macro-f1: 0.19191\n",
            "each epochs training time : 94m 9s\n",
            "\n",
            "\n",
            "Epoch 61/100\n",
            "----------\n",
            "train Loss: 0.63096 Acc: 85.46609 macro-f1: 0.19416\n",
            "vaild Loss: 0.64714 Acc: 85.20249 macro-f1: 0.18906\n",
            "each epochs training time : 95m 42s\n",
            "\n",
            "\n",
            "Epoch 62/100\n",
            "----------\n",
            "train Loss: 0.62393 Acc: 85.46609 macro-f1: 0.19242\n",
            "vaild Loss: 0.65111 Acc: 85.35826 macro-f1: 0.19000\n",
            "each epochs training time : 97m 15s\n",
            "\n",
            "\n",
            "Epoch 63/100\n",
            "----------\n",
            "train Loss: 0.61786 Acc: 85.66656 macro-f1: 0.21069\n",
            "vaild Loss: 0.64713 Acc: 85.20249 macro-f1: 0.20398\n",
            "each epochs training time : 98m 47s\n",
            "\n",
            "\n",
            "Epoch 64/100\n",
            "----------\n",
            "train Loss: 0.61899 Acc: 85.63314 macro-f1: 0.20593\n",
            "vaild Loss: 0.64646 Acc: 85.35826 macro-f1: 0.19967\n",
            "each epochs training time : 100m 20s\n",
            "\n",
            "\n",
            "Epoch 65/100\n",
            "----------\n",
            "train Loss: 0.62455 Acc: 85.23221 macro-f1: 0.18219\n",
            "vaild Loss: 0.63898 Acc: 85.28037 macro-f1: 0.18136\n",
            "each epochs training time : 101m 53s\n",
            "\n",
            "\n",
            "Epoch 66/100\n",
            "----------\n",
            "train Loss: 0.61467 Acc: 85.33244 macro-f1: 0.19180\n",
            "vaild Loss: 0.65109 Acc: 85.35826 macro-f1: 0.19012\n",
            "each epochs training time : 103m 25s\n",
            "\n",
            "\n",
            "Epoch 67/100\n",
            "----------\n",
            "train Loss: 0.61906 Acc: 85.56632 macro-f1: 0.20225\n",
            "vaild Loss: 0.64569 Acc: 85.20249 macro-f1: 0.19526\n",
            "each epochs training time : 104m 58s\n",
            "\n",
            "\n",
            "Epoch 68/100\n",
            "----------\n",
            "train Loss: 0.61750 Acc: 85.69997 macro-f1: 0.21341\n",
            "vaild Loss: 0.64579 Acc: 85.43614 macro-f1: 0.20720\n",
            "each epochs training time : 106m 31s\n",
            "\n",
            "\n",
            "Epoch 69/100\n",
            "----------\n",
            "train Loss: 0.61064 Acc: 85.63314 macro-f1: 0.20647\n",
            "vaild Loss: 0.64373 Acc: 85.35826 macro-f1: 0.20047\n",
            "each epochs training time : 108m 3s\n",
            "\n",
            "\n",
            "Epoch 70/100\n",
            "----------\n",
            "train Loss: 0.62818 Acc: 85.66656 macro-f1: 0.21092\n",
            "vaild Loss: 0.64813 Acc: 85.35826 macro-f1: 0.20502\n",
            "each epochs training time : 109m 36s\n",
            "\n",
            "\n",
            "Epoch 71/100\n",
            "----------\n",
            "train Loss: 0.62464 Acc: 85.63314 macro-f1: 0.21053\n",
            "vaild Loss: 0.65318 Acc: 85.43614 macro-f1: 0.20530\n",
            "each epochs training time : 111m 9s\n",
            "\n",
            "\n",
            "Epoch 72/100\n",
            "----------\n",
            "train Loss: 0.61465 Acc: 85.56632 macro-f1: 0.20629\n",
            "vaild Loss: 0.64487 Acc: 85.43614 macro-f1: 0.20065\n",
            "each epochs training time : 112m 42s\n",
            "\n",
            "\n",
            "Epoch 73/100\n",
            "----------\n",
            "train Loss: 0.60810 Acc: 85.63314 macro-f1: 0.20486\n",
            "vaild Loss: 0.64498 Acc: 85.43614 macro-f1: 0.20257\n",
            "each epochs training time : 114m 15s\n",
            "\n",
            "\n",
            "Epoch 74/100\n",
            "----------\n",
            "train Loss: 0.61784 Acc: 85.53291 macro-f1: 0.19831\n",
            "vaild Loss: 0.64709 Acc: 85.35826 macro-f1: 0.19595\n",
            "each epochs training time : 115m 48s\n",
            "\n",
            "\n",
            "Epoch 75/100\n",
            "----------\n",
            "train Loss: 0.61313 Acc: 85.56632 macro-f1: 0.20434\n",
            "vaild Loss: 0.64161 Acc: 85.28037 macro-f1: 0.19705\n",
            "each epochs training time : 117m 21s\n",
            "\n",
            "\n",
            "Epoch 76/100\n",
            "----------\n",
            "train Loss: 0.61319 Acc: 85.53291 macro-f1: 0.19987\n",
            "vaild Loss: 0.66027 Acc: 85.43614 macro-f1: 0.19912\n",
            "each epochs training time : 118m 54s\n",
            "\n",
            "\n",
            "Epoch 77/100\n",
            "----------\n",
            "train Loss: 0.61877 Acc: 85.43268 macro-f1: 0.19429\n",
            "vaild Loss: 0.63805 Acc: 85.35826 macro-f1: 0.19208\n",
            "each epochs training time : 120m 27s\n",
            "\n",
            "\n",
            "Epoch 78/100\n",
            "----------\n",
            "train Loss: 0.61685 Acc: 85.43268 macro-f1: 0.19076\n",
            "vaild Loss: 0.64595 Acc: 85.51402 macro-f1: 0.19198\n",
            "==> best model saved - 78 / 85.5\n",
            "each epochs training time : 122m 1s\n",
            "\n",
            "\n",
            "Epoch 79/100\n",
            "----------\n",
            "train Loss: 0.62156 Acc: 85.73338 macro-f1: 0.21595\n",
            "vaild Loss: 0.64120 Acc: 85.28037 macro-f1: 0.20670\n",
            "each epochs training time : 123m 34s\n",
            "\n",
            "\n",
            "Epoch 80/100\n",
            "----------\n",
            "train Loss: 0.61637 Acc: 85.43268 macro-f1: 0.19225\n",
            "vaild Loss: 0.63702 Acc: 85.51402 macro-f1: 0.19359\n",
            "each epochs training time : 125m 7s\n",
            "\n",
            "\n",
            "Epoch 81/100\n",
            "----------\n",
            "train Loss: 0.62426 Acc: 85.63314 macro-f1: 0.20452\n",
            "vaild Loss: 0.64680 Acc: 85.20249 macro-f1: 0.19815\n",
            "each epochs training time : 126m 40s\n",
            "\n",
            "\n",
            "Epoch 82/100\n",
            "----------\n",
            "train Loss: 0.62071 Acc: 85.36585 macro-f1: 0.18892\n",
            "vaild Loss: 0.64026 Acc: 85.35826 macro-f1: 0.18661\n",
            "each epochs training time : 128m 13s\n",
            "\n",
            "\n",
            "Epoch 83/100\n",
            "----------\n",
            "train Loss: 0.61323 Acc: 85.69997 macro-f1: 0.20653\n",
            "vaild Loss: 0.64761 Acc: 85.35826 macro-f1: 0.20014\n",
            "each epochs training time : 129m 46s\n",
            "\n",
            "\n",
            "Epoch 84/100\n",
            "----------\n",
            "train Loss: 0.60412 Acc: 85.63314 macro-f1: 0.20598\n",
            "vaild Loss: 0.63686 Acc: 85.28037 macro-f1: 0.19908\n",
            "each epochs training time : 131m 19s\n",
            "\n",
            "\n",
            "Epoch 85/100\n",
            "----------\n",
            "train Loss: 0.61597 Acc: 85.59973 macro-f1: 0.21085\n",
            "vaild Loss: 0.63546 Acc: 85.35826 macro-f1: 0.20499\n",
            "each epochs training time : 132m 52s\n",
            "\n",
            "\n",
            "Epoch 86/100\n",
            "----------\n",
            "train Loss: 0.61005 Acc: 85.46609 macro-f1: 0.19700\n",
            "vaild Loss: 0.64211 Acc: 85.28037 macro-f1: 0.19246\n",
            "each epochs training time : 134m 25s\n",
            "\n",
            "\n",
            "Epoch 87/100\n",
            "----------\n",
            "train Loss: 0.60155 Acc: 85.56632 macro-f1: 0.19963\n",
            "vaild Loss: 0.63984 Acc: 85.43614 macro-f1: 0.19707\n",
            "each epochs training time : 135m 58s\n",
            "\n",
            "\n",
            "Epoch 88/100\n",
            "----------\n",
            "train Loss: 0.61671 Acc: 85.36585 macro-f1: 0.19251\n",
            "vaild Loss: 0.63684 Acc: 85.28037 macro-f1: 0.18967\n",
            "each epochs training time : 137m 31s\n",
            "\n",
            "\n",
            "Epoch 89/100\n",
            "----------\n",
            "train Loss: 0.62190 Acc: 85.49950 macro-f1: 0.19602\n",
            "vaild Loss: 0.64056 Acc: 85.35826 macro-f1: 0.19249\n",
            "each epochs training time : 139m 4s\n",
            "\n",
            "\n",
            "Epoch 90/100\n",
            "----------\n",
            "train Loss: 0.60790 Acc: 85.69997 macro-f1: 0.21713\n",
            "vaild Loss: 0.68665 Acc: 85.35826 macro-f1: 0.20966\n",
            "each epochs training time : 140m 37s\n",
            "\n",
            "\n",
            "Epoch 91/100\n",
            "----------\n",
            "train Loss: 0.62077 Acc: 85.36585 macro-f1: 0.19383\n",
            "vaild Loss: 0.66877 Acc: 85.28037 macro-f1: 0.19212\n",
            "each epochs training time : 142m 11s\n",
            "\n",
            "\n",
            "Epoch 92/100\n",
            "----------\n",
            "train Loss: 0.60682 Acc: 85.63314 macro-f1: 0.20448\n",
            "vaild Loss: 0.63990 Acc: 85.20249 macro-f1: 0.19634\n",
            "each epochs training time : 143m 44s\n",
            "\n",
            "\n",
            "Epoch 93/100\n",
            "----------\n",
            "train Loss: 0.60426 Acc: 85.63314 macro-f1: 0.20628\n",
            "vaild Loss: 0.64092 Acc: 85.35826 macro-f1: 0.19938\n",
            "each epochs training time : 145m 17s\n",
            "\n",
            "\n",
            "Epoch 94/100\n",
            "----------\n",
            "train Loss: 0.61024 Acc: 85.53291 macro-f1: 0.20115\n",
            "vaild Loss: 0.63369 Acc: 85.43614 macro-f1: 0.19768\n",
            "each epochs training time : 146m 49s\n",
            "\n",
            "\n",
            "Epoch 95/100\n",
            "----------\n",
            "train Loss: 0.61801 Acc: 85.63314 macro-f1: 0.20766\n",
            "vaild Loss: 0.64409 Acc: 85.66978 macro-f1: 0.20661\n",
            "==> best model saved - 95 / 85.7\n",
            "each epochs training time : 148m 23s\n",
            "\n",
            "\n",
            "Epoch 96/100\n",
            "----------\n",
            "train Loss: 0.61333 Acc: 85.66656 macro-f1: 0.20606\n",
            "vaild Loss: 0.64517 Acc: 85.51402 macro-f1: 0.20249\n",
            "each epochs training time : 149m 56s\n",
            "\n",
            "\n",
            "Epoch 97/100\n",
            "----------\n",
            "train Loss: 0.61685 Acc: 85.63314 macro-f1: 0.20769\n",
            "vaild Loss: 0.63712 Acc: 85.35826 macro-f1: 0.19953\n",
            "each epochs training time : 151m 29s\n",
            "\n",
            "\n",
            "Epoch 98/100\n",
            "----------\n",
            "train Loss: 0.61322 Acc: 85.66656 macro-f1: 0.21082\n",
            "vaild Loss: 0.64967 Acc: 85.28037 macro-f1: 0.20175\n",
            "each epochs training time : 153m 2s\n",
            "\n",
            "\n",
            "Epoch 99/100\n",
            "----------\n",
            "train Loss: 0.62121 Acc: 85.56632 macro-f1: 0.20441\n",
            "vaild Loss: 0.64280 Acc: 85.43614 macro-f1: 0.20015\n",
            "each epochs training time : 154m 35s\n",
            "\n",
            "\n",
            "Training complete in 154m 35s\n",
            "Best valid Acc: 95 - 85.7\n",
            "model saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 결과 그래프 그리기\n",
        "print('best model : %d - %1.f / %.1f'%(best_idx, valid_acc[best_idx], valid_loss[best_idx]))\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(train_acc, 'b-')\n",
        "ax1.plot(valid_acc, 'r-')\n",
        "plt.plot(best_idx, valid_acc[best_idx], 'ro')\n",
        "ax1.set_xlabel('epoch')\n",
        "# Make the y-axis label, ticks and tick labels match the line color.\n",
        "ax1.set_ylabel('acc', color='k')\n",
        "ax1.tick_params('y', colors='k')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(train_loss, 'g-')\n",
        "ax2.plot(valid_loss, 'k-')\n",
        "plt.plot(best_idx, valid_loss[best_idx], 'ro')\n",
        "ax2.set_ylabel('loss', color='k')\n",
        "ax2.tick_params('y', colors='k')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "5kJPLUuEU1pH",
        "outputId": "43107801-7e40-43b7-e7bf-ba1b98dfd42f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best model : 95 - 86 / 0.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-o1YRRNYU1zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 추론"
      ],
      "metadata": {
        "id": "WQR1RKgTpKk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 모델을 평가 모드로 변경하고 test 데이터 분류\n",
        "test_png = sorted(glob('/content/drive/Othercomputers/내 MacBook Pro/open/test/*.png'))\n",
        "test_imgs = [img_load(n) for n in tqdm(test_png)]\n",
        "test_dataset = Custom_dataset_3(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "model.eval()\n",
        "f_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in (test_loader):\n",
        "        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            pred = model(x)\n",
        "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
      ],
      "metadata": {
        "id": "gj7gTQv6U11P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "805338ba-6fb4-41aa-ac5d-a8ef5312961f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2154/2154 [01:04<00:00, 33.40it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 숫자로된 레이블을 문자열 레이블로 변경\n",
        "label_decoder = {value:key for key, value in label_unique.items()}\n",
        "f_result = [label_decoder[result] for result in f_pred]"
      ],
      "metadata": {
        "id": "30_rcMw4U13G"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime as dt \n",
        "today = dt.today().strftime('%Y-%m-%d')\n",
        "version = f'efficientNet_b4_sam_by_timm_data_ver1_{today}'\n",
        "submission = pd.read_csv(f\"/content/drive/MyDrive/DACON_이상치 탐지 알고리즘 경진대회/open/sample_submission.csv\")\n",
        "\n",
        "## 시각적 확인을 위해 문자열 레이블로 이루어진 된 label 필드 생성\n",
        "submission[\"label\"] = f_result\n",
        "display(submission)\n",
        "submission.to_csv(f\"/content/drive/MyDrive/DACON_이상치 탐지 알고리즘 경진대회/open/sample_submission_{version}.csv\", index = False)"
      ],
      "metadata": {
        "id": "1zWu-D7WdRmQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "7889b8c7-fbc5-40de-ab89-eb602f1455dd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      index            label\n",
              "0         0        tile-good\n",
              "1         1        grid-good\n",
              "2         2  transistor-good\n",
              "3         3        tile-good\n",
              "4         4        tile-good\n",
              "...     ...              ...\n",
              "2149   2149        tile-good\n",
              "2150   2150       screw-good\n",
              "2151   2151        grid-good\n",
              "2152   2152       cable-good\n",
              "2153   2153      zipper-good\n",
              "\n",
              "[2154 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d78db8bc-d9b8-4710-90d2-f3be1e41e081\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>tile-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>grid-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>transistor-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>tile-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>tile-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2149</th>\n",
              "      <td>2149</td>\n",
              "      <td>tile-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2150</th>\n",
              "      <td>2150</td>\n",
              "      <td>screw-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2151</th>\n",
              "      <td>2151</td>\n",
              "      <td>grid-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2152</th>\n",
              "      <td>2152</td>\n",
              "      <td>cable-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2153</th>\n",
              "      <td>2153</td>\n",
              "      <td>zipper-good</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2154 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d78db8bc-d9b8-4710-90d2-f3be1e41e081')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d78db8bc-d9b8-4710-90d2-f3be1e41e081 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d78db8bc-d9b8-4710-90d2-f3be1e41e081');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 저장\n",
        "model_version = f'efficientNet_b4_sam_data_ver1_{today}'\n",
        "torch.save(model.state_dict(), f'/content/drive/MyDrive/DACON_이상치 탐지 알고리즘 경진대회/open/{model_version}.pt')"
      ],
      "metadata": {
        "id": "cG_tNWs2zxh8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "l7fjAkYDOYse"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}