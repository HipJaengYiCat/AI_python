{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNet2_MVtecAD_Dataset",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seunghee0518/AI_python/blob/main/EfficientNet2_SAMagulentationMVtecAD_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## trina/ test 나눠서 학습"
      ],
      "metadata": {
        "id": "lynhGDxilbRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "torch.hub : Pytorch Hub는 연구 재현성을 촉진하도록 설계된 사전 훈련 된 모델 저장소\n",
        "nvidia_efficientnet_b4 사전 모델 가져옴\n",
        "'''\n",
        "# import torch\n",
        "# model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b4', pretrained=True)\n",
        "!pip install timm\n",
        "import timm\n",
        "model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=88)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ-ytfDpoKMH",
        "outputId": "7cbc45d0-a789-44fb-8d4c-3b2510809419"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 37.5 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 51 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 61 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 102 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 112 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 122 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 153 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 163 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 174 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 184 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 194 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 204 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 215 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 225 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 235 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 245 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 256 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 266 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 276 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 286 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 307 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 317 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 327 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 348 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 358 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 368 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 378 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 389 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 399 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 409 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 419 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 430 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 431 kB 15.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.12.0+cu113)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2021.10.8)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.5.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b4_ra2_320-7eb33cd5.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b4_ra2_320-7eb33cd5.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from pprint import pprint\n",
        "# model_names = timm.list_models(pretrained=True)\n",
        "# pprint(model_names)"
      ],
      "metadata": {
        "id": "invECZxkPTyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKXv22Yk6zus",
        "outputId": "9c8b0af9-e290-469e-cdc2-b20cf2e39780"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 학습 코드\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "#import timm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import transforms, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "from PIL import Image\n",
        "# from efficientnet_pytorch import EfficientNet\n",
        "# model_name = 'efficientnet-b0'  # b5\n",
        "\n",
        "# image_size = EfficientNet.get_image_size(model_name)\n",
        "# print(image_size)\n",
        "# model = EfficientNet.from_pretrained(model_name, num_classes=88)"
      ],
      "metadata": {
        "id": "Gjs-R_R5lUKg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 기본 설정\n",
        "device = torch.device('cuda')\n",
        "batch_size  = 32\n",
        "random_seed = 1234\n",
        "img_size = 224\n",
        "random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZHMCtAvlDOp",
        "outputId": "9f37f5ed-10fe-4dfb-9805-7e32b7d2852c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7feee6632970>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## transforms 함수 정리\n",
        "* transforms.ToPILImage() - csv 파일로 데이터셋을 받을 경우, PIL image로 바꿔준다.\n",
        "* transforms.CenterCrop(size) - 가운데 부분을 size 크기로 자른다.\n",
        "* transforms.Grayscale(num_output_channels=1) - grayscale로 변환한다.\n",
        "* transforms.RandomAffine(degrees) - 랜덤으로 affine 변형을 한다.\n",
        "* transforms.RandomCrop(size) -이미지를 랜덤으로 아무데나 잘라 size 크기로 출력한다.\n",
        "* transforms.RandomResizedCrop(size) - 이미지 사이즈를 size로 변경한다\n",
        "* transforms.Resize(size) - 이미지 사이즈를 size로 변경한다\n",
        "* transforms.RandomRotation(degrees) 이미지를 랜덤으로 degrees 각도로 회전한다.\n",
        "* transforms.RandomResizedCrop(size, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333)) - 이미지를 랜덤으로 변형한다.\n",
        "* transforms.RandomVerticalFlip(p=0.5) - 이미지를 랜덤으로 수직으로 뒤집는다. p =0이면 뒤집지 않는다.\n",
        "* transforms.RandomHorizontalFlip(p=0.5) - 이미지를 랜덤으로 수평으로 뒤집는다.\n",
        "* transforms.ToTensor() - 이미지 데이터를 tensor로 바꿔준다.\n",
        "* transforms.Normalize(mean, std, inplace=False) - 이미지를 정규화한다."
      ],
      "metadata": {
        "id": "fTgH3bYzN7RA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 데이터 전처리 함수\n",
        "# make dataset\n",
        "#data_path = 'president/president_data'  # class 별 폴더로 나누어진 걸 가져와서 라벨도 달아준다\n",
        "# train_dataset = datasets.ImageFolder(data_path,\n",
        "#                                      transforms.Compose([\n",
        "#                                      transforms.Resize((224, 224)),\n",
        "#                                      transforms.RandomCrop(224),\n",
        "#                                      transforms.RandomRotation(90, expand=True),\n",
        "#                                      transforms.RandomVerticalFlip(),\n",
        "#                                      transforms.RandomHorizontalFlip(),\n",
        "#                                      transforms.ToTensor(), # 이미지 데이터를 tensor로 바꿔준다.\n",
        "#                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])) # Normalize는 많은 이미지의 평균, 표준편차로 정함(보통 많이 하는 값이라고함)\n",
        "\n",
        "\n",
        "### 이미지 전처리 함수 & 클래스\n",
        "## 이미지  > 넘파이 배열로 변환\n",
        "def img_load(path):\n",
        "    img = cv2.imread(path)[:,:,::-1] # Return type:\tnumpy.ndarray / 기본적으로 BGR로 불러옴, RGB 변환함\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    return img\n",
        "\n",
        "class Custom_dataset_1(Dataset): # 기본\n",
        "    def __init__(self, img_paths, labels, mode='train'):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode = mode\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.img_paths[idx]\n",
        "        img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "        img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "        ## 레이블 > 원-핫 인코딩 하기 \n",
        "        label = self.labels[idx]# (원핫인코딩 안할거면 해당 코드만 필요)\n",
        "        return img, label\n",
        "\n",
        "class Custom_dataset_2(Dataset): # 변형\n",
        "    def __init__(self, img_paths, labels, mode='train'):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode = mode\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.img_paths[idx]\n",
        "        if self.mode == 'train':\n",
        "          img = Image.fromarray(img)\n",
        "          #img = transforms.Resize((img_size, img_size))(img) # 처음 이미지 불러올때 resize 했으므로 생략\n",
        "          #img = transforms.RandomCrop(img_size)(img)\n",
        "          img = transforms.RandomRotation(90, expand=False)(img)\n",
        "          img = transforms.RandomVerticalFlip()(img)\n",
        "          img = transforms.RandomHorizontalFlip()(img)\n",
        "          img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "          img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "        if self.mode=='test':\n",
        "          img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "          img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "        ## 레이블\n",
        "        label = self.labels[idx]# (원핫인코딩 안할거면 해당 코드만 필요)\n",
        "        return img, label\n",
        "\n",
        "class Custom_dataset_3(Dataset): # 기본이미지 + 변형이미지 (train 시 2배 증량됨)\n",
        "    def __init__(self, img_paths, labels, mode='train'):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode=mode\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.mode=='train':\n",
        "          if idx < 4277: # 변경 없는 이미지\n",
        "            img = self.img_paths[idx]\n",
        "            img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "            img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "            label = self.labels[idx]\n",
        "            return img, label\n",
        "\n",
        "          else : # 랜덤 변경된 이미지 추가됨 \n",
        "            img = self.img_paths[idx]\n",
        "            img = Image.fromarray(img)\n",
        "            #img = transforms.Resize((img_size, img_size))(img) # 처음 이미지 불러올때 resize 했으므로 생략\n",
        "            #img = transforms.RandomCrop(img_size)(img)\n",
        "            img = transforms.RandomRotation(90, expand=False)(img)\n",
        "            img = transforms.RandomVerticalFlip()(img)\n",
        "            img = transforms.RandomHorizontalFlip()(img)\n",
        "            img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "            img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "            label = self.labels[idx]\n",
        "            return img, label\n",
        "\n",
        "        if self.mode=='test':\n",
        "          img = self.img_paths[idx]\n",
        "          img = transforms.ToTensor()(img)\n",
        "          img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "          label = self.labels[idx]\n",
        "          return img, label\n",
        "\n",
        "class SAM(torch.optim.Optimizer):\n",
        "    def __init__(self, params, base_optimizer, rho=0.05, **kwargs):\n",
        "        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n",
        "\n",
        "        defaults = dict(rho=rho, **kwargs)\n",
        "        super(SAM, self).__init__(params, defaults)\n",
        "\n",
        "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
        "        self.param_groups = self.base_optimizer.param_groups\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def first_step(self, zero_grad=False):\n",
        "        grad_norm = self._grad_norm()\n",
        "        for group in self.param_groups:\n",
        "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
        "\n",
        "            for p in group[\"params\"]:\n",
        "                if p.grad is None: continue\n",
        "                e_w = p.grad * scale.to(p)\n",
        "                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n",
        "                self.state[p][\"e_w\"] = e_w\n",
        "\n",
        "        if zero_grad: self.zero_grad()\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def second_step(self, zero_grad=False):\n",
        "        for group in self.param_groups:\n",
        "            for p in group[\"params\"]:\n",
        "                if p.grad is None: continue\n",
        "                p.sub_(self.state[p][\"e_w\"])  # get back to \"w\" from \"w + e(w)\"\n",
        "\n",
        "        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n",
        "\n",
        "        if zero_grad: self.zero_grad()\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure=None):\n",
        "        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n",
        "        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n",
        "\n",
        "        self.first_step(zero_grad=True)\n",
        "        closure()\n",
        "        self.second_step()\n",
        "\n",
        "    def _grad_norm(self):\n",
        "        shared_device = self.param_groups[0][\"params\"][0].device  # put everything on the same device, in case of model parallelism\n",
        "        norm = torch.norm(\n",
        "                    torch.stack([\n",
        "                        p.grad.norm(p=2).to(shared_device)\n",
        "                        for group in self.param_groups for p in group[\"params\"]\n",
        "                        if p.grad is not None\n",
        "                    ]),\n",
        "                    p=2\n",
        "               )\n",
        "        return norm"
      ],
      "metadata": {
        "id": "ORqFbwLXpSeu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 이미지 로드 및 전처리\n",
        "# 이미지 경로\n",
        "train_png = sorted(glob('/content/drive/Othercomputers/내 MacBook Pro/open/train/*.png'))\n",
        "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
        "\n",
        "#train_imgs = np.load('/content/drive/MyDrive/DACON_이상치 탐지 알고리즘 경진대회/train_imgs_224.npy')\n",
        "train_y = pd.read_csv(\"/content/drive/Othercomputers/내 MacBook Pro/open/train_df.csv\")\n",
        "\n",
        "train_labels = train_y[\"label\"] # 레이블순서는 이미지 파일 순서대로임\n",
        "\n",
        "label_unique = sorted(np.unique(train_labels))\n",
        "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))} # 오름차순으로 레이블별로 숫자 부여(0부터 시작)\n",
        "\n",
        "train_labels = [label_unique[k] for k in train_labels]\n",
        "\n",
        "# 커스텀 이미지 생성\n",
        "train_dataset = Custom_dataset_2(np.array(train_imgs), np.array(train_labels), mode='train')\n",
        "train_idx, vaild_idx = train_test_split(list(range(len(train_dataset))), stratify=train_labels, test_size=0.3, random_state=random_seed)\n",
        "\n",
        "# ## 이미지 증량 시만 사용\n",
        "# train_imgs = train_imgs + train_imgs\n",
        "# train_labels = train_labels+train_labels\n",
        "\n",
        "# train_dataset = Custom_dataset_3(np.array(train_imgs), np.array(train_labels), mode='train')\n",
        "\n",
        "### 데이터셋 분리 > 층화추출 & 테스터 데이터 비율 : 0.3, 시드 : 1234, 셔플 = True(default)\n",
        "train_idx, vaild_idx = train_test_split(list(range(len(train_dataset))), stratify=train_labels, test_size=0.3, random_state=random_seed)\n",
        "\n",
        "datasets = {} # 데이터셋을 담을 딕셔너리\n",
        "datasets['train'] = Subset(train_dataset, train_idx)\n",
        "datasets['vaild']  = Subset(train_dataset, vaild_idx)\n",
        "\n",
        "## data loader 선언\n",
        "dataloaders, batch_num = {}, {}\n",
        "dataloaders['train'] = torch.utils.data.DataLoader(datasets['train'],\n",
        "                                                  batch_size=batch_size, shuffle=True,\n",
        "                                                  num_workers=0)\n",
        "dataloaders['vaild']  = torch.utils.data.DataLoader(datasets['vaild'],\n",
        "                                                    batch_size=batch_size, shuffle=False,\n",
        "                                                    num_workers=0)\n",
        "'''\n",
        "데이터 변형 코드를 추가한 후 아래 오류코드가 나와\n",
        "Caught TypeError in DataLoader worker process 0\n",
        "DataLoader > num_workers 를 4 -> 0 로 낮춤\n",
        "'''\n",
        "\n",
        "batch_num['train'], batch_num['vaild'] = len(dataloaders['train']), len(dataloaders['vaild'])\n",
        "print('batch_size : %d,  train/vaild(데이터셋개수/배치사이즈) : %d / %d' % (batch_size, batch_num['train'],batch_num['vaild']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItvLP1Y3k-OW",
        "outputId": "d0e195cd-1299-43d5-cc89-47f9a0446b2c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4277/4277 [05:12<00:00, 13.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_size : 32,  train/vaild(데이터셋개수/배치사이즈) : 94 / 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 참고 블로그 : https://keep-steady.tistory.com/35\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "### f1 스코어 함수 \n",
        "def score_function(real, pred): # 라이브러리 > sklearn.metrics \n",
        "    score = f1_score(real, pred, average=\"macro\")\n",
        "    return score\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    #train_loss, train_acc, valid_loss, valid_acc = [], [], [], []\n",
        "    train_loss, train_acc, valid_loss, valid_acc, train_f1, valid_f1 = [], [], [], [], [], []\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))# - 1))\n",
        "        print('-' * 10)\n",
        "        train_pred=[]# 이거 추가 : f1스코어 계산\n",
        "        train_y=[]#이거 추가\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'vaild']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
        "            \n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device) # device = torch.device('cuda')\n",
        "                labels = labels.to(device) # device = torch.device('cuda')\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # # backward + optimize only if in training phase\n",
        "                    # if phase == 'train':\n",
        "                    #     loss.backward()\n",
        "                    #     optimizer.step()\n",
        "\n",
        "                    # backward + optimize only if in training phase + sam\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.first_step(zero_grad=True)\n",
        "                        criterion(model(inputs), labels).backward()\n",
        "                        optimizer.second_step(zero_grad=True)\n",
        "\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                num_cnt += len(labels)\n",
        "\n",
        "                train_pred += preds.detach().cpu().numpy().tolist() #이거 추가\n",
        "                train_y += labels.detach().cpu().data.numpy().tolist() #이거 추가\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "            \n",
        "            epoch_loss = float(running_loss / num_cnt)\n",
        "            epoch_acc  = float((running_corrects.double() / num_cnt).cpu()*100)\n",
        "            f1 = score_function(train_y,  train_pred) # score_function or f1_score\n",
        "\n",
        "            if phase == 'train':\n",
        "                train_loss.append(epoch_loss)\n",
        "                train_acc.append(epoch_acc)\n",
        "                train_f1.append(f1)\n",
        "            else:\n",
        "                valid_loss.append(epoch_loss)\n",
        "                valid_acc.append(epoch_acc)\n",
        "                valid_f1.append(f1)\n",
        "\n",
        "            print('{} Loss: {:.5f} Acc: {:.5f} macro-f1: {:.5f}'.format(phase, epoch_loss, epoch_acc, f1))\n",
        "           \n",
        "            # deep copy the model(최적모델 저장)\n",
        "            if phase == 'vaild' and epoch_acc > best_acc:\n",
        "                best_idx = epoch\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "#                 best_model_wts = copy.deepcopy(model.module.state_dict())\n",
        "                print('==> best model saved - %d / %.1f'%(best_idx, best_acc))\n",
        "        # 한 에포크마다 실행 시간 출력하기(누적 시간으로 출력됨)\n",
        "        time_elapsed = time.time() - since\n",
        "        print('each epochs training time : {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "        print('\\n')\n",
        "\n",
        "        # 한 에포크마다 필요없는 메모리 지우기 : 지우기 효과는 아직 확인 못해봄\n",
        "        try:      \n",
        "          gc.collect() # cpu 비움\n",
        "          torch.cuda.empty_cache() # gpu 비움\n",
        "        except:\n",
        "          pass\n",
        "          \n",
        "    ## 학습 마무리 후\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best valid Acc: %d - %.1f' %(best_idx, best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    '''\n",
        "    한 에포크 마다 저장된 최적의 모델 가중치로 조정 후 다음 에포크가 돌아감\n",
        "    '''\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    torch.save(model.state_dict(), 'president_model.pt')\n",
        "    print('model saved')\n",
        "    return model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc, train_f1, valid_f1\n",
        "\n",
        "# 설정\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # set gpu\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer_ft = optim.SGD(model.parameters(), \n",
        "#                          lr = 0.05,\n",
        "#                          momentum=0.9,\n",
        "#                          weight_decay=1e-4)\n",
        "\n",
        "# lmbda = lambda epoch: 0.98739\n",
        "# exp_lr_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer_ft, lr_lambda=lmbda)\n",
        "\n",
        "## 변경된 옵티마이저\n",
        "base_optimizer = torch.optim.SGD\n",
        "optimizer_ft = SAM(model.parameters(), base_optimizer, lr=0.001, momentum=0.9)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer_ft,\n",
        "                                                step_size = 5,\n",
        "                                                gamma = 0.75)\n",
        "\n",
        "\n",
        "\n",
        "# 사전학습된 가중치와 모델을 가져와 데이터셋으로 추가 모델 학습\n",
        "model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc, train_f1, valid_f1 = train_model(model, criterion, optimizer_ft, lr_scheduler, num_epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDNj4Yarkx-R",
        "outputId": "db0ba234-f213-4de1-89d6-a32ee6257e56"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/100\n",
            "----------\n",
            "train Loss: 4.31967 Acc: 8.88740 macro-f1: 0.02231\n",
            "vaild Loss: 4.00082 Acc: 30.06231 macro-f1: 0.03434\n",
            "==> best model saved - 0 / 30.1\n",
            "each epochs training time : 1m 30s\n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "----------\n",
            "train Loss: 3.63072 Acc: 55.86368 macro-f1: 0.10599\n",
            "vaild Loss: 3.22842 Acc: 71.80685 macro-f1: 0.11291\n",
            "==> best model saved - 1 / 71.8\n",
            "each epochs training time : 3m 2s\n",
            "\n",
            "\n",
            "Epoch 2/100\n",
            "----------\n",
            "train Loss: 2.66425 Acc: 76.47845 macro-f1: 0.13288\n",
            "vaild Loss: 1.95632 Acc: 80.91900 macro-f1: 0.13521\n",
            "==> best model saved - 2 / 80.9\n",
            "each epochs training time : 4m 35s\n",
            "\n",
            "\n",
            "Epoch 3/100\n",
            "----------\n",
            "train Loss: 1.55268 Acc: 82.52589 macro-f1: 0.14352\n",
            "vaild Loss: 1.35303 Acc: 83.72274 macro-f1: 0.14531\n",
            "==> best model saved - 3 / 83.7\n",
            "each epochs training time : 6m 9s\n",
            "\n",
            "\n",
            "Epoch 4/100\n",
            "----------\n",
            "train Loss: 1.30713 Acc: 84.29669 macro-f1: 0.15363\n",
            "vaild Loss: 1.22737 Acc: 84.65732 macro-f1: 0.15428\n",
            "==> best model saved - 4 / 84.7\n",
            "each epochs training time : 7m 44s\n",
            "\n",
            "\n",
            "Epoch 5/100\n",
            "----------\n",
            "train Loss: 1.20141 Acc: 84.79786 macro-f1: 0.15569\n",
            "vaild Loss: 1.12435 Acc: 84.73520 macro-f1: 0.15575\n",
            "==> best model saved - 5 / 84.7\n",
            "each epochs training time : 9m 19s\n",
            "\n",
            "\n",
            "Epoch 6/100\n",
            "----------\n",
            "train Loss: 1.14061 Acc: 84.79786 macro-f1: 0.15571\n",
            "vaild Loss: 1.09083 Acc: 84.81308 macro-f1: 0.15588\n",
            "==> best model saved - 6 / 84.8\n",
            "each epochs training time : 10m 54s\n",
            "\n",
            "\n",
            "Epoch 7/100\n",
            "----------\n",
            "train Loss: 1.09686 Acc: 84.83127 macro-f1: 0.15589\n",
            "vaild Loss: 1.03911 Acc: 84.81308 macro-f1: 0.15600\n",
            "each epochs training time : 12m 29s\n",
            "\n",
            "\n",
            "Epoch 8/100\n",
            "----------\n",
            "train Loss: 1.04712 Acc: 84.76445 macro-f1: 0.15561\n",
            "vaild Loss: 1.02092 Acc: 84.81308 macro-f1: 0.15580\n",
            "each epochs training time : 14m 4s\n",
            "\n",
            "\n",
            "Epoch 9/100\n",
            "----------\n",
            "train Loss: 1.01992 Acc: 84.76445 macro-f1: 0.15562\n",
            "vaild Loss: 0.97739 Acc: 84.81308 macro-f1: 0.15581\n",
            "each epochs training time : 15m 39s\n",
            "\n",
            "\n",
            "Epoch 10/100\n",
            "----------\n",
            "train Loss: 1.00050 Acc: 84.79786 macro-f1: 0.15577\n",
            "vaild Loss: 0.95194 Acc: 84.81308 macro-f1: 0.15592\n",
            "each epochs training time : 17m 14s\n",
            "\n",
            "\n",
            "Epoch 11/100\n",
            "----------\n",
            "train Loss: 0.98917 Acc: 84.83127 macro-f1: 0.15599\n",
            "vaild Loss: 0.94461 Acc: 84.81308 macro-f1: 0.15608\n",
            "each epochs training time : 18m 49s\n",
            "\n",
            "\n",
            "Epoch 12/100\n",
            "----------\n",
            "train Loss: 0.95592 Acc: 84.79786 macro-f1: 0.15586\n",
            "vaild Loss: 0.93028 Acc: 84.81308 macro-f1: 0.15598\n",
            "each epochs training time : 20m 24s\n",
            "\n",
            "\n",
            "Epoch 13/100\n",
            "----------\n",
            "train Loss: 0.92679 Acc: 84.86468 macro-f1: 0.15596\n",
            "vaild Loss: 0.89319 Acc: 84.81308 macro-f1: 0.15605\n",
            "each epochs training time : 21m 59s\n",
            "\n",
            "\n",
            "Epoch 14/100\n",
            "----------\n",
            "train Loss: 0.91306 Acc: 84.86468 macro-f1: 0.15595\n",
            "vaild Loss: 0.88570 Acc: 84.81308 macro-f1: 0.15606\n",
            "each epochs training time : 23m 35s\n",
            "\n",
            "\n",
            "Epoch 15/100\n",
            "----------\n",
            "train Loss: 0.90390 Acc: 84.89810 macro-f1: 0.15972\n",
            "vaild Loss: 0.86296 Acc: 84.81308 macro-f1: 0.15893\n",
            "each epochs training time : 25m 9s\n",
            "\n",
            "\n",
            "Epoch 16/100\n",
            "----------\n",
            "train Loss: 0.88408 Acc: 84.89810 macro-f1: 0.16051\n",
            "vaild Loss: 0.85845 Acc: 84.81308 macro-f1: 0.15932\n",
            "each epochs training time : 26m 44s\n",
            "\n",
            "\n",
            "Epoch 17/100\n",
            "----------\n",
            "train Loss: 0.88565 Acc: 84.89810 macro-f1: 0.16122\n",
            "vaild Loss: 0.84881 Acc: 84.81308 macro-f1: 0.15983\n",
            "each epochs training time : 28m 19s\n",
            "\n",
            "\n",
            "Epoch 18/100\n",
            "----------\n",
            "train Loss: 0.87838 Acc: 84.93151 macro-f1: 0.16053\n",
            "vaild Loss: 0.84580 Acc: 84.81308 macro-f1: 0.15933\n",
            "each epochs training time : 29m 54s\n",
            "\n",
            "\n",
            "Epoch 19/100\n",
            "----------\n",
            "train Loss: 0.84556 Acc: 84.83127 macro-f1: 0.15584\n",
            "vaild Loss: 0.83552 Acc: 84.81308 macro-f1: 0.15596\n",
            "each epochs training time : 31m 29s\n",
            "\n",
            "\n",
            "Epoch 20/100\n",
            "----------\n",
            "train Loss: 0.83961 Acc: 84.86468 macro-f1: 0.15906\n",
            "vaild Loss: 0.80875 Acc: 84.81308 macro-f1: 0.15850\n",
            "each epochs training time : 33m 5s\n",
            "\n",
            "\n",
            "Epoch 21/100\n",
            "----------\n",
            "train Loss: 0.82668 Acc: 84.79786 macro-f1: 0.15594\n",
            "vaild Loss: 0.80472 Acc: 84.81308 macro-f1: 0.15604\n",
            "each epochs training time : 34m 40s\n",
            "\n",
            "\n",
            "Epoch 22/100\n",
            "----------\n",
            "train Loss: 0.82662 Acc: 84.83127 macro-f1: 0.15592\n",
            "vaild Loss: 0.80907 Acc: 84.89097 macro-f1: 0.15744\n",
            "==> best model saved - 22 / 84.9\n",
            "each epochs training time : 36m 15s\n",
            "\n",
            "\n",
            "Epoch 23/100\n",
            "----------\n",
            "train Loss: 0.81547 Acc: 84.93151 macro-f1: 0.16109\n",
            "vaild Loss: 0.79426 Acc: 84.96885 macro-f1: 0.16371\n",
            "==> best model saved - 23 / 85.0\n",
            "each epochs training time : 37m 51s\n",
            "\n",
            "\n",
            "Epoch 24/100\n",
            "----------\n",
            "train Loss: 0.80803 Acc: 84.83127 macro-f1: 0.15577\n",
            "vaild Loss: 0.78738 Acc: 84.89097 macro-f1: 0.15800\n",
            "each epochs training time : 39m 27s\n",
            "\n",
            "\n",
            "Epoch 25/100\n",
            "----------\n",
            "train Loss: 0.80456 Acc: 84.93151 macro-f1: 0.16455\n",
            "vaild Loss: 0.78971 Acc: 84.81308 macro-f1: 0.16212\n",
            "each epochs training time : 41m 3s\n",
            "\n",
            "\n",
            "Epoch 26/100\n",
            "----------\n",
            "train Loss: 0.79251 Acc: 84.93151 macro-f1: 0.16528\n",
            "vaild Loss: 0.77760 Acc: 84.96885 macro-f1: 0.16591\n",
            "each epochs training time : 42m 39s\n",
            "\n",
            "\n",
            "Epoch 27/100\n",
            "----------\n",
            "train Loss: 0.79297 Acc: 84.79786 macro-f1: 0.15744\n",
            "vaild Loss: 0.77668 Acc: 84.73520 macro-f1: 0.15707\n",
            "each epochs training time : 44m 15s\n",
            "\n",
            "\n",
            "Epoch 28/100\n",
            "----------\n",
            "train Loss: 0.78538 Acc: 84.89810 macro-f1: 0.16171\n",
            "vaild Loss: 0.74926 Acc: 84.96885 macro-f1: 0.16317\n",
            "each epochs training time : 45m 52s\n",
            "\n",
            "\n",
            "Epoch 29/100\n",
            "----------\n",
            "train Loss: 0.78035 Acc: 84.89810 macro-f1: 0.16551\n",
            "vaild Loss: 0.74493 Acc: 84.89097 macro-f1: 0.16585\n",
            "each epochs training time : 47m 28s\n",
            "\n",
            "\n",
            "Epoch 30/100\n",
            "----------\n",
            "train Loss: 0.77400 Acc: 84.96492 macro-f1: 0.16297\n",
            "vaild Loss: 0.73798 Acc: 84.81308 macro-f1: 0.16320\n",
            "each epochs training time : 49m 4s\n",
            "\n",
            "\n",
            "Epoch 31/100\n",
            "----------\n",
            "train Loss: 0.76599 Acc: 85.03174 macro-f1: 0.17108\n",
            "vaild Loss: 0.74545 Acc: 84.89097 macro-f1: 0.16841\n",
            "each epochs training time : 50m 40s\n",
            "\n",
            "\n",
            "Epoch 32/100\n",
            "----------\n",
            "train Loss: 0.78750 Acc: 84.96492 macro-f1: 0.16850\n",
            "vaild Loss: 0.74443 Acc: 84.73520 macro-f1: 0.16509\n",
            "each epochs training time : 52m 16s\n",
            "\n",
            "\n",
            "Epoch 33/100\n",
            "----------\n",
            "train Loss: 0.77350 Acc: 84.96492 macro-f1: 0.16978\n",
            "vaild Loss: 0.74513 Acc: 84.81308 macro-f1: 0.16857\n",
            "each epochs training time : 53m 52s\n",
            "\n",
            "\n",
            "Epoch 34/100\n",
            "----------\n",
            "train Loss: 0.76396 Acc: 85.06515 macro-f1: 0.17112\n",
            "vaild Loss: 0.72655 Acc: 85.04673 macro-f1: 0.17183\n",
            "==> best model saved - 34 / 85.0\n",
            "each epochs training time : 55m 28s\n",
            "\n",
            "\n",
            "Epoch 35/100\n",
            "----------\n",
            "train Loss: 0.75704 Acc: 85.06515 macro-f1: 0.17393\n",
            "vaild Loss: 0.74026 Acc: 84.89097 macro-f1: 0.17294\n",
            "each epochs training time : 57m 5s\n",
            "\n",
            "\n",
            "Epoch 36/100\n",
            "----------\n",
            "train Loss: 0.74295 Acc: 85.03174 macro-f1: 0.17148\n",
            "vaild Loss: 0.73768 Acc: 85.04673 macro-f1: 0.17153\n",
            "each epochs training time : 58m 41s\n",
            "\n",
            "\n",
            "Epoch 37/100\n",
            "----------\n",
            "train Loss: 0.74245 Acc: 85.03174 macro-f1: 0.16677\n",
            "vaild Loss: 0.72318 Acc: 85.20249 macro-f1: 0.17336\n",
            "==> best model saved - 37 / 85.2\n",
            "each epochs training time : 60m 17s\n",
            "\n",
            "\n",
            "Epoch 38/100\n",
            "----------\n",
            "train Loss: 0.76009 Acc: 85.13197 macro-f1: 0.17553\n",
            "vaild Loss: 0.73033 Acc: 85.04673 macro-f1: 0.17433\n",
            "each epochs training time : 61m 53s\n",
            "\n",
            "\n",
            "Epoch 39/100\n",
            "----------\n",
            "train Loss: 0.74793 Acc: 85.06515 macro-f1: 0.16951\n",
            "vaild Loss: 0.72219 Acc: 84.96885 macro-f1: 0.16939\n",
            "each epochs training time : 63m 30s\n",
            "\n",
            "\n",
            "Epoch 40/100\n",
            "----------\n",
            "train Loss: 0.73684 Acc: 84.93151 macro-f1: 0.16821\n",
            "vaild Loss: 0.72012 Acc: 85.12461 macro-f1: 0.17133\n",
            "each epochs training time : 65m 6s\n",
            "\n",
            "\n",
            "Epoch 41/100\n",
            "----------\n",
            "train Loss: 0.74100 Acc: 85.13197 macro-f1: 0.17686\n",
            "vaild Loss: 0.72549 Acc: 84.96885 macro-f1: 0.17465\n",
            "each epochs training time : 66m 42s\n",
            "\n",
            "\n",
            "Epoch 42/100\n",
            "----------\n",
            "train Loss: 0.72005 Acc: 85.16539 macro-f1: 0.18193\n",
            "vaild Loss: 0.70810 Acc: 85.35826 macro-f1: 0.18699\n",
            "==> best model saved - 42 / 85.4\n",
            "each epochs training time : 68m 19s\n",
            "\n",
            "\n",
            "Epoch 43/100\n",
            "----------\n",
            "train Loss: 0.74452 Acc: 85.16539 macro-f1: 0.17926\n",
            "vaild Loss: 0.71997 Acc: 84.96885 macro-f1: 0.17621\n",
            "each epochs training time : 69m 55s\n",
            "\n",
            "\n",
            "Epoch 44/100\n",
            "----------\n",
            "train Loss: 0.72292 Acc: 85.06515 macro-f1: 0.17924\n",
            "vaild Loss: 0.70369 Acc: 85.04673 macro-f1: 0.17749\n",
            "each epochs training time : 71m 31s\n",
            "\n",
            "\n",
            "Epoch 45/100\n",
            "----------\n",
            "train Loss: 0.72090 Acc: 85.16539 macro-f1: 0.17699\n",
            "vaild Loss: 0.70677 Acc: 85.04673 macro-f1: 0.17752\n",
            "each epochs training time : 73m 7s\n",
            "\n",
            "\n",
            "Epoch 46/100\n",
            "----------\n",
            "train Loss: 0.73428 Acc: 85.09856 macro-f1: 0.17816\n",
            "vaild Loss: 0.70924 Acc: 84.96885 macro-f1: 0.17491\n",
            "each epochs training time : 74m 43s\n",
            "\n",
            "\n",
            "Epoch 47/100\n",
            "----------\n",
            "train Loss: 0.73431 Acc: 85.13197 macro-f1: 0.18010\n",
            "vaild Loss: 0.69962 Acc: 85.04673 macro-f1: 0.17774\n",
            "each epochs training time : 76m 20s\n",
            "\n",
            "\n",
            "Epoch 48/100\n",
            "----------\n",
            "train Loss: 0.73051 Acc: 85.09856 macro-f1: 0.17449\n",
            "vaild Loss: 0.70026 Acc: 84.96885 macro-f1: 0.17384\n",
            "each epochs training time : 77m 56s\n",
            "\n",
            "\n",
            "Epoch 49/100\n",
            "----------\n",
            "train Loss: 0.71685 Acc: 85.13197 macro-f1: 0.17602\n",
            "vaild Loss: 0.69981 Acc: 85.28037 macro-f1: 0.17781\n",
            "each epochs training time : 79m 32s\n",
            "\n",
            "\n",
            "Epoch 50/100\n",
            "----------\n",
            "train Loss: 0.72934 Acc: 85.23221 macro-f1: 0.18473\n",
            "vaild Loss: 0.69622 Acc: 85.35826 macro-f1: 0.18689\n",
            "each epochs training time : 81m 8s\n",
            "\n",
            "\n",
            "Epoch 51/100\n",
            "----------\n",
            "train Loss: 0.71805 Acc: 85.19880 macro-f1: 0.17766\n",
            "vaild Loss: 0.69733 Acc: 85.04673 macro-f1: 0.17679\n",
            "each epochs training time : 82m 45s\n",
            "\n",
            "\n",
            "Epoch 52/100\n",
            "----------\n",
            "train Loss: 0.73373 Acc: 85.03174 macro-f1: 0.17346\n",
            "vaild Loss: 0.69374 Acc: 85.12461 macro-f1: 0.17379\n",
            "each epochs training time : 84m 21s\n",
            "\n",
            "\n",
            "Epoch 53/100\n",
            "----------\n",
            "train Loss: 0.72189 Acc: 85.06515 macro-f1: 0.17392\n",
            "vaild Loss: 0.68993 Acc: 85.20249 macro-f1: 0.17578\n",
            "each epochs training time : 85m 57s\n",
            "\n",
            "\n",
            "Epoch 54/100\n",
            "----------\n",
            "train Loss: 0.72675 Acc: 85.19880 macro-f1: 0.18903\n",
            "vaild Loss: 0.69841 Acc: 85.12461 macro-f1: 0.18524\n",
            "each epochs training time : 87m 33s\n",
            "\n",
            "\n",
            "Epoch 55/100\n",
            "----------\n",
            "train Loss: 0.73123 Acc: 85.06515 macro-f1: 0.17111\n",
            "vaild Loss: 0.69997 Acc: 85.04673 macro-f1: 0.17220\n",
            "each epochs training time : 89m 9s\n",
            "\n",
            "\n",
            "Epoch 56/100\n",
            "----------\n",
            "train Loss: 0.71981 Acc: 84.99833 macro-f1: 0.16571\n",
            "vaild Loss: 0.68522 Acc: 85.20249 macro-f1: 0.17278\n",
            "each epochs training time : 90m 46s\n",
            "\n",
            "\n",
            "Epoch 57/100\n",
            "----------\n",
            "train Loss: 0.71806 Acc: 85.06515 macro-f1: 0.17897\n",
            "vaild Loss: 0.69947 Acc: 85.43614 macro-f1: 0.18445\n",
            "==> best model saved - 57 / 85.4\n",
            "each epochs training time : 92m 22s\n",
            "\n",
            "\n",
            "Epoch 58/100\n",
            "----------\n",
            "train Loss: 0.71734 Acc: 85.23221 macro-f1: 0.18367\n",
            "vaild Loss: 0.70391 Acc: 85.12461 macro-f1: 0.18323\n",
            "each epochs training time : 93m 58s\n",
            "\n",
            "\n",
            "Epoch 59/100\n",
            "----------\n",
            "train Loss: 0.71007 Acc: 85.09856 macro-f1: 0.17963\n",
            "vaild Loss: 0.68594 Acc: 85.51402 macro-f1: 0.18774\n",
            "==> best model saved - 59 / 85.5\n",
            "each epochs training time : 95m 34s\n",
            "\n",
            "\n",
            "Epoch 60/100\n",
            "----------\n",
            "train Loss: 0.70999 Acc: 85.06515 macro-f1: 0.17185\n",
            "vaild Loss: 0.68755 Acc: 84.89097 macro-f1: 0.16991\n",
            "each epochs training time : 97m 10s\n",
            "\n",
            "\n",
            "Epoch 61/100\n",
            "----------\n",
            "train Loss: 0.71445 Acc: 85.29903 macro-f1: 0.18150\n",
            "vaild Loss: 0.69905 Acc: 85.28037 macro-f1: 0.18254\n",
            "each epochs training time : 98m 47s\n",
            "\n",
            "\n",
            "Epoch 62/100\n",
            "----------\n",
            "train Loss: 0.71471 Acc: 85.19880 macro-f1: 0.17767\n",
            "vaild Loss: 0.69773 Acc: 85.20249 macro-f1: 0.18130\n",
            "each epochs training time : 100m 23s\n",
            "\n",
            "\n",
            "Epoch 63/100\n",
            "----------\n",
            "train Loss: 0.71613 Acc: 85.16539 macro-f1: 0.17740\n",
            "vaild Loss: 0.69781 Acc: 85.43614 macro-f1: 0.18532\n",
            "each epochs training time : 101m 59s\n",
            "\n",
            "\n",
            "Epoch 64/100\n",
            "----------\n",
            "train Loss: 0.70185 Acc: 85.09856 macro-f1: 0.16825\n",
            "vaild Loss: 0.68489 Acc: 85.20249 macro-f1: 0.17413\n",
            "each epochs training time : 103m 35s\n",
            "\n",
            "\n",
            "Epoch 65/100\n",
            "----------\n",
            "train Loss: 0.69866 Acc: 85.13197 macro-f1: 0.17695\n",
            "vaild Loss: 0.67980 Acc: 84.96885 macro-f1: 0.17488\n",
            "each epochs training time : 105m 10s\n",
            "\n",
            "\n",
            "Epoch 66/100\n",
            "----------\n",
            "train Loss: 0.70190 Acc: 85.06515 macro-f1: 0.17276\n",
            "vaild Loss: 0.69694 Acc: 85.28037 macro-f1: 0.17744\n",
            "each epochs training time : 106m 46s\n",
            "\n",
            "\n",
            "Epoch 67/100\n",
            "----------\n",
            "train Loss: 0.69423 Acc: 85.23221 macro-f1: 0.18263\n",
            "vaild Loss: 0.69650 Acc: 85.20249 macro-f1: 0.18374\n",
            "each epochs training time : 108m 22s\n",
            "\n",
            "\n",
            "Epoch 68/100\n",
            "----------\n",
            "train Loss: 0.70905 Acc: 85.29903 macro-f1: 0.18685\n",
            "vaild Loss: 0.67994 Acc: 85.28037 macro-f1: 0.18774\n",
            "each epochs training time : 109m 58s\n",
            "\n",
            "\n",
            "Epoch 69/100\n",
            "----------\n",
            "train Loss: 0.70531 Acc: 85.39926 macro-f1: 0.19856\n",
            "vaild Loss: 0.68068 Acc: 85.12461 macro-f1: 0.19433\n",
            "each epochs training time : 111m 34s\n",
            "\n",
            "\n",
            "Epoch 70/100\n",
            "----------\n",
            "train Loss: 0.70676 Acc: 85.13197 macro-f1: 0.18491\n",
            "vaild Loss: 0.69800 Acc: 85.04673 macro-f1: 0.18411\n",
            "each epochs training time : 113m 10s\n",
            "\n",
            "\n",
            "Epoch 71/100\n",
            "----------\n",
            "train Loss: 0.69866 Acc: 85.16539 macro-f1: 0.17415\n",
            "vaild Loss: 0.68985 Acc: 85.20249 macro-f1: 0.17749\n",
            "each epochs training time : 114m 46s\n",
            "\n",
            "\n",
            "Epoch 72/100\n",
            "----------\n",
            "train Loss: 0.71263 Acc: 85.19880 macro-f1: 0.18275\n",
            "vaild Loss: 0.69280 Acc: 85.28037 macro-f1: 0.18490\n",
            "each epochs training time : 116m 22s\n",
            "\n",
            "\n",
            "Epoch 73/100\n",
            "----------\n",
            "train Loss: 0.69582 Acc: 85.33244 macro-f1: 0.18578\n",
            "vaild Loss: 0.67915 Acc: 85.35826 macro-f1: 0.18929\n",
            "each epochs training time : 117m 58s\n",
            "\n",
            "\n",
            "Epoch 74/100\n",
            "----------\n",
            "train Loss: 0.71922 Acc: 85.26562 macro-f1: 0.18487\n",
            "vaild Loss: 0.69700 Acc: 85.04673 macro-f1: 0.18244\n",
            "each epochs training time : 119m 34s\n",
            "\n",
            "\n",
            "Epoch 75/100\n",
            "----------\n",
            "train Loss: 0.69030 Acc: 85.16539 macro-f1: 0.17766\n",
            "vaild Loss: 0.66833 Acc: 85.12461 macro-f1: 0.17911\n",
            "each epochs training time : 121m 10s\n",
            "\n",
            "\n",
            "Epoch 76/100\n",
            "----------\n",
            "train Loss: 0.70540 Acc: 85.33244 macro-f1: 0.18811\n",
            "vaild Loss: 0.69093 Acc: 85.12461 macro-f1: 0.18446\n",
            "each epochs training time : 122m 46s\n",
            "\n",
            "\n",
            "Epoch 77/100\n",
            "----------\n",
            "train Loss: 0.70213 Acc: 85.09856 macro-f1: 0.18214\n",
            "vaild Loss: 0.69121 Acc: 85.20249 macro-f1: 0.18374\n",
            "each epochs training time : 124m 22s\n",
            "\n",
            "\n",
            "Epoch 78/100\n",
            "----------\n",
            "train Loss: 0.70480 Acc: 85.29903 macro-f1: 0.18588\n",
            "vaild Loss: 0.68817 Acc: 85.04673 macro-f1: 0.18158\n",
            "each epochs training time : 125m 58s\n",
            "\n",
            "\n",
            "Epoch 79/100\n",
            "----------\n",
            "train Loss: 0.69701 Acc: 85.33244 macro-f1: 0.18941\n",
            "vaild Loss: 0.69481 Acc: 85.20249 macro-f1: 0.18849\n",
            "each epochs training time : 127m 34s\n",
            "\n",
            "\n",
            "Epoch 80/100\n",
            "----------\n",
            "train Loss: 0.71105 Acc: 85.16539 macro-f1: 0.17980\n",
            "vaild Loss: 0.71054 Acc: 85.20249 macro-f1: 0.17931\n",
            "each epochs training time : 129m 10s\n",
            "\n",
            "\n",
            "Epoch 81/100\n",
            "----------\n",
            "train Loss: 0.70212 Acc: 85.53291 macro-f1: 0.20169\n",
            "vaild Loss: 0.67902 Acc: 85.43614 macro-f1: 0.20100\n",
            "each epochs training time : 130m 46s\n",
            "\n",
            "\n",
            "Epoch 82/100\n",
            "----------\n",
            "train Loss: 0.70156 Acc: 85.09856 macro-f1: 0.17729\n",
            "vaild Loss: 0.67977 Acc: 85.28037 macro-f1: 0.18117\n",
            "each epochs training time : 132m 22s\n",
            "\n",
            "\n",
            "Epoch 83/100\n",
            "----------\n",
            "train Loss: 0.69786 Acc: 85.29903 macro-f1: 0.19036\n",
            "vaild Loss: 0.68893 Acc: 85.12461 macro-f1: 0.18685\n",
            "each epochs training time : 133m 58s\n",
            "\n",
            "\n",
            "Epoch 84/100\n",
            "----------\n",
            "train Loss: 0.71717 Acc: 85.19880 macro-f1: 0.18211\n",
            "vaild Loss: 0.71580 Acc: 85.20249 macro-f1: 0.18220\n",
            "each epochs training time : 135m 34s\n",
            "\n",
            "\n",
            "Epoch 85/100\n",
            "----------\n",
            "train Loss: 0.69390 Acc: 85.23221 macro-f1: 0.18343\n",
            "vaild Loss: 0.69230 Acc: 85.12461 macro-f1: 0.18316\n",
            "each epochs training time : 137m 10s\n",
            "\n",
            "\n",
            "Epoch 86/100\n",
            "----------\n",
            "train Loss: 0.69867 Acc: 85.13197 macro-f1: 0.18303\n",
            "vaild Loss: 0.69082 Acc: 84.96885 macro-f1: 0.18132\n",
            "each epochs training time : 138m 46s\n",
            "\n",
            "\n",
            "Epoch 87/100\n",
            "----------\n",
            "train Loss: 0.68766 Acc: 85.29903 macro-f1: 0.19233\n",
            "vaild Loss: 0.68388 Acc: 85.28037 macro-f1: 0.19193\n",
            "each epochs training time : 140m 22s\n",
            "\n",
            "\n",
            "Epoch 88/100\n",
            "----------\n",
            "train Loss: 0.70029 Acc: 85.13197 macro-f1: 0.18400\n",
            "vaild Loss: 0.67681 Acc: 85.35826 macro-f1: 0.18636\n",
            "each epochs training time : 141m 58s\n",
            "\n",
            "\n",
            "Epoch 89/100\n",
            "----------\n",
            "train Loss: 0.70215 Acc: 85.19880 macro-f1: 0.18170\n",
            "vaild Loss: 0.68322 Acc: 85.35826 macro-f1: 0.18513\n",
            "each epochs training time : 143m 34s\n",
            "\n",
            "\n",
            "Epoch 90/100\n",
            "----------\n",
            "train Loss: 0.68932 Acc: 85.29903 macro-f1: 0.18471\n",
            "vaild Loss: 0.67890 Acc: 85.04673 macro-f1: 0.18071\n",
            "each epochs training time : 145m 10s\n",
            "\n",
            "\n",
            "Epoch 91/100\n",
            "----------\n",
            "train Loss: 0.70759 Acc: 85.23221 macro-f1: 0.18930\n",
            "vaild Loss: 0.68786 Acc: 85.20249 macro-f1: 0.18822\n",
            "each epochs training time : 146m 46s\n",
            "\n",
            "\n",
            "Epoch 92/100\n",
            "----------\n",
            "train Loss: 0.70149 Acc: 85.26562 macro-f1: 0.18283\n",
            "vaild Loss: 0.68181 Acc: 85.20249 macro-f1: 0.18409\n",
            "each epochs training time : 148m 22s\n",
            "\n",
            "\n",
            "Epoch 93/100\n",
            "----------\n",
            "train Loss: 0.70191 Acc: 85.43268 macro-f1: 0.19539\n",
            "vaild Loss: 0.70166 Acc: 84.96885 macro-f1: 0.18997\n",
            "each epochs training time : 149m 58s\n",
            "\n",
            "\n",
            "Epoch 94/100\n",
            "----------\n",
            "train Loss: 0.70089 Acc: 85.26562 macro-f1: 0.18443\n",
            "vaild Loss: 0.70181 Acc: 85.20249 macro-f1: 0.18465\n",
            "each epochs training time : 151m 34s\n",
            "\n",
            "\n",
            "Epoch 95/100\n",
            "----------\n",
            "train Loss: 0.70690 Acc: 85.26562 macro-f1: 0.18649\n",
            "vaild Loss: 0.68821 Acc: 85.43614 macro-f1: 0.18918\n",
            "each epochs training time : 153m 10s\n",
            "\n",
            "\n",
            "Epoch 96/100\n",
            "----------\n",
            "train Loss: 0.69342 Acc: 85.29903 macro-f1: 0.18141\n",
            "vaild Loss: 0.67880 Acc: 85.51402 macro-f1: 0.18695\n",
            "each epochs training time : 154m 46s\n",
            "\n",
            "\n",
            "Epoch 97/100\n",
            "----------\n",
            "train Loss: 0.69077 Acc: 85.16539 macro-f1: 0.17986\n",
            "vaild Loss: 0.66947 Acc: 85.12461 macro-f1: 0.18058\n",
            "each epochs training time : 156m 22s\n",
            "\n",
            "\n",
            "Epoch 98/100\n",
            "----------\n",
            "train Loss: 0.69830 Acc: 85.26562 macro-f1: 0.18408\n",
            "vaild Loss: 0.69100 Acc: 85.28037 macro-f1: 0.18427\n",
            "each epochs training time : 157m 58s\n",
            "\n",
            "\n",
            "Epoch 99/100\n",
            "----------\n",
            "train Loss: 0.70113 Acc: 85.06515 macro-f1: 0.17256\n",
            "vaild Loss: 0.70305 Acc: 85.04673 macro-f1: 0.17340\n",
            "each epochs training time : 159m 34s\n",
            "\n",
            "\n",
            "Training complete in 159m 34s\n",
            "Best valid Acc: 59 - 85.5\n",
            "model saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 결과 그래프 그리기\n",
        "print('best model : %d - %1.f / %.1f'%(best_idx, valid_acc[best_idx], valid_loss[best_idx]))\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(train_acc, 'b-')\n",
        "ax1.plot(valid_acc, 'r-')\n",
        "plt.plot(best_idx, valid_acc[best_idx], 'ro')\n",
        "ax1.set_xlabel('epoch')\n",
        "# Make the y-axis label, ticks and tick labels match the line color.\n",
        "ax1.set_ylabel('acc', color='k')\n",
        "ax1.tick_params('y', colors='k')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(train_loss, 'g-')\n",
        "ax2.plot(valid_loss, 'k-')\n",
        "plt.plot(best_idx, valid_loss[best_idx], 'ro')\n",
        "ax2.set_ylabel('loss', color='k')\n",
        "ax2.tick_params('y', colors='k')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "5kJPLUuEU1pH",
        "outputId": "9c06cc5d-42b6-43ce-8046-e7f4cef672bc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best model : 59 - 86 / 0.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-o1YRRNYU1zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 추론"
      ],
      "metadata": {
        "id": "WQR1RKgTpKk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 모델을 평가 모드로 변경하고 test 데이터 분류\n",
        "test_png = sorted(glob('/content/drive/Othercomputers/내 MacBook Pro/open/test/*.png'))\n",
        "test_imgs = [img_load(n) for n in tqdm(test_png)]\n",
        "test_dataset = Custom_dataset_3(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "model.eval()\n",
        "f_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in (test_loader):\n",
        "        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            pred = model(x)\n",
        "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
      ],
      "metadata": {
        "id": "gj7gTQv6U11P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d2ed597-9258-4cf1-9dee-bc71a63a4bf8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2154/2154 [02:40<00:00, 13.43it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 숫자로된 레이블을 문자열 레이블로 변경\n",
        "label_decoder = {value:key for key, value in label_unique.items()}\n",
        "f_result = [label_decoder[result] for result in f_pred]"
      ],
      "metadata": {
        "id": "30_rcMw4U13G"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime as dt \n",
        "today = dt.today().strftime('%Y-%m-%d')\n",
        "version = f'efficientNet_b4_sam_by_timm_data_ver2_{today}'\n",
        "submission = pd.read_csv(f\"/content/drive/MyDrive/DACON_이상치 탐지 알고리즘 경진대회/open/sample_submission.csv\")\n",
        "\n",
        "## 시각적 확인을 위해 문자열 레이블로 이루어진 된 label 필드 생성\n",
        "submission[\"label\"] = f_result\n",
        "display(submission)\n",
        "submission.to_csv(f\"/content/drive/MyDrive/DACON_이상치 탐지 알고리즘 경진대회/open/sample_submission_{version}.csv\", index = False)"
      ],
      "metadata": {
        "id": "1zWu-D7WdRmQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "0fb66392-8679-4fd0-fb6d-7025421eeff1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      index            label\n",
              "0         0        tile-good\n",
              "1         1        grid-good\n",
              "2         2  transistor-good\n",
              "3         3        tile-good\n",
              "4         4        tile-good\n",
              "...     ...              ...\n",
              "2149   2149        tile-good\n",
              "2150   2150       screw-good\n",
              "2151   2151        grid-good\n",
              "2152   2152       cable-good\n",
              "2153   2153      zipper-good\n",
              "\n",
              "[2154 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-99542c84-4c68-4fba-9bab-c0740ed08353\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>tile-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>grid-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>transistor-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>tile-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>tile-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2149</th>\n",
              "      <td>2149</td>\n",
              "      <td>tile-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2150</th>\n",
              "      <td>2150</td>\n",
              "      <td>screw-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2151</th>\n",
              "      <td>2151</td>\n",
              "      <td>grid-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2152</th>\n",
              "      <td>2152</td>\n",
              "      <td>cable-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2153</th>\n",
              "      <td>2153</td>\n",
              "      <td>zipper-good</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2154 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99542c84-4c68-4fba-9bab-c0740ed08353')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-99542c84-4c68-4fba-9bab-c0740ed08353 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-99542c84-4c68-4fba-9bab-c0740ed08353');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 저장\n",
        "model_version = f'efficientNet_b4_sam_data_ver2_{today}'\n",
        "torch.save(model.state_dict(), f'/content/drive/MyDrive/DACON_이상치 탐지 알고리즘 경진대회/open/{model_version}.pt')"
      ],
      "metadata": {
        "id": "cG_tNWs2zxh8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "l7fjAkYDOYse"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}