{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNet_MVtecAD_Dataset",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seunghee0518/AI_python/blob/main/vit_base_patch16_224_MVtecAD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## trina/ test 나눠서 학습"
      ],
      "metadata": {
        "id": "lynhGDxilbRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "torch.hub : Pytorch Hub는 연구 재현성을 촉진하도록 설계된 사전 훈련 된 모델 저장소\n",
        "nvidia_efficientnet_b4 사전 모델 가져옴\n",
        "'''\n",
        "# import torch\n",
        "# model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b4', pretrained=True)\n",
        "!pip install timm\n",
        "import timm\n",
        "model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=88)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ-ytfDpoKMH",
        "outputId": "ad39aa57-2bd4-42dd-a475-125fd76a29c8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.5.4)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "model_names = timm.list_models(pretrained=True)\n",
        "pprint(model_names)"
      ],
      "metadata": {
        "id": "invECZxkPTyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKXv22Yk6zus",
        "outputId": "6d951a8c-6bb7-4644-f6cf-30d849c72bd6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 학습 코드\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "#import timm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import transforms, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "from PIL import Image\n",
        "# from efficientnet_pytorch import EfficientNet\n",
        "# model_name = 'efficientnet-b0'  # b5\n",
        "\n",
        "# image_size = EfficientNet.get_image_size(model_name)\n",
        "# print(image_size)\n",
        "# model = EfficientNet.from_pretrained(model_name, num_classes=88)"
      ],
      "metadata": {
        "id": "Gjs-R_R5lUKg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 기본 설정\n",
        "device = torch.device('cuda')\n",
        "batch_size  = 32\n",
        "random_seed = 1234\n",
        "img_size = 224\n",
        "random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZHMCtAvlDOp",
        "outputId": "133a8514-6634-4cee-f511-b3bc3615f9b3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f6ed74b7970>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## transforms 함수 정리\n",
        "* transforms.ToPILImage() - csv 파일로 데이터셋을 받을 경우, PIL image로 바꿔준다.\n",
        "* transforms.CenterCrop(size) - 가운데 부분을 size 크기로 자른다.\n",
        "* transforms.Grayscale(num_output_channels=1) - grayscale로 변환한다.\n",
        "* transforms.RandomAffine(degrees) - 랜덤으로 affine 변형을 한다.\n",
        "* transforms.RandomCrop(size) -이미지를 랜덤으로 아무데나 잘라 size 크기로 출력한다.\n",
        "* transforms.RandomResizedCrop(size) - 이미지 사이즈를 size로 변경한다\n",
        "* transforms.Resize(size) - 이미지 사이즈를 size로 변경한다\n",
        "* transforms.RandomRotation(degrees) 이미지를 랜덤으로 degrees 각도로 회전한다.\n",
        "* transforms.RandomResizedCrop(size, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333)) - 이미지를 랜덤으로 변형한다.\n",
        "* transforms.RandomVerticalFlip(p=0.5) - 이미지를 랜덤으로 수직으로 뒤집는다. p =0이면 뒤집지 않는다.\n",
        "* transforms.RandomHorizontalFlip(p=0.5) - 이미지를 랜덤으로 수평으로 뒤집는다.\n",
        "* transforms.ToTensor() - 이미지 데이터를 tensor로 바꿔준다.\n",
        "* transforms.Normalize(mean, std, inplace=False) - 이미지를 정규화한다."
      ],
      "metadata": {
        "id": "fTgH3bYzN7RA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 데이터 전처리 함수\n",
        "# make dataset\n",
        "#data_path = 'president/president_data'  # class 별 폴더로 나누어진 걸 가져와서 라벨도 달아준다\n",
        "# train_dataset = datasets.ImageFolder(data_path,\n",
        "#                                      transforms.Compose([\n",
        "#                                      transforms.Resize((224, 224)),\n",
        "#                                      transforms.RandomCrop(224),\n",
        "#                                      transforms.RandomRotation(90, expand=True),\n",
        "#                                      transforms.RandomVerticalFlip(),\n",
        "#                                      transforms.RandomHorizontalFlip(),\n",
        "#                                      transforms.ToTensor(), # 이미지 데이터를 tensor로 바꿔준다.\n",
        "#                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])) # Normalize는 많은 이미지의 평균, 표준편차로 정함(보통 많이 하는 값이라고함)\n",
        "\n",
        "\n",
        "### 이미지 전처리 함수 & 클래스\n",
        "## 이미지  > 넘파이 배열로 변환\n",
        "def img_load(path):\n",
        "    img = cv2.imread(path)[:,:,::-1] # Return type:\tnumpy.ndarray / 기본적으로 BGR로 불러옴, RGB 변환함\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    return img\n",
        "\n",
        "class Custom_dataset_1(Dataset): # 기본\n",
        "    def __init__(self, img_paths, labels, mode='train'):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode = mode\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.img_paths[idx]\n",
        "        img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "        img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "        ## 레이블 > 원-핫 인코딩 하기 \n",
        "        label = self.labels[idx]# (원핫인코딩 안할거면 해당 코드만 필요)\n",
        "        return img, label\n",
        "\n",
        "class Custom_dataset_2(Dataset): # 변형\n",
        "    def __init__(self, img_paths, labels, mode='train'):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode = mode\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.img_paths[idx]\n",
        "        if self.mode == 'train':\n",
        "          img = Image.fromarray(img)\n",
        "          #img = transforms.Resize((img_size, img_size))(img) # 처음 이미지 불러올때 resize 했으므로 생략\n",
        "          #img = transforms.RandomCrop(img_size)(img)\n",
        "          img = transforms.RandomRotation(90, expand=False)(img)\n",
        "          img = transforms.RandomVerticalFlip()(img)\n",
        "          img = transforms.RandomHorizontalFlip()(img)\n",
        "          img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "          img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "        if self.mode=='test':\n",
        "          img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "        ## 레이블\n",
        "        label = self.labels[idx]# (원핫인코딩 안할거면 해당 코드만 필요)\n",
        "        return img, label\n",
        "\n",
        "class Custom_dataset_3(Dataset): # 기본이미지 + 변형이미지 (train 시 2배 증량됨)\n",
        "    def __init__(self, img_paths, labels, mode='train'):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode=mode\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.mode=='train':\n",
        "          if idx < 4277: # 변경 없는 이미지\n",
        "            img = self.img_paths[idx]\n",
        "            img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "            img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "            label = self.labels[idx]\n",
        "            return img, label\n",
        "\n",
        "          else : # 랜덤 변경된 이미지 추가됨 \n",
        "            img = self.img_paths[idx]\n",
        "            img = Image.fromarray(img)\n",
        "            #img = transforms.Resize((img_size, img_size))(img) # 처음 이미지 불러올때 resize 했으므로 생략\n",
        "            #img = transforms.RandomCrop(img_size)(img)\n",
        "            img = transforms.RandomRotation(90, expand=False)(img)\n",
        "            img = transforms.RandomVerticalFlip()(img)\n",
        "            img = transforms.RandomHorizontalFlip()(img)\n",
        "            img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "            img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "            label = self.labels[idx]\n",
        "            return img, label\n",
        "\n",
        "        if self.mode=='test':\n",
        "          img = self.img_paths[idx]\n",
        "          img = transforms.ToTensor()(img)\n",
        "          img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "          label = self.labels[idx]\n",
        "          return img, label\n",
        "            "
      ],
      "metadata": {
        "id": "ORqFbwLXpSeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 이미지 로드 및 전처리\n",
        "# 이미지 경로\n",
        "train_png = sorted(glob('/content/drive/Othercomputers/내 MacBook Pro/open/train/*.png'))\n",
        "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
        "\n",
        "#train_imgs = np.load('/content/drive/MyDrive/DACON_이상치 탐지 알고리즘 경진대회/train_imgs_224.npy')\n",
        "train_y = pd.read_csv(\"/content/drive/Othercomputers/내 MacBook Pro/open/train_df.csv\")\n",
        "\n",
        "train_labels = train_y[\"label\"] # 레이블순서는 이미지 파일 순서대로임\n",
        "\n",
        "label_unique = sorted(np.unique(train_labels))\n",
        "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))} # 오름차순으로 레이블별로 숫자 부여(0부터 시작)\n",
        "\n",
        "train_labels = [label_unique[k] for k in train_labels]\n",
        "\n",
        "# 커스텀 이미지 생성\n",
        "train_dataset = Custom_dataset_2(np.array(train_imgs), np.array(train_labels), mode='train')\n",
        "train_idx, vaild_idx = train_test_split(list(range(len(train_dataset))), stratify=train_labels, test_size=0.3, random_state=random_seed)\n",
        "\n",
        "# ## 이미지 증량 시만 사용\n",
        "# train_imgs = train_imgs + train_imgs\n",
        "# train_labels = train_labels+train_labels\n",
        "\n",
        "# train_dataset = Custom_dataset_3(np.array(train_imgs), np.array(train_labels), mode='train')\n",
        "\n",
        "### 데이터셋 분리 > 층화추출 & 테스터 데이터 비율 : 0.3, 시드 : 1234, 셔플 = True(default)\n",
        "train_idx, vaild_idx = train_test_split(list(range(len(train_dataset))), stratify=train_labels, test_size=0.3, random_state=random_seed)\n",
        "\n",
        "datasets = {} # 데이터셋을 담을 딕셔너리\n",
        "datasets['train'] = Subset(train_dataset, train_idx)\n",
        "datasets['vaild']  = Subset(train_dataset, vaild_idx)\n",
        "\n",
        "## data loader 선언\n",
        "dataloaders, batch_num = {}, {}\n",
        "dataloaders['train'] = torch.utils.data.DataLoader(datasets['train'],\n",
        "                                                  batch_size=batch_size, shuffle=True,\n",
        "                                                  num_workers=0)\n",
        "dataloaders['vaild']  = torch.utils.data.DataLoader(datasets['vaild'],\n",
        "                                                    batch_size=batch_size, shuffle=False,\n",
        "                                                    num_workers=0)\n",
        "'''\n",
        "데이터 변형 코드를 추가한 후 아래 오류코드가 나와\n",
        "Caught TypeError in DataLoader worker process 0\n",
        "DataLoader > num_workers 를 4 -> 0 로 낮춤\n",
        "'''\n",
        "\n",
        "batch_num['train'], batch_num['vaild'] = len(dataloaders['train']), len(dataloaders['vaild'])\n",
        "print('batch_size : %d,  train/vaild(데이터셋개수/배치사이즈) : %d / %d' % (batch_size, batch_num['train'],batch_num['vaild']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItvLP1Y3k-OW",
        "outputId": "3346b0de-2b33-47a8-e2a6-70628d1d34df"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4277/4277 [02:12<00:00, 32.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_size : 32,  train/vaild(데이터셋개수/배치사이즈) : 94 / 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 참고 블로그 : https://keep-steady.tistory.com/35\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "### f1 스코어 함수 \n",
        "def score_function(real, pred): # 라이브러리 > sklearn.metrics \n",
        "    score = f1_score(real, pred, average=\"macro\")\n",
        "    return score\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    #train_loss, train_acc, valid_loss, valid_acc = [], [], [], []\n",
        "    train_loss, train_acc, valid_loss, valid_acc, train_f1, valid_f1 = [], [], [], [], [], []\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))# - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'vaild']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
        "            \n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device) # device = torch.device('cuda')\n",
        "                labels = labels.to(device) # device = torch.device('cuda')\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                num_cnt += len(labels)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "            \n",
        "            epoch_loss = float(running_loss / num_cnt)\n",
        "            epoch_acc  = float((running_corrects.double() / num_cnt).cpu()*100)\n",
        "            f1 = score_function(labels.cpu().data, preds.cpu()) # score_function or f1_score\n",
        "\n",
        "            if phase == 'train':\n",
        "                train_loss.append(epoch_loss)\n",
        "                train_acc.append(epoch_acc)\n",
        "                train_f1.append(f1)\n",
        "            else:\n",
        "                valid_loss.append(epoch_loss)\n",
        "                valid_acc.append(epoch_acc)\n",
        "                valid_f1.append(f1)\n",
        "\n",
        "            print('{} Loss: {:.5f} Acc: {:.5f} macro-f1: {:.5f}'.format(phase, epoch_loss, epoch_acc, f1))\n",
        "           \n",
        "            # deep copy the model(최적모델 저장)\n",
        "            if phase == 'vaild' and epoch_acc > best_acc:\n",
        "                best_idx = epoch\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "#                 best_model_wts = copy.deepcopy(model.module.state_dict())\n",
        "                print('==> best model saved - %d / %.1f'%(best_idx, best_acc))\n",
        "        # 한 에포크마다 실행 시간 출력하기(누적 시간으로 출력됨)\n",
        "        time_elapsed = time.time() - since\n",
        "        print('each epochs training time : {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "        print('\\n')\n",
        "\n",
        "        # 한 에포크마다 필요없는 메모리 지우기 : 지우기 효과는 아직 확인 못해봄\n",
        "        try:      \n",
        "          gc.collect() # cpu 비움\n",
        "          torch.cuda.empty_cache() # gpu 비움\n",
        "        except:\n",
        "          pass\n",
        "          \n",
        "    ## 학습 마무리 후\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best valid Acc: %d - %.1f' %(best_idx, best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    '''\n",
        "    한 에포크 마다 저장된 최적의 모델 가중치로 조정 후 다음 에포크가 돌아감\n",
        "    '''\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    torch.save(model.state_dict(), 'president_model.pt')\n",
        "    print('model saved')\n",
        "    return model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc, train_f1, valid_f1\n",
        "\n",
        "# 설정\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # set gpu\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_ft = optim.SGD(model.parameters(), \n",
        "                         lr = 0.05,\n",
        "                         momentum=0.9,\n",
        "                         weight_decay=1e-4)\n",
        "\n",
        "lmbda = lambda epoch: 0.98739\n",
        "exp_lr_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer_ft, lr_lambda=lmbda)\n",
        "\n",
        "# 사전학습된 가중치와 모델을 가져와 데이터셋으로 추가 모델 학습\n",
        "model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc, train_f1, valid_f1 = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HDNj4Yarkx-R",
        "outputId": "e8906c2e-75ea-4eb0-b363-d36a9d09f5fd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/100\n",
            "----------\n",
            "train Loss: 1548.58706 Acc: 6.04744 macro-f1: 0.01070\n",
            "vaild Loss: 2059.82878 Acc: 5.21807 macro-f1: 0.13333\n",
            "==> best model saved - 0 / 5.2\n",
            "each epochs training time : 1m 49s\n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "----------\n",
            "train Loss: 1039.92873 Acc: 6.44838 macro-f1: 0.00000\n",
            "vaild Loss: 753.45511 Acc: 5.14019 macro-f1: 0.00000\n",
            "each epochs training time : 3m 44s\n",
            "\n",
            "\n",
            "Epoch 2/100\n",
            "----------\n",
            "train Loss: 594.00988 Acc: 3.94253 macro-f1: 0.00000\n",
            "vaild Loss: 447.53607 Acc: 6.15265 macro-f1: 0.00000\n",
            "==> best model saved - 2 / 6.2\n",
            "each epochs training time : 5m 43s\n",
            "\n",
            "\n",
            "Epoch 3/100\n",
            "----------\n",
            "train Loss: 288.61113 Acc: 5.84698 macro-f1: 0.00000\n",
            "vaild Loss: 208.96540 Acc: 14.09657 macro-f1: 0.00000\n",
            "==> best model saved - 3 / 14.1\n",
            "each epochs training time : 7m 42s\n",
            "\n",
            "\n",
            "Epoch 4/100\n",
            "----------\n",
            "train Loss: 175.10365 Acc: 8.55329 macro-f1: 0.04762\n",
            "vaild Loss: 159.72237 Acc: 11.13707 macro-f1: 0.00000\n",
            "each epochs training time : 9m 41s\n",
            "\n",
            "\n",
            "Epoch 5/100\n",
            "----------\n",
            "train Loss: 60.70060 Acc: 10.49115 macro-f1: 0.05714\n",
            "vaild Loss: 53.78957 Acc: 19.62617 macro-f1: 0.60000\n",
            "==> best model saved - 5 / 19.6\n",
            "each epochs training time : 11m 41s\n",
            "\n",
            "\n",
            "Epoch 6/100\n",
            "----------\n",
            "train Loss: 28.66193 Acc: 17.07317 macro-f1: 0.02500\n",
            "vaild Loss: 17.51315 Acc: 13.31776 macro-f1: 0.00000\n",
            "each epochs training time : 13m 41s\n",
            "\n",
            "\n",
            "Epoch 7/100\n",
            "----------\n",
            "train Loss: 24.59130 Acc: 19.41196 macro-f1: 0.09491\n",
            "vaild Loss: 20.22128 Acc: 19.39252 macro-f1: 0.20000\n",
            "each epochs training time : 15m 41s\n",
            "\n",
            "\n",
            "Epoch 8/100\n",
            "----------\n",
            "train Loss: 17.14044 Acc: 21.98463 macro-f1: 0.32639\n",
            "vaild Loss: 17.21547 Acc: 18.38006 macro-f1: 0.25000\n",
            "each epochs training time : 17m 40s\n",
            "\n",
            "\n",
            "Epoch 9/100\n",
            "----------\n",
            "train Loss: 10.86588 Acc: 24.35683 macro-f1: 0.06349\n",
            "vaild Loss: 14.11354 Acc: 11.83801 macro-f1: 0.00000\n",
            "each epochs training time : 19m 40s\n",
            "\n",
            "\n",
            "Epoch 10/100\n",
            "----------\n",
            "train Loss: 12.69358 Acc: 22.88674 macro-f1: 0.27094\n",
            "vaild Loss: 12.53141 Acc: 22.81931 macro-f1: 0.20000\n",
            "==> best model saved - 10 / 22.8\n",
            "each epochs training time : 21m 41s\n",
            "\n",
            "\n",
            "Epoch 11/100\n",
            "----------\n",
            "train Loss: 39.76933 Acc: 14.19980 macro-f1: 0.01786\n",
            "vaild Loss: 21.38222 Acc: 7.24299 macro-f1: 0.00000\n",
            "each epochs training time : 23m 40s\n",
            "\n",
            "\n",
            "Epoch 12/100\n",
            "----------\n",
            "train Loss: 14.45480 Acc: 14.36686 macro-f1: 0.02941\n",
            "vaild Loss: 8.77193 Acc: 15.42056 macro-f1: 0.41667\n",
            "each epochs training time : 25m 40s\n",
            "\n",
            "\n",
            "Epoch 13/100\n",
            "----------\n",
            "train Loss: 9.89538 Acc: 15.50284 macro-f1: 0.12821\n",
            "vaild Loss: 10.46359 Acc: 18.84735 macro-f1: 0.00000\n",
            "each epochs training time : 27m 40s\n",
            "\n",
            "\n",
            "Epoch 14/100\n",
            "----------\n",
            "train Loss: 10.51471 Acc: 15.73672 macro-f1: 0.13889\n",
            "vaild Loss: 9.49590 Acc: 19.39252 macro-f1: 0.25000\n",
            "each epochs training time : 29m 39s\n",
            "\n",
            "\n",
            "Epoch 15/100\n",
            "----------\n",
            "train Loss: 8.98025 Acc: 16.93953 macro-f1: 0.03704\n",
            "vaild Loss: 5.03101 Acc: 20.95016 macro-f1: 0.33333\n",
            "each epochs training time : 31m 39s\n",
            "\n",
            "\n",
            "Epoch 16/100\n",
            "----------\n",
            "train Loss: 6.61591 Acc: 18.84397 macro-f1: 0.04082\n",
            "vaild Loss: 5.76086 Acc: 24.14330 macro-f1: 0.00000\n",
            "==> best model saved - 16 / 24.1\n",
            "each epochs training time : 33m 39s\n",
            "\n",
            "\n",
            "Epoch 17/100\n",
            "----------\n",
            "train Loss: 6.14765 Acc: 19.11126 macro-f1: 0.20682\n",
            "vaild Loss: 7.50893 Acc: 22.11838 macro-f1: 0.00000\n",
            "each epochs training time : 35m 38s\n",
            "\n",
            "\n",
            "Epoch 18/100\n",
            "----------\n",
            "train Loss: 29.53565 Acc: 9.22152 macro-f1: 0.00000\n",
            "vaild Loss: 12.28434 Acc: 3.34891 macro-f1: 0.00000\n",
            "each epochs training time : 37m 38s\n",
            "\n",
            "\n",
            "Epoch 19/100\n",
            "----------\n",
            "train Loss: 9.20221 Acc: 12.02807 macro-f1: 0.00962\n",
            "vaild Loss: 10.57499 Acc: 13.78505 macro-f1: 0.00000\n",
            "each epochs training time : 39m 38s\n",
            "\n",
            "\n",
            "Epoch 20/100\n",
            "----------\n",
            "train Loss: 9.50781 Acc: 11.52690 macro-f1: 0.04615\n",
            "vaild Loss: 7.31461 Acc: 10.59190 macro-f1: 0.00000\n",
            "each epochs training time : 41m 37s\n",
            "\n",
            "\n",
            "Epoch 21/100\n",
            "----------\n",
            "train Loss: 5.28145 Acc: 14.06615 macro-f1: 0.01562\n",
            "vaild Loss: 5.28947 Acc: 20.24922 macro-f1: 0.00000\n",
            "each epochs training time : 43m 37s\n",
            "\n",
            "\n",
            "Epoch 22/100\n",
            "----------\n",
            "train Loss: 6.94825 Acc: 12.36218 macro-f1: 0.03571\n",
            "vaild Loss: 3.98040 Acc: 19.47040 macro-f1: 0.16667\n",
            "each epochs training time : 45m 37s\n",
            "\n",
            "\n",
            "Epoch 23/100\n",
            "----------\n",
            "train Loss: 5.52152 Acc: 13.83228 macro-f1: 0.13056\n",
            "vaild Loss: 7.12408 Acc: 14.56386 macro-f1: 0.20000\n",
            "each epochs training time : 47m 37s\n",
            "\n",
            "\n",
            "Epoch 24/100\n",
            "----------\n",
            "train Loss: 6.23057 Acc: 13.56498 macro-f1: 0.03542\n",
            "vaild Loss: 4.74290 Acc: 9.65732 macro-f1: 0.00000\n",
            "each epochs training time : 49m 37s\n",
            "\n",
            "\n",
            "Epoch 25/100\n",
            "----------\n",
            "train Loss: 4.54251 Acc: 14.46709 macro-f1: 0.12821\n",
            "vaild Loss: 3.54613 Acc: 17.67913 macro-f1: 0.20000\n",
            "each epochs training time : 51m 38s\n",
            "\n",
            "\n",
            "Epoch 26/100\n",
            "----------\n",
            "train Loss: 3.85516 Acc: 15.16873 macro-f1: 0.02381\n",
            "vaild Loss: 3.56440 Acc: 17.99065 macro-f1: 0.00000\n",
            "each epochs training time : 53m 38s\n",
            "\n",
            "\n",
            "Epoch 27/100\n",
            "----------\n",
            "train Loss: 3.98625 Acc: 15.03508 macro-f1: 0.10490\n",
            "vaild Loss: 3.93746 Acc: 16.51090 macro-f1: 0.50000\n",
            "each epochs training time : 55m 38s\n",
            "\n",
            "\n",
            "Epoch 28/100\n",
            "----------\n",
            "train Loss: 3.56900 Acc: 15.90378 macro-f1: 0.15079\n",
            "vaild Loss: 3.30709 Acc: 19.85981 macro-f1: 0.00000\n",
            "each epochs training time : 57m 38s\n",
            "\n",
            "\n",
            "Epoch 29/100\n",
            "----------\n",
            "train Loss: 3.54360 Acc: 16.33812 macro-f1: 0.03125\n",
            "vaild Loss: 3.55937 Acc: 16.27726 macro-f1: 0.00000\n",
            "each epochs training time : 59m 38s\n",
            "\n",
            "\n",
            "Epoch 30/100\n",
            "----------\n",
            "train Loss: 3.43625 Acc: 17.70799 macro-f1: 0.04048\n",
            "vaild Loss: 3.57780 Acc: 17.28972 macro-f1: 0.13333\n",
            "each epochs training time : 61m 38s\n",
            "\n",
            "\n",
            "Epoch 31/100\n",
            "----------\n",
            "train Loss: 3.61513 Acc: 15.83695 macro-f1: 0.04762\n",
            "vaild Loss: 3.74972 Acc: 19.47040 macro-f1: 0.33333\n",
            "each epochs training time : 63m 38s\n",
            "\n",
            "\n",
            "Epoch 32/100\n",
            "----------\n",
            "train Loss: 3.54525 Acc: 17.74140 macro-f1: 0.11319\n",
            "vaild Loss: 3.71416 Acc: 13.23988 macro-f1: 0.00000\n",
            "each epochs training time : 65m 38s\n",
            "\n",
            "\n",
            "Epoch 33/100\n",
            "----------\n",
            "train Loss: 3.60984 Acc: 18.07551 macro-f1: 0.12381\n",
            "vaild Loss: 2.85436 Acc: 18.61371 macro-f1: 0.00000\n",
            "each epochs training time : 67m 38s\n",
            "\n",
            "\n",
            "Epoch 34/100\n",
            "----------\n",
            "train Loss: 3.39402 Acc: 18.87738 macro-f1: 0.04444\n",
            "vaild Loss: 3.20744 Acc: 20.95016 macro-f1: 0.20000\n",
            "each epochs training time : 69m 39s\n",
            "\n",
            "\n",
            "Epoch 35/100\n",
            "----------\n",
            "train Loss: 3.30579 Acc: 19.34514 macro-f1: 0.07111\n",
            "vaild Loss: 3.14126 Acc: 16.97819 macro-f1: 0.20000\n",
            "each epochs training time : 71m 39s\n",
            "\n",
            "\n",
            "Epoch 36/100\n",
            "----------\n",
            "train Loss: 2.99585 Acc: 20.24724 macro-f1: 0.13333\n",
            "vaild Loss: 2.78519 Acc: 22.58567 macro-f1: 0.00000\n",
            "each epochs training time : 73m 38s\n",
            "\n",
            "\n",
            "Epoch 37/100\n",
            "----------\n",
            "train Loss: 3.25775 Acc: 19.04444 macro-f1: 0.10714\n",
            "vaild Loss: 2.88167 Acc: 21.88474 macro-f1: 0.00000\n",
            "each epochs training time : 75m 38s\n",
            "\n",
            "\n",
            "Epoch 38/100\n",
            "----------\n",
            "train Loss: 3.09074 Acc: 21.31640 macro-f1: 0.02041\n",
            "vaild Loss: 3.62967 Acc: 17.67913 macro-f1: 0.00000\n",
            "each epochs training time : 77m 38s\n",
            "\n",
            "\n",
            "Epoch 39/100\n",
            "----------\n",
            "train Loss: 3.19417 Acc: 19.64584 macro-f1: 0.12500\n",
            "vaild Loss: 2.87099 Acc: 17.52336 macro-f1: 0.20000\n",
            "each epochs training time : 79m 38s\n",
            "\n",
            "\n",
            "Epoch 40/100\n",
            "----------\n",
            "train Loss: 2.99082 Acc: 21.75075 macro-f1: 0.23718\n",
            "vaild Loss: 2.77339 Acc: 24.61059 macro-f1: 1.00000\n",
            "==> best model saved - 40 / 24.6\n",
            "each epochs training time : 81m 37s\n",
            "\n",
            "\n",
            "Epoch 41/100\n",
            "----------\n",
            "train Loss: 5.59635 Acc: 18.44303 macro-f1: 0.05128\n",
            "vaild Loss: 5.75459 Acc: 10.43614 macro-f1: 0.25000\n",
            "each epochs training time : 83m 37s\n",
            "\n",
            "\n",
            "Epoch 42/100\n",
            "----------\n",
            "train Loss: 6.19103 Acc: 17.13999 macro-f1: 0.00000\n",
            "vaild Loss: 4.95703 Acc: 20.32710 macro-f1: 0.25000\n",
            "each epochs training time : 85m 37s\n",
            "\n",
            "\n",
            "Epoch 43/100\n",
            "----------\n",
            "train Loss: 4.17833 Acc: 19.54561 macro-f1: 0.16667\n",
            "vaild Loss: 3.60343 Acc: 18.06854 macro-f1: 0.00000\n",
            "each epochs training time : 87m 37s\n",
            "\n",
            "\n",
            "Epoch 44/100\n",
            "----------\n",
            "train Loss: 3.76435 Acc: 21.45005 macro-f1: 0.10000\n",
            "vaild Loss: 4.13870 Acc: 15.26480 macro-f1: 0.00000\n",
            "each epochs training time : 89m 37s\n",
            "\n",
            "\n",
            "Epoch 45/100\n",
            "----------\n",
            "train Loss: 3.95127 Acc: 19.77949 macro-f1: 0.11538\n",
            "vaild Loss: 5.00643 Acc: 18.53583 macro-f1: 0.20000\n",
            "each epochs training time : 91m 37s\n",
            "\n",
            "\n",
            "Epoch 46/100\n",
            "----------\n",
            "train Loss: 3.58349 Acc: 20.84865 macro-f1: 0.05291\n",
            "vaild Loss: 3.02615 Acc: 24.84424 macro-f1: 0.50000\n",
            "==> best model saved - 46 / 24.8\n",
            "each epochs training time : 93m 37s\n",
            "\n",
            "\n",
            "Epoch 47/100\n",
            "----------\n",
            "train Loss: 3.32511 Acc: 24.45707 macro-f1: 0.01786\n",
            "vaild Loss: 3.00841 Acc: 25.85670 macro-f1: 0.00000\n",
            "==> best model saved - 47 / 25.9\n",
            "each epochs training time : 95m 37s\n",
            "\n",
            "\n",
            "Epoch 48/100\n",
            "----------\n",
            "train Loss: 3.17178 Acc: 23.15403 macro-f1: 0.18367\n",
            "vaild Loss: 3.02792 Acc: 25.54517 macro-f1: 0.20000\n",
            "each epochs training time : 97m 38s\n",
            "\n",
            "\n",
            "Epoch 49/100\n",
            "----------\n",
            "train Loss: 3.06223 Acc: 23.65520 macro-f1: 0.11556\n",
            "vaild Loss: 2.80459 Acc: 25.46729 macro-f1: 0.00000\n",
            "each epochs training time : 99m 38s\n",
            "\n",
            "\n",
            "Epoch 50/100\n",
            "----------\n",
            "train Loss: 2.88058 Acc: 26.59539 macro-f1: 0.22778\n",
            "vaild Loss: 2.87656 Acc: 27.64798 macro-f1: 0.13333\n",
            "==> best model saved - 50 / 27.6\n",
            "each epochs training time : 101m 38s\n",
            "\n",
            "\n",
            "Epoch 51/100\n",
            "----------\n",
            "train Loss: 2.92013 Acc: 25.79352 macro-f1: 0.21587\n",
            "vaild Loss: 2.76183 Acc: 27.18069 macro-f1: 0.20000\n",
            "each epochs training time : 103m 39s\n",
            "\n",
            "\n",
            "Epoch 52/100\n",
            "----------\n",
            "train Loss: 3.44245 Acc: 23.82225 macro-f1: 0.15686\n",
            "vaild Loss: 3.02847 Acc: 24.37695 macro-f1: 0.00000\n",
            "each epochs training time : 105m 39s\n",
            "\n",
            "\n",
            "Epoch 53/100\n",
            "----------\n",
            "train Loss: 3.10100 Acc: 26.72903 macro-f1: 0.12381\n",
            "vaild Loss: 2.90928 Acc: 26.71340 macro-f1: 0.10000\n",
            "each epochs training time : 107m 40s\n",
            "\n",
            "\n",
            "Epoch 54/100\n",
            "----------\n",
            "train Loss: 2.94167 Acc: 25.59305 macro-f1: 0.30641\n",
            "vaild Loss: 3.13867 Acc: 27.72586 macro-f1: 0.20000\n",
            "==> best model saved - 54 / 27.7\n",
            "each epochs training time : 109m 40s\n",
            "\n",
            "\n",
            "Epoch 55/100\n",
            "----------\n",
            "train Loss: 2.88832 Acc: 27.86502 macro-f1: 0.30317\n",
            "vaild Loss: 2.70750 Acc: 28.66044 macro-f1: 0.00000\n",
            "==> best model saved - 55 / 28.7\n",
            "each epochs training time : 111m 40s\n",
            "\n",
            "\n",
            "Epoch 56/100\n",
            "----------\n",
            "train Loss: 2.77431 Acc: 28.39960 macro-f1: 0.26786\n",
            "vaild Loss: 2.60747 Acc: 31.61994 macro-f1: 0.11111\n",
            "==> best model saved - 56 / 31.6\n",
            "each epochs training time : 113m 41s\n",
            "\n",
            "\n",
            "Epoch 57/100\n",
            "----------\n",
            "train Loss: 2.78574 Acc: 29.80287 macro-f1: 0.16667\n",
            "vaild Loss: 2.71732 Acc: 25.77882 macro-f1: 0.20000\n",
            "each epochs training time : 115m 41s\n",
            "\n",
            "\n",
            "Epoch 58/100\n",
            "----------\n",
            "train Loss: 2.79704 Acc: 28.33278 macro-f1: 0.17059\n",
            "vaild Loss: 2.66554 Acc: 26.63551 macro-f1: 0.16667\n",
            "each epochs training time : 117m 41s\n",
            "\n",
            "\n",
            "Epoch 59/100\n",
            "----------\n",
            "train Loss: 2.63165 Acc: 30.20381 macro-f1: 0.20568\n",
            "vaild Loss: 2.61538 Acc: 32.86604 macro-f1: 0.16667\n",
            "==> best model saved - 59 / 32.9\n",
            "each epochs training time : 119m 42s\n",
            "\n",
            "\n",
            "Epoch 60/100\n",
            "----------\n",
            "train Loss: 2.64452 Acc: 28.90077 macro-f1: 0.21806\n",
            "vaild Loss: 2.78872 Acc: 26.40187 macro-f1: 0.00000\n",
            "each epochs training time : 121m 42s\n",
            "\n",
            "\n",
            "Epoch 61/100\n",
            "----------\n",
            "train Loss: 2.80198 Acc: 27.99866 macro-f1: 0.08333\n",
            "vaild Loss: 2.85366 Acc: 25.54517 macro-f1: 0.41667\n",
            "each epochs training time : 123m 43s\n",
            "\n",
            "\n",
            "Epoch 62/100\n",
            "----------\n",
            "train Loss: 2.71867 Acc: 28.16572 macro-f1: 0.06176\n",
            "vaild Loss: 2.51332 Acc: 33.17757 macro-f1: 0.13333\n",
            "==> best model saved - 62 / 33.2\n",
            "each epochs training time : 125m 43s\n",
            "\n",
            "\n",
            "Epoch 63/100\n",
            "----------\n",
            "train Loss: 3.75305 Acc: 12.26194 macro-f1: 0.00000\n",
            "vaild Loss: 4.00405 Acc: 5.68536 macro-f1: 0.00000\n",
            "each epochs training time : 127m 44s\n",
            "\n",
            "\n",
            "Epoch 64/100\n",
            "----------\n",
            "train Loss: nan Acc: 6.08086 macro-f1: 0.00000\n",
            "vaild Loss: nan Acc: 0.23364 macro-f1: 0.00000\n",
            "each epochs training time : 129m 33s\n",
            "\n",
            "\n",
            "Epoch 65/100\n",
            "----------\n",
            "train Loss: nan Acc: 0.23388 macro-f1: 0.00000\n",
            "vaild Loss: nan Acc: 0.23364 macro-f1: 0.00000\n",
            "each epochs training time : 131m 8s\n",
            "\n",
            "\n",
            "Epoch 66/100\n",
            "----------\n",
            "train Loss: nan Acc: 0.23388 macro-f1: 0.00000\n",
            "vaild Loss: nan Acc: 0.23364 macro-f1: 0.00000\n",
            "each epochs training time : 132m 42s\n",
            "\n",
            "\n",
            "Epoch 67/100\n",
            "----------\n",
            "train Loss: nan Acc: 0.23388 macro-f1: 0.00000\n",
            "vaild Loss: nan Acc: 0.23364 macro-f1: 0.00000\n",
            "each epochs training time : 134m 17s\n",
            "\n",
            "\n",
            "Epoch 68/100\n",
            "----------\n",
            "train Loss: nan Acc: 0.23388 macro-f1: 0.00000\n",
            "vaild Loss: nan Acc: 0.23364 macro-f1: 0.00000\n",
            "each epochs training time : 135m 52s\n",
            "\n",
            "\n",
            "Epoch 69/100\n",
            "----------\n",
            "train Loss: nan Acc: 0.23388 macro-f1: 0.00000\n",
            "vaild Loss: nan Acc: 0.23364 macro-f1: 0.00000\n",
            "each epochs training time : 137m 27s\n",
            "\n",
            "\n",
            "Epoch 70/100\n",
            "----------\n",
            "train Loss: nan Acc: 0.23388 macro-f1: 0.01010\n",
            "vaild Loss: nan Acc: 0.23364 macro-f1: 0.00000\n",
            "each epochs training time : 139m 2s\n",
            "\n",
            "\n",
            "Epoch 71/100\n",
            "----------\n",
            "train Loss: nan Acc: 0.23388 macro-f1: 0.00000\n",
            "vaild Loss: nan Acc: 0.23364 macro-f1: 0.00000\n",
            "each epochs training time : 140m 37s\n",
            "\n",
            "\n",
            "Epoch 72/100\n",
            "----------\n",
            "train Loss: nan Acc: 0.23388 macro-f1: 0.00000\n",
            "vaild Loss: nan Acc: 0.23364 macro-f1: 0.00000\n",
            "each epochs training time : 142m 11s\n",
            "\n",
            "\n",
            "Epoch 73/100\n",
            "----------\n",
            "train Loss: nan Acc: 0.23388 macro-f1: 0.00000\n",
            "vaild Loss: nan Acc: 0.23364 macro-f1: 0.00000\n",
            "each epochs training time : 143m 46s\n",
            "\n",
            "\n",
            "Epoch 74/100\n",
            "----------\n",
            "train Loss: nan Acc: 0.23388 macro-f1: 0.00000\n",
            "vaild Loss: nan Acc: 0.23364 macro-f1: 0.00000\n",
            "each epochs training time : 145m 21s\n",
            "\n",
            "\n",
            "Epoch 75/100\n",
            "----------\n",
            "train Loss: nan Acc: 0.23388 macro-f1: 0.00000\n",
            "vaild Loss: nan Acc: 0.23364 macro-f1: 0.00000\n",
            "each epochs training time : 146m 56s\n",
            "\n",
            "\n",
            "Epoch 76/100\n",
            "----------\n",
            "train Loss: nan Acc: 0.23388 macro-f1: 0.00000\n",
            "vaild Loss: nan Acc: 0.23364 macro-f1: 0.00000\n",
            "each epochs training time : 148m 31s\n",
            "\n",
            "\n",
            "Epoch 77/100\n",
            "----------\n",
            "train Loss: nan Acc: 0.23388 macro-f1: 0.00000\n",
            "vaild Loss: nan Acc: 0.23364 macro-f1: 0.00000\n",
            "each epochs training time : 150m 6s\n",
            "\n",
            "\n",
            "Epoch 78/100\n",
            "----------\n",
            "train Loss: nan Acc: 0.23388 macro-f1: 0.00000\n",
            "vaild Loss: nan Acc: 0.23364 macro-f1: 0.00000\n",
            "each epochs training time : 151m 41s\n",
            "\n",
            "\n",
            "Epoch 79/100\n",
            "----------\n",
            "train Loss: nan Acc: 0.23388 macro-f1: 0.00000\n",
            "vaild Loss: nan Acc: 0.23364 macro-f1: 0.00000\n",
            "each epochs training time : 153m 16s\n",
            "\n",
            "\n",
            "Epoch 80/100\n",
            "----------\n",
            "train Loss: nan Acc: 0.23388 macro-f1: 0.00000\n",
            "vaild Loss: nan Acc: 0.23364 macro-f1: 0.00000\n",
            "each epochs training time : 154m 50s\n",
            "\n",
            "\n",
            "Epoch 81/100\n",
            "----------\n",
            "train Loss: nan Acc: 0.23388 macro-f1: 0.00000\n",
            "vaild Loss: nan Acc: 0.23364 macro-f1: 0.00000\n",
            "each epochs training time : 156m 25s\n",
            "\n",
            "\n",
            "Epoch 82/100\n",
            "----------\n",
            "train Loss: nan Acc: 0.23388 macro-f1: 0.00000\n",
            "vaild Loss: nan Acc: 0.23364 macro-f1: 0.00000\n",
            "each epochs training time : 158m 0s\n",
            "\n",
            "\n",
            "Epoch 83/100\n",
            "----------\n",
            "train Loss: nan Acc: 0.23388 macro-f1: 0.00000\n",
            "vaild Loss: nan Acc: 0.23364 macro-f1: 0.00000\n",
            "each epochs training time : 159m 35s\n",
            "\n",
            "\n",
            "Epoch 84/100\n",
            "----------\n",
            "train Loss: nan Acc: 0.23388 macro-f1: 0.00000\n",
            "vaild Loss: nan Acc: 0.23364 macro-f1: 0.00000\n",
            "each epochs training time : 161m 10s\n",
            "\n",
            "\n",
            "Epoch 85/100\n",
            "----------\n",
            "train Loss: nan Acc: 0.23388 macro-f1: 0.00000\n",
            "vaild Loss: nan Acc: 0.23364 macro-f1: 0.00000\n",
            "each epochs training time : 162m 45s\n",
            "\n",
            "\n",
            "Epoch 86/100\n",
            "----------\n",
            "train Loss: nan Acc: 0.23388 macro-f1: 0.00000\n",
            "vaild Loss: nan Acc: 0.23364 macro-f1: 0.00000\n",
            "each epochs training time : 164m 19s\n",
            "\n",
            "\n",
            "Epoch 87/100\n",
            "----------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-412a340e76c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;31m# 사전학습된 가중치와 모델을 가져와 데이터셋으로 추가 모델 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-412a340e76c9>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# Iterate over data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# device = torch.device('cuda')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# device = torch.device('cuda')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-fd746c22d229>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     51\u001b[0m           \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomVerticalFlip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m           \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomHorizontalFlip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m           \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# PIL or ndarray -> tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m           \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.485\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.456\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.406\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.229\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.225\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \"\"\"\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# handle PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mmode_to_nptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"I\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I;16\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"F\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_to_nptype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'Image'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 결과 그래프 그리기\n",
        "print('best model : %d - %1.f / %.1f'%(best_idx, valid_acc[best_idx], valid_loss[best_idx]))\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(train_acc, 'b-')\n",
        "ax1.plot(valid_acc, 'r-')\n",
        "plt.plot(best_idx, valid_acc[best_idx], 'ro')\n",
        "ax1.set_xlabel('epoch')\n",
        "# Make the y-axis label, ticks and tick labels match the line color.\n",
        "ax1.set_ylabel('acc', color='k')\n",
        "ax1.tick_params('y', colors='k')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(train_loss, 'g-')\n",
        "ax2.plot(valid_loss, 'k-')\n",
        "plt.plot(best_idx, valid_loss[best_idx], 'ro')\n",
        "ax2.set_ylabel('loss', color='k')\n",
        "ax2.tick_params('y', colors='k')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5kJPLUuEU1pH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JJdS3MynU1rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ## 학습 결과 검수\n",
        "# def test_and_visualize_model(model, phase = 'test', num_images=4):\n",
        "#     # phase = 'train', 'valid', 'test'\n",
        "    \n",
        "#     was_training = model.training\n",
        "#     model.eval()\n",
        "#     fig = plt.figure()\n",
        "    \n",
        "#     running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
        "#             inputs = inputs.to(device)\n",
        "#             labels = labels.to(device)\n",
        "\n",
        "#             outputs = model(inputs)\n",
        "#             _, preds = torch.max(outputs, 1)\n",
        "#             loss = criterion(outputs, labels)  # batch의 평균 loss 출력\n",
        "\n",
        "#             running_loss    += loss.item() * inputs.size(0)\n",
        "#             running_corrects+= torch.sum(preds == labels.data)\n",
        "#             num_cnt += inputs.size(0)  # batch size\n",
        "\n",
        "#     #         if i == 2: break\n",
        "\n",
        "#         test_loss = running_loss / num_cnt\n",
        "#         test_acc  = running_corrects.double() / num_cnt       \n",
        "#         print('test done : loss/acc : %.2f / %.1f' % (test_loss, test_acc*100))\n",
        "\n",
        "#     # 예시 그림 plot\n",
        "#     with torch.no_grad():\n",
        "#         for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
        "#             inputs = inputs.to(device)\n",
        "#             labels = labels.to(device)\n",
        "\n",
        "#             outputs = model(inputs)\n",
        "#             _, preds = torch.max(outputs, 1)        \n",
        "\n",
        "#             # 예시 그림 plot\n",
        "#             for j in range(1, num_images+1):\n",
        "#                 ax = plt.subplot(num_images//2, 2, j)\n",
        "#                 ax.axis('off')\n",
        "#                 ax.set_title('%s : %s -> %s'%(\n",
        "#                     'True' if class_names[str(labels[j].cpu().numpy())]==class_names[str(preds[j].cpu().numpy())] else 'False',\n",
        "#                     class_names[str(labels[j].cpu().numpy())], class_names[str(preds[j].cpu().numpy())]))\n",
        "#                 imshow(inputs.cpu().data[j])          \n",
        "#             if i == 0 : break\n",
        "\n",
        "\n",
        "#     model.train(mode=was_training);  # 다시 train모드로\n",
        "    \n",
        "#     ## TEST!\n",
        "#     test_and_visualize_model(model, phase = 'test')"
      ],
      "metadata": {
        "id": "bZK4jMWoU1tQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LedsQjpUU1vI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "X2jIgWqSU1w9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-o1YRRNYU1zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 추론"
      ],
      "metadata": {
        "id": "WQR1RKgTpKk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 모델을 평가 모드로 변경하고 test 데이터 분류\n",
        "test_png = sorted(glob('/content/drive/Othercomputers/내 MacBook Pro/open/test/*.png'))\n",
        "test_imgs = [img_load(n) for n in tqdm(test_png)]\n",
        "test_dataset = Custom_dataset_3(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "model.eval()\n",
        "f_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in (test_loader):\n",
        "        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            pred = model(x)\n",
        "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
      ],
      "metadata": {
        "id": "gj7gTQv6U11P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 숫자로된 레이블을 문자열 레이블로 변경\n",
        "label_decoder = {value:key for key, value in label_unique.items()}\n",
        "f_result = [label_decoder[result] for result in f_pred]"
      ],
      "metadata": {
        "id": "30_rcMw4U13G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime as dt \n",
        "today = dt.today().strftime('%Y-%m-%d')\n",
        "version = f'vit_base_patch16_224_by_timm_data_ver2_{today}'\n",
        "submission = pd.read_csv(f\"/content/drive/MyDrive/DACON_이상치 탐지 알고리즘 경진대회/open/sample_submission.csv\")\n",
        "\n",
        "## 시각적 확인을 위해 문자열 레이블로 이루어진 된 label 필드 생성\n",
        "submission[\"label\"] = f_result\n",
        "display(submission)\n",
        "submission.to_csv(f\"/content/drive/MyDrive/DACON_이상치 탐지 알고리즘 경진대회/open/sample_submission_{version}.csv\", index = False)"
      ],
      "metadata": {
        "id": "1zWu-D7WdRmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cG_tNWs2zxh8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}