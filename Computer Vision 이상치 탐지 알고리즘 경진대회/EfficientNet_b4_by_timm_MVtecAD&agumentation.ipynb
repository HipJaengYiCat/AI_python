{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNet_MVtecAD_Dataset",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seunghee0518/AI_python/blob/main/EfficientNet_b4_by_timm_MVtecAD_%EA%B8%B0%EB%B3%B8_%EC%A6%9D%EA%B0%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## trina/ test 나눠서 학습"
      ],
      "metadata": {
        "id": "lynhGDxilbRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "torch.hub : Pytorch Hub는 연구 재현성을 촉진하도록 설계된 사전 훈련 된 모델 저장소\n",
        "nvidia_efficientnet_b4 사전 모델 가져옴\n",
        "'''\n",
        "# import torch\n",
        "# model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b4', pretrained=True)\n",
        "!pip install timm\n",
        "import timm\n",
        "model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=88)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ-ytfDpoKMH",
        "outputId": "a56acc45-8d56-41e6-e4fe-59f2d0f7cb4b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[K     |████████████████████████████████| 431 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.12.0+cu113)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2021.10.8)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.5.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b4_ra2_320-7eb33cd5.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b4_ra2_320-7eb33cd5.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from pprint import pprint\n",
        "# model_names = timm.list_models(pretrained=True)\n",
        "# pprint(model_names)"
      ],
      "metadata": {
        "id": "invECZxkPTyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKXv22Yk6zus",
        "outputId": "70a8fb85-bdaf-4af7-e7dc-ac98d9b98a29"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 학습 코드\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "#import timm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import transforms, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "from PIL import Image\n",
        "# from efficientnet_pytorch import EfficientNet\n",
        "# model_name = 'efficientnet-b0'  # b5\n",
        "\n",
        "# image_size = EfficientNet.get_image_size(model_name)\n",
        "# print(image_size)\n",
        "# model = EfficientNet.from_pretrained(model_name, num_classes=88)"
      ],
      "metadata": {
        "id": "Gjs-R_R5lUKg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 기본 설정\n",
        "device = torch.device('cuda')\n",
        "batch_size  = 32\n",
        "random_seed = 1234\n",
        "img_size = 224\n",
        "random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZHMCtAvlDOp",
        "outputId": "be7f1742-c0bc-42f7-bb31-3fbfd2f98790"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f6ed74b7970>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## transforms 함수 정리\n",
        "* transforms.ToPILImage() - csv 파일로 데이터셋을 받을 경우, PIL image로 바꿔준다.\n",
        "* transforms.CenterCrop(size) - 가운데 부분을 size 크기로 자른다.\n",
        "* transforms.Grayscale(num_output_channels=1) - grayscale로 변환한다.\n",
        "* transforms.RandomAffine(degrees) - 랜덤으로 affine 변형을 한다.\n",
        "* transforms.RandomCrop(size) -이미지를 랜덤으로 아무데나 잘라 size 크기로 출력한다.\n",
        "* transforms.RandomResizedCrop(size) - 이미지 사이즈를 size로 변경한다\n",
        "* transforms.Resize(size) - 이미지 사이즈를 size로 변경한다\n",
        "* transforms.RandomRotation(degrees) 이미지를 랜덤으로 degrees 각도로 회전한다.\n",
        "* transforms.RandomResizedCrop(size, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333)) - 이미지를 랜덤으로 변형한다.\n",
        "* transforms.RandomVerticalFlip(p=0.5) - 이미지를 랜덤으로 수직으로 뒤집는다. p =0이면 뒤집지 않는다.\n",
        "* transforms.RandomHorizontalFlip(p=0.5) - 이미지를 랜덤으로 수평으로 뒤집는다.\n",
        "* transforms.ToTensor() - 이미지 데이터를 tensor로 바꿔준다.\n",
        "* transforms.Normalize(mean, std, inplace=False) - 이미지를 정규화한다."
      ],
      "metadata": {
        "id": "fTgH3bYzN7RA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 데이터 전처리 함수\n",
        "# make dataset\n",
        "#data_path = 'president/president_data'  # class 별 폴더로 나누어진 걸 가져와서 라벨도 달아준다\n",
        "# train_dataset = datasets.ImageFolder(data_path,\n",
        "#                                      transforms.Compose([\n",
        "#                                      transforms.Resize((224, 224)),\n",
        "#                                      transforms.RandomCrop(224),\n",
        "#                                      transforms.RandomRotation(90, expand=True),\n",
        "#                                      transforms.RandomVerticalFlip(),\n",
        "#                                      transforms.RandomHorizontalFlip(),\n",
        "#                                      transforms.ToTensor(), # 이미지 데이터를 tensor로 바꿔준다.\n",
        "#                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])) # Normalize는 많은 이미지의 평균, 표준편차로 정함(보통 많이 하는 값이라고함)\n",
        "\n",
        "\n",
        "### 이미지 전처리 함수 & 클래스\n",
        "## 이미지  > 넘파이 배열로 변환\n",
        "def img_load(path):\n",
        "    img = cv2.imread(path)[:,:,::-1] # Return type:\tnumpy.ndarray / 기본적으로 BGR로 불러옴, RGB 변환함\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    return img\n",
        "\n",
        "class Custom_dataset_1(Dataset): # 기본\n",
        "    def __init__(self, img_paths, labels, mode='train'):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode = mode\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.img_paths[idx]\n",
        "        img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "        img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "        ## 레이블 > 원-핫 인코딩 하기 \n",
        "        label = self.labels[idx]# (원핫인코딩 안할거면 해당 코드만 필요)\n",
        "        return img, label\n",
        "\n",
        "class Custom_dataset_2(Dataset): # 변형\n",
        "    def __init__(self, img_paths, labels, mode='train'):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode = mode\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.img_paths[idx]\n",
        "        if self.mode == 'train':\n",
        "          img = Image.fromarray(img)\n",
        "          #img = transforms.Resize((img_size, img_size))(img) # 처음 이미지 불러올때 resize 했으므로 생략\n",
        "          #img = transforms.RandomCrop(img_size)(img)\n",
        "          img = transforms.RandomRotation(90, expand=False)(img)\n",
        "          img = transforms.RandomVerticalFlip()(img)\n",
        "          img = transforms.RandomHorizontalFlip()(img)\n",
        "          img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "          img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "        if self.mode=='test':\n",
        "          img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "        ## 레이블\n",
        "        label = self.labels[idx]# (원핫인코딩 안할거면 해당 코드만 필요)\n",
        "        return img, label\n",
        "\n",
        "class Custom_dataset_3(Dataset): # 기본이미지 + 변형이미지 (train 시 2배 증량됨)\n",
        "    def __init__(self, img_paths, labels, mode='train'):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode=mode\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.mode=='train':\n",
        "          if idx < 4277: # 변경 없는 이미지\n",
        "            img = self.img_paths[idx]\n",
        "            img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "            img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "            label = self.labels[idx]\n",
        "            return img, label\n",
        "\n",
        "          else : # 랜덤 변경된 이미지 추가됨 \n",
        "            img = self.img_paths[idx]\n",
        "            img = Image.fromarray(img)\n",
        "            #img = transforms.Resize((img_size, img_size))(img) # 처음 이미지 불러올때 resize 했으므로 생략\n",
        "            #img = transforms.RandomCrop(img_size)(img)\n",
        "            img = transforms.RandomRotation(90, expand=False)(img)\n",
        "            img = transforms.RandomVerticalFlip()(img)\n",
        "            img = transforms.RandomHorizontalFlip()(img)\n",
        "            img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "            img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "            label = self.labels[idx]\n",
        "            return img, label\n",
        "\n",
        "        if self.mode=='test':\n",
        "          img = self.img_paths[idx]\n",
        "          img = transforms.ToTensor()(img)\n",
        "          img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "          label = self.labels[idx]\n",
        "          return img, label\n",
        "            "
      ],
      "metadata": {
        "id": "ORqFbwLXpSeu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 이미지 로드 및 전처리\n",
        "# 이미지 경로\n",
        "train_png = sorted(glob('/content/drive/Othercomputers/내 MacBook Pro/open/train/*.png'))\n",
        "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
        "\n",
        "#train_imgs = np.load('/content/drive/MyDrive/DACON_이상치 탐지 알고리즘 경진대회/train_imgs_224.npy')\n",
        "train_y = pd.read_csv(\"/content/drive/Othercomputers/내 MacBook Pro/open/train_df.csv\")\n",
        "\n",
        "train_labels = train_y[\"label\"] # 레이블순서는 이미지 파일 순서대로임\n",
        "\n",
        "label_unique = sorted(np.unique(train_labels))\n",
        "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))} # 오름차순으로 레이블별로 숫자 부여(0부터 시작)\n",
        "\n",
        "train_labels = [label_unique[k] for k in train_labels]\n",
        "\n",
        "## 커스텀 이미지 생성\n",
        "# train_dataset = Custom_dataset_2(np.array(train_imgs), np.array(train_labels), mode='train')\n",
        "# train_idx, vaild_idx = train_test_split(list(range(len(train_dataset))), stratify=train_labels, test_size=0.3, random_state=random_seed)\n",
        "\n",
        "## 이미지 증량 시만 사용\n",
        "train_imgs = train_imgs + train_imgs\n",
        "train_labels = train_labels+train_labels\n",
        "\n",
        "train_dataset = Custom_dataset_3(np.array(train_imgs), np.array(train_labels), mode='train')\n",
        "\n",
        "### 데이터셋 분리 > 층화추출 & 테스터 데이터 비율 : 0.3, 시드 : 1234, 셔플 = True(default)\n",
        "train_idx, vaild_idx = train_test_split(list(range(len(train_dataset))), stratify=train_labels, test_size=0.3, random_state=random_seed)\n",
        "\n",
        "datasets = {} # 데이터셋을 담을 딕셔너리\n",
        "datasets['train'] = Subset(train_dataset, train_idx)\n",
        "datasets['vaild']  = Subset(train_dataset, vaild_idx)\n",
        "\n",
        "## data loader 선언\n",
        "dataloaders, batch_num = {}, {}\n",
        "dataloaders['train'] = torch.utils.data.DataLoader(datasets['train'],\n",
        "                                                  batch_size=batch_size, shuffle=True,\n",
        "                                                  num_workers=0)\n",
        "dataloaders['vaild']  = torch.utils.data.DataLoader(datasets['vaild'],\n",
        "                                                    batch_size=batch_size, shuffle=False,\n",
        "                                                    num_workers=0)\n",
        "'''\n",
        "데이터 변형 코드를 추가한 후 아래 오류코드가 나와\n",
        "Caught TypeError in DataLoader worker process 0\n",
        "DataLoader > num_workers 를 4 -> 0 로 낮춤\n",
        "'''\n",
        "\n",
        "batch_num['train'], batch_num['vaild'] = len(dataloaders['train']), len(dataloaders['vaild'])\n",
        "print('batch_size : %d,  train/vaild(데이터셋개수/배치사이즈) : %d / %d' % (batch_size, batch_num['train'],batch_num['vaild']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItvLP1Y3k-OW",
        "outputId": "67ddfc8f-d87c-43ec-a26f-bc26ed5a6ffa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4277/4277 [05:13<00:00, 13.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_size : 32,  train/vaild(데이터셋개수/배치사이즈) : 188 / 81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 참고 블로그 : https://keep-steady.tistory.com/35\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "### f1 스코어 함수 \n",
        "def score_function(real, pred): # 라이브러리 > sklearn.metrics \n",
        "    score = f1_score(real, pred, average=\"macro\")\n",
        "    return score\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    #train_loss, train_acc, valid_loss, valid_acc = [], [], [], []\n",
        "    train_loss, train_acc, valid_loss, valid_acc, train_f1, valid_f1 = [], [], [], [], [], []\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))# - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'vaild']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
        "            \n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device) # device = torch.device('cuda')\n",
        "                labels = labels.to(device) # device = torch.device('cuda')\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                num_cnt += len(labels)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "            \n",
        "            epoch_loss = float(running_loss / num_cnt)\n",
        "            epoch_acc  = float((running_corrects.double() / num_cnt).cpu()*100)\n",
        "            f1 = score_function(labels.cpu().data, preds.cpu()) # score_function or f1_score\n",
        "\n",
        "            if phase == 'train':\n",
        "                train_loss.append(epoch_loss)\n",
        "                train_acc.append(epoch_acc)\n",
        "                train_f1.append(f1)\n",
        "            else:\n",
        "                valid_loss.append(epoch_loss)\n",
        "                valid_acc.append(epoch_acc)\n",
        "                valid_f1.append(f1)\n",
        "\n",
        "            print('{} Loss: {:.5f} Acc: {:.5f} macro-f1: {:.5f}'.format(phase, epoch_loss, epoch_acc, f1))\n",
        "           \n",
        "            # deep copy the model(최적모델 저장)\n",
        "            if phase == 'vaild' and epoch_acc > best_acc:\n",
        "                best_idx = epoch\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "#                 best_model_wts = copy.deepcopy(model.module.state_dict())\n",
        "                print('==> best model saved - %d / %.1f'%(best_idx, best_acc))\n",
        "        # 한 에포크마다 실행 시간 출력하기(누적 시간으로 출력됨)\n",
        "        time_elapsed = time.time() - since\n",
        "        print('each epochs training time : {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "        print('\\n')\n",
        "\n",
        "        # 한 에포크마다 필요없는 메모리 지우기 : 지우기 효과는 아직 확인 못해봄\n",
        "        try:      \n",
        "          gc.collect() # cpu 비움\n",
        "          torch.cuda.empty_cache() # gpu 비움\n",
        "        except:\n",
        "          pass\n",
        "          \n",
        "    ## 학습 마무리 후\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best valid Acc: %d - %.1f' %(best_idx, best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    '''\n",
        "    한 에포크 마다 저장된 최적의 모델 가중치로 조정 후 다음 에포크가 돌아감\n",
        "    '''\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    torch.save(model.state_dict(), 'president_model.pt')\n",
        "    print('model saved')\n",
        "    return model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc, train_f1, valid_f1\n",
        "\n",
        "# 설정\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # set gpu\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_ft = optim.SGD(model.parameters(), \n",
        "                         lr = 0.05,\n",
        "                         momentum=0.9,\n",
        "                         weight_decay=1e-4)\n",
        "\n",
        "lmbda = lambda epoch: 0.98739\n",
        "exp_lr_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer_ft, lr_lambda=lmbda)\n",
        "\n",
        "# 사전학습된 가중치와 모델을 가져와 데이터셋으로 추가 모델 학습\n",
        "model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc, train_f1, valid_f1 = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDNj4Yarkx-R",
        "outputId": "09ee2561-0cb9-4434-96ca-65c556296f7c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/100\n",
            "----------\n",
            "train Loss: 1.06115 Acc: 82.04443 macro-f1: 0.20000\n",
            "vaild Loss: 0.54104 Acc: 87.10557 macro-f1: 1.00000\n",
            "==> best model saved - 0 / 87.1\n",
            "each epochs training time : 1m 39s\n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "----------\n",
            "train Loss: 0.46699 Acc: 88.37481 macro-f1: 0.50000\n",
            "vaild Loss: 0.40596 Acc: 89.75458 macro-f1: 0.71429\n",
            "==> best model saved - 1 / 89.8\n",
            "each epochs training time : 3m 22s\n",
            "\n",
            "\n",
            "Epoch 2/100\n",
            "----------\n",
            "train Loss: 0.34775 Acc: 90.84683 macro-f1: 0.50000\n",
            "vaild Loss: 0.32327 Acc: 91.35177 macro-f1: 1.00000\n",
            "==> best model saved - 2 / 91.4\n",
            "each epochs training time : 5m 5s\n",
            "\n",
            "\n",
            "Epoch 3/100\n",
            "----------\n",
            "train Loss: 0.25461 Acc: 93.15183 macro-f1: 1.00000\n",
            "vaild Loss: 0.26693 Acc: 92.59836 macro-f1: 1.00000\n",
            "==> best model saved - 3 / 92.6\n",
            "each epochs training time : 6m 48s\n",
            "\n",
            "\n",
            "Epoch 4/100\n",
            "----------\n",
            "train Loss: 0.18869 Acc: 94.73860 macro-f1: 0.50000\n",
            "vaild Loss: 0.21890 Acc: 93.76704 macro-f1: 0.71429\n",
            "==> best model saved - 4 / 93.8\n",
            "each epochs training time : 8m 31s\n",
            "\n",
            "\n",
            "Epoch 5/100\n",
            "----------\n",
            "train Loss: 0.15783 Acc: 95.74077 macro-f1: 1.00000\n",
            "vaild Loss: 0.18079 Acc: 94.85781 macro-f1: 1.00000\n",
            "==> best model saved - 5 / 94.9\n",
            "each epochs training time : 10m 14s\n",
            "\n",
            "\n",
            "Epoch 6/100\n",
            "----------\n",
            "train Loss: 0.11807 Acc: 96.64273 macro-f1: 0.55556\n",
            "vaild Loss: 0.17573 Acc: 94.81885 macro-f1: 1.00000\n",
            "each epochs training time : 11m 56s\n",
            "\n",
            "\n",
            "Epoch 7/100\n",
            "----------\n",
            "train Loss: 0.10778 Acc: 96.89327 macro-f1: 1.00000\n",
            "vaild Loss: 0.16125 Acc: 95.63693 macro-f1: 0.71429\n",
            "==> best model saved - 7 / 95.6\n",
            "each epochs training time : 13m 39s\n",
            "\n",
            "\n",
            "Epoch 8/100\n",
            "----------\n",
            "train Loss: 0.08193 Acc: 97.47787 macro-f1: 1.00000\n",
            "vaild Loss: 0.14688 Acc: 95.87067 macro-f1: 1.00000\n",
            "==> best model saved - 8 / 95.9\n",
            "each epochs training time : 15m 22s\n",
            "\n",
            "\n",
            "Epoch 9/100\n",
            "----------\n",
            "train Loss: 0.07205 Acc: 97.91214 macro-f1: 0.50000\n",
            "vaild Loss: 0.15430 Acc: 95.90962 macro-f1: 1.00000\n",
            "==> best model saved - 9 / 95.9\n",
            "each epochs training time : 17m 5s\n",
            "\n",
            "\n",
            "Epoch 10/100\n",
            "----------\n",
            "train Loss: 0.07213 Acc: 98.14598 macro-f1: 1.00000\n",
            "vaild Loss: 0.12907 Acc: 96.45501 macro-f1: 1.00000\n",
            "==> best model saved - 10 / 96.5\n",
            "each epochs training time : 18m 48s\n",
            "\n",
            "\n",
            "Epoch 11/100\n",
            "----------\n",
            "train Loss: 0.06411 Acc: 98.07917 macro-f1: 1.00000\n",
            "vaild Loss: 0.13257 Acc: 96.61083 macro-f1: 1.00000\n",
            "==> best model saved - 11 / 96.6\n",
            "each epochs training time : 20m 31s\n",
            "\n",
            "\n",
            "Epoch 12/100\n",
            "----------\n",
            "train Loss: 0.04773 Acc: 98.42993 macro-f1: 0.50000\n",
            "vaild Loss: 0.12753 Acc: 96.49396 macro-f1: 1.00000\n",
            "each epochs training time : 22m 14s\n",
            "\n",
            "\n",
            "Epoch 13/100\n",
            "----------\n",
            "train Loss: 0.06131 Acc: 98.39653 macro-f1: 1.00000\n",
            "vaild Loss: 0.11516 Acc: 96.92248 macro-f1: 1.00000\n",
            "==> best model saved - 13 / 96.9\n",
            "each epochs training time : 23m 57s\n",
            "\n",
            "\n",
            "Epoch 14/100\n",
            "----------\n",
            "train Loss: 0.03661 Acc: 99.04794 macro-f1: 1.00000\n",
            "vaild Loss: 0.11990 Acc: 96.92248 macro-f1: 1.00000\n",
            "each epochs training time : 25m 40s\n",
            "\n",
            "\n",
            "Epoch 15/100\n",
            "----------\n",
            "train Loss: 0.03578 Acc: 99.01453 macro-f1: 1.00000\n",
            "vaild Loss: 0.10794 Acc: 97.07830 macro-f1: 1.00000\n",
            "==> best model saved - 15 / 97.1\n",
            "each epochs training time : 27m 23s\n",
            "\n",
            "\n",
            "Epoch 16/100\n",
            "----------\n",
            "train Loss: 0.03451 Acc: 98.99783 macro-f1: 1.00000\n",
            "vaild Loss: 0.10932 Acc: 97.19517 macro-f1: 1.00000\n",
            "==> best model saved - 16 / 97.2\n",
            "each epochs training time : 29m 5s\n",
            "\n",
            "\n",
            "Epoch 17/100\n",
            "----------\n",
            "train Loss: 0.03634 Acc: 98.99783 macro-f1: 1.00000\n",
            "vaild Loss: 0.13131 Acc: 96.92248 macro-f1: 1.00000\n",
            "each epochs training time : 30m 48s\n",
            "\n",
            "\n",
            "Epoch 18/100\n",
            "----------\n",
            "train Loss: 0.03902 Acc: 98.98113 macro-f1: 0.55556\n",
            "vaild Loss: 0.10014 Acc: 97.31204 macro-f1: 1.00000\n",
            "==> best model saved - 18 / 97.3\n",
            "each epochs training time : 32m 31s\n",
            "\n",
            "\n",
            "Epoch 19/100\n",
            "----------\n",
            "train Loss: 0.03311 Acc: 98.98113 macro-f1: 1.00000\n",
            "vaild Loss: 0.11191 Acc: 96.88352 macro-f1: 1.00000\n",
            "each epochs training time : 34m 14s\n",
            "\n",
            "\n",
            "Epoch 20/100\n",
            "----------\n",
            "train Loss: 0.02526 Acc: 99.26507 macro-f1: 0.50000\n",
            "vaild Loss: 0.12276 Acc: 97.27308 macro-f1: 1.00000\n",
            "each epochs training time : 35m 57s\n",
            "\n",
            "\n",
            "Epoch 21/100\n",
            "----------\n",
            "train Loss: 0.03080 Acc: 99.21497 macro-f1: 0.50000\n",
            "vaild Loss: 0.10532 Acc: 97.46786 macro-f1: 1.00000\n",
            "==> best model saved - 21 / 97.5\n",
            "each epochs training time : 37m 40s\n",
            "\n",
            "\n",
            "Epoch 22/100\n",
            "----------\n",
            "train Loss: 0.02944 Acc: 99.09805 macro-f1: 0.00000\n",
            "vaild Loss: 0.12853 Acc: 97.03935 macro-f1: 1.00000\n",
            "each epochs training time : 39m 22s\n",
            "\n",
            "\n",
            "Epoch 23/100\n",
            "----------\n",
            "train Loss: 0.03067 Acc: 99.11475 macro-f1: 0.20000\n",
            "vaild Loss: 0.08803 Acc: 97.74055 macro-f1: 1.00000\n",
            "==> best model saved - 23 / 97.7\n",
            "each epochs training time : 41m 5s\n",
            "\n",
            "\n",
            "Epoch 24/100\n",
            "----------\n",
            "train Loss: 0.04759 Acc: 98.83080 macro-f1: 0.50000\n",
            "vaild Loss: 0.10761 Acc: 97.23413 macro-f1: 1.00000\n",
            "each epochs training time : 42m 48s\n",
            "\n",
            "\n",
            "Epoch 25/100\n",
            "----------\n",
            "train Loss: 0.03826 Acc: 98.96442 macro-f1: 0.50000\n",
            "vaild Loss: 0.10472 Acc: 97.27308 macro-f1: 1.00000\n",
            "each epochs training time : 44m 31s\n",
            "\n",
            "\n",
            "Epoch 26/100\n",
            "----------\n",
            "train Loss: 0.03606 Acc: 98.98113 macro-f1: 1.00000\n",
            "vaild Loss: 0.09245 Acc: 97.58473 macro-f1: 1.00000\n",
            "each epochs training time : 46m 13s\n",
            "\n",
            "\n",
            "Epoch 27/100\n",
            "----------\n",
            "train Loss: 0.02784 Acc: 99.21497 macro-f1: 1.00000\n",
            "vaild Loss: 0.11574 Acc: 97.38995 macro-f1: 1.00000\n",
            "each epochs training time : 47m 56s\n",
            "\n",
            "\n",
            "Epoch 28/100\n",
            "----------\n",
            "train Loss: 0.02725 Acc: 99.24837 macro-f1: 1.00000\n",
            "vaild Loss: 0.10502 Acc: 97.77951 macro-f1: 1.00000\n",
            "==> best model saved - 28 / 97.8\n",
            "each epochs training time : 49m 39s\n",
            "\n",
            "\n",
            "Epoch 29/100\n",
            "----------\n",
            "train Loss: 0.02108 Acc: 99.33189 macro-f1: 0.50000\n",
            "vaild Loss: 0.12002 Acc: 96.84457 macro-f1: 1.00000\n",
            "each epochs training time : 51m 22s\n",
            "\n",
            "\n",
            "Epoch 30/100\n",
            "----------\n",
            "train Loss: 0.02898 Acc: 99.18156 macro-f1: 0.50000\n",
            "vaild Loss: 0.08928 Acc: 97.74055 macro-f1: 1.00000\n",
            "each epochs training time : 53m 5s\n",
            "\n",
            "\n",
            "Epoch 31/100\n",
            "----------\n",
            "train Loss: 0.01860 Acc: 99.58243 macro-f1: 1.00000\n",
            "vaild Loss: 0.07934 Acc: 98.20802 macro-f1: 1.00000\n",
            "==> best model saved - 31 / 98.2\n",
            "each epochs training time : 54m 48s\n",
            "\n",
            "\n",
            "Epoch 32/100\n",
            "----------\n",
            "train Loss: 0.01880 Acc: 99.41540 macro-f1: 0.50000\n",
            "vaild Loss: 0.10011 Acc: 97.50682 macro-f1: 1.00000\n",
            "each epochs training time : 56m 31s\n",
            "\n",
            "\n",
            "Epoch 33/100\n",
            "----------\n",
            "train Loss: 0.02081 Acc: 99.41540 macro-f1: 1.00000\n",
            "vaild Loss: 0.09782 Acc: 97.46786 macro-f1: 1.00000\n",
            "each epochs training time : 58m 14s\n",
            "\n",
            "\n",
            "Epoch 34/100\n",
            "----------\n",
            "train Loss: 0.01564 Acc: 99.53232 macro-f1: 1.00000\n",
            "vaild Loss: 0.09573 Acc: 97.70160 macro-f1: 1.00000\n",
            "each epochs training time : 59m 56s\n",
            "\n",
            "\n",
            "Epoch 35/100\n",
            "----------\n",
            "train Loss: 0.02056 Acc: 99.39870 macro-f1: 0.20000\n",
            "vaild Loss: 0.09185 Acc: 98.01325 macro-f1: 1.00000\n",
            "each epochs training time : 61m 39s\n",
            "\n",
            "\n",
            "Epoch 36/100\n",
            "----------\n",
            "train Loss: 0.02575 Acc: 99.29848 macro-f1: 0.50000\n",
            "vaild Loss: 0.08573 Acc: 97.66264 macro-f1: 1.00000\n",
            "each epochs training time : 63m 22s\n",
            "\n",
            "\n",
            "Epoch 37/100\n",
            "----------\n",
            "train Loss: 0.01935 Acc: 99.51562 macro-f1: 1.00000\n",
            "vaild Loss: 0.07562 Acc: 98.13011 macro-f1: 1.00000\n",
            "each epochs training time : 65m 5s\n",
            "\n",
            "\n",
            "Epoch 38/100\n",
            "----------\n",
            "train Loss: 0.01664 Acc: 99.53232 macro-f1: 1.00000\n",
            "vaild Loss: 0.10260 Acc: 97.27308 macro-f1: 1.00000\n",
            "each epochs training time : 66m 47s\n",
            "\n",
            "\n",
            "Epoch 39/100\n",
            "----------\n",
            "train Loss: 0.01557 Acc: 99.61583 macro-f1: 0.50000\n",
            "vaild Loss: 0.08864 Acc: 98.01325 macro-f1: 1.00000\n",
            "each epochs training time : 68m 30s\n",
            "\n",
            "\n",
            "Epoch 40/100\n",
            "----------\n",
            "train Loss: 0.02053 Acc: 99.49891 macro-f1: 1.00000\n",
            "vaild Loss: 0.10388 Acc: 97.31204 macro-f1: 1.00000\n",
            "each epochs training time : 70m 13s\n",
            "\n",
            "\n",
            "Epoch 41/100\n",
            "----------\n",
            "train Loss: 0.01795 Acc: 99.56573 macro-f1: 1.00000\n",
            "vaild Loss: 0.10756 Acc: 97.27308 macro-f1: 1.00000\n",
            "each epochs training time : 71m 56s\n",
            "\n",
            "\n",
            "Epoch 42/100\n",
            "----------\n",
            "train Loss: 0.00963 Acc: 99.76616 macro-f1: 1.00000\n",
            "vaild Loss: 0.09105 Acc: 98.05220 macro-f1: 1.00000\n",
            "each epochs training time : 73m 38s\n",
            "\n",
            "\n",
            "Epoch 43/100\n",
            "----------\n",
            "train Loss: 0.01220 Acc: 99.63254 macro-f1: 1.00000\n",
            "vaild Loss: 0.12039 Acc: 97.54577 macro-f1: 1.00000\n",
            "each epochs training time : 75m 21s\n",
            "\n",
            "\n",
            "Epoch 44/100\n",
            "----------\n",
            "train Loss: 0.02232 Acc: 99.41540 macro-f1: 1.00000\n",
            "vaild Loss: 0.08968 Acc: 97.74055 macro-f1: 1.00000\n",
            "each epochs training time : 77m 4s\n",
            "\n",
            "\n",
            "Epoch 45/100\n",
            "----------\n",
            "train Loss: 0.01385 Acc: 99.61583 macro-f1: 1.00000\n",
            "vaild Loss: 0.07775 Acc: 98.16907 macro-f1: 1.00000\n",
            "each epochs training time : 78m 47s\n",
            "\n",
            "\n",
            "Epoch 46/100\n",
            "----------\n",
            "train Loss: 0.00968 Acc: 99.74946 macro-f1: 1.00000\n",
            "vaild Loss: 0.08853 Acc: 97.81847 macro-f1: 1.00000\n",
            "each epochs training time : 80m 30s\n",
            "\n",
            "\n",
            "Epoch 47/100\n",
            "----------\n",
            "train Loss: 0.01130 Acc: 99.68265 macro-f1: 0.55556\n",
            "vaild Loss: 0.08903 Acc: 97.89638 macro-f1: 1.00000\n",
            "each epochs training time : 82m 12s\n",
            "\n",
            "\n",
            "Epoch 48/100\n",
            "----------\n",
            "train Loss: 0.01201 Acc: 99.68265 macro-f1: 0.50000\n",
            "vaild Loss: 0.10006 Acc: 97.70160 macro-f1: 1.00000\n",
            "each epochs training time : 83m 55s\n",
            "\n",
            "\n",
            "Epoch 49/100\n",
            "----------\n",
            "train Loss: 0.01620 Acc: 99.53232 macro-f1: 0.50000\n",
            "vaild Loss: 0.08417 Acc: 98.05220 macro-f1: 1.00000\n",
            "each epochs training time : 85m 38s\n",
            "\n",
            "\n",
            "Epoch 50/100\n",
            "----------\n",
            "train Loss: 0.01172 Acc: 99.64924 macro-f1: 0.50000\n",
            "vaild Loss: 0.09058 Acc: 97.93533 macro-f1: 1.00000\n",
            "each epochs training time : 87m 21s\n",
            "\n",
            "\n",
            "Epoch 51/100\n",
            "----------\n",
            "train Loss: 0.01319 Acc: 99.63254 macro-f1: 1.00000\n",
            "vaild Loss: 0.09710 Acc: 97.93533 macro-f1: 1.00000\n",
            "each epochs training time : 89m 4s\n",
            "\n",
            "\n",
            "Epoch 52/100\n",
            "----------\n",
            "train Loss: 0.00819 Acc: 99.79957 macro-f1: 0.00000\n",
            "vaild Loss: 0.08657 Acc: 98.40280 macro-f1: 1.00000\n",
            "==> best model saved - 52 / 98.4\n",
            "each epochs training time : 90m 47s\n",
            "\n",
            "\n",
            "Epoch 53/100\n",
            "----------\n",
            "train Loss: 0.01555 Acc: 99.63254 macro-f1: 1.00000\n",
            "vaild Loss: 0.09550 Acc: 98.20802 macro-f1: 1.00000\n",
            "each epochs training time : 92m 29s\n",
            "\n",
            "\n",
            "Epoch 54/100\n",
            "----------\n",
            "train Loss: 0.01258 Acc: 99.71605 macro-f1: 1.00000\n",
            "vaild Loss: 0.08223 Acc: 98.13011 macro-f1: 1.00000\n",
            "each epochs training time : 94m 12s\n",
            "\n",
            "\n",
            "Epoch 55/100\n",
            "----------\n",
            "train Loss: 0.01089 Acc: 99.64924 macro-f1: 0.33333\n",
            "vaild Loss: 0.07650 Acc: 98.09116 macro-f1: 1.00000\n",
            "each epochs training time : 95m 55s\n",
            "\n",
            "\n",
            "Epoch 56/100\n",
            "----------\n",
            "train Loss: 0.01231 Acc: 99.68265 macro-f1: 1.00000\n",
            "vaild Loss: 0.07083 Acc: 98.28594 macro-f1: 1.00000\n",
            "each epochs training time : 97m 38s\n",
            "\n",
            "\n",
            "Epoch 57/100\n",
            "----------\n",
            "train Loss: 0.00591 Acc: 99.86638 macro-f1: 1.00000\n",
            "vaild Loss: 0.08037 Acc: 98.13011 macro-f1: 1.00000\n",
            "each epochs training time : 99m 20s\n",
            "\n",
            "\n",
            "Epoch 58/100\n",
            "----------\n",
            "train Loss: 0.00658 Acc: 99.83297 macro-f1: 1.00000\n",
            "vaild Loss: 0.09753 Acc: 97.89638 macro-f1: 1.00000\n",
            "each epochs training time : 101m 3s\n",
            "\n",
            "\n",
            "Epoch 59/100\n",
            "----------\n",
            "train Loss: 0.01022 Acc: 99.74946 macro-f1: 1.00000\n",
            "vaild Loss: 0.08304 Acc: 98.13011 macro-f1: 1.00000\n",
            "each epochs training time : 102m 46s\n",
            "\n",
            "\n",
            "Epoch 60/100\n",
            "----------\n",
            "train Loss: 0.00794 Acc: 99.78286 macro-f1: 0.50000\n",
            "vaild Loss: 0.07974 Acc: 98.28594 macro-f1: 1.00000\n",
            "each epochs training time : 104m 29s\n",
            "\n",
            "\n",
            "Epoch 61/100\n",
            "----------\n",
            "train Loss: 0.00932 Acc: 99.74946 macro-f1: 1.00000\n",
            "vaild Loss: 0.08611 Acc: 98.05220 macro-f1: 1.00000\n",
            "each epochs training time : 106m 12s\n",
            "\n",
            "\n",
            "Epoch 62/100\n",
            "----------\n",
            "train Loss: 0.00959 Acc: 99.78286 macro-f1: 1.00000\n",
            "vaild Loss: 0.07967 Acc: 98.32489 macro-f1: 1.00000\n",
            "each epochs training time : 107m 54s\n",
            "\n",
            "\n",
            "Epoch 63/100\n",
            "----------\n",
            "train Loss: 0.00601 Acc: 99.81627 macro-f1: 1.00000\n",
            "vaild Loss: 0.08318 Acc: 98.20802 macro-f1: 1.00000\n",
            "each epochs training time : 109m 37s\n",
            "\n",
            "\n",
            "Epoch 64/100\n",
            "----------\n",
            "train Loss: 0.00680 Acc: 99.81627 macro-f1: 0.50000\n",
            "vaild Loss: 0.08287 Acc: 98.16907 macro-f1: 1.00000\n",
            "each epochs training time : 111m 20s\n",
            "\n",
            "\n",
            "Epoch 65/100\n",
            "----------\n",
            "train Loss: 0.00907 Acc: 99.71605 macro-f1: 0.33333\n",
            "vaild Loss: 0.08280 Acc: 98.32489 macro-f1: 1.00000\n",
            "each epochs training time : 113m 3s\n",
            "\n",
            "\n",
            "Epoch 66/100\n",
            "----------\n",
            "train Loss: 0.00751 Acc: 99.81627 macro-f1: 0.00000\n",
            "vaild Loss: 0.08448 Acc: 98.09116 macro-f1: 1.00000\n",
            "each epochs training time : 114m 46s\n",
            "\n",
            "\n",
            "Epoch 67/100\n",
            "----------\n",
            "train Loss: 0.01033 Acc: 99.71605 macro-f1: 1.00000\n",
            "vaild Loss: 0.08096 Acc: 98.05220 macro-f1: 1.00000\n",
            "each epochs training time : 116m 28s\n",
            "\n",
            "\n",
            "Epoch 68/100\n",
            "----------\n",
            "train Loss: 0.00885 Acc: 99.73275 macro-f1: 1.00000\n",
            "vaild Loss: 0.07328 Acc: 98.20802 macro-f1: 1.00000\n",
            "each epochs training time : 118m 11s\n",
            "\n",
            "\n",
            "Epoch 69/100\n",
            "----------\n",
            "train Loss: 0.00673 Acc: 99.81627 macro-f1: 1.00000\n",
            "vaild Loss: 0.08303 Acc: 98.13011 macro-f1: 1.00000\n",
            "each epochs training time : 119m 54s\n",
            "\n",
            "\n",
            "Epoch 70/100\n",
            "----------\n",
            "train Loss: 0.00723 Acc: 99.81627 macro-f1: 0.50000\n",
            "vaild Loss: 0.09687 Acc: 98.05220 macro-f1: 1.00000\n",
            "each epochs training time : 121m 36s\n",
            "\n",
            "\n",
            "Epoch 71/100\n",
            "----------\n",
            "train Loss: 0.01166 Acc: 99.68265 macro-f1: 0.50000\n",
            "vaild Loss: 0.08381 Acc: 98.24698 macro-f1: 1.00000\n",
            "each epochs training time : 123m 19s\n",
            "\n",
            "\n",
            "Epoch 72/100\n",
            "----------\n",
            "train Loss: 0.00980 Acc: 99.78286 macro-f1: 1.00000\n",
            "vaild Loss: 0.08417 Acc: 98.28594 macro-f1: 1.00000\n",
            "each epochs training time : 125m 2s\n",
            "\n",
            "\n",
            "Epoch 73/100\n",
            "----------\n",
            "train Loss: 0.00834 Acc: 99.78286 macro-f1: 0.20000\n",
            "vaild Loss: 0.09492 Acc: 97.89638 macro-f1: 1.00000\n",
            "each epochs training time : 126m 44s\n",
            "\n",
            "\n",
            "Epoch 74/100\n",
            "----------\n",
            "train Loss: 0.00594 Acc: 99.89978 macro-f1: 1.00000\n",
            "vaild Loss: 0.07870 Acc: 98.16907 macro-f1: 1.00000\n",
            "each epochs training time : 128m 27s\n",
            "\n",
            "\n",
            "Epoch 75/100\n",
            "----------\n",
            "train Loss: 0.00447 Acc: 99.86638 macro-f1: 1.00000\n",
            "vaild Loss: 0.08588 Acc: 98.09116 macro-f1: 1.00000\n",
            "each epochs training time : 130m 10s\n",
            "\n",
            "\n",
            "Epoch 76/100\n",
            "----------\n",
            "train Loss: 0.00757 Acc: 99.74946 macro-f1: 1.00000\n",
            "vaild Loss: 0.08068 Acc: 98.13011 macro-f1: 1.00000\n",
            "each epochs training time : 131m 53s\n",
            "\n",
            "\n",
            "Epoch 77/100\n",
            "----------\n",
            "train Loss: 0.00519 Acc: 99.83297 macro-f1: 1.00000\n",
            "vaild Loss: 0.09468 Acc: 98.16907 macro-f1: 1.00000\n",
            "each epochs training time : 133m 35s\n",
            "\n",
            "\n",
            "Epoch 78/100\n",
            "----------\n",
            "train Loss: 0.00650 Acc: 99.84967 macro-f1: 1.00000\n",
            "vaild Loss: 0.07828 Acc: 98.40280 macro-f1: 1.00000\n",
            "each epochs training time : 135m 18s\n",
            "\n",
            "\n",
            "Epoch 79/100\n",
            "----------\n",
            "train Loss: 0.00638 Acc: 99.79957 macro-f1: 1.00000\n",
            "vaild Loss: 0.07701 Acc: 98.16907 macro-f1: 1.00000\n",
            "each epochs training time : 137m 1s\n",
            "\n",
            "\n",
            "Epoch 80/100\n",
            "----------\n",
            "train Loss: 0.00424 Acc: 99.88308 macro-f1: 0.50000\n",
            "vaild Loss: 0.09468 Acc: 98.05220 macro-f1: 1.00000\n",
            "each epochs training time : 138m 43s\n",
            "\n",
            "\n",
            "Epoch 81/100\n",
            "----------\n",
            "train Loss: 0.00657 Acc: 99.83297 macro-f1: 1.00000\n",
            "vaild Loss: 0.07441 Acc: 98.28594 macro-f1: 1.00000\n",
            "each epochs training time : 140m 26s\n",
            "\n",
            "\n",
            "Epoch 82/100\n",
            "----------\n",
            "train Loss: 0.00570 Acc: 99.86638 macro-f1: 1.00000\n",
            "vaild Loss: 0.07727 Acc: 98.32489 macro-f1: 1.00000\n",
            "each epochs training time : 142m 9s\n",
            "\n",
            "\n",
            "Epoch 83/100\n",
            "----------\n",
            "train Loss: 0.00549 Acc: 99.86638 macro-f1: 1.00000\n",
            "vaild Loss: 0.07002 Acc: 98.44176 macro-f1: 1.00000\n",
            "==> best model saved - 83 / 98.4\n",
            "each epochs training time : 143m 51s\n",
            "\n",
            "\n",
            "Epoch 84/100\n",
            "----------\n",
            "train Loss: 0.00427 Acc: 99.91649 macro-f1: 0.50000\n",
            "vaild Loss: 0.07987 Acc: 98.44176 macro-f1: 1.00000\n",
            "each epochs training time : 145m 34s\n",
            "\n",
            "\n",
            "Epoch 85/100\n",
            "----------\n",
            "train Loss: 0.01127 Acc: 99.73275 macro-f1: 1.00000\n",
            "vaild Loss: 0.07698 Acc: 98.48072 macro-f1: 1.00000\n",
            "==> best model saved - 85 / 98.5\n",
            "each epochs training time : 147m 17s\n",
            "\n",
            "\n",
            "Epoch 86/100\n",
            "----------\n",
            "train Loss: 0.00517 Acc: 99.84967 macro-f1: 0.50000\n",
            "vaild Loss: 0.08276 Acc: 98.16907 macro-f1: 1.00000\n",
            "each epochs training time : 148m 59s\n",
            "\n",
            "\n",
            "Epoch 87/100\n",
            "----------\n",
            "train Loss: 0.00473 Acc: 99.84967 macro-f1: 1.00000\n",
            "vaild Loss: 0.08104 Acc: 98.32489 macro-f1: 1.00000\n",
            "each epochs training time : 150m 42s\n",
            "\n",
            "\n",
            "Epoch 88/100\n",
            "----------\n",
            "train Loss: 0.00682 Acc: 99.79957 macro-f1: 1.00000\n",
            "vaild Loss: 0.07632 Acc: 98.59758 macro-f1: 1.00000\n",
            "==> best model saved - 88 / 98.6\n",
            "each epochs training time : 152m 25s\n",
            "\n",
            "\n",
            "Epoch 89/100\n",
            "----------\n",
            "train Loss: 0.00451 Acc: 99.84967 macro-f1: 1.00000\n",
            "vaild Loss: 0.07721 Acc: 98.51967 macro-f1: 1.00000\n",
            "each epochs training time : 154m 8s\n",
            "\n",
            "\n",
            "Epoch 90/100\n",
            "----------\n",
            "train Loss: 0.00395 Acc: 99.89978 macro-f1: 0.50000\n",
            "vaild Loss: 0.08140 Acc: 98.24698 macro-f1: 1.00000\n",
            "each epochs training time : 155m 50s\n",
            "\n",
            "\n",
            "Epoch 91/100\n",
            "----------\n",
            "train Loss: 0.00574 Acc: 99.74946 macro-f1: 1.00000\n",
            "vaild Loss: 0.07666 Acc: 98.40280 macro-f1: 1.00000\n",
            "each epochs training time : 157m 32s\n",
            "\n",
            "\n",
            "Epoch 92/100\n",
            "----------\n",
            "train Loss: 0.00412 Acc: 99.91649 macro-f1: 1.00000\n",
            "vaild Loss: 0.08855 Acc: 98.32489 macro-f1: 1.00000\n",
            "each epochs training time : 159m 15s\n",
            "\n",
            "\n",
            "Epoch 93/100\n",
            "----------\n",
            "train Loss: 0.00432 Acc: 99.88308 macro-f1: 1.00000\n",
            "vaild Loss: 0.08078 Acc: 98.67550 macro-f1: 1.00000\n",
            "==> best model saved - 93 / 98.7\n",
            "each epochs training time : 160m 57s\n",
            "\n",
            "\n",
            "Epoch 94/100\n",
            "----------\n",
            "train Loss: 0.00491 Acc: 99.88308 macro-f1: 1.00000\n",
            "vaild Loss: 0.08653 Acc: 98.20802 macro-f1: 1.00000\n",
            "each epochs training time : 162m 39s\n",
            "\n",
            "\n",
            "Epoch 95/100\n",
            "----------\n",
            "train Loss: 0.00515 Acc: 99.84967 macro-f1: 1.00000\n",
            "vaild Loss: 0.07759 Acc: 98.36385 macro-f1: 1.00000\n",
            "each epochs training time : 164m 22s\n",
            "\n",
            "\n",
            "Epoch 96/100\n",
            "----------\n",
            "train Loss: 0.00233 Acc: 99.93319 macro-f1: 1.00000\n",
            "vaild Loss: 0.06585 Acc: 98.75341 macro-f1: 1.00000\n",
            "==> best model saved - 96 / 98.8\n",
            "each epochs training time : 166m 4s\n",
            "\n",
            "\n",
            "Epoch 97/100\n",
            "----------\n",
            "train Loss: 0.00631 Acc: 99.84967 macro-f1: 0.55556\n",
            "vaild Loss: 0.08451 Acc: 98.28594 macro-f1: 1.00000\n",
            "each epochs training time : 167m 46s\n",
            "\n",
            "\n",
            "Epoch 98/100\n",
            "----------\n",
            "train Loss: 0.00449 Acc: 99.88308 macro-f1: 0.55556\n",
            "vaild Loss: 0.07877 Acc: 98.16907 macro-f1: 1.00000\n",
            "each epochs training time : 169m 28s\n",
            "\n",
            "\n",
            "Epoch 99/100\n",
            "----------\n",
            "train Loss: 0.00451 Acc: 99.83297 macro-f1: 0.50000\n",
            "vaild Loss: 0.07866 Acc: 98.32489 macro-f1: 1.00000\n",
            "each epochs training time : 171m 10s\n",
            "\n",
            "\n",
            "Training complete in 171m 11s\n",
            "Best valid Acc: 96 - 98.8\n",
            "model saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 결과 그래프 그리기\n",
        "print('best model : %d - %1.f / %.1f'%(best_idx, valid_acc[best_idx], valid_loss[best_idx]))\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(train_acc, 'b-')\n",
        "ax1.plot(valid_acc, 'r-')\n",
        "plt.plot(best_idx, valid_acc[best_idx], 'ro')\n",
        "ax1.set_xlabel('epoch')\n",
        "# Make the y-axis label, ticks and tick labels match the line color.\n",
        "ax1.set_ylabel('acc', color='k')\n",
        "ax1.tick_params('y', colors='k')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(train_loss, 'g-')\n",
        "ax2.plot(valid_loss, 'k-')\n",
        "plt.plot(best_idx, valid_loss[best_idx], 'ro')\n",
        "ax2.set_ylabel('loss', color='k')\n",
        "ax2.tick_params('y', colors='k')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "5kJPLUuEU1pH",
        "outputId": "99d76ac9-4087-47e2-9971-52d820714b6e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best model : 96 - 99 / 0.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JJdS3MynU1rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ## 학습 결과 검수\n",
        "# def test_and_visualize_model(model, phase = 'test', num_images=4):\n",
        "#     # phase = 'train', 'valid', 'test'\n",
        "    \n",
        "#     was_training = model.training\n",
        "#     model.eval()\n",
        "#     fig = plt.figure()\n",
        "    \n",
        "#     running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
        "#             inputs = inputs.to(device)\n",
        "#             labels = labels.to(device)\n",
        "\n",
        "#             outputs = model(inputs)\n",
        "#             _, preds = torch.max(outputs, 1)\n",
        "#             loss = criterion(outputs, labels)  # batch의 평균 loss 출력\n",
        "\n",
        "#             running_loss    += loss.item() * inputs.size(0)\n",
        "#             running_corrects+= torch.sum(preds == labels.data)\n",
        "#             num_cnt += inputs.size(0)  # batch size\n",
        "\n",
        "#     #         if i == 2: break\n",
        "\n",
        "#         test_loss = running_loss / num_cnt\n",
        "#         test_acc  = running_corrects.double() / num_cnt       \n",
        "#         print('test done : loss/acc : %.2f / %.1f' % (test_loss, test_acc*100))\n",
        "\n",
        "#     # 예시 그림 plot\n",
        "#     with torch.no_grad():\n",
        "#         for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
        "#             inputs = inputs.to(device)\n",
        "#             labels = labels.to(device)\n",
        "\n",
        "#             outputs = model(inputs)\n",
        "#             _, preds = torch.max(outputs, 1)        \n",
        "\n",
        "#             # 예시 그림 plot\n",
        "#             for j in range(1, num_images+1):\n",
        "#                 ax = plt.subplot(num_images//2, 2, j)\n",
        "#                 ax.axis('off')\n",
        "#                 ax.set_title('%s : %s -> %s'%(\n",
        "#                     'True' if class_names[str(labels[j].cpu().numpy())]==class_names[str(preds[j].cpu().numpy())] else 'False',\n",
        "#                     class_names[str(labels[j].cpu().numpy())], class_names[str(preds[j].cpu().numpy())]))\n",
        "#                 imshow(inputs.cpu().data[j])          \n",
        "#             if i == 0 : break\n",
        "\n",
        "\n",
        "#     model.train(mode=was_training);  # 다시 train모드로\n",
        "    \n",
        "#     ## TEST!\n",
        "#     test_and_visualize_model(model, phase = 'test')"
      ],
      "metadata": {
        "id": "bZK4jMWoU1tQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LedsQjpUU1vI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "X2jIgWqSU1w9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-o1YRRNYU1zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 추론"
      ],
      "metadata": {
        "id": "WQR1RKgTpKk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 모델을 평가 모드로 변경하고 test 데이터 분류\n",
        "test_png = sorted(glob('/content/drive/Othercomputers/내 MacBook Pro/open/test/*.png'))\n",
        "test_imgs = [img_load(n) for n in tqdm(test_png)]\n",
        "test_dataset = Custom_dataset_3(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "model.eval()\n",
        "f_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in (test_loader):\n",
        "        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            pred = model(x)\n",
        "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
      ],
      "metadata": {
        "id": "gj7gTQv6U11P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "606e603e-f263-45a8-98b9-665a02e9fa03"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2154/2154 [03:14<00:00, 11.08it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 숫자로된 레이블을 문자열 레이블로 변경\n",
        "label_decoder = {value:key for key, value in label_unique.items()}\n",
        "f_result = [label_decoder[result] for result in f_pred]"
      ],
      "metadata": {
        "id": "30_rcMw4U13G"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime as dt \n",
        "today = dt.today().strftime('%Y-%m-%d')\n",
        "version = f'efficientNet_b4_by_timm_data_ver3_{today}'\n",
        "submission = pd.read_csv(f\"/content/drive/MyDrive/DACON_이상치 탐지 알고리즘 경진대회/open/sample_submission.csv\")\n",
        "\n",
        "## 시각적 확인을 위해 문자열 레이블로 이루어진 된 label 필드 생성\n",
        "submission[\"label\"] = f_result\n",
        "display(submission)\n",
        "submission.to_csv(f\"/content/drive/MyDrive/DACON_이상치 탐지 알고리즘 경진대회/open/sample_submission_{version}.csv\", index = False)"
      ],
      "metadata": {
        "id": "1zWu-D7WdRmQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "bbb04cb4-9697-4661-bd88-5b562a58f719"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      index             label\n",
              "0         0   tile-glue_strip\n",
              "1         1         grid-good\n",
              "2         2   transistor-good\n",
              "3         3  tile-gray_stroke\n",
              "4         4         tile-good\n",
              "...     ...               ...\n",
              "2149   2149  tile-gray_stroke\n",
              "2150   2150        screw-good\n",
              "2151   2151         grid-good\n",
              "2152   2152        cable-good\n",
              "2153   2153       zipper-good\n",
              "\n",
              "[2154 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ee08a4b-14bf-4b2f-9f2d-a5bffd8affe5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>tile-glue_strip</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>grid-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>transistor-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>tile-gray_stroke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>tile-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2149</th>\n",
              "      <td>2149</td>\n",
              "      <td>tile-gray_stroke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2150</th>\n",
              "      <td>2150</td>\n",
              "      <td>screw-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2151</th>\n",
              "      <td>2151</td>\n",
              "      <td>grid-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2152</th>\n",
              "      <td>2152</td>\n",
              "      <td>cable-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2153</th>\n",
              "      <td>2153</td>\n",
              "      <td>zipper-good</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2154 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ee08a4b-14bf-4b2f-9f2d-a5bffd8affe5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9ee08a4b-14bf-4b2f-9f2d-a5bffd8affe5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9ee08a4b-14bf-4b2f-9f2d-a5bffd8affe5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cG_tNWs2zxh8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
