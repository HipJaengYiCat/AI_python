{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNet_train_test",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seunghee0518/AI_python/blob/main/EfficientNet_b4_MVtecAD_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## trina/ test 나눠서 학습"
      ],
      "metadata": {
        "id": "lynhGDxilbRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "torch.hub : Pytorch Hub는 연구 재현성을 촉진하도록 설계된 사전 훈련 된 모델 저장소\n",
        "nvidia_efficientnet_b4 사전 모델 가져옴\n",
        "'''\n",
        "import torch\n",
        "model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b4', pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ-ytfDpoKMH",
        "outputId": "bcf0d871-22e7-48ed-cf4f-0d5af86d55ab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n",
            "/root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/common.py:14: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
            "  \"pytorch_quantization module not found, quantization will not be available\"\n",
            "/root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/efficientnet.py:18: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
            "  \"pytorch_quantization module not found, quantization will not be available\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKXv22Yk6zus",
        "outputId": "0c5b5166-5601-4dcb-a1d5-0e30f1217d22"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 학습 코드\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "#import timm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import gc\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import transforms, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# from efficientnet_pytorch import EfficientNet\n",
        "# model_name = 'efficientnet-b0'  # b5\n",
        "\n",
        "# image_size = EfficientNet.get_image_size(model_name)\n",
        "# print(image_size)\n",
        "# model = EfficientNet.from_pretrained(model_name, num_classes=88)"
      ],
      "metadata": {
        "id": "Gjs-R_R5lUKg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 데이타 로드!!\n",
        "device = torch.device('cuda')\n",
        "batch_size  = 32\n",
        "random_seed = 1234\n",
        "img_size = 224\n",
        "random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "## make dataset\n",
        "# data_path = 'president/president_data'  # class 별 폴더로 나누어진걸 확 가져와서 라벨도 달아준다\n",
        "# train_dataset = datasets.ImageFolder(data_path,\n",
        "#                                      transforms.Compose([\n",
        "#                                      transforms.Resize((224, 224)),\n",
        "#                                      transforms.ToTensor(), # 이미지 데이터를 tensor로 바꿔준다.\n",
        "#                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalize는 많은 이미지의 평균, 표준편차로 정함(보통 많이 하는 값이라고함)\n",
        "#                                 ]))\n",
        "\n",
        "## 이미지 경로\n",
        "#train_png = sorted(glob('/content/drive/Othercomputers/내 MacBook Pro/open/train/*.png'))\n",
        "#test_png = sorted(glob('/content/drive/Othercomputers/내 MacBook Pro/open/train/*.png'))\n",
        "\n",
        "train_imgs = np.load('/content/drive/MyDrive/DACON_이상치 탐지 알고리즘 경진대회/train_imgs_224.npy')\n",
        "train_y = pd.read_csv(\"/content/drive/Othercomputers/내 MacBook Pro/open/train_df.csv\")\n",
        "\n",
        "train_labels = train_y[\"label\"] # 레이블순서는 이미지 파일 순서대로임\n",
        "\n",
        "label_unique = sorted(np.unique(train_labels))\n",
        "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))} # 오름차순으로 레이블별로 숫자 부여(0부터 시작)\n",
        "\n",
        "train_labels = [label_unique[k] for k in train_labels]\n",
        "\n",
        "class Custom_dataset_3(Dataset):\n",
        "    def __init__(self, img_paths, labels, mode='train'):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode=mode\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.img_paths[idx]\n",
        "        img = transforms.ToTensor()(img)\n",
        "        img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "\n",
        "        if self.mode=='test':\n",
        "            pass\n",
        "        ## 레이블 > 원-핫 인코딩 하기 \n",
        "        label = self.labels[idx]# (원핫인코딩 안할거면 해당 코드만 필요)\n",
        "        return img, label\n",
        "\n",
        "\n",
        "train_dataset = Custom_dataset_3(np.array(train_imgs), np.array(train_labels), mode='train')\n",
        "\n",
        "### 데이터셋 분리 > 층화추출 & 테스터 데이터 비율 : 0.3, 시드 : 1234, 셔플 = True(default)\n",
        "train_idx, test_idx = train_test_split(list(range(len(train_dataset))), stratify=train_labels, test_size=0.3, random_state=random_seed)\n",
        "\n",
        "datasets = {} # 데이터셋을 담을 딕셔너리\n",
        "datasets['train'] = Subset(train_dataset, train_idx)\n",
        "datasets['test']  = Subset(train_dataset, test_idx)\n",
        "\n",
        "## data loader 선언\n",
        "dataloaders, batch_num = {}, {}\n",
        "dataloaders['train'] = torch.utils.data.DataLoader(datasets['train'],\n",
        "                                                  batch_size=batch_size, shuffle=True,\n",
        "                                                  num_workers=4)\n",
        "dataloaders['test']  = torch.utils.data.DataLoader(datasets['test'],\n",
        "                                                  batch_size=batch_size, shuffle=False,\n",
        "                                                  num_workers=4)\n",
        "batch_num['train'], batch_num['test'] = len(dataloaders['train']), len(dataloaders['test'])\n",
        "print('batch_size : %d,  train/test(데이터셋개수/배치사이즈) : %d / %d' % (batch_size, batch_num['train'],batch_num['test']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORqFbwLXpSeu",
        "outputId": "1c4e39a1-cfd4-49b2-a10c-77bb1c8ca714"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_size : 32,  train/test(데이터셋개수/배치사이즈) : 94 / 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### f1 스코어 함수 \n",
        "# def score_function(real, pred): # 라이브러리 > sklearn.metrics \n",
        "#     score = f1_score(real, pred, average=\"macro\")\n",
        "#     return score\n",
        "!pip install torchmetrics\n",
        "from torchmetrics import F1Score # 라이브러리 > torchmetrics\n",
        "f1_score = F1Score(num_classes=len(label_unique))\n",
        "\n",
        "# target = torch.tensor([0, 1, 2, 0, 1, 2])\n",
        "# preds = torch.tensor([0, 2, 1, 0, 0, 1])\n",
        "#f1_score(preds, target)"
      ],
      "metadata": {
        "id": "EJ4ZHzQiFUrc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce8a319b-fe76-4a2c-ae6d-3b423a20b977"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: pyDeprecate==0.3.* in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (0.3.2)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.11.0+cu113)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 참고 블로그 : https://keep-steady.tistory.com/35\n",
        "import gc\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    #train_loss, train_acc, valid_loss, valid_acc = [], [], [], []\n",
        "    train_loss, train_acc, valid_loss, valid_acc, train_f1, valid_f1 = [], [], [], [], [], []\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))# - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
        "            \n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device) # device = torch.device('cuda')\n",
        "                labels = labels.to(device) # device = torch.device('cuda')\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                num_cnt += len(labels)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "            \n",
        "            epoch_loss = float(running_loss / num_cnt)\n",
        "            epoch_acc  = float((running_corrects.double() / num_cnt).cpu()*100)\n",
        "            f1 = f1_score(labels.cpu().data, preds.cpu())\n",
        "\n",
        "            if phase == 'train':\n",
        "                train_loss.append(epoch_loss)\n",
        "                train_acc.append(epoch_acc)\n",
        "                train_f1.append(f1)\n",
        "            else:\n",
        "                valid_loss.append(epoch_loss)\n",
        "                valid_acc.append(epoch_acc)\n",
        "                valid_f1.append(f1)\n",
        "\n",
        "            print('{} Loss: {:.5f} Acc: {:.5f} f1: {:.5f}'.format(phase, epoch_loss, epoch_acc, f1))\n",
        "           \n",
        "            # deep copy the model(최적모델 저장)\n",
        "            if phase == 'test' and epoch_acc > best_acc:\n",
        "                best_idx = epoch\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "#                 best_model_wts = copy.deepcopy(model.module.state_dict())\n",
        "                print('==> best model saved - %d / %.1f'%(best_idx, best_acc))\n",
        "        # 한에포크 마다 실행 시간 출력하기\n",
        "        time_elapsed = time.time() - since\n",
        "        print('one epochs training time : {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "        print('\\n')\n",
        "        # 한 에포크마다 필요없는 메모리 지우기 : 지우기 효과는 아직 확인 못해봄\n",
        "        try:      \n",
        "          gc.collect() # cpu 비움\n",
        "          torch.cuda.empty_cache() # gpu 비움\n",
        "        except:\n",
        "          pass\n",
        "    ## 학습 마무리 후\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best valid Acc: %d - %.1f' %(best_idx, best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    torch.save(model.state_dict(), 'president_model.pt')\n",
        "    print('model saved')\n",
        "    return model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc, train_f1, valid_f1\n",
        "\n",
        "# 설정\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # set gpu\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_ft = optim.SGD(model.parameters(), \n",
        "                         lr = 0.05,\n",
        "                         momentum=0.9,\n",
        "                         weight_decay=1e-4)\n",
        "\n",
        "lmbda = lambda epoch: 0.98739\n",
        "exp_lr_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer_ft, lr_lambda=lmbda)\n",
        "\n",
        "# 사전학습된 가중치와 모델을 가져와 데이터셋으로 추가 모델 학습\n",
        "model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc, train_f1, valid_f1 = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDNj4Yarkx-R",
        "outputId": "6f76f819-986a-4252-b95e-64f3decff1e2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/100\n",
            "----------\n",
            "train Loss: 0.08464 Acc: 97.76144 f1: 1.00000\n",
            "test Loss: 0.48439 Acc: 89.01869 f1: 1.00000\n",
            "==> best model saved - 0 / 89.0\n",
            "one epochs training time : 0m 49s\n",
            "Epoch 1/100\n",
            "----------\n",
            "train Loss: 0.04664 Acc: 98.59673 f1: 1.00000\n",
            "test Loss: 0.41441 Acc: 91.74455 f1: 1.00000\n",
            "==> best model saved - 1 / 91.7\n",
            "one epochs training time : 1m 38s\n",
            "Epoch 2/100\n",
            "----------\n",
            "train Loss: 0.03930 Acc: 99.03107 f1: 1.00000\n",
            "test Loss: 0.50928 Acc: 88.55140 f1: 1.00000\n",
            "one epochs training time : 2m 28s\n",
            "Epoch 3/100\n",
            "----------\n",
            "train Loss: 0.04135 Acc: 98.83060 f1: 1.00000\n",
            "test Loss: 0.43042 Acc: 91.97819 f1: 1.00000\n",
            "==> best model saved - 3 / 92.0\n",
            "one epochs training time : 3m 17s\n",
            "Epoch 4/100\n",
            "----------\n",
            "train Loss: 0.05250 Acc: 98.63014 f1: 1.00000\n",
            "test Loss: 0.39743 Acc: 91.90031 f1: 1.00000\n",
            "one epochs training time : 4m 6s\n",
            "Epoch 5/100\n",
            "----------\n",
            "train Loss: 0.04072 Acc: 99.03107 f1: 1.00000\n",
            "test Loss: 0.48282 Acc: 91.27726 f1: 1.00000\n",
            "one epochs training time : 4m 56s\n",
            "Epoch 6/100\n",
            "----------\n",
            "train Loss: 0.05766 Acc: 98.66355 f1: 1.00000\n",
            "test Loss: 0.40453 Acc: 91.58879 f1: 1.00000\n",
            "one epochs training time : 5m 45s\n",
            "Epoch 7/100\n",
            "----------\n",
            "train Loss: 0.03713 Acc: 99.19813 f1: 1.00000\n",
            "test Loss: 0.50144 Acc: 90.73209 f1: 1.00000\n",
            "one epochs training time : 6m 34s\n",
            "Epoch 8/100\n",
            "----------\n",
            "train Loss: 0.02886 Acc: 99.39860 f1: 1.00000\n",
            "test Loss: 0.41658 Acc: 92.60125 f1: 1.00000\n",
            "==> best model saved - 8 / 92.6\n",
            "one epochs training time : 7m 23s\n",
            "Epoch 9/100\n",
            "----------\n",
            "train Loss: 0.00940 Acc: 99.76612 f1: 1.00000\n",
            "test Loss: 0.45081 Acc: 92.28972 f1: 1.00000\n",
            "one epochs training time : 8m 12s\n",
            "Epoch 10/100\n",
            "----------\n",
            "train Loss: 0.02046 Acc: 99.49883 f1: 1.00000\n",
            "test Loss: 0.42338 Acc: 92.36760 f1: 1.00000\n",
            "one epochs training time : 9m 2s\n",
            "Epoch 11/100\n",
            "----------\n",
            "train Loss: 0.00598 Acc: 99.79953 f1: 1.00000\n",
            "test Loss: 0.41170 Acc: 93.06854 f1: 1.00000\n",
            "==> best model saved - 11 / 93.1\n",
            "one epochs training time : 9m 51s\n",
            "Epoch 12/100\n",
            "----------\n",
            "train Loss: 0.00238 Acc: 99.93318 f1: 1.00000\n",
            "test Loss: 0.41372 Acc: 92.91277 f1: 1.00000\n",
            "one epochs training time : 10m 40s\n",
            "Epoch 13/100\n",
            "----------\n",
            "train Loss: 0.00110 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.44035 Acc: 92.99065 f1: 1.00000\n",
            "one epochs training time : 11m 29s\n",
            "Epoch 14/100\n",
            "----------\n",
            "train Loss: 0.00073 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.44609 Acc: 93.14642 f1: 1.00000\n",
            "==> best model saved - 14 / 93.1\n",
            "one epochs training time : 12m 18s\n",
            "Epoch 15/100\n",
            "----------\n",
            "train Loss: 0.00060 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.43032 Acc: 93.22430 f1: 1.00000\n",
            "==> best model saved - 15 / 93.2\n",
            "one epochs training time : 13m 8s\n",
            "Epoch 16/100\n",
            "----------\n",
            "train Loss: 0.00075 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.43842 Acc: 93.06854 f1: 1.00000\n",
            "one epochs training time : 13m 57s\n",
            "Epoch 17/100\n",
            "----------\n",
            "train Loss: 0.00335 Acc: 99.89977 f1: 1.00000\n",
            "test Loss: 0.60195 Acc: 90.57632 f1: 0.50000\n",
            "one epochs training time : 14m 46s\n",
            "Epoch 18/100\n",
            "----------\n",
            "train Loss: 0.01930 Acc: 99.59906 f1: 1.00000\n",
            "test Loss: 0.55918 Acc: 91.82243 f1: 1.00000\n",
            "one epochs training time : 15m 35s\n",
            "Epoch 19/100\n",
            "----------\n",
            "train Loss: 0.01206 Acc: 99.69930 f1: 1.00000\n",
            "test Loss: 0.58075 Acc: 91.19938 f1: 1.00000\n",
            "one epochs training time : 16m 24s\n",
            "Epoch 20/100\n",
            "----------\n",
            "train Loss: 0.00849 Acc: 99.73271 f1: 1.00000\n",
            "test Loss: 0.43925 Acc: 92.44548 f1: 1.00000\n",
            "one epochs training time : 17m 14s\n",
            "Epoch 21/100\n",
            "----------\n",
            "train Loss: 0.00775 Acc: 99.89977 f1: 1.00000\n",
            "test Loss: 0.46840 Acc: 92.52336 f1: 1.00000\n",
            "one epochs training time : 18m 3s\n",
            "Epoch 22/100\n",
            "----------\n",
            "train Loss: 0.00166 Acc: 99.96659 f1: 1.00000\n",
            "test Loss: 0.51186 Acc: 91.58879 f1: 1.00000\n",
            "one epochs training time : 18m 52s\n",
            "Epoch 23/100\n",
            "----------\n",
            "train Loss: 0.00119 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.46205 Acc: 92.05607 f1: 1.00000\n",
            "one epochs training time : 19m 41s\n",
            "Epoch 24/100\n",
            "----------\n",
            "train Loss: 0.00082 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.46195 Acc: 92.67913 f1: 1.00000\n",
            "one epochs training time : 20m 31s\n",
            "Epoch 25/100\n",
            "----------\n",
            "train Loss: 0.00054 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.46345 Acc: 92.44548 f1: 1.00000\n",
            "one epochs training time : 21m 20s\n",
            "Epoch 26/100\n",
            "----------\n",
            "train Loss: 0.00805 Acc: 99.86635 f1: 1.00000\n",
            "test Loss: 0.45302 Acc: 92.36760 f1: 1.00000\n",
            "one epochs training time : 22m 9s\n",
            "Epoch 27/100\n",
            "----------\n",
            "train Loss: 0.00399 Acc: 99.93318 f1: 1.00000\n",
            "test Loss: 0.43391 Acc: 92.60125 f1: 1.00000\n",
            "one epochs training time : 22m 58s\n",
            "Epoch 28/100\n",
            "----------\n",
            "train Loss: 0.00064 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.43654 Acc: 92.83489 f1: 1.00000\n",
            "one epochs training time : 23m 48s\n",
            "Epoch 29/100\n",
            "----------\n",
            "train Loss: 0.00045 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.44485 Acc: 92.83489 f1: 1.00000\n",
            "one epochs training time : 24m 37s\n",
            "Epoch 30/100\n",
            "----------\n",
            "train Loss: 0.00187 Acc: 99.93318 f1: 1.00000\n",
            "test Loss: 0.46756 Acc: 92.44548 f1: 1.00000\n",
            "one epochs training time : 25m 26s\n",
            "Epoch 31/100\n",
            "----------\n",
            "train Loss: 0.00073 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.44040 Acc: 92.83489 f1: 1.00000\n",
            "one epochs training time : 26m 16s\n",
            "Epoch 32/100\n",
            "----------\n",
            "train Loss: 0.00073 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.45884 Acc: 92.75701 f1: 1.00000\n",
            "one epochs training time : 27m 5s\n",
            "Epoch 33/100\n",
            "----------\n",
            "train Loss: 0.00059 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.46486 Acc: 92.67913 f1: 1.00000\n",
            "one epochs training time : 27m 54s\n",
            "Epoch 34/100\n",
            "----------\n",
            "train Loss: 0.00043 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.45876 Acc: 92.91277 f1: 1.00000\n",
            "one epochs training time : 28m 43s\n",
            "Epoch 35/100\n",
            "----------\n",
            "train Loss: 0.00077 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.45506 Acc: 93.06854 f1: 1.00000\n",
            "one epochs training time : 29m 32s\n",
            "Epoch 36/100\n",
            "----------\n",
            "train Loss: 0.00043 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.45602 Acc: 93.22430 f1: 1.00000\n",
            "one epochs training time : 30m 22s\n",
            "Epoch 37/100\n",
            "----------\n",
            "train Loss: 0.00539 Acc: 99.93318 f1: 1.00000\n",
            "test Loss: 0.49938 Acc: 92.28972 f1: 1.00000\n",
            "one epochs training time : 31m 11s\n",
            "Epoch 38/100\n",
            "----------\n",
            "train Loss: 0.00074 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.48271 Acc: 92.05607 f1: 1.00000\n",
            "one epochs training time : 32m 0s\n",
            "Epoch 39/100\n",
            "----------\n",
            "train Loss: 0.00063 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.46820 Acc: 92.36760 f1: 1.00000\n",
            "one epochs training time : 32m 49s\n",
            "Epoch 40/100\n",
            "----------\n",
            "train Loss: 0.00052 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.48963 Acc: 92.05607 f1: 1.00000\n",
            "one epochs training time : 33m 38s\n",
            "Epoch 41/100\n",
            "----------\n",
            "train Loss: 0.00150 Acc: 99.93318 f1: 1.00000\n",
            "test Loss: 0.47021 Acc: 92.44548 f1: 1.00000\n",
            "one epochs training time : 34m 27s\n",
            "Epoch 42/100\n",
            "----------\n",
            "train Loss: 0.00080 Acc: 99.96659 f1: 1.00000\n",
            "test Loss: 0.47415 Acc: 92.28972 f1: 1.00000\n",
            "one epochs training time : 35m 16s\n",
            "Epoch 43/100\n",
            "----------\n",
            "train Loss: 0.00037 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.46499 Acc: 92.52336 f1: 1.00000\n",
            "one epochs training time : 36m 6s\n",
            "Epoch 44/100\n",
            "----------\n",
            "train Loss: 0.00027 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.46717 Acc: 92.36760 f1: 1.00000\n",
            "one epochs training time : 36m 55s\n",
            "Epoch 45/100\n",
            "----------\n",
            "train Loss: 0.00038 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.47182 Acc: 92.36760 f1: 1.00000\n",
            "one epochs training time : 37m 44s\n",
            "Epoch 46/100\n",
            "----------\n",
            "train Loss: 0.00025 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.47488 Acc: 92.36760 f1: 1.00000\n",
            "one epochs training time : 38m 33s\n",
            "Epoch 47/100\n",
            "----------\n",
            "train Loss: 0.00024 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.47779 Acc: 92.36760 f1: 1.00000\n",
            "one epochs training time : 39m 22s\n",
            "Epoch 48/100\n",
            "----------\n",
            "train Loss: 0.00026 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.47980 Acc: 92.36760 f1: 1.00000\n",
            "one epochs training time : 40m 11s\n",
            "Epoch 49/100\n",
            "----------\n",
            "train Loss: 0.00039 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.47607 Acc: 92.67913 f1: 1.00000\n",
            "one epochs training time : 41m 0s\n",
            "Epoch 50/100\n",
            "----------\n",
            "train Loss: 0.00037 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.48261 Acc: 92.44548 f1: 1.00000\n",
            "one epochs training time : 41m 49s\n",
            "Epoch 51/100\n",
            "----------\n",
            "train Loss: 0.00031 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.48240 Acc: 92.52336 f1: 1.00000\n",
            "one epochs training time : 42m 39s\n",
            "Epoch 52/100\n",
            "----------\n",
            "train Loss: 0.00171 Acc: 99.96659 f1: 1.00000\n",
            "test Loss: 0.50052 Acc: 92.13396 f1: 1.00000\n",
            "one epochs training time : 43m 28s\n",
            "Epoch 53/100\n",
            "----------\n",
            "train Loss: 0.00027 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.49792 Acc: 92.44548 f1: 1.00000\n",
            "one epochs training time : 44m 17s\n",
            "Epoch 54/100\n",
            "----------\n",
            "train Loss: 0.00025 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.49755 Acc: 92.52336 f1: 1.00000\n",
            "one epochs training time : 45m 6s\n",
            "Epoch 55/100\n",
            "----------\n",
            "train Loss: 0.00297 Acc: 99.93318 f1: 1.00000\n",
            "test Loss: 0.48984 Acc: 92.52336 f1: 1.00000\n",
            "one epochs training time : 45m 55s\n",
            "Epoch 56/100\n",
            "----------\n",
            "train Loss: 0.00030 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.49087 Acc: 92.44548 f1: 1.00000\n",
            "one epochs training time : 46m 44s\n",
            "Epoch 57/100\n",
            "----------\n",
            "train Loss: 0.00043 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.48774 Acc: 92.28972 f1: 1.00000\n",
            "one epochs training time : 47m 33s\n",
            "Epoch 58/100\n",
            "----------\n",
            "train Loss: 0.00035 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.48139 Acc: 92.21184 f1: 1.00000\n",
            "one epochs training time : 48m 23s\n",
            "Epoch 59/100\n",
            "----------\n",
            "train Loss: 0.00030 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.47541 Acc: 92.28972 f1: 1.00000\n",
            "one epochs training time : 49m 12s\n",
            "Epoch 60/100\n",
            "----------\n",
            "train Loss: 0.00022 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.47890 Acc: 92.28972 f1: 1.00000\n",
            "one epochs training time : 50m 1s\n",
            "Epoch 61/100\n",
            "----------\n",
            "train Loss: 0.00027 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.48653 Acc: 92.44548 f1: 1.00000\n",
            "one epochs training time : 50m 50s\n",
            "Epoch 62/100\n",
            "----------\n",
            "train Loss: 0.00177 Acc: 99.96659 f1: 1.00000\n",
            "test Loss: 0.44909 Acc: 92.91277 f1: 1.00000\n",
            "one epochs training time : 51m 40s\n",
            "Epoch 63/100\n",
            "----------\n",
            "train Loss: 0.00051 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.45249 Acc: 92.75701 f1: 1.00000\n",
            "one epochs training time : 52m 29s\n",
            "Epoch 64/100\n",
            "----------\n",
            "train Loss: 0.00035 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.46013 Acc: 92.75701 f1: 1.00000\n",
            "one epochs training time : 53m 18s\n",
            "Epoch 65/100\n",
            "----------\n",
            "train Loss: 0.00031 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.46321 Acc: 92.75701 f1: 1.00000\n",
            "one epochs training time : 54m 7s\n",
            "Epoch 66/100\n",
            "----------\n",
            "train Loss: 0.00037 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.46675 Acc: 92.75701 f1: 1.00000\n",
            "one epochs training time : 54m 56s\n",
            "Epoch 67/100\n",
            "----------\n",
            "train Loss: 0.00029 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.46960 Acc: 92.75701 f1: 1.00000\n",
            "one epochs training time : 55m 45s\n",
            "Epoch 68/100\n",
            "----------\n",
            "train Loss: 0.00032 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.46705 Acc: 92.67913 f1: 1.00000\n",
            "one epochs training time : 56m 35s\n",
            "Epoch 69/100\n",
            "----------\n",
            "train Loss: 0.00026 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.47007 Acc: 92.67913 f1: 1.00000\n",
            "one epochs training time : 57m 24s\n",
            "Epoch 70/100\n",
            "----------\n",
            "train Loss: 0.00039 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.46505 Acc: 92.75701 f1: 1.00000\n",
            "one epochs training time : 58m 13s\n",
            "Epoch 71/100\n",
            "----------\n",
            "train Loss: 0.00024 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.46601 Acc: 92.75701 f1: 1.00000\n",
            "one epochs training time : 59m 2s\n",
            "Epoch 72/100\n",
            "----------\n",
            "train Loss: 0.00033 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.47492 Acc: 92.67913 f1: 1.00000\n",
            "one epochs training time : 59m 52s\n",
            "Epoch 73/100\n",
            "----------\n",
            "train Loss: 0.00036 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.46767 Acc: 92.75701 f1: 1.00000\n",
            "one epochs training time : 60m 41s\n",
            "Epoch 74/100\n",
            "----------\n",
            "train Loss: 0.00034 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.47003 Acc: 92.67913 f1: 1.00000\n",
            "one epochs training time : 61m 30s\n",
            "Epoch 75/100\n",
            "----------\n",
            "train Loss: 0.00031 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.47496 Acc: 92.67913 f1: 1.00000\n",
            "one epochs training time : 62m 19s\n",
            "Epoch 76/100\n",
            "----------\n",
            "train Loss: 0.00040 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.47571 Acc: 92.67913 f1: 1.00000\n",
            "one epochs training time : 63m 8s\n",
            "Epoch 77/100\n",
            "----------\n",
            "train Loss: 0.00030 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.47571 Acc: 92.67913 f1: 1.00000\n",
            "one epochs training time : 63m 58s\n",
            "Epoch 78/100\n",
            "----------\n",
            "train Loss: 0.00048 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.46875 Acc: 92.83489 f1: 1.00000\n",
            "one epochs training time : 64m 47s\n",
            "Epoch 79/100\n",
            "----------\n",
            "train Loss: 0.00022 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.46890 Acc: 92.83489 f1: 1.00000\n",
            "one epochs training time : 65m 36s\n",
            "Epoch 80/100\n",
            "----------\n",
            "train Loss: 0.00026 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.47314 Acc: 92.75701 f1: 1.00000\n",
            "one epochs training time : 66m 25s\n",
            "Epoch 81/100\n",
            "----------\n",
            "train Loss: 0.00029 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.47289 Acc: 92.83489 f1: 1.00000\n",
            "one epochs training time : 67m 14s\n",
            "Epoch 82/100\n",
            "----------\n",
            "train Loss: 0.00030 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.47730 Acc: 92.67913 f1: 1.00000\n",
            "one epochs training time : 68m 4s\n",
            "Epoch 83/100\n",
            "----------\n",
            "train Loss: 0.00020 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.47837 Acc: 92.67913 f1: 1.00000\n",
            "one epochs training time : 68m 53s\n",
            "Epoch 84/100\n",
            "----------\n",
            "train Loss: 0.00033 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.47647 Acc: 92.67913 f1: 1.00000\n",
            "one epochs training time : 69m 42s\n",
            "Epoch 85/100\n",
            "----------\n",
            "train Loss: 0.00034 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.47414 Acc: 92.67913 f1: 1.00000\n",
            "one epochs training time : 70m 31s\n",
            "Epoch 86/100\n",
            "----------\n",
            "train Loss: 0.00023 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.47579 Acc: 92.67913 f1: 1.00000\n",
            "one epochs training time : 71m 20s\n",
            "Epoch 87/100\n",
            "----------\n",
            "train Loss: 0.00034 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.47450 Acc: 92.75701 f1: 1.00000\n",
            "one epochs training time : 72m 9s\n",
            "Epoch 88/100\n",
            "----------\n",
            "train Loss: 0.00031 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.46029 Acc: 92.83489 f1: 1.00000\n",
            "one epochs training time : 72m 59s\n",
            "Epoch 89/100\n",
            "----------\n",
            "train Loss: 0.00044 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.45187 Acc: 92.99065 f1: 1.00000\n",
            "one epochs training time : 73m 48s\n",
            "Epoch 90/100\n",
            "----------\n",
            "train Loss: 0.00057 Acc: 99.96659 f1: 1.00000\n",
            "test Loss: 0.43982 Acc: 92.99065 f1: 1.00000\n",
            "one epochs training time : 74m 37s\n",
            "Epoch 91/100\n",
            "----------\n",
            "train Loss: 0.00035 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.44038 Acc: 92.99065 f1: 1.00000\n",
            "one epochs training time : 75m 26s\n",
            "Epoch 92/100\n",
            "----------\n",
            "train Loss: 0.00058 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.44166 Acc: 93.14642 f1: 1.00000\n",
            "one epochs training time : 76m 15s\n",
            "Epoch 93/100\n",
            "----------\n",
            "train Loss: 0.00049 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.43481 Acc: 93.22430 f1: 1.00000\n",
            "one epochs training time : 77m 5s\n",
            "Epoch 94/100\n",
            "----------\n",
            "train Loss: 0.00031 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.43830 Acc: 93.14642 f1: 1.00000\n",
            "one epochs training time : 77m 54s\n",
            "Epoch 95/100\n",
            "----------\n",
            "train Loss: 0.00040 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.44306 Acc: 93.06854 f1: 1.00000\n",
            "one epochs training time : 78m 43s\n",
            "Epoch 96/100\n",
            "----------\n",
            "train Loss: 0.00032 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.44567 Acc: 92.99065 f1: 1.00000\n",
            "one epochs training time : 79m 32s\n",
            "Epoch 97/100\n",
            "----------\n",
            "train Loss: 0.00035 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.44674 Acc: 92.99065 f1: 1.00000\n",
            "one epochs training time : 80m 21s\n",
            "Epoch 98/100\n",
            "----------\n",
            "train Loss: 0.00026 Acc: 100.00000 f1: 1.00000\n",
            "test Loss: 0.45027 Acc: 93.06854 f1: 1.00000\n",
            "one epochs training time : 81m 10s\n",
            "Epoch 99/100\n",
            "----------\n",
            "train Loss: 0.00078 Acc: 99.96659 f1: 1.00000\n",
            "test Loss: 0.44906 Acc: 92.99065 f1: 1.00000\n",
            "one epochs training time : 81m 60s\n",
            "Training complete in 81m 60s\n",
            "Best valid Acc: 15 - 93.2\n",
            "model saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 결과 그래프 그리기\n",
        "print('best model : %d - %1.f / %.1f'%(best_idx, valid_acc[best_idx], valid_loss[best_idx]))\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(train_acc, 'b-')\n",
        "ax1.plot(valid_acc, 'r-')\n",
        "plt.plot(best_idx, valid_acc[best_idx], 'ro')\n",
        "ax1.set_xlabel('epoch')\n",
        "# Make the y-axis label, ticks and tick labels match the line color.\n",
        "ax1.set_ylabel('acc', color='k')\n",
        "ax1.tick_params('y', colors='k')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(train_loss, 'g-')\n",
        "ax2.plot(valid_loss, 'k-')\n",
        "plt.plot(best_idx, valid_loss[best_idx], 'ro')\n",
        "ax2.set_ylabel('loss', color='k')\n",
        "ax2.tick_params('y', colors='k')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "5kJPLUuEU1pH",
        "outputId": "60a2a023-7606-4ab0-a639-640f4b1a900d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best model : 15 - 93 / 0.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JJdS3MynU1rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 학습 결과 검수\n",
        "def test_and_visualize_model(model, phase = 'test', num_images=4):\n",
        "    # phase = 'train', 'valid', 'test'\n",
        "    \n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    fig = plt.figure()\n",
        "    \n",
        "    running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)  # batch의 평균 loss 출력\n",
        "\n",
        "            running_loss    += loss.item() * inputs.size(0)\n",
        "            running_corrects+= torch.sum(preds == labels.data)\n",
        "            num_cnt += inputs.size(0)  # batch size\n",
        "\n",
        "    #         if i == 2: break\n",
        "\n",
        "        test_loss = running_loss / num_cnt\n",
        "        test_acc  = running_corrects.double() / num_cnt       \n",
        "        print('test done : loss/acc : %.2f / %.1f' % (test_loss, test_acc*100))\n",
        "\n",
        "    # 예시 그림 plot\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)        \n",
        "\n",
        "            # 예시 그림 plot\n",
        "            for j in range(1, num_images+1):\n",
        "                ax = plt.subplot(num_images//2, 2, j)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('%s : %s -> %s'%(\n",
        "                    'True' if class_names[str(labels[j].cpu().numpy())]==class_names[str(preds[j].cpu().numpy())] else 'False',\n",
        "                    class_names[str(labels[j].cpu().numpy())], class_names[str(preds[j].cpu().numpy())]))\n",
        "                imshow(inputs.cpu().data[j])          \n",
        "            if i == 0 : break\n",
        "\n",
        "\n",
        "    model.train(mode=was_training);  # 다시 train모드로\n",
        "    \n",
        "    ## TEST!\n",
        "    test_and_visualize_model(model, phase = 'test')"
      ],
      "metadata": {
        "id": "bZK4jMWoU1tQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LedsQjpUU1vI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "X2jIgWqSU1w9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-o1YRRNYU1zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gj7gTQv6U11P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "30_rcMw4U13G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1zWu-D7WdRmQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}