{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNet_MVtecAD_Dataset",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seunghee0518/AI_python/blob/main/EfficientNet_b4_by_timm_MVtecAD_transfoms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## trina/ test 나눠서 학습"
      ],
      "metadata": {
        "id": "lynhGDxilbRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "torch.hub : Pytorch Hub는 연구 재현성을 촉진하도록 설계된 사전 훈련 된 모델 저장소\n",
        "nvidia_efficientnet_b4 사전 모델 가져옴\n",
        "'''\n",
        "# import torch\n",
        "# model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b4', pretrained=True)\n",
        "!pip install timm\n",
        "import timm\n",
        "model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=88)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ-ytfDpoKMH",
        "outputId": "b6b09ffc-1933-40ef-deaa-c7dcd121b543"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 20.3 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 16.7 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 266 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 276 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 286 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 307 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 317 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 327 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 348 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 358 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 368 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 378 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 389 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 399 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 409 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 419 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 430 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 431 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.12.0+cu113)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.5.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b4_ra2_320-7eb33cd5.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b4_ra2_320-7eb33cd5.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from pprint import pprint\n",
        "# model_names = timm.list_models(pretrained=True)\n",
        "# pprint(model_names)"
      ],
      "metadata": {
        "id": "invECZxkPTyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKXv22Yk6zus",
        "outputId": "1ddfadc9-4448-4275-fecc-be8d93a855de"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 학습 코드\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "#import timm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import transforms, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "from PIL import Image\n",
        "# from efficientnet_pytorch import EfficientNet\n",
        "# model_name = 'efficientnet-b0'  # b5\n",
        "\n",
        "# image_size = EfficientNet.get_image_size(model_name)\n",
        "# print(image_size)\n",
        "# model = EfficientNet.from_pretrained(model_name, num_classes=88)"
      ],
      "metadata": {
        "id": "Gjs-R_R5lUKg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 기본 설정\n",
        "device = torch.device('cuda')\n",
        "batch_size  = 32\n",
        "random_seed = 1234\n",
        "img_size = 224\n",
        "random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZHMCtAvlDOp",
        "outputId": "233ecce6-f71c-4575-ab06-6d57ee7f8e9a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f5631413990>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## transforms 함수 정리\n",
        "* transforms.ToPILImage() - csv 파일로 데이터셋을 받을 경우, PIL image로 바꿔준다.\n",
        "* transforms.CenterCrop(size) - 가운데 부분을 size 크기로 자른다.\n",
        "* transforms.Grayscale(num_output_channels=1) - grayscale로 변환한다.\n",
        "* transforms.RandomAffine(degrees) - 랜덤으로 affine 변형을 한다.\n",
        "* transforms.RandomCrop(size) -이미지를 랜덤으로 아무데나 잘라 size 크기로 출력한다.\n",
        "* transforms.RandomResizedCrop(size) - 이미지 사이즈를 size로 변경한다\n",
        "* transforms.Resize(size) - 이미지 사이즈를 size로 변경한다\n",
        "* transforms.RandomRotation(degrees) 이미지를 랜덤으로 degrees 각도로 회전한다.\n",
        "* transforms.RandomResizedCrop(size, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333)) - 이미지를 랜덤으로 변형한다.\n",
        "* transforms.RandomVerticalFlip(p=0.5) - 이미지를 랜덤으로 수직으로 뒤집는다. p =0이면 뒤집지 않는다.\n",
        "* transforms.RandomHorizontalFlip(p=0.5) - 이미지를 랜덤으로 수평으로 뒤집는다.\n",
        "* transforms.ToTensor() - 이미지 데이터를 tensor로 바꿔준다.\n",
        "* transforms.Normalize(mean, std, inplace=False) - 이미지를 정규화한다."
      ],
      "metadata": {
        "id": "fTgH3bYzN7RA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 데이터 전처리 함수\n",
        "# make dataset\n",
        "#data_path = 'president/president_data'  # class 별 폴더로 나누어진 걸 가져와서 라벨도 달아준다\n",
        "# train_dataset = datasets.ImageFolder(data_path,\n",
        "#                                      transforms.Compose([\n",
        "#                                      transforms.Resize((224, 224)),\n",
        "#                                      transforms.RandomCrop(224),\n",
        "#                                      transforms.RandomRotation(90, expand=True),\n",
        "#                                      transforms.RandomVerticalFlip(),\n",
        "#                                      transforms.RandomHorizontalFlip(),\n",
        "#                                      transforms.ToTensor(), # 이미지 데이터를 tensor로 바꿔준다.\n",
        "#                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])) # Normalize는 많은 이미지의 평균, 표준편차로 정함(보통 많이 하는 값이라고함)\n",
        "\n",
        "\n",
        "### 이미지 전처리 함수 & 클래스\n",
        "## 이미지  > 넘파이 배열로 변환\n",
        "def img_load(path):\n",
        "    img = cv2.imread(path)[:,:,::-1] # Return type:\tnumpy.ndarray / 기본적으로 BGR로 불러옴, RGB 변환함\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    return img\n",
        "\n",
        "class Custom_dataset_1(Dataset): # 기본\n",
        "    def __init__(self, img_paths, labels, mode='train'):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode = mode\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.img_paths[idx]\n",
        "        img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "        img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "        ## 레이블 > 원-핫 인코딩 하기 \n",
        "        label = self.labels[idx]# (원핫인코딩 안할거면 해당 코드만 필요)\n",
        "        return img, label\n",
        "\n",
        "class Custom_dataset_2(Dataset): # 변형\n",
        "    def __init__(self, img_paths, labels, mode='train'):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode = mode\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.img_paths[idx]\n",
        "        if self.mode == 'train':\n",
        "          img = Image.fromarray(img)\n",
        "          #img = transforms.Resize((img_size, img_size))(img) # 처음 이미지 불러올때 resize 했으므로 생략\n",
        "          #img = transforms.RandomCrop(img_size)(img)\n",
        "          img = transforms.RandomRotation(90, expand=False)(img)\n",
        "          img = transforms.RandomVerticalFlip()(img)\n",
        "          img = transforms.RandomHorizontalFlip()(img)\n",
        "          img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "          img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "        if self.mode=='test':\n",
        "          img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "        ## 레이블\n",
        "        label = self.labels[idx]# (원핫인코딩 안할거면 해당 코드만 필요)\n",
        "        return img, label\n",
        "\n",
        "class Custom_dataset_3(Dataset): # 기본이미지 + 변형이미지 (train 시 2배 증량됨)\n",
        "    def __init__(self, img_paths, labels, mode='train'):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode=mode\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.mode=='train':\n",
        "          if idx < 4277: # 변경 없는 이미지\n",
        "            img = self.img_paths[idx]\n",
        "            img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "            img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "            label = self.labels[idx]\n",
        "            return img, label\n",
        "\n",
        "          else : # 랜덤 변경된 이미지 추가됨 \n",
        "            img = self.img_paths[idx]\n",
        "            img = Image.fromarray(img)\n",
        "            #img = transforms.Resize((img_size, img_size))(img) # 처음 이미지 불러올때 resize 했으므로 생략\n",
        "            #img = transforms.RandomCrop(img_size)(img)\n",
        "            img = transforms.RandomRotation(90, expand=False)(img)\n",
        "            img = transforms.RandomVerticalFlip()(img)\n",
        "            img = transforms.RandomHorizontalFlip()(img)\n",
        "            img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "            img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "            label = self.labels[idx]\n",
        "            return img, label\n",
        "\n",
        "        if self.mode=='test':\n",
        "          img = self.img_paths[idx]\n",
        "          img = transforms.ToTensor()(img)\n",
        "          img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "          label = self.labels[idx]\n",
        "          return img, label\n",
        "            "
      ],
      "metadata": {
        "id": "ORqFbwLXpSeu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 이미지 로드 및 전처리\n",
        "# 이미지 경로\n",
        "train_png = sorted(glob('/content/drive/Othercomputers/내 MacBook Pro/open/train/*.png'))\n",
        "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
        "\n",
        "#train_imgs = np.load('/content/drive/MyDrive/DACON_이상치 탐지 알고리즘 경진대회/train_imgs_224.npy')\n",
        "train_y = pd.read_csv(\"/content/drive/Othercomputers/내 MacBook Pro/open/train_df.csv\")\n",
        "\n",
        "train_labels = train_y[\"label\"] # 레이블순서는 이미지 파일 순서대로임\n",
        "\n",
        "label_unique = sorted(np.unique(train_labels))\n",
        "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))} # 오름차순으로 레이블별로 숫자 부여(0부터 시작)\n",
        "\n",
        "train_labels = [label_unique[k] for k in train_labels]\n",
        "train_dataset = Custom_dataset_2(np.array(train_imgs), np.array(train_labels), mode='train')\n",
        "train_idx, vaild_idx = train_test_split(list(range(len(train_dataset))), stratify=train_labels, test_size=0.3, random_state=random_seed)\n",
        "\n",
        "# ## 이미지 증량 시만 사용\n",
        "# train_imgs = train_imgs + train_imgs\n",
        "# train_labels = train_labels+train_labels\n",
        "\n",
        "# train_dataset = Custom_dataset_3(np.array(train_imgs), np.array(train_labels), mode='train')\n",
        "\n",
        "# ### 데이터셋 분리 > 층화추출 & 테스터 데이터 비율 : 0.3, 시드 : 1234, 셔플 = True(default)\n",
        "# train_idx, vaild_idx = train_test_split(list(range(len(train_dataset))), stratify=train_labels, test_size=0.3, random_state=random_seed)\n",
        "\n",
        "datasets = {} # 데이터셋을 담을 딕셔너리\n",
        "datasets['train'] = Subset(train_dataset, train_idx)\n",
        "datasets['vaild']  = Subset(train_dataset, vaild_idx)\n",
        "\n",
        "## data loader 선언\n",
        "dataloaders, batch_num = {}, {}\n",
        "dataloaders['train'] = torch.utils.data.DataLoader(datasets['train'],\n",
        "                                                  batch_size=batch_size, shuffle=True,\n",
        "                                                  num_workers=0)\n",
        "dataloaders['vaild']  = torch.utils.data.DataLoader(datasets['vaild'],\n",
        "                                                    batch_size=batch_size, shuffle=False,\n",
        "                                                    num_workers=0)\n",
        "'''\n",
        "데이터 변형 코드를 추가한 후 아래 오류코드가 나와\n",
        "Caught TypeError in DataLoader worker process 0\n",
        "DataLoader > num_workers 를 4 -> 0 로 낮춤\n",
        "'''\n",
        "\n",
        "batch_num['train'], batch_num['vaild'] = len(dataloaders['train']), len(dataloaders['vaild'])\n",
        "print('batch_size : %d,  train/vaild(데이터셋개수/배치사이즈) : %d / %d' % (batch_size, batch_num['train'],batch_num['vaild']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItvLP1Y3k-OW",
        "outputId": "b3ecd9c1-0afd-4c98-d6b4-798569862380"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4277/4277 [03:39<00:00, 19.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_size : 32,  train/vaild(데이터셋개수/배치사이즈) : 94 / 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 참고 블로그 : https://keep-steady.tistory.com/35\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "### f1 스코어 함수 \n",
        "def score_function(real, pred): # 라이브러리 > sklearn.metrics \n",
        "    score = f1_score(real, pred, average=\"macro\")\n",
        "    return score\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    #train_loss, train_acc, valid_loss, valid_acc = [], [], [], []\n",
        "    train_loss, train_acc, valid_loss, valid_acc, train_f1, valid_f1 = [], [], [], [], [], []\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))# - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'vaild']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
        "            \n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device) # device = torch.device('cuda')\n",
        "                labels = labels.to(device) # device = torch.device('cuda')\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                num_cnt += len(labels)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "            \n",
        "            epoch_loss = float(running_loss / num_cnt)\n",
        "            epoch_acc  = float((running_corrects.double() / num_cnt).cpu()*100)\n",
        "            f1 = score_function(labels.cpu().data, preds.cpu()) # score_function or f1_score\n",
        "\n",
        "            if phase == 'train':\n",
        "                train_loss.append(epoch_loss)\n",
        "                train_acc.append(epoch_acc)\n",
        "                train_f1.append(f1)\n",
        "            else:\n",
        "                valid_loss.append(epoch_loss)\n",
        "                valid_acc.append(epoch_acc)\n",
        "                valid_f1.append(f1)\n",
        "\n",
        "            print('{} Loss: {:.5f} Acc: {:.5f} macro-f1: {:.5f}'.format(phase, epoch_loss, epoch_acc, f1))\n",
        "           \n",
        "            # deep copy the model(최적모델 저장)\n",
        "            if phase == 'vaild' and epoch_acc > best_acc:\n",
        "                best_idx = epoch\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "#                 best_model_wts = copy.deepcopy(model.module.state_dict())\n",
        "                print('==> best model saved - %d / %.1f'%(best_idx, best_acc))\n",
        "        # 한 에포크마다 실행 시간 출력하기(누적 시간으로 출력됨)\n",
        "        time_elapsed = time.time() - since\n",
        "        print('each epochs training time : {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "        print('\\n')\n",
        "\n",
        "        # 한 에포크마다 필요없는 메모리 지우기 : 지우기 효과는 아직 확인 못해봄\n",
        "        try:      \n",
        "          gc.collect() # cpu 비움\n",
        "          torch.cuda.empty_cache() # gpu 비움\n",
        "        except:\n",
        "          pass\n",
        "          \n",
        "    ## 학습 마무리 후\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best valid Acc: %d - %.1f' %(best_idx, best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    '''\n",
        "    한 에포크 마다 저장된 최적의 모델 가중치로 조정 후 다음 에포크가 돌아감\n",
        "    '''\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    torch.save(model.state_dict(), 'president_model.pt')\n",
        "    print('model saved')\n",
        "    return model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc, train_f1, valid_f1\n",
        "\n",
        "# 설정\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # set gpu\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_ft = optim.SGD(model.parameters(), \n",
        "                         lr = 0.05,\n",
        "                         momentum=0.9,\n",
        "                         weight_decay=1e-4)\n",
        "\n",
        "lmbda = lambda epoch: 0.98739\n",
        "exp_lr_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer_ft, lr_lambda=lmbda)\n",
        "\n",
        "# 사전학습된 가중치와 모델을 가져와 데이터셋으로 추가 모델 학습\n",
        "model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc, train_f1, valid_f1 = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDNj4Yarkx-R",
        "outputId": "5d3044fd-73aa-4397-9b08-a4612ac43b09"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/100\n",
            "----------\n",
            "train Loss: 1.46207 Acc: 76.97962 macro-f1: 0.73810\n",
            "vaild Loss: 0.80955 Acc: 84.89097 macro-f1: 1.00000\n",
            "==> best model saved - 0 / 84.9\n",
            "each epochs training time : 0m 50s\n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "----------\n",
            "train Loss: 0.68405 Acc: 85.29903 macro-f1: 0.51111\n",
            "vaild Loss: 0.56478 Acc: 87.30530 macro-f1: 1.00000\n",
            "==> best model saved - 1 / 87.3\n",
            "each epochs training time : 1m 41s\n",
            "\n",
            "\n",
            "Epoch 2/100\n",
            "----------\n",
            "train Loss: 0.53840 Acc: 87.00301 macro-f1: 0.74359\n",
            "vaild Loss: 0.52435 Acc: 88.00623 macro-f1: 1.00000\n",
            "==> best model saved - 2 / 88.0\n",
            "each epochs training time : 2m 34s\n",
            "\n",
            "\n",
            "Epoch 3/100\n",
            "----------\n",
            "train Loss: 0.44291 Acc: 88.90745 macro-f1: 0.75385\n",
            "vaild Loss: 0.42053 Acc: 89.79751 macro-f1: 1.00000\n",
            "==> best model saved - 3 / 89.8\n",
            "each epochs training time : 3m 27s\n",
            "\n",
            "\n",
            "Epoch 4/100\n",
            "----------\n",
            "train Loss: 0.39433 Acc: 90.24390 macro-f1: 0.84615\n",
            "vaild Loss: 0.39179 Acc: 89.71963 macro-f1: 1.00000\n",
            "each epochs training time : 4m 19s\n",
            "\n",
            "\n",
            "Epoch 5/100\n",
            "----------\n",
            "train Loss: 0.33496 Acc: 91.07918 macro-f1: 0.80513\n",
            "vaild Loss: 0.37403 Acc: 90.65421 macro-f1: 1.00000\n",
            "==> best model saved - 5 / 90.7\n",
            "each epochs training time : 5m 12s\n",
            "\n",
            "\n",
            "Epoch 6/100\n",
            "----------\n",
            "train Loss: 0.30985 Acc: 91.51353 macro-f1: 0.84615\n",
            "vaild Loss: 0.36904 Acc: 90.26480 macro-f1: 1.00000\n",
            "each epochs training time : 6m 5s\n",
            "\n",
            "\n",
            "Epoch 7/100\n",
            "----------\n",
            "train Loss: 0.27164 Acc: 92.38223 macro-f1: 0.73810\n",
            "vaild Loss: 0.31997 Acc: 91.27726 macro-f1: 1.00000\n",
            "==> best model saved - 7 / 91.3\n",
            "each epochs training time : 6m 58s\n",
            "\n",
            "\n",
            "Epoch 8/100\n",
            "----------\n",
            "train Loss: 0.23977 Acc: 93.35115 macro-f1: 0.88889\n",
            "vaild Loss: 0.29866 Acc: 92.52336 macro-f1: 1.00000\n",
            "==> best model saved - 8 / 92.5\n",
            "each epochs training time : 7m 50s\n",
            "\n",
            "\n",
            "Epoch 9/100\n",
            "----------\n",
            "train Loss: 0.23043 Acc: 93.58503 macro-f1: 0.70909\n",
            "vaild Loss: 0.26638 Acc: 92.36760 macro-f1: 1.00000\n",
            "each epochs training time : 8m 43s\n",
            "\n",
            "\n",
            "Epoch 10/100\n",
            "----------\n",
            "train Loss: 0.18305 Acc: 94.78784 macro-f1: 0.61905\n",
            "vaild Loss: 0.27605 Acc: 92.83489 macro-f1: 1.00000\n",
            "==> best model saved - 10 / 92.8\n",
            "each epochs training time : 9m 36s\n",
            "\n",
            "\n",
            "Epoch 11/100\n",
            "----------\n",
            "train Loss: 0.16947 Acc: 94.95489 macro-f1: 0.87879\n",
            "vaild Loss: 0.26266 Acc: 92.67913 macro-f1: 1.00000\n",
            "each epochs training time : 10m 29s\n",
            "\n",
            "\n",
            "Epoch 12/100\n",
            "----------\n",
            "train Loss: 0.14042 Acc: 95.48948 macro-f1: 0.84615\n",
            "vaild Loss: 0.23945 Acc: 93.69159 macro-f1: 1.00000\n",
            "==> best model saved - 12 / 93.7\n",
            "each epochs training time : 11m 22s\n",
            "\n",
            "\n",
            "Epoch 13/100\n",
            "----------\n",
            "train Loss: 0.12959 Acc: 96.29135 macro-f1: 1.00000\n",
            "vaild Loss: 0.24148 Acc: 93.84735 macro-f1: 1.00000\n",
            "==> best model saved - 13 / 93.8\n",
            "each epochs training time : 12m 15s\n",
            "\n",
            "\n",
            "Epoch 14/100\n",
            "----------\n",
            "train Loss: 0.11242 Acc: 96.69228 macro-f1: 1.00000\n",
            "vaild Loss: 0.20795 Acc: 94.70405 macro-f1: 1.00000\n",
            "==> best model saved - 14 / 94.7\n",
            "each epochs training time : 13m 7s\n",
            "\n",
            "\n",
            "Epoch 15/100\n",
            "----------\n",
            "train Loss: 0.10390 Acc: 96.99298 macro-f1: 1.00000\n",
            "vaild Loss: 0.25574 Acc: 92.91277 macro-f1: 1.00000\n",
            "each epochs training time : 14m 0s\n",
            "\n",
            "\n",
            "Epoch 16/100\n",
            "----------\n",
            "train Loss: 0.10086 Acc: 97.12663 macro-f1: 1.00000\n",
            "vaild Loss: 0.21677 Acc: 94.08100 macro-f1: 1.00000\n",
            "each epochs training time : 14m 53s\n",
            "\n",
            "\n",
            "Epoch 17/100\n",
            "----------\n",
            "train Loss: 0.07939 Acc: 97.79485 macro-f1: 1.00000\n",
            "vaild Loss: 0.20997 Acc: 94.78193 macro-f1: 1.00000\n",
            "==> best model saved - 17 / 94.8\n",
            "each epochs training time : 15m 46s\n",
            "\n",
            "\n",
            "Epoch 18/100\n",
            "----------\n",
            "train Loss: 0.09012 Acc: 97.42733 macro-f1: 1.00000\n",
            "vaild Loss: 0.19787 Acc: 95.17134 macro-f1: 1.00000\n",
            "==> best model saved - 18 / 95.2\n",
            "each epochs training time : 16m 39s\n",
            "\n",
            "\n",
            "Epoch 19/100\n",
            "----------\n",
            "train Loss: 0.06796 Acc: 97.79485 macro-f1: 1.00000\n",
            "vaild Loss: 0.18214 Acc: 94.93769 macro-f1: 1.00000\n",
            "each epochs training time : 17m 31s\n",
            "\n",
            "\n",
            "Epoch 20/100\n",
            "----------\n",
            "train Loss: 0.07204 Acc: 97.89509 macro-f1: 1.00000\n",
            "vaild Loss: 0.17881 Acc: 95.63863 macro-f1: 1.00000\n",
            "==> best model saved - 20 / 95.6\n",
            "each epochs training time : 18m 24s\n",
            "\n",
            "\n",
            "Epoch 21/100\n",
            "----------\n",
            "train Loss: 0.06285 Acc: 98.22920 macro-f1: 1.00000\n",
            "vaild Loss: 0.18534 Acc: 94.93769 macro-f1: 1.00000\n",
            "each epochs training time : 19m 17s\n",
            "\n",
            "\n",
            "Epoch 22/100\n",
            "----------\n",
            "train Loss: 0.04564 Acc: 98.56331 macro-f1: 0.89744\n",
            "vaild Loss: 0.19216 Acc: 95.63863 macro-f1: 1.00000\n",
            "each epochs training time : 20m 9s\n",
            "\n",
            "\n",
            "Epoch 23/100\n",
            "----------\n",
            "train Loss: 0.05017 Acc: 98.56331 macro-f1: 0.84615\n",
            "vaild Loss: 0.19642 Acc: 94.70405 macro-f1: 1.00000\n",
            "each epochs training time : 21m 2s\n",
            "\n",
            "\n",
            "Epoch 24/100\n",
            "----------\n",
            "train Loss: 0.05262 Acc: 98.36285 macro-f1: 0.86667\n",
            "vaild Loss: 0.17881 Acc: 95.56075 macro-f1: 1.00000\n",
            "each epochs training time : 21m 55s\n",
            "\n",
            "\n",
            "Epoch 25/100\n",
            "----------\n",
            "train Loss: 0.04614 Acc: 98.83060 macro-f1: 1.00000\n",
            "vaild Loss: 0.19342 Acc: 95.48287 macro-f1: 1.00000\n",
            "each epochs training time : 22m 47s\n",
            "\n",
            "\n",
            "Epoch 26/100\n",
            "----------\n",
            "train Loss: 0.04227 Acc: 98.69696 macro-f1: 1.00000\n",
            "vaild Loss: 0.20529 Acc: 95.09346 macro-f1: 0.66667\n",
            "each epochs training time : 23m 40s\n",
            "\n",
            "\n",
            "Epoch 27/100\n",
            "----------\n",
            "train Loss: 0.03992 Acc: 98.83060 macro-f1: 1.00000\n",
            "vaild Loss: 0.20220 Acc: 95.17134 macro-f1: 1.00000\n",
            "each epochs training time : 24m 33s\n",
            "\n",
            "\n",
            "Epoch 28/100\n",
            "----------\n",
            "train Loss: 0.05148 Acc: 98.42967 macro-f1: 1.00000\n",
            "vaild Loss: 0.21685 Acc: 95.17134 macro-f1: 1.00000\n",
            "each epochs training time : 25m 25s\n",
            "\n",
            "\n",
            "Epoch 29/100\n",
            "----------\n",
            "train Loss: 0.04219 Acc: 98.66355 macro-f1: 0.90476\n",
            "vaild Loss: 0.18442 Acc: 95.79439 macro-f1: 1.00000\n",
            "==> best model saved - 29 / 95.8\n",
            "each epochs training time : 26m 18s\n",
            "\n",
            "\n",
            "Epoch 30/100\n",
            "----------\n",
            "train Loss: 0.03866 Acc: 98.79719 macro-f1: 1.00000\n",
            "vaild Loss: 0.20900 Acc: 95.40498 macro-f1: 1.00000\n",
            "each epochs training time : 27m 11s\n",
            "\n",
            "\n",
            "Epoch 31/100\n",
            "----------\n",
            "train Loss: 0.03343 Acc: 99.13131 macro-f1: 1.00000\n",
            "vaild Loss: 0.20226 Acc: 95.32710 macro-f1: 1.00000\n",
            "each epochs training time : 28m 3s\n",
            "\n",
            "\n",
            "Epoch 32/100\n",
            "----------\n",
            "train Loss: 0.03126 Acc: 98.99766 macro-f1: 1.00000\n",
            "vaild Loss: 0.18828 Acc: 95.32710 macro-f1: 1.00000\n",
            "each epochs training time : 28m 56s\n",
            "\n",
            "\n",
            "Epoch 33/100\n",
            "----------\n",
            "train Loss: 0.02844 Acc: 99.19813 macro-f1: 1.00000\n",
            "vaild Loss: 0.19031 Acc: 95.79439 macro-f1: 1.00000\n",
            "each epochs training time : 29m 49s\n",
            "\n",
            "\n",
            "Epoch 34/100\n",
            "----------\n",
            "train Loss: 0.02450 Acc: 99.06448 macro-f1: 1.00000\n",
            "vaild Loss: 0.21798 Acc: 95.71651 macro-f1: 1.00000\n",
            "each epochs training time : 30m 41s\n",
            "\n",
            "\n",
            "Epoch 35/100\n",
            "----------\n",
            "train Loss: 0.02952 Acc: 99.13131 macro-f1: 1.00000\n",
            "vaild Loss: 0.19184 Acc: 95.95016 macro-f1: 1.00000\n",
            "==> best model saved - 35 / 96.0\n",
            "each epochs training time : 31m 34s\n",
            "\n",
            "\n",
            "Epoch 36/100\n",
            "----------\n",
            "train Loss: 0.02694 Acc: 99.29836 macro-f1: 1.00000\n",
            "vaild Loss: 0.18197 Acc: 95.56075 macro-f1: 1.00000\n",
            "each epochs training time : 32m 27s\n",
            "\n",
            "\n",
            "Epoch 37/100\n",
            "----------\n",
            "train Loss: 0.01956 Acc: 99.36519 macro-f1: 1.00000\n",
            "vaild Loss: 0.17871 Acc: 96.10592 macro-f1: 1.00000\n",
            "==> best model saved - 37 / 96.1\n",
            "each epochs training time : 33m 19s\n",
            "\n",
            "\n",
            "Epoch 38/100\n",
            "----------\n",
            "train Loss: 0.01797 Acc: 99.43201 macro-f1: 1.00000\n",
            "vaild Loss: 0.22454 Acc: 95.17134 macro-f1: 1.00000\n",
            "each epochs training time : 34m 12s\n",
            "\n",
            "\n",
            "Epoch 39/100\n",
            "----------\n",
            "train Loss: 0.01383 Acc: 99.56565 macro-f1: 0.85714\n",
            "vaild Loss: 0.20761 Acc: 95.71651 macro-f1: 1.00000\n",
            "each epochs training time : 35m 5s\n",
            "\n",
            "\n",
            "Epoch 40/100\n",
            "----------\n",
            "train Loss: 0.02299 Acc: 99.43201 macro-f1: 0.76190\n",
            "vaild Loss: 0.19761 Acc: 95.87227 macro-f1: 1.00000\n",
            "each epochs training time : 35m 57s\n",
            "\n",
            "\n",
            "Epoch 41/100\n",
            "----------\n",
            "train Loss: 0.03084 Acc: 99.03107 macro-f1: 1.00000\n",
            "vaild Loss: 0.17598 Acc: 96.26168 macro-f1: 1.00000\n",
            "==> best model saved - 41 / 96.3\n",
            "each epochs training time : 36m 50s\n",
            "\n",
            "\n",
            "Epoch 42/100\n",
            "----------\n",
            "train Loss: 0.02535 Acc: 99.13131 macro-f1: 1.00000\n",
            "vaild Loss: 0.20401 Acc: 96.18380 macro-f1: 1.00000\n",
            "each epochs training time : 37m 43s\n",
            "\n",
            "\n",
            "Epoch 43/100\n",
            "----------\n",
            "train Loss: 0.01709 Acc: 99.53224 macro-f1: 1.00000\n",
            "vaild Loss: 0.21431 Acc: 95.32710 macro-f1: 1.00000\n",
            "each epochs training time : 38m 35s\n",
            "\n",
            "\n",
            "Epoch 44/100\n",
            "----------\n",
            "train Loss: 0.01779 Acc: 99.26495 macro-f1: 1.00000\n",
            "vaild Loss: 0.18000 Acc: 96.72897 macro-f1: 1.00000\n",
            "==> best model saved - 44 / 96.7\n",
            "each epochs training time : 39m 28s\n",
            "\n",
            "\n",
            "Epoch 45/100\n",
            "----------\n",
            "train Loss: 0.01622 Acc: 99.49883 macro-f1: 1.00000\n",
            "vaild Loss: 0.18587 Acc: 96.41745 macro-f1: 1.00000\n",
            "each epochs training time : 40m 21s\n",
            "\n",
            "\n",
            "Epoch 46/100\n",
            "----------\n",
            "train Loss: 0.01026 Acc: 99.66589 macro-f1: 1.00000\n",
            "vaild Loss: 0.20799 Acc: 95.87227 macro-f1: 1.00000\n",
            "each epochs training time : 41m 13s\n",
            "\n",
            "\n",
            "Epoch 47/100\n",
            "----------\n",
            "train Loss: 0.01314 Acc: 99.49883 macro-f1: 1.00000\n",
            "vaild Loss: 0.22887 Acc: 95.79439 macro-f1: 1.00000\n",
            "each epochs training time : 42m 6s\n",
            "\n",
            "\n",
            "Epoch 48/100\n",
            "----------\n",
            "train Loss: 0.01206 Acc: 99.53224 macro-f1: 0.85714\n",
            "vaild Loss: 0.19297 Acc: 96.49533 macro-f1: 1.00000\n",
            "each epochs training time : 42m 58s\n",
            "\n",
            "\n",
            "Epoch 49/100\n",
            "----------\n",
            "train Loss: 0.01464 Acc: 99.73271 macro-f1: 1.00000\n",
            "vaild Loss: 0.19673 Acc: 95.63863 macro-f1: 1.00000\n",
            "each epochs training time : 43m 51s\n",
            "\n",
            "\n",
            "Epoch 50/100\n",
            "----------\n",
            "train Loss: 0.00939 Acc: 99.79953 macro-f1: 0.83333\n",
            "vaild Loss: 0.19242 Acc: 96.33956 macro-f1: 1.00000\n",
            "each epochs training time : 44m 44s\n",
            "\n",
            "\n",
            "Epoch 51/100\n",
            "----------\n",
            "train Loss: 0.01404 Acc: 99.56565 macro-f1: 1.00000\n",
            "vaild Loss: 0.21291 Acc: 96.18380 macro-f1: 1.00000\n",
            "each epochs training time : 45m 36s\n",
            "\n",
            "\n",
            "Epoch 52/100\n",
            "----------\n",
            "train Loss: 0.01136 Acc: 99.66589 macro-f1: 1.00000\n",
            "vaild Loss: 0.20874 Acc: 95.87227 macro-f1: 1.00000\n",
            "each epochs training time : 46m 29s\n",
            "\n",
            "\n",
            "Epoch 53/100\n",
            "----------\n",
            "train Loss: 0.01050 Acc: 99.66589 macro-f1: 1.00000\n",
            "vaild Loss: 0.20230 Acc: 96.10592 macro-f1: 1.00000\n",
            "each epochs training time : 47m 21s\n",
            "\n",
            "\n",
            "Epoch 54/100\n",
            "----------\n",
            "train Loss: 0.01287 Acc: 99.56565 macro-f1: 1.00000\n",
            "vaild Loss: 0.21655 Acc: 95.63863 macro-f1: 1.00000\n",
            "each epochs training time : 48m 14s\n",
            "\n",
            "\n",
            "Epoch 55/100\n",
            "----------\n",
            "train Loss: 0.01117 Acc: 99.69930 macro-f1: 1.00000\n",
            "vaild Loss: 0.20280 Acc: 95.95016 macro-f1: 1.00000\n",
            "each epochs training time : 49m 7s\n",
            "\n",
            "\n",
            "Epoch 56/100\n",
            "----------\n",
            "train Loss: 0.01092 Acc: 99.59906 macro-f1: 1.00000\n",
            "vaild Loss: 0.21068 Acc: 96.10592 macro-f1: 1.00000\n",
            "each epochs training time : 49m 59s\n",
            "\n",
            "\n",
            "Epoch 57/100\n",
            "----------\n",
            "train Loss: 0.00751 Acc: 99.86635 macro-f1: 1.00000\n",
            "vaild Loss: 0.19074 Acc: 95.95016 macro-f1: 1.00000\n",
            "each epochs training time : 50m 52s\n",
            "\n",
            "\n",
            "Epoch 58/100\n",
            "----------\n",
            "train Loss: 0.01432 Acc: 99.59906 macro-f1: 1.00000\n",
            "vaild Loss: 0.20085 Acc: 95.87227 macro-f1: 1.00000\n",
            "each epochs training time : 51m 45s\n",
            "\n",
            "\n",
            "Epoch 59/100\n",
            "----------\n",
            "train Loss: 0.01303 Acc: 99.59906 macro-f1: 1.00000\n",
            "vaild Loss: 0.20046 Acc: 96.18380 macro-f1: 1.00000\n",
            "each epochs training time : 52m 37s\n",
            "\n",
            "\n",
            "Epoch 60/100\n",
            "----------\n",
            "train Loss: 0.01218 Acc: 99.63248 macro-f1: 1.00000\n",
            "vaild Loss: 0.21284 Acc: 95.87227 macro-f1: 1.00000\n",
            "each epochs training time : 53m 30s\n",
            "\n",
            "\n",
            "Epoch 61/100\n",
            "----------\n",
            "train Loss: 0.01610 Acc: 99.49883 macro-f1: 1.00000\n",
            "vaild Loss: 0.17039 Acc: 96.33956 macro-f1: 1.00000\n",
            "each epochs training time : 54m 22s\n",
            "\n",
            "\n",
            "Epoch 62/100\n",
            "----------\n",
            "train Loss: 0.00849 Acc: 99.73271 macro-f1: 1.00000\n",
            "vaild Loss: 0.18413 Acc: 96.02804 macro-f1: 1.00000\n",
            "each epochs training time : 55m 15s\n",
            "\n",
            "\n",
            "Epoch 63/100\n",
            "----------\n",
            "train Loss: 0.01502 Acc: 99.46542 macro-f1: 1.00000\n",
            "vaild Loss: 0.21550 Acc: 96.10592 macro-f1: 1.00000\n",
            "each epochs training time : 56m 8s\n",
            "\n",
            "\n",
            "Epoch 64/100\n",
            "----------\n",
            "train Loss: 0.01259 Acc: 99.63248 macro-f1: 1.00000\n",
            "vaild Loss: 0.20534 Acc: 95.71651 macro-f1: 1.00000\n",
            "each epochs training time : 57m 0s\n",
            "\n",
            "\n",
            "Epoch 65/100\n",
            "----------\n",
            "train Loss: 0.00539 Acc: 99.83294 macro-f1: 1.00000\n",
            "vaild Loss: 0.21158 Acc: 96.57321 macro-f1: 1.00000\n",
            "each epochs training time : 57m 53s\n",
            "\n",
            "\n",
            "Epoch 66/100\n",
            "----------\n",
            "train Loss: 0.01100 Acc: 99.59906 macro-f1: 1.00000\n",
            "vaild Loss: 0.19027 Acc: 96.10592 macro-f1: 1.00000\n",
            "each epochs training time : 58m 46s\n",
            "\n",
            "\n",
            "Epoch 67/100\n",
            "----------\n",
            "train Loss: 0.01037 Acc: 99.66589 macro-f1: 0.85714\n",
            "vaild Loss: 0.19507 Acc: 96.26168 macro-f1: 1.00000\n",
            "each epochs training time : 59m 38s\n",
            "\n",
            "\n",
            "Epoch 68/100\n",
            "----------\n",
            "train Loss: 0.00849 Acc: 99.73271 macro-f1: 0.85714\n",
            "vaild Loss: 0.19639 Acc: 96.72897 macro-f1: 1.00000\n",
            "each epochs training time : 60m 31s\n",
            "\n",
            "\n",
            "Epoch 69/100\n",
            "----------\n",
            "train Loss: 0.00621 Acc: 99.76612 macro-f1: 1.00000\n",
            "vaild Loss: 0.19232 Acc: 96.49533 macro-f1: 1.00000\n",
            "each epochs training time : 61m 23s\n",
            "\n",
            "\n",
            "Epoch 70/100\n",
            "----------\n",
            "train Loss: 0.00987 Acc: 99.63248 macro-f1: 1.00000\n",
            "vaild Loss: 0.18607 Acc: 96.18380 macro-f1: 1.00000\n",
            "each epochs training time : 62m 16s\n",
            "\n",
            "\n",
            "Epoch 71/100\n",
            "----------\n",
            "train Loss: 0.00776 Acc: 99.76612 macro-f1: 1.00000\n",
            "vaild Loss: 0.18115 Acc: 96.18380 macro-f1: 1.00000\n",
            "each epochs training time : 63m 9s\n",
            "\n",
            "\n",
            "Epoch 72/100\n",
            "----------\n",
            "train Loss: 0.01061 Acc: 99.53224 macro-f1: 0.88000\n",
            "vaild Loss: 0.16831 Acc: 96.41745 macro-f1: 1.00000\n",
            "each epochs training time : 64m 1s\n",
            "\n",
            "\n",
            "Epoch 73/100\n",
            "----------\n",
            "train Loss: 0.00768 Acc: 99.86635 macro-f1: 1.00000\n",
            "vaild Loss: 0.18484 Acc: 96.18380 macro-f1: 1.00000\n",
            "each epochs training time : 64m 54s\n",
            "\n",
            "\n",
            "Epoch 74/100\n",
            "----------\n",
            "train Loss: 0.00676 Acc: 99.76612 macro-f1: 1.00000\n",
            "vaild Loss: 0.18226 Acc: 96.80685 macro-f1: 1.00000\n",
            "==> best model saved - 74 / 96.8\n",
            "each epochs training time : 65m 46s\n",
            "\n",
            "\n",
            "Epoch 75/100\n",
            "----------\n",
            "train Loss: 0.00959 Acc: 99.73271 macro-f1: 1.00000\n",
            "vaild Loss: 0.19890 Acc: 96.49533 macro-f1: 1.00000\n",
            "each epochs training time : 66m 39s\n",
            "\n",
            "\n",
            "Epoch 76/100\n",
            "----------\n",
            "train Loss: 0.00838 Acc: 99.73271 macro-f1: 1.00000\n",
            "vaild Loss: 0.18096 Acc: 96.49533 macro-f1: 1.00000\n",
            "each epochs training time : 67m 32s\n",
            "\n",
            "\n",
            "Epoch 77/100\n",
            "----------\n",
            "train Loss: 0.00327 Acc: 99.93318 macro-f1: 1.00000\n",
            "vaild Loss: 0.18217 Acc: 96.57321 macro-f1: 1.00000\n",
            "each epochs training time : 68m 24s\n",
            "\n",
            "\n",
            "Epoch 78/100\n",
            "----------\n",
            "train Loss: 0.00614 Acc: 99.79953 macro-f1: 1.00000\n",
            "vaild Loss: 0.20487 Acc: 95.95016 macro-f1: 1.00000\n",
            "each epochs training time : 69m 17s\n",
            "\n",
            "\n",
            "Epoch 79/100\n",
            "----------\n",
            "train Loss: 0.00612 Acc: 99.79953 macro-f1: 1.00000\n",
            "vaild Loss: 0.19070 Acc: 96.10592 macro-f1: 1.00000\n",
            "each epochs training time : 70m 10s\n",
            "\n",
            "\n",
            "Epoch 80/100\n",
            "----------\n",
            "train Loss: 0.00755 Acc: 99.76612 macro-f1: 0.85714\n",
            "vaild Loss: 0.22009 Acc: 96.41745 macro-f1: 1.00000\n",
            "each epochs training time : 71m 2s\n",
            "\n",
            "\n",
            "Epoch 81/100\n",
            "----------\n",
            "train Loss: 0.00732 Acc: 99.76612 macro-f1: 1.00000\n",
            "vaild Loss: 0.21458 Acc: 96.02804 macro-f1: 1.00000\n",
            "each epochs training time : 71m 55s\n",
            "\n",
            "\n",
            "Epoch 82/100\n",
            "----------\n",
            "train Loss: 0.00732 Acc: 99.83294 macro-f1: 1.00000\n",
            "vaild Loss: 0.18533 Acc: 96.57321 macro-f1: 1.00000\n",
            "each epochs training time : 72m 47s\n",
            "\n",
            "\n",
            "Epoch 83/100\n",
            "----------\n",
            "train Loss: 0.00496 Acc: 99.93318 macro-f1: 1.00000\n",
            "vaild Loss: 0.19520 Acc: 96.26168 macro-f1: 1.00000\n",
            "each epochs training time : 73m 40s\n",
            "\n",
            "\n",
            "Epoch 84/100\n",
            "----------\n",
            "train Loss: 0.00382 Acc: 99.83294 macro-f1: 1.00000\n",
            "vaild Loss: 0.19521 Acc: 95.87227 macro-f1: 1.00000\n",
            "each epochs training time : 74m 33s\n",
            "\n",
            "\n",
            "Epoch 85/100\n",
            "----------\n",
            "train Loss: 0.00463 Acc: 99.83294 macro-f1: 1.00000\n",
            "vaild Loss: 0.21837 Acc: 96.02804 macro-f1: 1.00000\n",
            "each epochs training time : 75m 25s\n",
            "\n",
            "\n",
            "Epoch 86/100\n",
            "----------\n",
            "train Loss: 0.00348 Acc: 99.89977 macro-f1: 1.00000\n",
            "vaild Loss: 0.23176 Acc: 96.26168 macro-f1: 1.00000\n",
            "each epochs training time : 76m 18s\n",
            "\n",
            "\n",
            "Epoch 87/100\n",
            "----------\n",
            "train Loss: 0.00180 Acc: 99.96659 macro-f1: 1.00000\n",
            "vaild Loss: 0.20061 Acc: 96.88474 macro-f1: 1.00000\n",
            "==> best model saved - 87 / 96.9\n",
            "each epochs training time : 77m 11s\n",
            "\n",
            "\n",
            "Epoch 88/100\n",
            "----------\n",
            "train Loss: 0.00274 Acc: 99.86635 macro-f1: 1.00000\n",
            "vaild Loss: 0.22484 Acc: 96.26168 macro-f1: 1.00000\n",
            "each epochs training time : 78m 3s\n",
            "\n",
            "\n",
            "Epoch 89/100\n",
            "----------\n",
            "train Loss: 0.00374 Acc: 99.83294 macro-f1: 1.00000\n",
            "vaild Loss: 0.20915 Acc: 96.33956 macro-f1: 1.00000\n",
            "each epochs training time : 78m 56s\n",
            "\n",
            "\n",
            "Epoch 90/100\n",
            "----------\n",
            "train Loss: 0.00220 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.20803 Acc: 96.26168 macro-f1: 1.00000\n",
            "each epochs training time : 79m 48s\n",
            "\n",
            "\n",
            "Epoch 91/100\n",
            "----------\n",
            "train Loss: 0.00519 Acc: 99.83294 macro-f1: 1.00000\n",
            "vaild Loss: 0.21093 Acc: 96.65109 macro-f1: 1.00000\n",
            "each epochs training time : 80m 41s\n",
            "\n",
            "\n",
            "Epoch 92/100\n",
            "----------\n",
            "train Loss: 0.00289 Acc: 99.93318 macro-f1: 1.00000\n",
            "vaild Loss: 0.23644 Acc: 96.26168 macro-f1: 1.00000\n",
            "each epochs training time : 81m 34s\n",
            "\n",
            "\n",
            "Epoch 93/100\n",
            "----------\n",
            "train Loss: 0.00286 Acc: 99.93318 macro-f1: 1.00000\n",
            "vaild Loss: 0.23236 Acc: 96.26168 macro-f1: 1.00000\n",
            "each epochs training time : 82m 26s\n",
            "\n",
            "\n",
            "Epoch 94/100\n",
            "----------\n",
            "train Loss: 0.00249 Acc: 99.93318 macro-f1: 1.00000\n",
            "vaild Loss: 0.21226 Acc: 96.57321 macro-f1: 1.00000\n",
            "each epochs training time : 83m 19s\n",
            "\n",
            "\n",
            "Epoch 95/100\n",
            "----------\n",
            "train Loss: 0.00158 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.20369 Acc: 96.26168 macro-f1: 1.00000\n",
            "each epochs training time : 84m 11s\n",
            "\n",
            "\n",
            "Epoch 96/100\n",
            "----------\n",
            "train Loss: 0.00581 Acc: 99.83294 macro-f1: 1.00000\n",
            "vaild Loss: 0.22851 Acc: 96.41745 macro-f1: 1.00000\n",
            "each epochs training time : 85m 4s\n",
            "\n",
            "\n",
            "Epoch 97/100\n",
            "----------\n",
            "train Loss: 0.00224 Acc: 99.93318 macro-f1: 1.00000\n",
            "vaild Loss: 0.21178 Acc: 96.26168 macro-f1: 1.00000\n",
            "each epochs training time : 85m 57s\n",
            "\n",
            "\n",
            "Epoch 98/100\n",
            "----------\n",
            "train Loss: 0.00499 Acc: 99.86635 macro-f1: 1.00000\n",
            "vaild Loss: 0.20993 Acc: 96.41745 macro-f1: 1.00000\n",
            "each epochs training time : 86m 49s\n",
            "\n",
            "\n",
            "Epoch 99/100\n",
            "----------\n",
            "train Loss: 0.00515 Acc: 99.83294 macro-f1: 1.00000\n",
            "vaild Loss: 0.19482 Acc: 96.72897 macro-f1: 1.00000\n",
            "each epochs training time : 87m 42s\n",
            "\n",
            "\n",
            "Training complete in 87m 42s\n",
            "Best valid Acc: 87 - 96.9\n",
            "model saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 결과 그래프 그리기\n",
        "print('best model : %d - %1.f / %.1f'%(best_idx, valid_acc[best_idx], valid_loss[best_idx]))\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(train_acc, 'b-')\n",
        "ax1.plot(valid_acc, 'r-')\n",
        "plt.plot(best_idx, valid_acc[best_idx], 'ro')\n",
        "ax1.set_xlabel('epoch')\n",
        "# Make the y-axis label, ticks and tick labels match the line color.\n",
        "ax1.set_ylabel('acc', color='k')\n",
        "ax1.tick_params('y', colors='k')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(train_loss, 'g-')\n",
        "ax2.plot(valid_loss, 'k-')\n",
        "plt.plot(best_idx, valid_loss[best_idx], 'ro')\n",
        "ax2.set_ylabel('loss', color='k')\n",
        "ax2.tick_params('y', colors='k')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "5kJPLUuEU1pH",
        "outputId": "d65f840f-0ca3-40f6-c10a-7a4e147cffe3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best model : 87 - 97 / 0.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JJdS3MynU1rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ## 학습 결과 검수\n",
        "# def test_and_visualize_model(model, phase = 'test', num_images=4):\n",
        "#     # phase = 'train', 'valid', 'test'\n",
        "    \n",
        "#     was_training = model.training\n",
        "#     model.eval()\n",
        "#     fig = plt.figure()\n",
        "    \n",
        "#     running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
        "#             inputs = inputs.to(device)\n",
        "#             labels = labels.to(device)\n",
        "\n",
        "#             outputs = model(inputs)\n",
        "#             _, preds = torch.max(outputs, 1)\n",
        "#             loss = criterion(outputs, labels)  # batch의 평균 loss 출력\n",
        "\n",
        "#             running_loss    += loss.item() * inputs.size(0)\n",
        "#             running_corrects+= torch.sum(preds == labels.data)\n",
        "#             num_cnt += inputs.size(0)  # batch size\n",
        "\n",
        "#     #         if i == 2: break\n",
        "\n",
        "#         test_loss = running_loss / num_cnt\n",
        "#         test_acc  = running_corrects.double() / num_cnt       \n",
        "#         print('test done : loss/acc : %.2f / %.1f' % (test_loss, test_acc*100))\n",
        "\n",
        "#     # 예시 그림 plot\n",
        "#     with torch.no_grad():\n",
        "#         for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
        "#             inputs = inputs.to(device)\n",
        "#             labels = labels.to(device)\n",
        "\n",
        "#             outputs = model(inputs)\n",
        "#             _, preds = torch.max(outputs, 1)        \n",
        "\n",
        "#             # 예시 그림 plot\n",
        "#             for j in range(1, num_images+1):\n",
        "#                 ax = plt.subplot(num_images//2, 2, j)\n",
        "#                 ax.axis('off')\n",
        "#                 ax.set_title('%s : %s -> %s'%(\n",
        "#                     'True' if class_names[str(labels[j].cpu().numpy())]==class_names[str(preds[j].cpu().numpy())] else 'False',\n",
        "#                     class_names[str(labels[j].cpu().numpy())], class_names[str(preds[j].cpu().numpy())]))\n",
        "#                 imshow(inputs.cpu().data[j])          \n",
        "#             if i == 0 : break\n",
        "\n",
        "\n",
        "#     model.train(mode=was_training);  # 다시 train모드로\n",
        "    \n",
        "#     ## TEST!\n",
        "#     test_and_visualize_model(model, phase = 'test')"
      ],
      "metadata": {
        "id": "bZK4jMWoU1tQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LedsQjpUU1vI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "X2jIgWqSU1w9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-o1YRRNYU1zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 추론"
      ],
      "metadata": {
        "id": "WQR1RKgTpKk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 모델을 평가 모드로 변경하고 test 데이터 분류\n",
        "test_png = sorted(glob('/content/drive/Othercomputers/내 MacBook Pro/open/test/*.png'))\n",
        "test_imgs = [img_load(n) for n in tqdm(test_png)]\n",
        "test_dataset = Custom_dataset_3(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "model.eval()\n",
        "f_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in (test_loader):\n",
        "        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            pred = model(x)\n",
        "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
      ],
      "metadata": {
        "id": "gj7gTQv6U11P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1c85530-9950-42f4-d3bd-c498950b281e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2154/2154 [04:25<00:00,  8.12it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 숫자로된 레이블을 문자열 레이블로 변경\n",
        "label_decoder = {value:key for key, value in label_unique.items()}\n",
        "f_result = [label_decoder[result] for result in f_pred]"
      ],
      "metadata": {
        "id": "30_rcMw4U13G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime as dt \n",
        "today = dt.today().strftime('%Y-%m-%d')\n",
        "version = f'efficientNet_b4_by_timm_data_ver2_{today}'\n",
        "submission = pd.read_csv(f\"/content/drive/MyDrive/DACON_이상치 탐지 알고리즘 경진대회/open/sample_submission.csv\")\n",
        "\n",
        "## 시각적 확인을 위해 문자열 레이블로 이루어진 된 label 필드 생성\n",
        "submission[\"label\"] = f_result\n",
        "display(submission)\n",
        "submission.to_csv(f\"/content/drive/MyDrive/DACON_이상치 탐지 알고리즘 경진대회/open/sample_submission_{version}.csv\", index = False)"
      ],
      "metadata": {
        "id": "1zWu-D7WdRmQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cef35b9f-ead9-463e-ff7f-60946d075d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      index             label\n",
              "0         0   tile-glue_strip\n",
              "1         1         grid-good\n",
              "2         2   transistor-good\n",
              "3         3         tile-good\n",
              "4         4         tile-good\n",
              "...     ...               ...\n",
              "2149   2149  tile-gray_stroke\n",
              "2150   2150        screw-good\n",
              "2151   2151         grid-good\n",
              "2152   2152        cable-good\n",
              "2153   2153       zipper-good\n",
              "\n",
              "[2154 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4eb498c5-cfe3-40f9-8a25-ba4b3824c33a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>tile-glue_strip</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>grid-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>transistor-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>tile-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>tile-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2149</th>\n",
              "      <td>2149</td>\n",
              "      <td>tile-gray_stroke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2150</th>\n",
              "      <td>2150</td>\n",
              "      <td>screw-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2151</th>\n",
              "      <td>2151</td>\n",
              "      <td>grid-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2152</th>\n",
              "      <td>2152</td>\n",
              "      <td>cable-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2153</th>\n",
              "      <td>2153</td>\n",
              "      <td>zipper-good</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2154 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4eb498c5-cfe3-40f9-8a25-ba4b3824c33a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4eb498c5-cfe3-40f9-8a25-ba4b3824c33a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4eb498c5-cfe3-40f9-8a25-ba4b3824c33a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cG_tNWs2zxh8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}