{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FCN(Fully Connected Network)_MNIST_딥러닝의통계적이해_중간과제물.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QZSi-Q46f5Up",
        "SD4Bblry-zLa",
        "vJjBO7cuQ4pC"
      ],
      "authorship_tag": "ABX9TyMN56aLguPqNdYnVRQBmvVQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seunghee0518/AI_python/blob/main/FCN(Fully_Connected_Network)_MNIST_%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%98%ED%86%B5%EA%B3%84%EC%A0%81%EC%9D%B4%ED%95%B4_%EC%A4%91%EA%B0%84%EA%B3%BC%EC%A0%9C%EB%AC%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihHv6LNT__Cp"
      },
      "source": [
        "# MNIST 데이터를 이용해 손글씨를 식별하는 은닉층 1개의 완전연결신경망"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cGCeTqjAMud",
        "outputId": "c32caeff-bb40-424a-f09a-5706e982d739"
      },
      "source": [
        "#import library\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, models\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, Conv2D, MaxPool2D\n",
        "from tensorflow.keras.utils import plot_model\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "PjODhd-SAin7",
        "outputId": "c5783ab9-df86-4b93-c386-97af3cc9b0ef"
      },
      "source": [
        "# MNIST데이터셋 불러오기 & 데이터셋 확인\n",
        "mnist = datasets.mnist\n",
        "(train_x, train_y), (test_x, test_y) = mnist.load_data()\n",
        "train_x, test_x = train_x / 255.0, test_x / 255.0\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "for col1 in range(16) : \n",
        "  plt.subplot(4, 4, col1+1)\n",
        "  plt.imshow(train_x[col1].reshape(28, 28), cmap = plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 16 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dJ3btZCBDZz",
        "outputId": "6788a905-84e5-4d74-e0bc-6848a6dfd4b8"
      },
      "source": [
        "#MNIST 이미지 데이터 구조 확인\n",
        "digit = train_x[0]\n",
        "print(\"digit : \", digit.shape)\n",
        "print(\"train images : \", train_x.shape)\n",
        "print(\"test images : \", test_x.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "digit :  (28, 28)\n",
            "train images :  (60000, 28, 28)\n",
            "test images :  (10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TBKY5AcHBZt"
      },
      "source": [
        "# 은닉층1개"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "s8jQeyFPDBt3",
        "outputId": "237c22ef-948c-49b5-c54b-c8c4cf09bad1"
      },
      "source": [
        "#MNIST 이미지 식별하는 완전신경망(은닉층 1개)\n",
        "#신경망 작성\n",
        "model1_1 = models.Sequential([\n",
        "                              Flatten(input_shape = (28, 28)),\n",
        "                              Dense(512, activation= 'relu'),\n",
        "                              Dense(10, activation= 'softmax') # 분류할 개수 10개(0~9까지 숫자)\n",
        "                              ])\n",
        "\n",
        "#신경망 요약\n",
        "model1_1.summary()\n",
        "plot_model(model1_1, to_file= \" model1_1_mnist.png\", show_shapes= True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKsiyQDOEu--",
        "outputId": "6ed5682c-1865-4181-f5b8-aa242216bd94"
      },
      "source": [
        "#신경망 학습\n",
        "model1_1.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "hist1_1 = model1_1.fit(train_x, train_y, epochs = 12, batch_size = 256, validation_split = 0.25)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "176/176 [==============================] - 4s 7ms/step - loss: 0.3770 - accuracy: 0.8962 - val_loss: 0.2026 - val_accuracy: 0.9439\n",
            "Epoch 2/12\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.1597 - accuracy: 0.9552 - val_loss: 0.1436 - val_accuracy: 0.9583\n",
            "Epoch 3/12\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.1095 - accuracy: 0.9694 - val_loss: 0.1196 - val_accuracy: 0.9646\n",
            "Epoch 4/12\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0811 - accuracy: 0.9770 - val_loss: 0.1097 - val_accuracy: 0.9680\n",
            "Epoch 5/12\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0622 - accuracy: 0.9827 - val_loss: 0.0929 - val_accuracy: 0.9719\n",
            "Epoch 6/12\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0482 - accuracy: 0.9868 - val_loss: 0.0932 - val_accuracy: 0.9730\n",
            "Epoch 7/12\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0372 - accuracy: 0.9903 - val_loss: 0.0878 - val_accuracy: 0.9733\n",
            "Epoch 8/12\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0299 - accuracy: 0.9929 - val_loss: 0.0821 - val_accuracy: 0.9757\n",
            "Epoch 9/12\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0229 - accuracy: 0.9950 - val_loss: 0.0860 - val_accuracy: 0.9743\n",
            "Epoch 10/12\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0179 - accuracy: 0.9966 - val_loss: 0.0830 - val_accuracy: 0.9759\n",
            "Epoch 11/12\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0145 - accuracy: 0.9974 - val_loss: 0.0819 - val_accuracy: 0.9761\n",
            "Epoch 12/12\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0117 - accuracy: 0.9983 - val_loss: 0.0816 - val_accuracy: 0.9778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "UWhx3jfuDuRe",
        "outputId": "e56a9a75-18be-4eb4-8b10-2096e820bd9b"
      },
      "source": [
        "#학습 그래프 \n",
        "plt.plot(hist1_1.history['accuracy'], 'b-')\n",
        "plt.plot(hist1_1.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train1_1 = model1_1.evaluate(train_x, train_y)\n",
        "sc_test1_1 = model1_1.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train1_1[1], \"train loss : \", sc_train1_1[0])\n",
        "print(\"test accuracy : \", sc_test1_1[1], \" test loss : \", sc_test1_1[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0273 - accuracy: 0.9938\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0648 - accuracy: 0.9812\n",
            "train accuracy :  0.9937999844551086 train loss :  0.02729642763733864\n",
            "test accuracy :  0.9811999797821045  test loss :  0.06480918824672699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h57AbRi6KAJ5"
      },
      "source": [
        "위 결과를 보면 은닉층이 1개 일 때 훈련데이터의 정확도는 99.3%, 시험 데이터의 정확도는 98% 정도로 시험데이터의 정확도가 더 낮다는 것을 알 수 있다.\n",
        "따라서 시험데이터의 정확도 더 늘리기 위해 은닉층을 2개로 늘려보았다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyaVNmknJPW-"
      },
      "source": [
        "# 은닉층2개\n",
        "* model2_1 뉴런 수 : 512 / 512\n",
        "* model2_2 뉴런 수 : 512 / 256"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "id": "nloX73QdGPFI",
        "outputId": "465608fc-d944-4fa6-d0e5-1590eb71754c"
      },
      "source": [
        "#MNIST 이미지 식별하는 완전신경망(은닉층 2개(은닉층 뉴런512개))\n",
        "#신경망 작성\n",
        "model2_1 = models.Sequential([\n",
        "                            Flatten(input_shape = (28, 28)),\n",
        "                            Dense(512, activation = 'relu'),\n",
        "                            Dense(512, activation = 'relu'),\n",
        "                            Dense(10, activation= 'softmax')\n",
        "                            ])\n",
        "\n",
        "#신경망 요약\n",
        "model2_1.summary()\n",
        "plot_model(model2_1, to_file= \" model2_1_mnist.png\", show_shapes= True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        },
        "id": "EPMC_peRJJCB",
        "outputId": "fc9512d1-a912-43ed-fa79-e9a876f82e7d"
      },
      "source": [
        "#은닉층2개 신경망 학습\n",
        "model2_1.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "hist2_1 = model2_1.fit(train_x, train_y, epochs = 12, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "#학습 그래프 \n",
        "plt.plot(hist2_1.history['accuracy'], 'b-')\n",
        "plt.plot(hist2_1.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train2_1 = model2_1.evaluate(train_x, train_y)\n",
        "sc_test2_1 = model2_1.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train2_1[1], \" train loss : \", sc_train2_1[0])\n",
        "print(\"test accuracy : \", sc_test2_1[1], \" test loss : \", sc_test2_1[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "176/176 [==============================] - 2s 7ms/step - loss: 0.3064 - accuracy: 0.9124 - val_loss: 0.1435 - val_accuracy: 0.9595\n",
            "Epoch 2/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.1066 - accuracy: 0.9688 - val_loss: 0.1159 - val_accuracy: 0.9657\n",
            "Epoch 3/12\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0655 - accuracy: 0.9809 - val_loss: 0.1005 - val_accuracy: 0.9695\n",
            "Epoch 4/12\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0402 - accuracy: 0.9880 - val_loss: 0.0994 - val_accuracy: 0.9719\n",
            "Epoch 5/12\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0298 - accuracy: 0.9912 - val_loss: 0.0897 - val_accuracy: 0.9736\n",
            "Epoch 6/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 0.0907 - val_accuracy: 0.9754\n",
            "Epoch 7/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 0.0909 - val_accuracy: 0.9771\n",
            "Epoch 8/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.0971 - val_accuracy: 0.9757\n",
            "Epoch 9/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.1095 - val_accuracy: 0.9721\n",
            "Epoch 10/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.1049 - val_accuracy: 0.9761\n",
            "Epoch 11/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0105 - accuracy: 0.9972 - val_loss: 0.1162 - val_accuracy: 0.9718\n",
            "Epoch 12/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.1104 - val_accuracy: 0.9743\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0347 - accuracy: 0.9913\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0843 - accuracy: 0.9801\n",
            "train accuracy :  0.9912999868392944  train loss :  0.034651078283786774\n",
            "test accuracy :  0.9800999760627747  test loss :  0.08432424813508987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "id": "kJMHN8ntMEkj",
        "outputId": "3c5a349a-2366-4c53-e917-99590e48d557"
      },
      "source": [
        "#MNIST 이미지 식별하는 완전신경망(은닉층 2개(은닉층 뉴런512개, 256개))\n",
        "#신경망 작성\n",
        "model2_2 = models.Sequential([\n",
        "                            Flatten(input_shape = (28, 28)),\n",
        "                            Dense(512, activation = 'relu'),\n",
        "                            Dense(256, activation = 'relu'),\n",
        "                            Dense(10, activation= 'softmax')\n",
        "                            ])\n",
        "\n",
        "#신경망 요약\n",
        "model2_2.summary()\n",
        "plot_model(model2_2, to_file= \" model2_2_mnist.png\", show_shapes= True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_2 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 535,818\n",
            "Trainable params: 535,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        },
        "id": "dfRIXXqzMMx4",
        "outputId": "f6f3977b-35dd-440b-e703-5aeed74bd1c9"
      },
      "source": [
        "#은닉층2개 신경망 학습\n",
        "model2_2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "hist2_2 = model2_2.fit(train_x, train_y, epochs = 12, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "#학습 그래프 \n",
        "plt.plot(hist2_2.history['accuracy'], 'b-')\n",
        "plt.plot(hist2_2.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train2_2 = model2_2.evaluate(train_x, train_y)\n",
        "sc_test2_2 = model2_2.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train2_2[1], \" train loss : \", sc_train2_2[0])\n",
        "print(\"test accuracy : \", sc_test2_2[1], \" test loss : \", sc_test2_2[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3192 - accuracy: 0.9081 - val_loss: 0.1505 - val_accuracy: 0.9551\n",
            "Epoch 2/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.1108 - accuracy: 0.9668 - val_loss: 0.1125 - val_accuracy: 0.9667\n",
            "Epoch 3/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0719 - accuracy: 0.9787 - val_loss: 0.0969 - val_accuracy: 0.9717\n",
            "Epoch 4/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0469 - accuracy: 0.9857 - val_loss: 0.0948 - val_accuracy: 0.9715\n",
            "Epoch 5/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0339 - accuracy: 0.9899 - val_loss: 0.0849 - val_accuracy: 0.9755\n",
            "Epoch 6/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0240 - accuracy: 0.9933 - val_loss: 0.0889 - val_accuracy: 0.9747\n",
            "Epoch 7/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0148 - accuracy: 0.9962 - val_loss: 0.0855 - val_accuracy: 0.9771\n",
            "Epoch 8/12\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0109 - accuracy: 0.9971 - val_loss: 0.0911 - val_accuracy: 0.9766\n",
            "Epoch 9/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.0989 - val_accuracy: 0.9749\n",
            "Epoch 10/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.0926 - val_accuracy: 0.9767\n",
            "Epoch 11/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.1088 - val_accuracy: 0.9750\n",
            "Epoch 12/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.1085 - val_accuracy: 0.9750\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0343 - accuracy: 0.9915\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0930 - accuracy: 0.9754\n",
            "train accuracy :  0.9915000200271606  train loss :  0.03434007987380028\n",
            "test accuracy :  0.9753999710083008  test loss :  0.09303631633520126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtXubJC8CGmU",
        "outputId": "19a0932c-824f-4b94-d704-fdf7e18122fc"
      },
      "source": [
        "print(\"=========== [은닉층 1개] ===========\")\n",
        "print(\"train accuracy : \", sc_train1_1[1], \"train loss : \", sc_train1_1[0])\n",
        "print(\"test accuracy : \", sc_test1_1[1], \" test loss : \", sc_test1_1[0])\n",
        "print(\"/n\")\n",
        "\n",
        "print(\"=========== [은닉층 2개] ===========\")\n",
        "print(\"=========== hidden = 512 / 512 ===========\")\n",
        "print(\"train accuracy : \", sc_train2_1[1], \"train loss : \", sc_train2_1[0])\n",
        "print(\"test accuracy : \", sc_test2_1[1], \" test loss : \", sc_test2_1[0])\n",
        "print(\"/n\")\n",
        "\n",
        "print(\"=========== hidden = 512 / 256 ===========\")\n",
        "print(\"train accuracy : \", sc_train2_2[1], \"train loss : \", sc_train2_2[0])\n",
        "print(\"test accuracy : \", sc_test2_2[1], \" test loss : \", sc_test2_2[0])\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========== [은닉층 1개] ===========\n",
            "train accuracy :  0.9937999844551086 train loss :  0.02729642763733864\n",
            "test accuracy :  0.9811999797821045  test loss :  0.06480918824672699\n",
            "/n\n",
            "=========== [은닉층 2개] ===========\n",
            "=========== hidden = 512 / 512 ===========\n",
            "train accuracy :  0.9912999868392944 train loss :  0.034651078283786774\n",
            "test accuracy :  0.9800999760627747  test loss :  0.08432424813508987\n",
            "/n\n",
            "=========== hidden = 512 / 256 ===========\n",
            "train accuracy :  0.9915000200271606 train loss :  0.03434007987380028\n",
            "test accuracy :  0.9753999710083008  test loss :  0.09303631633520126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO-St7a5VJzO"
      },
      "source": [
        "은닉층을 2개 & 은닉층별 뉴런의 수가 512/256일 때 훈련데이터의 정확도는 99.4%, 시험데이터는 98.01%로 은닉층이 1개 였을 때보다 약간 증가 했지만 시험데이터의 정확도 차이가 미비한 것을 볼 수 있다.\n",
        "따라서 은닉층이 1개일 경우와 은닉층이 2개(뉴런의 수 512/256)의 epochs 수를 늘려 보았다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCcTdkEHVitf"
      },
      "source": [
        "# 은닉층 1개 & epochs = 120 / 500 / 1000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "d5cFsW2YOoaX",
        "outputId": "01df00db-cf5e-440a-bde7-dbe52026b018"
      },
      "source": [
        "#은닉층 1개 & epochs = 120\n",
        "model1_2 = models.Sequential([\n",
        "                            Flatten(input_shape = (28, 28)),\n",
        "                            Dense(512, activation= 'relu'),\n",
        "                            Dense(10, activation= 'softmax')\n",
        "                            ])\n",
        "\n",
        "model1_2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "#신경망 학습2\n",
        "hist1_2 = model1_2.fit(train_x, train_y, epochs = 120, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "plt.plot(hist1_2.history['accuracy'], 'b-')\n",
        "plt.plot(hist1_2.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train1_2 = model1_2.evaluate(train_x, train_y)\n",
        "sc_test1_2 = model1_2.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train1_2[1], \"train loss : \", sc_train1_2[0])\n",
        "print(\"test accuracy : \", sc_test1_2[1], \" test loss : \", sc_test1_2[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3639 - accuracy: 0.9002 - val_loss: 0.1997 - val_accuracy: 0.9431\n",
            "Epoch 2/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.1561 - accuracy: 0.9561 - val_loss: 0.1398 - val_accuracy: 0.9593\n",
            "Epoch 3/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.1071 - accuracy: 0.9692 - val_loss: 0.1220 - val_accuracy: 0.9634\n",
            "Epoch 4/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0790 - accuracy: 0.9780 - val_loss: 0.1032 - val_accuracy: 0.9692\n",
            "Epoch 5/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0602 - accuracy: 0.9827 - val_loss: 0.1000 - val_accuracy: 0.9699\n",
            "Epoch 6/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0460 - accuracy: 0.9880 - val_loss: 0.0912 - val_accuracy: 0.9715\n",
            "Epoch 7/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0368 - accuracy: 0.9905 - val_loss: 0.0879 - val_accuracy: 0.9726\n",
            "Epoch 8/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0292 - accuracy: 0.9929 - val_loss: 0.0902 - val_accuracy: 0.9730\n",
            "Epoch 9/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0222 - accuracy: 0.9955 - val_loss: 0.0858 - val_accuracy: 0.9742\n",
            "Epoch 10/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0180 - accuracy: 0.9966 - val_loss: 0.0846 - val_accuracy: 0.9744\n",
            "Epoch 11/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0142 - accuracy: 0.9977 - val_loss: 0.0807 - val_accuracy: 0.9772\n",
            "Epoch 12/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0113 - accuracy: 0.9983 - val_loss: 0.0798 - val_accuracy: 0.9775\n",
            "Epoch 13/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.9988 - val_loss: 0.0834 - val_accuracy: 0.9766\n",
            "Epoch 14/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0072 - accuracy: 0.9994 - val_loss: 0.0820 - val_accuracy: 0.9774\n",
            "Epoch 15/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 0.9997 - val_loss: 0.0898 - val_accuracy: 0.9756\n",
            "Epoch 16/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.0871 - val_accuracy: 0.9763\n",
            "Epoch 17/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0037 - accuracy: 0.9999 - val_loss: 0.0856 - val_accuracy: 0.9767\n",
            "Epoch 18/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.0832 - val_accuracy: 0.9781\n",
            "Epoch 19/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.0857 - val_accuracy: 0.9781\n",
            "Epoch 20/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9785\n",
            "Epoch 21/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 0.9783\n",
            "Epoch 22/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0875 - val_accuracy: 0.9782\n",
            "Epoch 23/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0896 - val_accuracy: 0.9783\n",
            "Epoch 24/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9785\n",
            "Epoch 25/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.5424e-04 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 0.9783\n",
            "Epoch 26/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.3130e-04 - accuracy: 1.0000 - val_loss: 0.0914 - val_accuracy: 0.9785\n",
            "Epoch 27/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.2766e-04 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9791\n",
            "Epoch 28/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.5271e-04 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9783\n",
            "Epoch 29/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.7792e-04 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9783\n",
            "Epoch 30/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.1642e-04 - accuracy: 1.0000 - val_loss: 0.0952 - val_accuracy: 0.9785\n",
            "Epoch 31/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.4790e-04 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9781\n",
            "Epoch 32/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.9617e-04 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 0.9783\n",
            "Epoch 33/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.5951e-04 - accuracy: 1.0000 - val_loss: 0.0985 - val_accuracy: 0.9788\n",
            "Epoch 34/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.2535e-04 - accuracy: 1.0000 - val_loss: 0.0985 - val_accuracy: 0.9782\n",
            "Epoch 35/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.8468e-04 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9791\n",
            "Epoch 36/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.5862e-04 - accuracy: 1.0000 - val_loss: 0.0996 - val_accuracy: 0.9785\n",
            "Epoch 37/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.3126e-04 - accuracy: 1.0000 - val_loss: 0.1008 - val_accuracy: 0.9789\n",
            "Epoch 38/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.1664e-04 - accuracy: 1.0000 - val_loss: 0.1017 - val_accuracy: 0.9786\n",
            "Epoch 39/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8806e-04 - accuracy: 1.0000 - val_loss: 0.1032 - val_accuracy: 0.9789\n",
            "Epoch 40/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.6505e-04 - accuracy: 1.0000 - val_loss: 0.1033 - val_accuracy: 0.9787\n",
            "Epoch 41/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4752e-04 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 0.9787\n",
            "Epoch 42/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3496e-04 - accuracy: 1.0000 - val_loss: 0.1045 - val_accuracy: 0.9789\n",
            "Epoch 43/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2084e-04 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 0.9786\n",
            "Epoch 44/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.6321e-04 - accuracy: 0.9999 - val_loss: 0.2405 - val_accuracy: 0.9561\n",
            "Epoch 45/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0357 - accuracy: 0.9889 - val_loss: 0.1078 - val_accuracy: 0.9761\n",
            "Epoch 46/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.1121 - val_accuracy: 0.9767\n",
            "Epoch 47/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.1058 - val_accuracy: 0.9777\n",
            "Epoch 48/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.1297e-04 - accuracy: 1.0000 - val_loss: 0.1070 - val_accuracy: 0.9784\n",
            "Epoch 49/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.2469e-04 - accuracy: 1.0000 - val_loss: 0.1050 - val_accuracy: 0.9787\n",
            "Epoch 50/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.4512e-04 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9786\n",
            "Epoch 51/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.1163e-04 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 0.9785\n",
            "Epoch 52/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8927e-04 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9787\n",
            "Epoch 53/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7160e-04 - accuracy: 1.0000 - val_loss: 0.1079 - val_accuracy: 0.9784\n",
            "Epoch 54/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5581e-04 - accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 0.9784\n",
            "Epoch 55/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4244e-04 - accuracy: 1.0000 - val_loss: 0.1092 - val_accuracy: 0.9787\n",
            "Epoch 56/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3192e-04 - accuracy: 1.0000 - val_loss: 0.1100 - val_accuracy: 0.9787\n",
            "Epoch 57/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2212e-04 - accuracy: 1.0000 - val_loss: 0.1101 - val_accuracy: 0.9788\n",
            "Epoch 58/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1322e-04 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 0.9785\n",
            "Epoch 59/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0500e-04 - accuracy: 1.0000 - val_loss: 0.1112 - val_accuracy: 0.9787\n",
            "Epoch 60/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.7337e-05 - accuracy: 1.0000 - val_loss: 0.1115 - val_accuracy: 0.9786\n",
            "Epoch 61/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.0432e-05 - accuracy: 1.0000 - val_loss: 0.1116 - val_accuracy: 0.9787\n",
            "Epoch 62/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.4073e-05 - accuracy: 1.0000 - val_loss: 0.1123 - val_accuracy: 0.9784\n",
            "Epoch 63/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.8640e-05 - accuracy: 1.0000 - val_loss: 0.1134 - val_accuracy: 0.9782\n",
            "Epoch 64/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.3026e-05 - accuracy: 1.0000 - val_loss: 0.1138 - val_accuracy: 0.9787\n",
            "Epoch 65/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.8054e-05 - accuracy: 1.0000 - val_loss: 0.1145 - val_accuracy: 0.9783\n",
            "Epoch 66/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.3627e-05 - accuracy: 1.0000 - val_loss: 0.1144 - val_accuracy: 0.9783\n",
            "Epoch 67/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.9352e-05 - accuracy: 1.0000 - val_loss: 0.1155 - val_accuracy: 0.9787\n",
            "Epoch 68/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.5144e-05 - accuracy: 1.0000 - val_loss: 0.1157 - val_accuracy: 0.9783\n",
            "Epoch 69/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.1568e-05 - accuracy: 1.0000 - val_loss: 0.1158 - val_accuracy: 0.9785\n",
            "Epoch 70/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.8020e-05 - accuracy: 1.0000 - val_loss: 0.1168 - val_accuracy: 0.9783\n",
            "Epoch 71/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.4762e-05 - accuracy: 1.0000 - val_loss: 0.1169 - val_accuracy: 0.9781\n",
            "Epoch 72/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.2032e-05 - accuracy: 1.0000 - val_loss: 0.1175 - val_accuracy: 0.9789\n",
            "Epoch 73/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.9218e-05 - accuracy: 1.0000 - val_loss: 0.1183 - val_accuracy: 0.9785\n",
            "Epoch 74/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.6671e-05 - accuracy: 1.0000 - val_loss: 0.1186 - val_accuracy: 0.9785\n",
            "Epoch 75/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.3754e-05 - accuracy: 1.0000 - val_loss: 0.1194 - val_accuracy: 0.9787\n",
            "Epoch 76/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.1621e-05 - accuracy: 1.0000 - val_loss: 0.1193 - val_accuracy: 0.9790\n",
            "Epoch 77/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.9363e-05 - accuracy: 1.0000 - val_loss: 0.1201 - val_accuracy: 0.9791\n",
            "Epoch 78/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.7200e-05 - accuracy: 1.0000 - val_loss: 0.1205 - val_accuracy: 0.9791\n",
            "Epoch 79/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.5415e-05 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9789\n",
            "Epoch 80/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.3531e-05 - accuracy: 1.0000 - val_loss: 0.1219 - val_accuracy: 0.9792\n",
            "Epoch 81/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.1843e-05 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 0.9789\n",
            "Epoch 82/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.0247e-05 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9793\n",
            "Epoch 83/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8542e-05 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9789\n",
            "Epoch 84/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7435e-05 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9791\n",
            "Epoch 85/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.6049e-05 - accuracy: 1.0000 - val_loss: 0.1243 - val_accuracy: 0.9791\n",
            "Epoch 86/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4863e-05 - accuracy: 1.0000 - val_loss: 0.1246 - val_accuracy: 0.9789\n",
            "Epoch 87/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3731e-05 - accuracy: 1.0000 - val_loss: 0.1253 - val_accuracy: 0.9789\n",
            "Epoch 88/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2599e-05 - accuracy: 1.0000 - val_loss: 0.1255 - val_accuracy: 0.9791\n",
            "Epoch 89/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1637e-05 - accuracy: 1.0000 - val_loss: 0.1270 - val_accuracy: 0.9787\n",
            "Epoch 90/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0893e-05 - accuracy: 1.0000 - val_loss: 0.1262 - val_accuracy: 0.9789\n",
            "Epoch 91/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0175e-05 - accuracy: 1.0000 - val_loss: 0.1277 - val_accuracy: 0.9793\n",
            "Epoch 92/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.2548e-06 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 0.9788\n",
            "Epoch 93/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.4926e-06 - accuracy: 1.0000 - val_loss: 0.1277 - val_accuracy: 0.9793\n",
            "Epoch 94/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.7817e-06 - accuracy: 1.0000 - val_loss: 0.1294 - val_accuracy: 0.9793\n",
            "Epoch 95/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.2200e-06 - accuracy: 1.0000 - val_loss: 0.1305 - val_accuracy: 0.9791\n",
            "Epoch 96/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.5772e-06 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9793\n",
            "Epoch 97/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.0434e-06 - accuracy: 1.0000 - val_loss: 0.1309 - val_accuracy: 0.9790\n",
            "Epoch 98/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.5835e-06 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.9794\n",
            "Epoch 99/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1852e-06 - accuracy: 1.0000 - val_loss: 0.1323 - val_accuracy: 0.9793\n",
            "Epoch 100/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.7641e-06 - accuracy: 1.0000 - val_loss: 0.1339 - val_accuracy: 0.9795\n",
            "Epoch 101/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.3564e-06 - accuracy: 1.0000 - val_loss: 0.1345 - val_accuracy: 0.9797\n",
            "Epoch 102/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.0034e-06 - accuracy: 1.0000 - val_loss: 0.1347 - val_accuracy: 0.9795\n",
            "Epoch 103/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.6851e-06 - accuracy: 1.0000 - val_loss: 0.1362 - val_accuracy: 0.9794\n",
            "Epoch 104/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.3879e-06 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9793\n",
            "Epoch 105/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0523e-06 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9793\n",
            "Epoch 106/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.8255e-06 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9795\n",
            "Epoch 107/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.5958e-06 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9795\n",
            "Epoch 108/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.3704e-06 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9793\n",
            "Epoch 109/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.1982e-06 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 0.9795\n",
            "Epoch 110/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.9930e-06 - accuracy: 1.0000 - val_loss: 0.1407 - val_accuracy: 0.9795\n",
            "Epoch 111/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8163e-06 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9793\n",
            "Epoch 112/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6846e-06 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 0.9795\n",
            "Epoch 113/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5518e-06 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9795\n",
            "Epoch 114/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4198e-06 - accuracy: 1.0000 - val_loss: 0.1440 - val_accuracy: 0.9797\n",
            "Epoch 115/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3004e-06 - accuracy: 1.0000 - val_loss: 0.1450 - val_accuracy: 0.9795\n",
            "Epoch 116/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1972e-06 - accuracy: 1.0000 - val_loss: 0.1447 - val_accuracy: 0.9794\n",
            "Epoch 117/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0966e-06 - accuracy: 1.0000 - val_loss: 0.1469 - val_accuracy: 0.9797\n",
            "Epoch 118/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0153e-06 - accuracy: 1.0000 - val_loss: 0.1473 - val_accuracy: 0.9794\n",
            "Epoch 119/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.3023e-07 - accuracy: 1.0000 - val_loss: 0.1473 - val_accuracy: 0.9795\n",
            "Epoch 120/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.6548e-07 - accuracy: 1.0000 - val_loss: 0.1489 - val_accuracy: 0.9797\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0372 - accuracy: 0.9949\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1186 - accuracy: 0.9807\n",
            "train accuracy :  0.9949333071708679 train loss :  0.0372379831969738\n",
            "test accuracy :  0.9807000160217285  test loss :  0.11860010027885437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "o6p7_433O4U5",
        "outputId": "72767a95-0e4c-410c-c3c7-95d97568ca81"
      },
      "source": [
        "#신경망 학습3\n",
        "model1_3 = models.Sequential([\n",
        "                            Flatten(input_shape = (28, 28)),\n",
        "                            Dense(512, activation= 'relu'),\n",
        "                            Dense(10, activation= 'softmax')\n",
        "                            ])\n",
        "\n",
        "model1_3.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "hist1_3 = model1_3.fit(train_x, train_y, epochs = 500, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "#학습 그래프3\n",
        "plt.plot(hist1_3.history['accuracy'], 'b-')\n",
        "plt.plot(hist1_3.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train1_3 = model1_3.evaluate(train_x, train_y)\n",
        "sc_test1_3 = model1_3.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train1_3[1], \"train loss : \", sc_train1_3[0])\n",
        "print(\"test accuracy : \", sc_test1_3[1], \" test loss : \", sc_test1_3[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3765 - accuracy: 0.8977 - val_loss: 0.1984 - val_accuracy: 0.9441\n",
            "Epoch 2/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.1608 - accuracy: 0.9550 - val_loss: 0.1472 - val_accuracy: 0.9566\n",
            "Epoch 3/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.1086 - accuracy: 0.9698 - val_loss: 0.1146 - val_accuracy: 0.9660\n",
            "Epoch 4/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0793 - accuracy: 0.9777 - val_loss: 0.1051 - val_accuracy: 0.9686\n",
            "Epoch 5/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0617 - accuracy: 0.9836 - val_loss: 0.0976 - val_accuracy: 0.9709\n",
            "Epoch 6/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0472 - accuracy: 0.9871 - val_loss: 0.0872 - val_accuracy: 0.9743\n",
            "Epoch 7/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0382 - accuracy: 0.9900 - val_loss: 0.0870 - val_accuracy: 0.9735\n",
            "Epoch 8/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0293 - accuracy: 0.9930 - val_loss: 0.0830 - val_accuracy: 0.9756\n",
            "Epoch 9/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0235 - accuracy: 0.9950 - val_loss: 0.0840 - val_accuracy: 0.9747\n",
            "Epoch 10/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0179 - accuracy: 0.9967 - val_loss: 0.0876 - val_accuracy: 0.9730\n",
            "Epoch 11/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0151 - accuracy: 0.9974 - val_loss: 0.0801 - val_accuracy: 0.9765\n",
            "Epoch 12/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0119 - accuracy: 0.9982 - val_loss: 0.0823 - val_accuracy: 0.9763\n",
            "Epoch 13/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.9989 - val_loss: 0.0784 - val_accuracy: 0.9778\n",
            "Epoch 14/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0071 - accuracy: 0.9994 - val_loss: 0.0797 - val_accuracy: 0.9774\n",
            "Epoch 15/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0056 - accuracy: 0.9996 - val_loss: 0.0839 - val_accuracy: 0.9771\n",
            "Epoch 16/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 0.9998 - val_loss: 0.0811 - val_accuracy: 0.9773\n",
            "Epoch 17/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0036 - accuracy: 0.9999 - val_loss: 0.0816 - val_accuracy: 0.9775\n",
            "Epoch 18/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 0.9999 - val_loss: 0.0854 - val_accuracy: 0.9770\n",
            "Epoch 19/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 0.0825 - val_accuracy: 0.9775\n",
            "Epoch 20/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 0.9775\n",
            "Epoch 21/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9783\n",
            "Epoch 22/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0865 - val_accuracy: 0.9779\n",
            "Epoch 23/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9782\n",
            "Epoch 24/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9784\n",
            "Epoch 25/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.5028e-04 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9785\n",
            "Epoch 26/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.4759e-04 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9785\n",
            "Epoch 27/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.4627e-04 - accuracy: 1.0000 - val_loss: 0.0910 - val_accuracy: 0.9782\n",
            "Epoch 28/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.5687e-04 - accuracy: 1.0000 - val_loss: 0.0909 - val_accuracy: 0.9787\n",
            "Epoch 29/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8099e-04 - accuracy: 1.0000 - val_loss: 0.0913 - val_accuracy: 0.9783\n",
            "Epoch 30/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.2012e-04 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9793\n",
            "Epoch 31/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.0471e-04 - accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 0.9791\n",
            "Epoch 32/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.1873e-04 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 0.9785\n",
            "Epoch 33/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.9758e-04 - accuracy: 1.0000 - val_loss: 0.0957 - val_accuracy: 0.9785\n",
            "Epoch 34/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.2890e-04 - accuracy: 1.0000 - val_loss: 0.0974 - val_accuracy: 0.9781\n",
            "Epoch 35/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.9160e-04 - accuracy: 1.0000 - val_loss: 0.0957 - val_accuracy: 0.9789\n",
            "Epoch 36/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.6956e-04 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9786\n",
            "Epoch 37/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.2983e-04 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9791\n",
            "Epoch 38/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.0989e-04 - accuracy: 1.0000 - val_loss: 0.1000 - val_accuracy: 0.9787\n",
            "Epoch 39/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8677e-04 - accuracy: 1.0000 - val_loss: 0.0998 - val_accuracy: 0.9793\n",
            "Epoch 40/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.6720e-04 - accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 0.9787\n",
            "Epoch 41/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4918e-04 - accuracy: 1.0000 - val_loss: 0.1002 - val_accuracy: 0.9797\n",
            "Epoch 42/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3548e-04 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 0.9791\n",
            "Epoch 43/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2385e-04 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9797\n",
            "Epoch 44/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1139e-04 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9789\n",
            "Epoch 45/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.9815e-05 - accuracy: 1.0000 - val_loss: 0.1040 - val_accuracy: 0.9791\n",
            "Epoch 46/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.2242e-05 - accuracy: 1.0000 - val_loss: 0.1064 - val_accuracy: 0.9792\n",
            "Epoch 47/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.2604e-05 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9794\n",
            "Epoch 48/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.4001e-05 - accuracy: 1.0000 - val_loss: 0.1086 - val_accuracy: 0.9793\n",
            "Epoch 49/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.8079e-05 - accuracy: 1.0000 - val_loss: 0.1088 - val_accuracy: 0.9793\n",
            "Epoch 50/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.0890e-05 - accuracy: 1.0000 - val_loss: 0.1087 - val_accuracy: 0.9795\n",
            "Epoch 51/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.3701e-05 - accuracy: 1.0000 - val_loss: 0.1112 - val_accuracy: 0.9793\n",
            "Epoch 52/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.8579e-05 - accuracy: 1.0000 - val_loss: 0.1114 - val_accuracy: 0.9797\n",
            "Epoch 53/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.4018e-05 - accuracy: 1.0000 - val_loss: 0.1121 - val_accuracy: 0.9793\n",
            "Epoch 54/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.9330e-05 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9791\n",
            "Epoch 55/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.6596e-05 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9795\n",
            "Epoch 56/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.3391e-05 - accuracy: 1.0000 - val_loss: 0.1149 - val_accuracy: 0.9794\n",
            "Epoch 57/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.9888e-05 - accuracy: 1.0000 - val_loss: 0.1164 - val_accuracy: 0.9789\n",
            "Epoch 58/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.6913e-05 - accuracy: 1.0000 - val_loss: 0.1162 - val_accuracy: 0.9795\n",
            "Epoch 59/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.3956e-05 - accuracy: 1.0000 - val_loss: 0.1174 - val_accuracy: 0.9795\n",
            "Epoch 60/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.2089e-05 - accuracy: 1.0000 - val_loss: 0.1186 - val_accuracy: 0.9793\n",
            "Epoch 61/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.0168e-05 - accuracy: 1.0000 - val_loss: 0.1199 - val_accuracy: 0.9794\n",
            "Epoch 62/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8369e-05 - accuracy: 1.0000 - val_loss: 0.1202 - val_accuracy: 0.9793\n",
            "Epoch 63/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.6305e-05 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9795\n",
            "Epoch 64/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5034e-05 - accuracy: 1.0000 - val_loss: 0.1210 - val_accuracy: 0.9795\n",
            "Epoch 65/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3724e-05 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9796\n",
            "Epoch 66/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2332e-05 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9793\n",
            "Epoch 67/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0972e-05 - accuracy: 1.0000 - val_loss: 0.1241 - val_accuracy: 0.9794\n",
            "Epoch 68/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0035e-05 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9795\n",
            "Epoch 69/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.1304e-06 - accuracy: 1.0000 - val_loss: 0.1256 - val_accuracy: 0.9793\n",
            "Epoch 70/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.4217e-06 - accuracy: 1.0000 - val_loss: 0.1275 - val_accuracy: 0.9791\n",
            "Epoch 71/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.5668e-06 - accuracy: 1.0000 - val_loss: 0.1287 - val_accuracy: 0.9793\n",
            "Epoch 72/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.7499e-06 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9797\n",
            "Epoch 73/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.1825e-06 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9798\n",
            "Epoch 74/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.6579e-06 - accuracy: 1.0000 - val_loss: 0.1305 - val_accuracy: 0.9796\n",
            "Epoch 75/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.1132e-06 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.9796\n",
            "Epoch 76/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.7900e-06 - accuracy: 1.0000 - val_loss: 0.1328 - val_accuracy: 0.9797\n",
            "Epoch 77/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.3199e-06 - accuracy: 1.0000 - val_loss: 0.1323 - val_accuracy: 0.9793\n",
            "Epoch 78/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.9739e-06 - accuracy: 1.0000 - val_loss: 0.1343 - val_accuracy: 0.9793\n",
            "Epoch 79/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.4853e-06 - accuracy: 1.0000 - val_loss: 0.1353 - val_accuracy: 0.9795\n",
            "Epoch 80/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.2880e-06 - accuracy: 1.0000 - val_loss: 0.1354 - val_accuracy: 0.9799\n",
            "Epoch 81/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.9154e-06 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.9794\n",
            "Epoch 82/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.6502e-06 - accuracy: 1.0000 - val_loss: 0.1375 - val_accuracy: 0.9795\n",
            "Epoch 83/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.4049e-06 - accuracy: 1.0000 - val_loss: 0.1381 - val_accuracy: 0.9795\n",
            "Epoch 84/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.2451e-06 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9793\n",
            "Epoch 85/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.0872e-06 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.9794\n",
            "Epoch 86/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8262e-06 - accuracy: 1.0000 - val_loss: 0.1405 - val_accuracy: 0.9794\n",
            "Epoch 87/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.6727e-06 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9800\n",
            "Epoch 88/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5090e-06 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9797\n",
            "Epoch 89/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3888e-06 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9798\n",
            "Epoch 90/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2698e-06 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9796\n",
            "Epoch 91/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1579e-06 - accuracy: 1.0000 - val_loss: 0.1445 - val_accuracy: 0.9797\n",
            "Epoch 92/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0647e-06 - accuracy: 1.0000 - val_loss: 0.1465 - val_accuracy: 0.9795\n",
            "Epoch 93/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.8450e-07 - accuracy: 1.0000 - val_loss: 0.1465 - val_accuracy: 0.9795\n",
            "Epoch 94/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.9173e-07 - accuracy: 1.0000 - val_loss: 0.1464 - val_accuracy: 0.9797\n",
            "Epoch 95/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.3169e-07 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9799\n",
            "Epoch 96/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.5500e-07 - accuracy: 1.0000 - val_loss: 0.1483 - val_accuracy: 0.9798\n",
            "Epoch 97/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.0247e-07 - accuracy: 1.0000 - val_loss: 0.1501 - val_accuracy: 0.9799\n",
            "Epoch 98/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.3371e-07 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9797\n",
            "Epoch 99/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.8317e-07 - accuracy: 1.0000 - val_loss: 0.1519 - val_accuracy: 0.9801\n",
            "Epoch 100/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.3128e-07 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 0.9797\n",
            "Epoch 101/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.9340e-07 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9801\n",
            "Epoch 102/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.6019e-07 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9795\n",
            "Epoch 103/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.1670e-07 - accuracy: 1.0000 - val_loss: 0.1553 - val_accuracy: 0.9797\n",
            "Epoch 104/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.9084e-07 - accuracy: 1.0000 - val_loss: 0.1551 - val_accuracy: 0.9798\n",
            "Epoch 105/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.6294e-07 - accuracy: 1.0000 - val_loss: 0.1557 - val_accuracy: 0.9797\n",
            "Epoch 106/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3051e-07 - accuracy: 1.0000 - val_loss: 0.1563 - val_accuracy: 0.9799\n",
            "Epoch 107/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.0913e-07 - accuracy: 1.0000 - val_loss: 0.1577 - val_accuracy: 0.9797\n",
            "Epoch 108/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.8542e-07 - accuracy: 1.0000 - val_loss: 0.1575 - val_accuracy: 0.9799\n",
            "Epoch 109/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.6459e-07 - accuracy: 1.0000 - val_loss: 0.1584 - val_accuracy: 0.9795\n",
            "Epoch 110/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.4478e-07 - accuracy: 1.0000 - val_loss: 0.1597 - val_accuracy: 0.9797\n",
            "Epoch 111/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.2962e-07 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 0.9798\n",
            "Epoch 112/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.1289e-07 - accuracy: 1.0000 - val_loss: 0.1605 - val_accuracy: 0.9796\n",
            "Epoch 113/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.9582e-07 - accuracy: 1.0000 - val_loss: 0.1613 - val_accuracy: 0.9799\n",
            "Epoch 114/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8317e-07 - accuracy: 1.0000 - val_loss: 0.1624 - val_accuracy: 0.9799\n",
            "Epoch 115/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.7251e-07 - accuracy: 1.0000 - val_loss: 0.1618 - val_accuracy: 0.9798\n",
            "Epoch 116/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5999e-07 - accuracy: 1.0000 - val_loss: 0.1638 - val_accuracy: 0.9798\n",
            "Epoch 117/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4976e-07 - accuracy: 1.0000 - val_loss: 0.1638 - val_accuracy: 0.9799\n",
            "Epoch 118/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3998e-07 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9801\n",
            "Epoch 119/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3141e-07 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9799\n",
            "Epoch 120/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2369e-07 - accuracy: 1.0000 - val_loss: 0.1662 - val_accuracy: 0.9799\n",
            "Epoch 121/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1606e-07 - accuracy: 1.0000 - val_loss: 0.1660 - val_accuracy: 0.9799\n",
            "Epoch 122/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0850e-07 - accuracy: 1.0000 - val_loss: 0.1661 - val_accuracy: 0.9799\n",
            "Epoch 123/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0263e-07 - accuracy: 1.0000 - val_loss: 0.1674 - val_accuracy: 0.9798\n",
            "Epoch 124/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.6861e-08 - accuracy: 1.0000 - val_loss: 0.1680 - val_accuracy: 0.9799\n",
            "Epoch 125/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.1637e-08 - accuracy: 1.0000 - val_loss: 0.1688 - val_accuracy: 0.9799\n",
            "Epoch 126/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.5995e-08 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 0.9799\n",
            "Epoch 127/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.1656e-08 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 0.9798\n",
            "Epoch 128/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.7279e-08 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 0.9801\n",
            "Epoch 129/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.3314e-08 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 0.9799\n",
            "Epoch 130/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.0246e-08 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 0.9800\n",
            "Epoch 131/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.6339e-08 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 0.9799\n",
            "Epoch 132/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.3072e-08 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 0.9799\n",
            "Epoch 133/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.0328e-08 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 0.9799\n",
            "Epoch 134/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.7705e-08 - accuracy: 1.0000 - val_loss: 0.1727 - val_accuracy: 0.9801\n",
            "Epoch 135/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.4720e-08 - accuracy: 1.0000 - val_loss: 0.1735 - val_accuracy: 0.9797\n",
            "Epoch 136/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.2595e-08 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.9799\n",
            "Epoch 137/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.0304e-08 - accuracy: 1.0000 - val_loss: 0.1738 - val_accuracy: 0.9801\n",
            "Epoch 138/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.8063e-08 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9799\n",
            "Epoch 139/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.6155e-08 - accuracy: 1.0000 - val_loss: 0.1745 - val_accuracy: 0.9800\n",
            "Epoch 140/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.4235e-08 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 0.9802\n",
            "Epoch 141/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.2780e-08 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 0.9799\n",
            "Epoch 142/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.1024e-08 - accuracy: 1.0000 - val_loss: 0.1761 - val_accuracy: 0.9799\n",
            "Epoch 143/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9379e-08 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 0.9799\n",
            "Epoch 144/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.8120e-08 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 0.9799\n",
            "Epoch 145/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.6634e-08 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.9799\n",
            "Epoch 146/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.5527e-08 - accuracy: 1.0000 - val_loss: 0.1770 - val_accuracy: 0.9799\n",
            "Epoch 147/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.4367e-08 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9800\n",
            "Epoch 148/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.3225e-08 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 0.9800\n",
            "Epoch 149/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.2128e-08 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9799\n",
            "Epoch 150/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.1182e-08 - accuracy: 1.0000 - val_loss: 0.1786 - val_accuracy: 0.9799\n",
            "Epoch 151/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.0247e-08 - accuracy: 1.0000 - val_loss: 0.1785 - val_accuracy: 0.9801\n",
            "Epoch 152/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.9331e-08 - accuracy: 1.0000 - val_loss: 0.1794 - val_accuracy: 0.9799\n",
            "Epoch 153/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.8425e-08 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9801\n",
            "Epoch 154/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7569e-08 - accuracy: 1.0000 - val_loss: 0.1796 - val_accuracy: 0.9800\n",
            "Epoch 155/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6830e-08 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 0.9799\n",
            "Epoch 156/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.6226e-08 - accuracy: 1.0000 - val_loss: 0.1799 - val_accuracy: 0.9800\n",
            "Epoch 157/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.5304e-08 - accuracy: 1.0000 - val_loss: 0.1804 - val_accuracy: 0.9799\n",
            "Epoch 158/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4663e-08 - accuracy: 1.0000 - val_loss: 0.1804 - val_accuracy: 0.9801\n",
            "Epoch 159/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3972e-08 - accuracy: 1.0000 - val_loss: 0.1807 - val_accuracy: 0.9800\n",
            "Epoch 160/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.3503e-08 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 0.9800\n",
            "Epoch 161/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.2970e-08 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9800\n",
            "Epoch 162/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.2385e-08 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9800\n",
            "Epoch 163/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.1768e-08 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9800\n",
            "Epoch 164/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.1386e-08 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9799\n",
            "Epoch 165/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0846e-08 - accuracy: 1.0000 - val_loss: 0.1821 - val_accuracy: 0.9801\n",
            "Epoch 166/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.0356e-08 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9800\n",
            "Epoch 167/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9937e-08 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 0.9800\n",
            "Epoch 168/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.9587e-08 - accuracy: 1.0000 - val_loss: 0.1823 - val_accuracy: 0.9801\n",
            "Epoch 169/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9052e-08 - accuracy: 1.0000 - val_loss: 0.1825 - val_accuracy: 0.9801\n",
            "Epoch 170/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8764e-08 - accuracy: 1.0000 - val_loss: 0.1827 - val_accuracy: 0.9801\n",
            "Epoch 171/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8454e-08 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 0.9801\n",
            "Epoch 172/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8009e-08 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 0.9800\n",
            "Epoch 173/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.7699e-08 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 0.9801\n",
            "Epoch 174/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.7381e-08 - accuracy: 1.0000 - val_loss: 0.1837 - val_accuracy: 0.9800\n",
            "Epoch 175/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.7063e-08 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9801\n",
            "Epoch 176/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.6668e-08 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9799\n",
            "Epoch 177/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.6374e-08 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.9801\n",
            "Epoch 178/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.6178e-08 - accuracy: 1.0000 - val_loss: 0.1839 - val_accuracy: 0.9800\n",
            "Epoch 179/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5839e-08 - accuracy: 1.0000 - val_loss: 0.1850 - val_accuracy: 0.9799\n",
            "Epoch 180/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5646e-08 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9800\n",
            "Epoch 181/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5304e-08 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 0.9800\n",
            "Epoch 182/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5057e-08 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9801\n",
            "Epoch 183/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4684e-08 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 0.9801\n",
            "Epoch 184/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4620e-08 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9801\n",
            "Epoch 185/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4337e-08 - accuracy: 1.0000 - val_loss: 0.1850 - val_accuracy: 0.9799\n",
            "Epoch 186/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4265e-08 - accuracy: 1.0000 - val_loss: 0.1853 - val_accuracy: 0.9801\n",
            "Epoch 187/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3892e-08 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9801\n",
            "Epoch 188/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3810e-08 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9801\n",
            "Epoch 189/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3595e-08 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9801\n",
            "Epoch 190/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3309e-08 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9801\n",
            "Epoch 191/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3200e-08 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9801\n",
            "Epoch 192/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3002e-08 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 0.9801\n",
            "Epoch 193/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2747e-08 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9801\n",
            "Epoch 194/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2618e-08 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9801\n",
            "Epoch 195/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2445e-08 - accuracy: 1.0000 - val_loss: 0.1864 - val_accuracy: 0.9801\n",
            "Epoch 196/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2284e-08 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9800\n",
            "Epoch 197/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2053e-08 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 0.9801\n",
            "Epoch 198/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1982e-08 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9801\n",
            "Epoch 199/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1881e-08 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9801\n",
            "Epoch 200/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1590e-08 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9801\n",
            "Epoch 201/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1518e-08 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9801\n",
            "Epoch 202/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1370e-08 - accuracy: 1.0000 - val_loss: 0.1870 - val_accuracy: 0.9801\n",
            "Epoch 203/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1216e-08 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9801\n",
            "Epoch 204/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1137e-08 - accuracy: 1.0000 - val_loss: 0.1873 - val_accuracy: 0.9801\n",
            "Epoch 205/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0949e-08 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9801\n",
            "Epoch 206/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0830e-08 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 0.9801\n",
            "Epoch 207/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0742e-08 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9802\n",
            "Epoch 208/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0578e-08 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9801\n",
            "Epoch 209/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0475e-08 - accuracy: 1.0000 - val_loss: 0.1879 - val_accuracy: 0.9801\n",
            "Epoch 210/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0294e-08 - accuracy: 1.0000 - val_loss: 0.1879 - val_accuracy: 0.9801\n",
            "Epoch 211/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0204e-08 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9802\n",
            "Epoch 212/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0093e-08 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9801\n",
            "Epoch 213/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.9871e-09 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 0.9801\n",
            "Epoch 214/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.9315e-09 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9801\n",
            "Epoch 215/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.8255e-09 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9801\n",
            "Epoch 216/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.6824e-09 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 0.9801\n",
            "Epoch 217/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.5473e-09 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9801\n",
            "Epoch 218/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.4705e-09 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9800\n",
            "Epoch 219/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.3884e-09 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.9801\n",
            "Epoch 220/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.3036e-09 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 0.9801\n",
            "Epoch 221/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.1844e-09 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9802\n",
            "Epoch 222/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.1341e-09 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9801\n",
            "Epoch 223/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.9857e-09 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9801\n",
            "Epoch 224/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.9778e-09 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9801\n",
            "Epoch 225/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.7870e-09 - accuracy: 1.0000 - val_loss: 0.1892 - val_accuracy: 0.9801\n",
            "Epoch 226/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.7632e-09 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9801\n",
            "Epoch 227/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.6334e-09 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9801\n",
            "Epoch 228/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.5751e-09 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9801\n",
            "Epoch 229/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.4718e-09 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9801\n",
            "Epoch 230/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.4400e-09 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9801\n",
            "Epoch 231/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.3288e-09 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9801\n",
            "Epoch 232/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.2917e-09 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.9801\n",
            "Epoch 233/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.1857e-09 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9801\n",
            "Epoch 234/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.0850e-09 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 0.9801\n",
            "Epoch 235/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.0506e-09 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9801\n",
            "Epoch 236/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.9658e-09 - accuracy: 1.0000 - val_loss: 0.1900 - val_accuracy: 0.9801\n",
            "Epoch 237/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.9102e-09 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9801\n",
            "Epoch 238/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7989e-09 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9801\n",
            "Epoch 239/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.7777e-09 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9801\n",
            "Epoch 240/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7168e-09 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9801\n",
            "Epoch 241/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.6718e-09 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 0.9801\n",
            "Epoch 242/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.5897e-09 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 0.9800\n",
            "Epoch 243/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.5022e-09 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9801\n",
            "Epoch 244/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.4969e-09 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9801\n",
            "Epoch 245/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.4042e-09 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9801\n",
            "Epoch 246/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.3433e-09 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9801\n",
            "Epoch 247/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.2797e-09 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.9801\n",
            "Epoch 248/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.2320e-09 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9801\n",
            "Epoch 249/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.1976e-09 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9800\n",
            "Epoch 250/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.0784e-09 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9800\n",
            "Epoch 251/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0916e-09 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9799\n",
            "Epoch 252/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0254e-09 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9801\n",
            "Epoch 253/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.9751e-09 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9800\n",
            "Epoch 254/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.9115e-09 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9800\n",
            "Epoch 255/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8797e-09 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9799\n",
            "Epoch 256/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8241e-09 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9800\n",
            "Epoch 257/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.7472e-09 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9801\n",
            "Epoch 258/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.7790e-09 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9801\n",
            "Epoch 259/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7208e-09 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9801\n",
            "Epoch 260/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.6386e-09 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9800\n",
            "Epoch 261/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.6095e-09 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 0.9800\n",
            "Epoch 262/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.5671e-09 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9799\n",
            "Epoch 263/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5141e-09 - accuracy: 1.0000 - val_loss: 0.1919 - val_accuracy: 0.9800\n",
            "Epoch 264/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.4426e-09 - accuracy: 1.0000 - val_loss: 0.1920 - val_accuracy: 0.9800\n",
            "Epoch 265/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.4585e-09 - accuracy: 1.0000 - val_loss: 0.1920 - val_accuracy: 0.9799\n",
            "Epoch 266/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3843e-09 - accuracy: 1.0000 - val_loss: 0.1920 - val_accuracy: 0.9800\n",
            "Epoch 267/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3737e-09 - accuracy: 1.0000 - val_loss: 0.1920 - val_accuracy: 0.9799\n",
            "Epoch 268/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3499e-09 - accuracy: 1.0000 - val_loss: 0.1922 - val_accuracy: 0.9798\n",
            "Epoch 269/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2731e-09 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9799\n",
            "Epoch 270/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.2784e-09 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 0.9799\n",
            "Epoch 271/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3048e-09 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9799\n",
            "Epoch 272/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1274e-09 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 0.9799\n",
            "Epoch 273/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1618e-09 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 0.9799\n",
            "Epoch 274/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2068e-09 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 0.9799\n",
            "Epoch 275/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1247e-09 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9799\n",
            "Epoch 276/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.1062e-09 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9799\n",
            "Epoch 277/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0187e-09 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9799\n",
            "Epoch 278/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0002e-09 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9799\n",
            "Epoch 279/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.0293e-09 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 0.9798\n",
            "Epoch 280/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0134e-09 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 0.9799\n",
            "Epoch 281/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9446e-09 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9799\n",
            "Epoch 282/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9287e-09 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9798\n",
            "Epoch 283/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9128e-09 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9799\n",
            "Epoch 284/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8651e-09 - accuracy: 1.0000 - val_loss: 0.1931 - val_accuracy: 0.9799\n",
            "Epoch 285/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8942e-09 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9799\n",
            "Epoch 286/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8015e-09 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9798\n",
            "Epoch 287/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8095e-09 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9797\n",
            "Epoch 288/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7909e-09 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9798\n",
            "Epoch 289/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8624e-09 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9797\n",
            "Epoch 290/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.6956e-09 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9798\n",
            "Epoch 291/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7777e-09 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 0.9799\n",
            "Epoch 292/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7247e-09 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9799\n",
            "Epoch 293/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7062e-09 - accuracy: 1.0000 - val_loss: 0.1935 - val_accuracy: 0.9799\n",
            "Epoch 294/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6081e-09 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9799\n",
            "Epoch 295/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6505e-09 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9799\n",
            "Epoch 296/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6214e-09 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 0.9797\n",
            "Epoch 297/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6267e-09 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 0.9799\n",
            "Epoch 298/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6161e-09 - accuracy: 1.0000 - val_loss: 0.1940 - val_accuracy: 0.9799\n",
            "Epoch 299/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6399e-09 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9799\n",
            "Epoch 300/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5869e-09 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 0.9798\n",
            "Epoch 301/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5710e-09 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9798\n",
            "Epoch 302/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6055e-09 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 0.9798\n",
            "Epoch 303/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6055e-09 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9798\n",
            "Epoch 304/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5340e-09 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9799\n",
            "Epoch 305/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5101e-09 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 0.9799\n",
            "Epoch 306/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5340e-09 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 0.9798\n",
            "Epoch 307/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4412e-09 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9798\n",
            "Epoch 308/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4042e-09 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9798\n",
            "Epoch 309/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4704e-09 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 0.9798\n",
            "Epoch 310/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4280e-09 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.9798\n",
            "Epoch 311/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4704e-09 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.9797\n",
            "Epoch 312/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4598e-09 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.9797\n",
            "Epoch 313/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3909e-09 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9797\n",
            "Epoch 314/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3750e-09 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9797\n",
            "Epoch 315/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3856e-09 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9798\n",
            "Epoch 316/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4518e-09 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9798\n",
            "Epoch 317/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3803e-09 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 0.9797\n",
            "Epoch 318/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4121e-09 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9798\n",
            "Epoch 319/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3591e-09 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9797\n",
            "Epoch 320/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3618e-09 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9797\n",
            "Epoch 321/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2849e-09 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9798\n",
            "Epoch 322/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3035e-09 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9797\n",
            "Epoch 323/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3379e-09 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9797\n",
            "Epoch 324/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3697e-09 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9797\n",
            "Epoch 325/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2876e-09 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9797\n",
            "Epoch 326/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3035e-09 - accuracy: 1.0000 - val_loss: 0.1958 - val_accuracy: 0.9797\n",
            "Epoch 327/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3353e-09 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9798\n",
            "Epoch 328/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2955e-09 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9797\n",
            "Epoch 329/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3008e-09 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 0.9797\n",
            "Epoch 330/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2214e-09 - accuracy: 1.0000 - val_loss: 0.1958 - val_accuracy: 0.9797\n",
            "Epoch 331/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3565e-09 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9797\n",
            "Epoch 332/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2638e-09 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 0.9797\n",
            "Epoch 333/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3247e-09 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.9797\n",
            "Epoch 334/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2876e-09 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 0.9797\n",
            "Epoch 335/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2055e-09 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9797\n",
            "Epoch 336/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2955e-09 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.9797\n",
            "Epoch 337/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2240e-09 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.9797\n",
            "Epoch 338/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2028e-09 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.9797\n",
            "Epoch 339/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2638e-09 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.9797\n",
            "Epoch 340/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2982e-09 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.9797\n",
            "Epoch 341/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2267e-09 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.9797\n",
            "Epoch 342/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1737e-09 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9797\n",
            "Epoch 343/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2028e-09 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9797\n",
            "Epoch 344/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1498e-09 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9797\n",
            "Epoch 345/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1525e-09 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9797\n",
            "Epoch 346/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2187e-09 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9797\n",
            "Epoch 347/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2187e-09 - accuracy: 1.0000 - val_loss: 0.1969 - val_accuracy: 0.9797\n",
            "Epoch 348/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1843e-09 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 0.9798\n",
            "Epoch 349/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1525e-09 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 0.9797\n",
            "Epoch 350/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2161e-09 - accuracy: 1.0000 - val_loss: 0.1969 - val_accuracy: 0.9798\n",
            "Epoch 351/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1816e-09 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9797\n",
            "Epoch 352/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2108e-09 - accuracy: 1.0000 - val_loss: 0.1971 - val_accuracy: 0.9798\n",
            "Epoch 353/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1737e-09 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9798\n",
            "Epoch 354/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2426e-09 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 0.9797\n",
            "Epoch 355/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1578e-09 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9798\n",
            "Epoch 356/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1657e-09 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9798\n",
            "Epoch 357/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1472e-09 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9798\n",
            "Epoch 358/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1922e-09 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 0.9798\n",
            "Epoch 359/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1339e-09 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9797\n",
            "Epoch 360/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1181e-09 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 0.9798\n",
            "Epoch 361/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1869e-09 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9798\n",
            "Epoch 362/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1869e-09 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9798\n",
            "Epoch 363/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1551e-09 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9797\n",
            "Epoch 364/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1790e-09 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9797\n",
            "Epoch 365/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1710e-09 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9797\n",
            "Epoch 366/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1498e-09 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9798\n",
            "Epoch 367/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1207e-09 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9798\n",
            "Epoch 368/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1710e-09 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9798\n",
            "Epoch 369/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1419e-09 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9798\n",
            "Epoch 370/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1631e-09 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9797\n",
            "Epoch 371/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1313e-09 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9798\n",
            "Epoch 372/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1048e-09 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9798\n",
            "Epoch 373/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1684e-09 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 0.9797\n",
            "Epoch 374/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1392e-09 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9797\n",
            "Epoch 375/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1207e-09 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9798\n",
            "Epoch 376/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1445e-09 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9798\n",
            "Epoch 377/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1551e-09 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.9798\n",
            "Epoch 378/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1234e-09 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.9797\n",
            "Epoch 379/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1472e-09 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.9797\n",
            "Epoch 380/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1498e-09 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.9797\n",
            "Epoch 381/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1445e-09 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9798\n",
            "Epoch 382/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1207e-09 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9798\n",
            "Epoch 383/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0810e-09 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.9798\n",
            "Epoch 384/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0783e-09 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9797\n",
            "Epoch 385/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1790e-09 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.9797\n",
            "Epoch 386/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1286e-09 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.9797\n",
            "Epoch 387/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1313e-09 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9797\n",
            "Epoch 388/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1048e-09 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9799\n",
            "Epoch 389/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1339e-09 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9799\n",
            "Epoch 390/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1207e-09 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.9799\n",
            "Epoch 391/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1075e-09 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.9799\n",
            "Epoch 392/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0757e-09 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 0.9798\n",
            "Epoch 393/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0598e-09 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 0.9799\n",
            "Epoch 394/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1181e-09 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9799\n",
            "Epoch 395/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0757e-09 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9799\n",
            "Epoch 396/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1260e-09 - accuracy: 1.0000 - val_loss: 0.1994 - val_accuracy: 0.9798\n",
            "Epoch 397/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0995e-09 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9799\n",
            "Epoch 398/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1816e-09 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9797\n",
            "Epoch 399/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1313e-09 - accuracy: 1.0000 - val_loss: 0.1994 - val_accuracy: 0.9798\n",
            "Epoch 400/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0889e-09 - accuracy: 1.0000 - val_loss: 0.1994 - val_accuracy: 0.9799\n",
            "Epoch 401/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1075e-09 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9799\n",
            "Epoch 402/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0995e-09 - accuracy: 1.0000 - val_loss: 0.1996 - val_accuracy: 0.9799\n",
            "Epoch 403/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0704e-09 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9797\n",
            "Epoch 404/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0969e-09 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.9797\n",
            "Epoch 405/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1260e-09 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9797\n",
            "Epoch 406/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0783e-09 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.9797\n",
            "Epoch 407/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0518e-09 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9797\n",
            "Epoch 408/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1048e-09 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9798\n",
            "Epoch 409/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0836e-09 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9799\n",
            "Epoch 410/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1128e-09 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9797\n",
            "Epoch 411/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1392e-09 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.9797\n",
            "Epoch 412/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1154e-09 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9797\n",
            "Epoch 413/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1578e-09 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9796\n",
            "Epoch 414/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0704e-09 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9797\n",
            "Epoch 415/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1234e-09 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9797\n",
            "Epoch 416/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0200e-09 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9797\n",
            "Epoch 417/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1710e-09 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9797\n",
            "Epoch 418/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0942e-09 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9797\n",
            "Epoch 419/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1075e-09 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9796\n",
            "Epoch 420/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0571e-09 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9797\n",
            "Epoch 421/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0916e-09 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9797\n",
            "Epoch 422/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0942e-09 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9796\n",
            "Epoch 423/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0916e-09 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9796\n",
            "Epoch 424/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1286e-09 - accuracy: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.9796\n",
            "Epoch 425/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0995e-09 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9795\n",
            "Epoch 426/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1392e-09 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9797\n",
            "Epoch 427/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0757e-09 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9796\n",
            "Epoch 428/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0651e-09 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9797\n",
            "Epoch 429/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1445e-09 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9796\n",
            "Epoch 430/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0704e-09 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9795\n",
            "Epoch 431/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1234e-09 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9796\n",
            "Epoch 432/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0598e-09 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9797\n",
            "Epoch 433/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0174e-09 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9795\n",
            "Epoch 434/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1286e-09 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9795\n",
            "Epoch 435/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0942e-09 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9796\n",
            "Epoch 436/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0810e-09 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9795\n",
            "Epoch 437/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0783e-09 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9796\n",
            "Epoch 438/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1048e-09 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9795\n",
            "Epoch 439/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0704e-09 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9795\n",
            "Epoch 440/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0783e-09 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9795\n",
            "Epoch 441/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0995e-09 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9797\n",
            "Epoch 442/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0783e-09 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9795\n",
            "Epoch 443/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1445e-09 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9795\n",
            "Epoch 444/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1022e-09 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9795\n",
            "Epoch 445/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1286e-09 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9795\n",
            "Epoch 446/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1419e-09 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9794\n",
            "Epoch 447/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0651e-09 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9795\n",
            "Epoch 448/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1392e-09 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9795\n",
            "Epoch 449/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1286e-09 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9794\n",
            "Epoch 450/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1286e-09 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9795\n",
            "Epoch 451/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0280e-09 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9794\n",
            "Epoch 452/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1525e-09 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9796\n",
            "Epoch 453/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0916e-09 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9795\n",
            "Epoch 454/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0704e-09 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9794\n",
            "Epoch 455/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1922e-09 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9795\n",
            "Epoch 456/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0677e-09 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9794\n",
            "Epoch 457/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1313e-09 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9795\n",
            "Epoch 458/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1339e-09 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9794\n",
            "Epoch 459/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0810e-09 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9794\n",
            "Epoch 460/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1472e-09 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9794\n",
            "Epoch 461/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1075e-09 - accuracy: 1.0000 - val_loss: 0.2025 - val_accuracy: 0.9794\n",
            "Epoch 462/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0969e-09 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9795\n",
            "Epoch 463/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1445e-09 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9794\n",
            "Epoch 464/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0995e-09 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9794\n",
            "Epoch 465/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1975e-09 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9795\n",
            "Epoch 466/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1339e-09 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 0.9795\n",
            "Epoch 467/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1392e-09 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 0.9795\n",
            "Epoch 468/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1763e-09 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9795\n",
            "Epoch 469/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1551e-09 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9795\n",
            "Epoch 470/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1578e-09 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9795\n",
            "Epoch 471/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1339e-09 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9795\n",
            "Epoch 472/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1339e-09 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 0.9795\n",
            "Epoch 473/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1498e-09 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9795\n",
            "Epoch 474/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1604e-09 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9794\n",
            "Epoch 475/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1684e-09 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9795\n",
            "Epoch 476/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1737e-09 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.9794\n",
            "Epoch 477/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1843e-09 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9795\n",
            "Epoch 478/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1498e-09 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 0.9795\n",
            "Epoch 479/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2055e-09 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9794\n",
            "Epoch 480/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1101e-09 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9795\n",
            "Epoch 481/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1816e-09 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.9795\n",
            "Epoch 482/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1843e-09 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9794\n",
            "Epoch 483/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1234e-09 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.9795\n",
            "Epoch 484/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1816e-09 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9793\n",
            "Epoch 485/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1790e-09 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9794\n",
            "Epoch 486/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1022e-09 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 0.9794\n",
            "Epoch 487/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1922e-09 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9794\n",
            "Epoch 488/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0995e-09 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 0.9793\n",
            "Epoch 489/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2240e-09 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 0.9795\n",
            "Epoch 490/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1737e-09 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9795\n",
            "Epoch 491/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1525e-09 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9794\n",
            "Epoch 492/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1737e-09 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9795\n",
            "Epoch 493/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1896e-09 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9795\n",
            "Epoch 494/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1075e-09 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9794\n",
            "Epoch 495/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1551e-09 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9795\n",
            "Epoch 496/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1525e-09 - accuracy: 1.0000 - val_loss: 0.2046 - val_accuracy: 0.9795\n",
            "Epoch 497/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2108e-09 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.9795\n",
            "Epoch 498/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1710e-09 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 0.9794\n",
            "Epoch 499/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1710e-09 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.9794\n",
            "Epoch 500/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1869e-09 - accuracy: 1.0000 - val_loss: 0.2046 - val_accuracy: 0.9795\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0512 - accuracy: 0.9949\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1595 - accuracy: 0.9816\n",
            "train accuracy :  0.994866669178009 train loss :  0.05115368217229843\n",
            "test accuracy :  0.9815999865531921  test loss :  0.15946437418460846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "S1-tzs7pQ-kL",
        "outputId": "a2b6d9d0-a534-4f07-b84c-f04293848910"
      },
      "source": [
        "#신경망 학습4\n",
        "model1_4 = models.Sequential([\n",
        "                            Flatten(input_shape = (28, 28)),\n",
        "                            Dense(512, activation= 'relu'),\n",
        "                            Dense(10, activation= 'softmax')\n",
        "                            ])\n",
        "\n",
        "model1_4.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "hist1_4 = model1_4.fit(train_x, train_y, epochs = 1000, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "#학습 그래프4\n",
        "plt.plot(hist1_4.history['accuracy'], 'b-')\n",
        "plt.plot(hist1_4.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train1_4 = model1_4.evaluate(train_x, train_y)\n",
        "sc_test1_4 = model1_4.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train1_4[1], \"train loss : \", sc_train1_4[0])\n",
        "print(\"test accuracy : \", sc_test1_4[1], \" test loss : \", sc_test1_4[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3709 - accuracy: 0.8987 - val_loss: 0.1955 - val_accuracy: 0.9449\n",
            "Epoch 2/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.1603 - accuracy: 0.9545 - val_loss: 0.1509 - val_accuracy: 0.9559\n",
            "Epoch 3/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.1092 - accuracy: 0.9695 - val_loss: 0.1194 - val_accuracy: 0.9661\n",
            "Epoch 4/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0821 - accuracy: 0.9766 - val_loss: 0.1110 - val_accuracy: 0.9681\n",
            "Epoch 5/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0624 - accuracy: 0.9831 - val_loss: 0.1008 - val_accuracy: 0.9691\n",
            "Epoch 6/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0481 - accuracy: 0.9870 - val_loss: 0.0936 - val_accuracy: 0.9727\n",
            "Epoch 7/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0385 - accuracy: 0.9899 - val_loss: 0.0921 - val_accuracy: 0.9721\n",
            "Epoch 8/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0304 - accuracy: 0.9924 - val_loss: 0.0871 - val_accuracy: 0.9742\n",
            "Epoch 9/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0231 - accuracy: 0.9950 - val_loss: 0.0854 - val_accuracy: 0.9740\n",
            "Epoch 10/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0184 - accuracy: 0.9967 - val_loss: 0.0820 - val_accuracy: 0.9765\n",
            "Epoch 11/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0151 - accuracy: 0.9972 - val_loss: 0.0892 - val_accuracy: 0.9741\n",
            "Epoch 12/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0123 - accuracy: 0.9981 - val_loss: 0.0832 - val_accuracy: 0.9758\n",
            "Epoch 13/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0101 - accuracy: 0.9985 - val_loss: 0.0865 - val_accuracy: 0.9755\n",
            "Epoch 14/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0074 - accuracy: 0.9995 - val_loss: 0.0837 - val_accuracy: 0.9777\n",
            "Epoch 15/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0064 - accuracy: 0.9995 - val_loss: 0.0849 - val_accuracy: 0.9759\n",
            "Epoch 16/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0046 - accuracy: 0.9998 - val_loss: 0.0873 - val_accuracy: 0.9763\n",
            "Epoch 17/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 0.9997 - val_loss: 0.0907 - val_accuracy: 0.9769\n",
            "Epoch 18/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0038 - accuracy: 0.9998 - val_loss: 0.0844 - val_accuracy: 0.9781\n",
            "Epoch 19/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.0865 - val_accuracy: 0.9774\n",
            "Epoch 20/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0873 - val_accuracy: 0.9780\n",
            "Epoch 21/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9779\n",
            "Epoch 22/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 0.9788\n",
            "Epoch 23/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9788\n",
            "Epoch 24/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0896 - val_accuracy: 0.9777\n",
            "Epoch 25/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.5765e-04 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9787\n",
            "Epoch 26/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.7274e-04 - accuracy: 1.0000 - val_loss: 0.0925 - val_accuracy: 0.9789\n",
            "Epoch 27/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.4831e-04 - accuracy: 1.0000 - val_loss: 0.0926 - val_accuracy: 0.9784\n",
            "Epoch 28/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.6419e-04 - accuracy: 1.0000 - val_loss: 0.0936 - val_accuracy: 0.9785\n",
            "Epoch 29/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.8098e-04 - accuracy: 1.0000 - val_loss: 0.0950 - val_accuracy: 0.9782\n",
            "Epoch 30/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.2973e-04 - accuracy: 1.0000 - val_loss: 0.0960 - val_accuracy: 0.9785\n",
            "Epoch 31/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.7654e-04 - accuracy: 1.0000 - val_loss: 0.0960 - val_accuracy: 0.9791\n",
            "Epoch 32/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.0640e-04 - accuracy: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9786\n",
            "Epoch 33/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.8435e-04 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9789\n",
            "Epoch 34/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.3623e-04 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 0.9783\n",
            "Epoch 35/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.9471e-04 - accuracy: 1.0000 - val_loss: 0.0998 - val_accuracy: 0.9790\n",
            "Epoch 36/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.6458e-04 - accuracy: 1.0000 - val_loss: 0.1003 - val_accuracy: 0.9783\n",
            "Epoch 37/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.3626e-04 - accuracy: 1.0000 - val_loss: 0.1011 - val_accuracy: 0.9787\n",
            "Epoch 38/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.1431e-04 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9787\n",
            "Epoch 39/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.9494e-04 - accuracy: 1.0000 - val_loss: 0.1026 - val_accuracy: 0.9787\n",
            "Epoch 40/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.7192e-04 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 0.9793\n",
            "Epoch 41/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.6014e-04 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9795\n",
            "Epoch 42/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4396e-04 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9793\n",
            "Epoch 43/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2886e-04 - accuracy: 1.0000 - val_loss: 0.1069 - val_accuracy: 0.9793\n",
            "Epoch 44/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1202e-04 - accuracy: 1.0000 - val_loss: 0.1076 - val_accuracy: 0.9797\n",
            "Epoch 45/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0301e-04 - accuracy: 1.0000 - val_loss: 0.1084 - val_accuracy: 0.9788\n",
            "Epoch 46/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.5737e-05 - accuracy: 1.0000 - val_loss: 0.1087 - val_accuracy: 0.9793\n",
            "Epoch 47/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.3498e-05 - accuracy: 1.0000 - val_loss: 0.1100 - val_accuracy: 0.9793\n",
            "Epoch 48/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.3963e-05 - accuracy: 1.0000 - val_loss: 0.1104 - val_accuracy: 0.9799\n",
            "Epoch 49/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.7417e-05 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9791\n",
            "Epoch 50/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.1664e-05 - accuracy: 1.0000 - val_loss: 0.1131 - val_accuracy: 0.9793\n",
            "Epoch 51/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.5559e-05 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.9794\n",
            "Epoch 52/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.1306e-05 - accuracy: 1.0000 - val_loss: 0.1141 - val_accuracy: 0.9794\n",
            "Epoch 53/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.5814e-05 - accuracy: 1.0000 - val_loss: 0.1142 - val_accuracy: 0.9792\n",
            "Epoch 54/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.0965e-05 - accuracy: 1.0000 - val_loss: 0.1151 - val_accuracy: 0.9799\n",
            "Epoch 55/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.7155e-05 - accuracy: 1.0000 - val_loss: 0.1168 - val_accuracy: 0.9795\n",
            "Epoch 56/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.3978e-05 - accuracy: 1.0000 - val_loss: 0.1175 - val_accuracy: 0.9793\n",
            "Epoch 57/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.0294e-05 - accuracy: 1.0000 - val_loss: 0.1183 - val_accuracy: 0.9795\n",
            "Epoch 58/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.7706e-05 - accuracy: 1.0000 - val_loss: 0.1198 - val_accuracy: 0.9794\n",
            "Epoch 59/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.4742e-05 - accuracy: 1.0000 - val_loss: 0.1200 - val_accuracy: 0.9798\n",
            "Epoch 60/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.2748e-05 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 0.9798\n",
            "Epoch 61/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.0481e-05 - accuracy: 1.0000 - val_loss: 0.1211 - val_accuracy: 0.9795\n",
            "Epoch 62/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8935e-05 - accuracy: 1.0000 - val_loss: 0.1222 - val_accuracy: 0.9794\n",
            "Epoch 63/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.7343e-05 - accuracy: 1.0000 - val_loss: 0.1237 - val_accuracy: 0.9799\n",
            "Epoch 64/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5246e-05 - accuracy: 1.0000 - val_loss: 0.1253 - val_accuracy: 0.9795\n",
            "Epoch 65/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3815e-05 - accuracy: 1.0000 - val_loss: 0.1255 - val_accuracy: 0.9797\n",
            "Epoch 66/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2859e-05 - accuracy: 1.0000 - val_loss: 0.1261 - val_accuracy: 0.9799\n",
            "Epoch 67/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1356e-05 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9799\n",
            "Epoch 68/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0287e-05 - accuracy: 1.0000 - val_loss: 0.1278 - val_accuracy: 0.9797\n",
            "Epoch 69/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.4582e-06 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.9799\n",
            "Epoch 70/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.4206e-06 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 0.9797\n",
            "Epoch 71/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.8077e-06 - accuracy: 1.0000 - val_loss: 0.1299 - val_accuracy: 0.9798\n",
            "Epoch 72/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.0011e-06 - accuracy: 1.0000 - val_loss: 0.1315 - val_accuracy: 0.9799\n",
            "Epoch 73/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.3743e-06 - accuracy: 1.0000 - val_loss: 0.1329 - val_accuracy: 0.9795\n",
            "Epoch 74/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.8091e-06 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.9795\n",
            "Epoch 75/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.2422e-06 - accuracy: 1.0000 - val_loss: 0.1341 - val_accuracy: 0.9796\n",
            "Epoch 76/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.7642e-06 - accuracy: 1.0000 - val_loss: 0.1346 - val_accuracy: 0.9798\n",
            "Epoch 77/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.3422e-06 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.9794\n",
            "Epoch 78/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.9699e-06 - accuracy: 1.0000 - val_loss: 0.1364 - val_accuracy: 0.9801\n",
            "Epoch 79/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.6075e-06 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9795\n",
            "Epoch 80/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.3554e-06 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9798\n",
            "Epoch 81/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.9817e-06 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9801\n",
            "Epoch 82/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.7247e-06 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.9800\n",
            "Epoch 83/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.4911e-06 - accuracy: 1.0000 - val_loss: 0.1407 - val_accuracy: 0.9801\n",
            "Epoch 84/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.2511e-06 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9801\n",
            "Epoch 85/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.0772e-06 - accuracy: 1.0000 - val_loss: 0.1419 - val_accuracy: 0.9801\n",
            "Epoch 86/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8950e-06 - accuracy: 1.0000 - val_loss: 0.1437 - val_accuracy: 0.9798\n",
            "Epoch 87/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.7155e-06 - accuracy: 1.0000 - val_loss: 0.1445 - val_accuracy: 0.9796\n",
            "Epoch 88/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5543e-06 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.9800\n",
            "Epoch 89/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4225e-06 - accuracy: 1.0000 - val_loss: 0.1452 - val_accuracy: 0.9799\n",
            "Epoch 90/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3437e-06 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.9797\n",
            "Epoch 91/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2027e-06 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9803\n",
            "Epoch 92/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0984e-06 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 0.9801\n",
            "Epoch 93/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.9963e-07 - accuracy: 1.0000 - val_loss: 0.1487 - val_accuracy: 0.9803\n",
            "Epoch 94/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.2098e-07 - accuracy: 1.0000 - val_loss: 0.1496 - val_accuracy: 0.9799\n",
            "Epoch 95/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.3745e-07 - accuracy: 1.0000 - val_loss: 0.1506 - val_accuracy: 0.9801\n",
            "Epoch 96/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.7724e-07 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 0.9800\n",
            "Epoch 97/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.1156e-07 - accuracy: 1.0000 - val_loss: 0.1518 - val_accuracy: 0.9800\n",
            "Epoch 98/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.4039e-07 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9800\n",
            "Epoch 99/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.0009e-07 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9804\n",
            "Epoch 100/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.5281e-07 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 0.9801\n",
            "Epoch 101/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.1850e-07 - accuracy: 1.0000 - val_loss: 0.1557 - val_accuracy: 0.9801\n",
            "Epoch 102/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.6326e-07 - accuracy: 1.0000 - val_loss: 0.1550 - val_accuracy: 0.9805\n",
            "Epoch 103/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.3043e-07 - accuracy: 1.0000 - val_loss: 0.1558 - val_accuracy: 0.9802\n",
            "Epoch 104/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.0178e-07 - accuracy: 1.0000 - val_loss: 0.1575 - val_accuracy: 0.9803\n",
            "Epoch 105/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.6860e-07 - accuracy: 1.0000 - val_loss: 0.1580 - val_accuracy: 0.9803\n",
            "Epoch 106/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.3895e-07 - accuracy: 1.0000 - val_loss: 0.1581 - val_accuracy: 0.9808\n",
            "Epoch 107/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.1388e-07 - accuracy: 1.0000 - val_loss: 0.1586 - val_accuracy: 0.9805\n",
            "Epoch 108/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.8816e-07 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 0.9802\n",
            "Epoch 109/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.6790e-07 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9801\n",
            "Epoch 110/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.4979e-07 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.9805\n",
            "Epoch 111/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.3226e-07 - accuracy: 1.0000 - val_loss: 0.1617 - val_accuracy: 0.9806\n",
            "Epoch 112/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.1434e-07 - accuracy: 1.0000 - val_loss: 0.1626 - val_accuracy: 0.9801\n",
            "Epoch 113/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.9952e-07 - accuracy: 1.0000 - val_loss: 0.1632 - val_accuracy: 0.9804\n",
            "Epoch 114/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8720e-07 - accuracy: 1.0000 - val_loss: 0.1637 - val_accuracy: 0.9802\n",
            "Epoch 115/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.7394e-07 - accuracy: 1.0000 - val_loss: 0.1642 - val_accuracy: 0.9804\n",
            "Epoch 116/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.6432e-07 - accuracy: 1.0000 - val_loss: 0.1648 - val_accuracy: 0.9805\n",
            "Epoch 117/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5093e-07 - accuracy: 1.0000 - val_loss: 0.1654 - val_accuracy: 0.9807\n",
            "Epoch 118/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4198e-07 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9805\n",
            "Epoch 119/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3202e-07 - accuracy: 1.0000 - val_loss: 0.1673 - val_accuracy: 0.9805\n",
            "Epoch 120/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2388e-07 - accuracy: 1.0000 - val_loss: 0.1670 - val_accuracy: 0.9804\n",
            "Epoch 121/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1802e-07 - accuracy: 1.0000 - val_loss: 0.1687 - val_accuracy: 0.9806\n",
            "Epoch 122/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1117e-07 - accuracy: 1.0000 - val_loss: 0.1682 - val_accuracy: 0.9805\n",
            "Epoch 123/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0343e-07 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 0.9807\n",
            "Epoch 124/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.7672e-08 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 0.9807\n",
            "Epoch 125/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.2930e-08 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 0.9807\n",
            "Epoch 126/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.6964e-08 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9806\n",
            "Epoch 127/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.2983e-08 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 0.9805\n",
            "Epoch 128/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.8056e-08 - accuracy: 1.0000 - val_loss: 0.1712 - val_accuracy: 0.9805\n",
            "Epoch 129/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.4426e-08 - accuracy: 1.0000 - val_loss: 0.1723 - val_accuracy: 0.9807\n",
            "Epoch 130/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.9859e-08 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 0.9805\n",
            "Epoch 131/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.7046e-08 - accuracy: 1.0000 - val_loss: 0.1731 - val_accuracy: 0.9805\n",
            "Epoch 132/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.3290e-08 - accuracy: 1.0000 - val_loss: 0.1738 - val_accuracy: 0.9806\n",
            "Epoch 133/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.0773e-08 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 0.9805\n",
            "Epoch 134/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7578e-08 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9807\n",
            "Epoch 135/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.5411e-08 - accuracy: 1.0000 - val_loss: 0.1750 - val_accuracy: 0.9805\n",
            "Epoch 136/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3030e-08 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 0.9805\n",
            "Epoch 137/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.0682e-08 - accuracy: 1.0000 - val_loss: 0.1758 - val_accuracy: 0.9806\n",
            "Epoch 138/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.8526e-08 - accuracy: 1.0000 - val_loss: 0.1762 - val_accuracy: 0.9807\n",
            "Epoch 139/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.6370e-08 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 0.9804\n",
            "Epoch 140/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.4696e-08 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9807\n",
            "Epoch 141/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.2968e-08 - accuracy: 1.0000 - val_loss: 0.1773 - val_accuracy: 0.9805\n",
            "Epoch 142/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.1673e-08 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9805\n",
            "Epoch 143/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.9662e-08 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9807\n",
            "Epoch 144/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.8242e-08 - accuracy: 1.0000 - val_loss: 0.1783 - val_accuracy: 0.9806\n",
            "Epoch 145/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.7026e-08 - accuracy: 1.0000 - val_loss: 0.1787 - val_accuracy: 0.9807\n",
            "Epoch 146/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.5606e-08 - accuracy: 1.0000 - val_loss: 0.1788 - val_accuracy: 0.9805\n",
            "Epoch 147/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.4414e-08 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 0.9803\n",
            "Epoch 148/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.3307e-08 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 0.9805\n",
            "Epoch 149/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.2266e-08 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 0.9805\n",
            "Epoch 150/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1209e-08 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 0.9804\n",
            "Epoch 151/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.0229e-08 - accuracy: 1.0000 - val_loss: 0.1807 - val_accuracy: 0.9807\n",
            "Epoch 152/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.9373e-08 - accuracy: 1.0000 - val_loss: 0.1808 - val_accuracy: 0.9807\n",
            "Epoch 153/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.8655e-08 - accuracy: 1.0000 - val_loss: 0.1813 - val_accuracy: 0.9806\n",
            "Epoch 154/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.7691e-08 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9807\n",
            "Epoch 155/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.6851e-08 - accuracy: 1.0000 - val_loss: 0.1818 - val_accuracy: 0.9805\n",
            "Epoch 156/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.6189e-08 - accuracy: 1.0000 - val_loss: 0.1818 - val_accuracy: 0.9804\n",
            "Epoch 157/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.5471e-08 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9805\n",
            "Epoch 158/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.4878e-08 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 0.9805\n",
            "Epoch 159/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.4067e-08 - accuracy: 1.0000 - val_loss: 0.1827 - val_accuracy: 0.9805\n",
            "Epoch 160/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.3580e-08 - accuracy: 1.0000 - val_loss: 0.1827 - val_accuracy: 0.9807\n",
            "Epoch 161/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.2954e-08 - accuracy: 1.0000 - val_loss: 0.1831 - val_accuracy: 0.9806\n",
            "Epoch 162/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.2332e-08 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 0.9804\n",
            "Epoch 163/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.2030e-08 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9807\n",
            "Epoch 164/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.1383e-08 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9805\n",
            "Epoch 165/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.1002e-08 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9806\n",
            "Epoch 166/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.0523e-08 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9805\n",
            "Epoch 167/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.9998e-08 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.9805\n",
            "Epoch 168/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.9529e-08 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.9805\n",
            "Epoch 169/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.9134e-08 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 0.9806\n",
            "Epoch 170/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8803e-08 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9805\n",
            "Epoch 171/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8464e-08 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 0.9805\n",
            "Epoch 172/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8043e-08 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9807\n",
            "Epoch 173/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.7714e-08 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9806\n",
            "Epoch 174/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.7360e-08 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9807\n",
            "Epoch 175/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.7153e-08 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9805\n",
            "Epoch 176/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6750e-08 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9805\n",
            "Epoch 177/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.6406e-08 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 0.9806\n",
            "Epoch 178/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.6120e-08 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9804\n",
            "Epoch 179/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5937e-08 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9805\n",
            "Epoch 180/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5555e-08 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9805\n",
            "Epoch 181/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5365e-08 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 0.9806\n",
            "Epoch 182/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5126e-08 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 0.9805\n",
            "Epoch 183/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4819e-08 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9805\n",
            "Epoch 184/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4541e-08 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9805\n",
            "Epoch 185/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4326e-08 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9805\n",
            "Epoch 186/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4141e-08 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9805\n",
            "Epoch 187/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3918e-08 - accuracy: 1.0000 - val_loss: 0.1873 - val_accuracy: 0.9803\n",
            "Epoch 188/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3706e-08 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9805\n",
            "Epoch 189/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3606e-08 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9805\n",
            "Epoch 190/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3338e-08 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9805\n",
            "Epoch 191/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3049e-08 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.9805\n",
            "Epoch 192/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2943e-08 - accuracy: 1.0000 - val_loss: 0.1879 - val_accuracy: 0.9805\n",
            "Epoch 193/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2739e-08 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9805\n",
            "Epoch 194/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2549e-08 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9805\n",
            "Epoch 195/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2422e-08 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9805\n",
            "Epoch 196/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2300e-08 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 0.9804\n",
            "Epoch 197/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1998e-08 - accuracy: 1.0000 - val_loss: 0.1885 - val_accuracy: 0.9804\n",
            "Epoch 198/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1953e-08 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9804\n",
            "Epoch 199/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1757e-08 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 0.9805\n",
            "Epoch 200/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1619e-08 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9805\n",
            "Epoch 201/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1508e-08 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 0.9804\n",
            "Epoch 202/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1306e-08 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.9804\n",
            "Epoch 203/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1129e-08 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9803\n",
            "Epoch 204/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1049e-08 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9802\n",
            "Epoch 205/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0930e-08 - accuracy: 1.0000 - val_loss: 0.1892 - val_accuracy: 0.9805\n",
            "Epoch 206/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0798e-08 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9805\n",
            "Epoch 207/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0673e-08 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9805\n",
            "Epoch 208/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0525e-08 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9803\n",
            "Epoch 209/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0414e-08 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9805\n",
            "Epoch 210/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0305e-08 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9803\n",
            "Epoch 211/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0122e-08 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.9803\n",
            "Epoch 212/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0077e-08 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9803\n",
            "Epoch 213/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.9791e-09 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9803\n",
            "Epoch 214/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.8387e-09 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 0.9805\n",
            "Epoch 215/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.7381e-09 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 0.9803\n",
            "Epoch 216/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.6056e-09 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9803\n",
            "Epoch 217/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.5208e-09 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9803\n",
            "Epoch 218/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.4440e-09 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9804\n",
            "Epoch 219/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.3063e-09 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9803\n",
            "Epoch 220/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.2665e-09 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9803\n",
            "Epoch 221/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.0811e-09 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9803\n",
            "Epoch 222/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.0626e-09 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9803\n",
            "Epoch 223/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.9222e-09 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9803\n",
            "Epoch 224/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.8824e-09 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.9803\n",
            "Epoch 225/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.7182e-09 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9803\n",
            "Epoch 226/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.7288e-09 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9803\n",
            "Epoch 227/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.5831e-09 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9804\n",
            "Epoch 228/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.4480e-09 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9804\n",
            "Epoch 229/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.4665e-09 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9804\n",
            "Epoch 230/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.3817e-09 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9803\n",
            "Epoch 231/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.2546e-09 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9804\n",
            "Epoch 232/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.2069e-09 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9803\n",
            "Epoch 233/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.1248e-09 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9804\n",
            "Epoch 234/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.0797e-09 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9804\n",
            "Epoch 235/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.9817e-09 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9803\n",
            "Epoch 236/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.9711e-09 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9803\n",
            "Epoch 237/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.8281e-09 - accuracy: 1.0000 - val_loss: 0.1916 - val_accuracy: 0.9803\n",
            "Epoch 238/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.8201e-09 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9803\n",
            "Epoch 239/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7115e-09 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9803\n",
            "Epoch 240/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7142e-09 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 0.9803\n",
            "Epoch 241/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.6135e-09 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9803\n",
            "Epoch 242/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.5950e-09 - accuracy: 1.0000 - val_loss: 0.1919 - val_accuracy: 0.9802\n",
            "Epoch 243/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.4996e-09 - accuracy: 1.0000 - val_loss: 0.1920 - val_accuracy: 0.9804\n",
            "Epoch 244/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4916e-09 - accuracy: 1.0000 - val_loss: 0.1920 - val_accuracy: 0.9803\n",
            "Epoch 245/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.3565e-09 - accuracy: 1.0000 - val_loss: 0.1920 - val_accuracy: 0.9803\n",
            "Epoch 246/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.3512e-09 - accuracy: 1.0000 - val_loss: 0.1919 - val_accuracy: 0.9803\n",
            "Epoch 247/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.2612e-09 - accuracy: 1.0000 - val_loss: 0.1922 - val_accuracy: 0.9803\n",
            "Epoch 248/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.1790e-09 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9803\n",
            "Epoch 249/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.2691e-09 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9803\n",
            "Epoch 250/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0784e-09 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9803\n",
            "Epoch 251/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0466e-09 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 0.9803\n",
            "Epoch 252/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0492e-09 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9803\n",
            "Epoch 253/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.9804e-09 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 0.9803\n",
            "Epoch 254/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8718e-09 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 0.9803\n",
            "Epoch 255/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8956e-09 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9803\n",
            "Epoch 256/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8929e-09 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 0.9803\n",
            "Epoch 257/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.7737e-09 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 0.9802\n",
            "Epoch 258/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7499e-09 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9803\n",
            "Epoch 259/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.6969e-09 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9803\n",
            "Epoch 260/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7711e-09 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9803\n",
            "Epoch 261/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5512e-09 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9803\n",
            "Epoch 262/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5724e-09 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9802\n",
            "Epoch 263/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5168e-09 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9803\n",
            "Epoch 264/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.4717e-09 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9803\n",
            "Epoch 265/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5009e-09 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9803\n",
            "Epoch 266/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.4452e-09 - accuracy: 1.0000 - val_loss: 0.1932 - val_accuracy: 0.9803\n",
            "Epoch 267/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.4611e-09 - accuracy: 1.0000 - val_loss: 0.1932 - val_accuracy: 0.9803\n",
            "Epoch 268/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3976e-09 - accuracy: 1.0000 - val_loss: 0.1932 - val_accuracy: 0.9803\n",
            "Epoch 269/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2890e-09 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9803\n",
            "Epoch 270/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3207e-09 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9803\n",
            "Epoch 271/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2625e-09 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9803\n",
            "Epoch 272/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2174e-09 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9803\n",
            "Epoch 273/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2757e-09 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9801\n",
            "Epoch 274/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1724e-09 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9803\n",
            "Epoch 275/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1724e-09 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 0.9802\n",
            "Epoch 276/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1565e-09 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9801\n",
            "Epoch 277/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1538e-09 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9802\n",
            "Epoch 278/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1062e-09 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9801\n",
            "Epoch 279/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0532e-09 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 0.9802\n",
            "Epoch 280/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0293e-09 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 0.9802\n",
            "Epoch 281/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0717e-09 - accuracy: 1.0000 - val_loss: 0.1940 - val_accuracy: 0.9802\n",
            "Epoch 282/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9949e-09 - accuracy: 1.0000 - val_loss: 0.1939 - val_accuracy: 0.9802\n",
            "Epoch 283/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9684e-09 - accuracy: 1.0000 - val_loss: 0.1940 - val_accuracy: 0.9802\n",
            "Epoch 284/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9658e-09 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9803\n",
            "Epoch 285/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8969e-09 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9801\n",
            "Epoch 286/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9313e-09 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9802\n",
            "Epoch 287/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8386e-09 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9801\n",
            "Epoch 288/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8969e-09 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 0.9802\n",
            "Epoch 289/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8571e-09 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 0.9801\n",
            "Epoch 290/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8439e-09 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9801\n",
            "Epoch 291/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8519e-09 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9801\n",
            "Epoch 292/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7538e-09 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9801\n",
            "Epoch 293/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7724e-09 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9801\n",
            "Epoch 294/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7538e-09 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9801\n",
            "Epoch 295/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7485e-09 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9801\n",
            "Epoch 296/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7512e-09 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9801\n",
            "Epoch 297/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7220e-09 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9801\n",
            "Epoch 298/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6399e-09 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9801\n",
            "Epoch 299/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6108e-09 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 0.9800\n",
            "Epoch 300/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6320e-09 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9801\n",
            "Epoch 301/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6426e-09 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.9801\n",
            "Epoch 302/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6505e-09 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9801\n",
            "Epoch 303/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6293e-09 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9801\n",
            "Epoch 304/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6028e-09 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9801\n",
            "Epoch 305/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5816e-09 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 0.9801\n",
            "Epoch 306/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5631e-09 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9801\n",
            "Epoch 307/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5472e-09 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9801\n",
            "Epoch 308/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5048e-09 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9801\n",
            "Epoch 309/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5419e-09 - accuracy: 1.0000 - val_loss: 0.1954 - val_accuracy: 0.9801\n",
            "Epoch 310/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4995e-09 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9801\n",
            "Epoch 311/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4651e-09 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.9801\n",
            "Epoch 312/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5313e-09 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9801\n",
            "Epoch 313/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4677e-09 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.9801\n",
            "Epoch 314/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4942e-09 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9801\n",
            "Epoch 315/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4174e-09 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9801\n",
            "Epoch 316/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4942e-09 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9801\n",
            "Epoch 317/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3962e-09 - accuracy: 1.0000 - val_loss: 0.1958 - val_accuracy: 0.9801\n",
            "Epoch 318/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3538e-09 - accuracy: 1.0000 - val_loss: 0.1958 - val_accuracy: 0.9802\n",
            "Epoch 319/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3856e-09 - accuracy: 1.0000 - val_loss: 0.1958 - val_accuracy: 0.9802\n",
            "Epoch 320/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4095e-09 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9802\n",
            "Epoch 321/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3591e-09 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9802\n",
            "Epoch 322/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3671e-09 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 0.9802\n",
            "Epoch 323/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3644e-09 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.9802\n",
            "Epoch 324/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3167e-09 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.9801\n",
            "Epoch 325/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3061e-09 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9801\n",
            "Epoch 326/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3803e-09 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9802\n",
            "Epoch 327/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3300e-09 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9801\n",
            "Epoch 328/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2823e-09 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9801\n",
            "Epoch 329/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3353e-09 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.9801\n",
            "Epoch 330/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3300e-09 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.9802\n",
            "Epoch 331/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3061e-09 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.9801\n",
            "Epoch 332/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2664e-09 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9802\n",
            "Epoch 333/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3141e-09 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9801\n",
            "Epoch 334/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2664e-09 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.9801\n",
            "Epoch 335/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2558e-09 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9802\n",
            "Epoch 336/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2293e-09 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9801\n",
            "Epoch 337/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2532e-09 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9802\n",
            "Epoch 338/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2373e-09 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9801\n",
            "Epoch 339/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2849e-09 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 0.9800\n",
            "Epoch 340/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2055e-09 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9801\n",
            "Epoch 341/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2426e-09 - accuracy: 1.0000 - val_loss: 0.1971 - val_accuracy: 0.9800\n",
            "Epoch 342/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2611e-09 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9801\n",
            "Epoch 343/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2240e-09 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9800\n",
            "Epoch 344/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2320e-09 - accuracy: 1.0000 - val_loss: 0.1971 - val_accuracy: 0.9801\n",
            "Epoch 345/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1684e-09 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9801\n",
            "Epoch 346/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1922e-09 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9801\n",
            "Epoch 347/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1578e-09 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9801\n",
            "Epoch 348/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2028e-09 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9803\n",
            "Epoch 349/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2267e-09 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9801\n",
            "Epoch 350/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1366e-09 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9800\n",
            "Epoch 351/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2028e-09 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 0.9801\n",
            "Epoch 352/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1366e-09 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 0.9801\n",
            "Epoch 353/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2134e-09 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 0.9801\n",
            "Epoch 354/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1604e-09 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 0.9801\n",
            "Epoch 355/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2240e-09 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 0.9801\n",
            "Epoch 356/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1657e-09 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9800\n",
            "Epoch 357/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1445e-09 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 0.9801\n",
            "Epoch 358/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1048e-09 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9801\n",
            "Epoch 359/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1207e-09 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9801\n",
            "Epoch 360/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1366e-09 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9801\n",
            "Epoch 361/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0942e-09 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9801\n",
            "Epoch 362/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1286e-09 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 0.9801\n",
            "Epoch 363/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1286e-09 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 0.9801\n",
            "Epoch 364/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1048e-09 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9801\n",
            "Epoch 365/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1684e-09 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9800\n",
            "Epoch 366/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1763e-09 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.9801\n",
            "Epoch 367/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1366e-09 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.9801\n",
            "Epoch 368/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2028e-09 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9800\n",
            "Epoch 369/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1313e-09 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 0.9801\n",
            "Epoch 370/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1313e-09 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.9801\n",
            "Epoch 371/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0651e-09 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9801\n",
            "Epoch 372/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1816e-09 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9801\n",
            "Epoch 373/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1419e-09 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9801\n",
            "Epoch 374/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1313e-09 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9801\n",
            "Epoch 375/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1128e-09 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.9801\n",
            "Epoch 376/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0704e-09 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.9801\n",
            "Epoch 377/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0995e-09 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9800\n",
            "Epoch 378/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1631e-09 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.9801\n",
            "Epoch 379/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0969e-09 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 0.9801\n",
            "Epoch 380/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1128e-09 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9801\n",
            "Epoch 381/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0995e-09 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9801\n",
            "Epoch 382/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0942e-09 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9801\n",
            "Epoch 383/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0704e-09 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9801\n",
            "Epoch 384/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0810e-09 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9801\n",
            "Epoch 385/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0757e-09 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9801\n",
            "Epoch 386/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1631e-09 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.9801\n",
            "Epoch 387/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1710e-09 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9801\n",
            "Epoch 388/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1260e-09 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9801\n",
            "Epoch 389/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1154e-09 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.9800\n",
            "Epoch 390/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0704e-09 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9801\n",
            "Epoch 391/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1419e-09 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9800\n",
            "Epoch 392/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0995e-09 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9800\n",
            "Epoch 393/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1472e-09 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9800\n",
            "Epoch 394/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1048e-09 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9801\n",
            "Epoch 395/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1525e-09 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9800\n",
            "Epoch 396/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1525e-09 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.9799\n",
            "Epoch 397/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1260e-09 - accuracy: 1.0000 - val_loss: 0.1996 - val_accuracy: 0.9801\n",
            "Epoch 398/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0969e-09 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9799\n",
            "Epoch 399/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1604e-09 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9800\n",
            "Epoch 400/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1154e-09 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9799\n",
            "Epoch 401/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0810e-09 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9800\n",
            "Epoch 402/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1022e-09 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9800\n",
            "Epoch 403/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1763e-09 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9799\n",
            "Epoch 404/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1631e-09 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9799\n",
            "Epoch 405/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1260e-09 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9799\n",
            "Epoch 406/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1551e-09 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9801\n",
            "Epoch 407/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1551e-09 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9800\n",
            "Epoch 408/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0545e-09 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9799\n",
            "Epoch 409/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0995e-09 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9799\n",
            "Epoch 410/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1313e-09 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9799\n",
            "Epoch 411/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1604e-09 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9799\n",
            "Epoch 412/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1869e-09 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9799\n",
            "Epoch 413/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1525e-09 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9799\n",
            "Epoch 414/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1578e-09 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9799\n",
            "Epoch 415/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1604e-09 - accuracy: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.9798\n",
            "Epoch 416/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1498e-09 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9799\n",
            "Epoch 417/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1207e-09 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9798\n",
            "Epoch 418/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1472e-09 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9798\n",
            "Epoch 419/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0889e-09 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9798\n",
            "Epoch 420/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1234e-09 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9799\n",
            "Epoch 421/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1154e-09 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9798\n",
            "Epoch 422/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1286e-09 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9799\n",
            "Epoch 423/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1339e-09 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9798\n",
            "Epoch 424/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1790e-09 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9799\n",
            "Epoch 425/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1022e-09 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9797\n",
            "Epoch 426/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1525e-09 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9799\n",
            "Epoch 427/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1286e-09 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9797\n",
            "Epoch 428/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1551e-09 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9798\n",
            "Epoch 429/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0995e-09 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9797\n",
            "Epoch 430/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1631e-09 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9797\n",
            "Epoch 431/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1392e-09 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9797\n",
            "Epoch 432/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1578e-09 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9797\n",
            "Epoch 433/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1181e-09 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9797\n",
            "Epoch 434/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1472e-09 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9797\n",
            "Epoch 435/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1763e-09 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9798\n",
            "Epoch 436/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1339e-09 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9795\n",
            "Epoch 437/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2028e-09 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9796\n",
            "Epoch 438/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2055e-09 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9797\n",
            "Epoch 439/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1657e-09 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9797\n",
            "Epoch 440/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1657e-09 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9797\n",
            "Epoch 441/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2426e-09 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9796\n",
            "Epoch 442/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1684e-09 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9797\n",
            "Epoch 443/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2108e-09 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9797\n",
            "Epoch 444/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1551e-09 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9797\n",
            "Epoch 445/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1869e-09 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9796\n",
            "Epoch 446/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1763e-09 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9797\n",
            "Epoch 447/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1869e-09 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9797\n",
            "Epoch 448/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1816e-09 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9796\n",
            "Epoch 449/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1657e-09 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.9795\n",
            "Epoch 450/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1763e-09 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9795\n",
            "Epoch 451/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2214e-09 - accuracy: 1.0000 - val_loss: 0.2025 - val_accuracy: 0.9795\n",
            "Epoch 452/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2108e-09 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9795\n",
            "Epoch 453/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1790e-09 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9795\n",
            "Epoch 454/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2505e-09 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.9795\n",
            "Epoch 455/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1869e-09 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9796\n",
            "Epoch 456/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2055e-09 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9795\n",
            "Epoch 457/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1843e-09 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 0.9795\n",
            "Epoch 458/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2849e-09 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.9795\n",
            "Epoch 459/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1684e-09 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9795\n",
            "Epoch 460/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2055e-09 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9794\n",
            "Epoch 461/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2240e-09 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 0.9795\n",
            "Epoch 462/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2028e-09 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 0.9795\n",
            "Epoch 463/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2399e-09 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9795\n",
            "Epoch 464/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1896e-09 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9794\n",
            "Epoch 465/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2002e-09 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9794\n",
            "Epoch 466/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2426e-09 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9794\n",
            "Epoch 467/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1975e-09 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9793\n",
            "Epoch 468/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2267e-09 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9794\n",
            "Epoch 469/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2320e-09 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9793\n",
            "Epoch 470/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1949e-09 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9794\n",
            "Epoch 471/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2134e-09 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9795\n",
            "Epoch 472/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2691e-09 - accuracy: 1.0000 - val_loss: 0.2038 - val_accuracy: 0.9794\n",
            "Epoch 473/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1737e-09 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9793\n",
            "Epoch 474/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2214e-09 - accuracy: 1.0000 - val_loss: 0.2038 - val_accuracy: 0.9795\n",
            "Epoch 475/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2955e-09 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 0.9793\n",
            "Epoch 476/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2240e-09 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9793\n",
            "Epoch 477/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2373e-09 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9793\n",
            "Epoch 478/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2585e-09 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9793\n",
            "Epoch 479/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2849e-09 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9793\n",
            "Epoch 480/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2955e-09 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9793\n",
            "Epoch 481/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2426e-09 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9793\n",
            "Epoch 482/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2717e-09 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9793\n",
            "Epoch 483/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3088e-09 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 0.9793\n",
            "Epoch 484/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1763e-09 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9794\n",
            "Epoch 485/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2638e-09 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9794\n",
            "Epoch 486/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2902e-09 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9794\n",
            "Epoch 487/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2664e-09 - accuracy: 1.0000 - val_loss: 0.2046 - val_accuracy: 0.9793\n",
            "Epoch 488/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2743e-09 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 0.9793\n",
            "Epoch 489/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2770e-09 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 0.9792\n",
            "Epoch 490/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3061e-09 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9793\n",
            "Epoch 491/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2743e-09 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.9793\n",
            "Epoch 492/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1922e-09 - accuracy: 1.0000 - val_loss: 0.2046 - val_accuracy: 0.9793\n",
            "Epoch 493/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2585e-09 - accuracy: 1.0000 - val_loss: 0.2046 - val_accuracy: 0.9792\n",
            "Epoch 494/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3432e-09 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.9791\n",
            "Epoch 495/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2929e-09 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.9793\n",
            "Epoch 496/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3088e-09 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 0.9791\n",
            "Epoch 497/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2479e-09 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 0.9792\n",
            "Epoch 498/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2823e-09 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 0.9792\n",
            "Epoch 499/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2743e-09 - accuracy: 1.0000 - val_loss: 0.2052 - val_accuracy: 0.9793\n",
            "Epoch 500/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3141e-09 - accuracy: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.9793\n",
            "Epoch 501/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3830e-09 - accuracy: 1.0000 - val_loss: 0.2051 - val_accuracy: 0.9792\n",
            "Epoch 502/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3035e-09 - accuracy: 1.0000 - val_loss: 0.2052 - val_accuracy: 0.9792\n",
            "Epoch 503/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2532e-09 - accuracy: 1.0000 - val_loss: 0.2053 - val_accuracy: 0.9792\n",
            "Epoch 504/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3061e-09 - accuracy: 1.0000 - val_loss: 0.2054 - val_accuracy: 0.9792\n",
            "Epoch 505/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3353e-09 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 0.9791\n",
            "Epoch 506/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3485e-09 - accuracy: 1.0000 - val_loss: 0.2054 - val_accuracy: 0.9793\n",
            "Epoch 507/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3300e-09 - accuracy: 1.0000 - val_loss: 0.2053 - val_accuracy: 0.9791\n",
            "Epoch 508/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2638e-09 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 0.9791\n",
            "Epoch 509/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2982e-09 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9792\n",
            "Epoch 510/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2320e-09 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9791\n",
            "Epoch 511/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3909e-09 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.9791\n",
            "Epoch 512/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3936e-09 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9791\n",
            "Epoch 513/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3326e-09 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.9791\n",
            "Epoch 514/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3273e-09 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9790\n",
            "Epoch 515/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3909e-09 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.9792\n",
            "Epoch 516/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3671e-09 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9792\n",
            "Epoch 517/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2770e-09 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9791\n",
            "Epoch 518/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3459e-09 - accuracy: 1.0000 - val_loss: 0.2060 - val_accuracy: 0.9791\n",
            "Epoch 519/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3777e-09 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9791\n",
            "Epoch 520/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3512e-09 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9792\n",
            "Epoch 521/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3326e-09 - accuracy: 1.0000 - val_loss: 0.2060 - val_accuracy: 0.9791\n",
            "Epoch 522/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3194e-09 - accuracy: 1.0000 - val_loss: 0.2062 - val_accuracy: 0.9791\n",
            "Epoch 523/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3512e-09 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9791\n",
            "Epoch 524/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3220e-09 - accuracy: 1.0000 - val_loss: 0.2062 - val_accuracy: 0.9791\n",
            "Epoch 525/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3379e-09 - accuracy: 1.0000 - val_loss: 0.2064 - val_accuracy: 0.9791\n",
            "Epoch 526/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4704e-09 - accuracy: 1.0000 - val_loss: 0.2065 - val_accuracy: 0.9791\n",
            "Epoch 527/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3220e-09 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9789\n",
            "Epoch 528/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4095e-09 - accuracy: 1.0000 - val_loss: 0.2066 - val_accuracy: 0.9792\n",
            "Epoch 529/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4439e-09 - accuracy: 1.0000 - val_loss: 0.2064 - val_accuracy: 0.9790\n",
            "Epoch 530/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3909e-09 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9791\n",
            "Epoch 531/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3300e-09 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9790\n",
            "Epoch 532/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4068e-09 - accuracy: 1.0000 - val_loss: 0.2066 - val_accuracy: 0.9791\n",
            "Epoch 533/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3777e-09 - accuracy: 1.0000 - val_loss: 0.2066 - val_accuracy: 0.9790\n",
            "Epoch 534/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3856e-09 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9791\n",
            "Epoch 535/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4148e-09 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9791\n",
            "Epoch 536/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3406e-09 - accuracy: 1.0000 - val_loss: 0.2070 - val_accuracy: 0.9791\n",
            "Epoch 537/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4598e-09 - accuracy: 1.0000 - val_loss: 0.2070 - val_accuracy: 0.9791\n",
            "Epoch 538/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3909e-09 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 0.9791\n",
            "Epoch 539/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4704e-09 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9790\n",
            "Epoch 540/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3724e-09 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9789\n",
            "Epoch 541/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5154e-09 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9790\n",
            "Epoch 542/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3989e-09 - accuracy: 1.0000 - val_loss: 0.2073 - val_accuracy: 0.9790\n",
            "Epoch 543/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4412e-09 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 0.9789\n",
            "Epoch 544/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4200e-09 - accuracy: 1.0000 - val_loss: 0.2073 - val_accuracy: 0.9791\n",
            "Epoch 545/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4253e-09 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9791\n",
            "Epoch 546/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4704e-09 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9791\n",
            "Epoch 547/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3803e-09 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 0.9790\n",
            "Epoch 548/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5101e-09 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9791\n",
            "Epoch 549/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3803e-09 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.9789\n",
            "Epoch 550/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4518e-09 - accuracy: 1.0000 - val_loss: 0.2077 - val_accuracy: 0.9789\n",
            "Epoch 551/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4439e-09 - accuracy: 1.0000 - val_loss: 0.2077 - val_accuracy: 0.9791\n",
            "Epoch 552/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4386e-09 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.9789\n",
            "Epoch 553/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4306e-09 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.9789\n",
            "Epoch 554/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4916e-09 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9790\n",
            "Epoch 555/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5048e-09 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.9789\n",
            "Epoch 556/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4439e-09 - accuracy: 1.0000 - val_loss: 0.2078 - val_accuracy: 0.9789\n",
            "Epoch 557/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4492e-09 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9789\n",
            "Epoch 558/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4942e-09 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9789\n",
            "Epoch 559/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4810e-09 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9790\n",
            "Epoch 560/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4969e-09 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9789\n",
            "Epoch 561/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5260e-09 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9790\n",
            "Epoch 562/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4969e-09 - accuracy: 1.0000 - val_loss: 0.2082 - val_accuracy: 0.9789\n",
            "Epoch 563/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4386e-09 - accuracy: 1.0000 - val_loss: 0.2082 - val_accuracy: 0.9789\n",
            "Epoch 564/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4995e-09 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9789\n",
            "Epoch 565/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5101e-09 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9789\n",
            "Epoch 566/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5128e-09 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.9789\n",
            "Epoch 567/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5075e-09 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9789\n",
            "Epoch 568/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5525e-09 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9789\n",
            "Epoch 569/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4863e-09 - accuracy: 1.0000 - val_loss: 0.2087 - val_accuracy: 0.9789\n",
            "Epoch 570/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5048e-09 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9789\n",
            "Epoch 571/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5260e-09 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9789\n",
            "Epoch 572/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4757e-09 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.9789\n",
            "Epoch 573/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5552e-09 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9789\n",
            "Epoch 574/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4280e-09 - accuracy: 1.0000 - val_loss: 0.2089 - val_accuracy: 0.9789\n",
            "Epoch 575/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5790e-09 - accuracy: 1.0000 - val_loss: 0.2089 - val_accuracy: 0.9789\n",
            "Epoch 576/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5446e-09 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9788\n",
            "Epoch 577/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5128e-09 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.9789\n",
            "Epoch 578/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5737e-09 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9789\n",
            "Epoch 579/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5816e-09 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9789\n",
            "Epoch 580/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5790e-09 - accuracy: 1.0000 - val_loss: 0.2089 - val_accuracy: 0.9789\n",
            "Epoch 581/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5605e-09 - accuracy: 1.0000 - val_loss: 0.2089 - val_accuracy: 0.9788\n",
            "Epoch 582/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6055e-09 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9789\n",
            "Epoch 583/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5419e-09 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9789\n",
            "Epoch 584/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5896e-09 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9789\n",
            "Epoch 585/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5684e-09 - accuracy: 1.0000 - val_loss: 0.2093 - val_accuracy: 0.9788\n",
            "Epoch 586/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5816e-09 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.9789\n",
            "Epoch 587/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6346e-09 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9789\n",
            "Epoch 588/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5525e-09 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.9789\n",
            "Epoch 589/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6055e-09 - accuracy: 1.0000 - val_loss: 0.2093 - val_accuracy: 0.9789\n",
            "Epoch 590/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5816e-09 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9788\n",
            "Epoch 591/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5737e-09 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9789\n",
            "Epoch 592/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5922e-09 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9788\n",
            "Epoch 593/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5737e-09 - accuracy: 1.0000 - val_loss: 0.2097 - val_accuracy: 0.9789\n",
            "Epoch 594/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5843e-09 - accuracy: 1.0000 - val_loss: 0.2097 - val_accuracy: 0.9788\n",
            "Epoch 595/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5922e-09 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9787\n",
            "Epoch 596/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6214e-09 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9788\n",
            "Epoch 597/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4677e-09 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9786\n",
            "Epoch 598/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5896e-09 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9789\n",
            "Epoch 599/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5366e-09 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9789\n",
            "Epoch 600/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5896e-09 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.9788\n",
            "Epoch 601/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5684e-09 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9789\n",
            "Epoch 602/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5631e-09 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9788\n",
            "Epoch 603/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6346e-09 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9787\n",
            "Epoch 604/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6081e-09 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.9787\n",
            "Epoch 605/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5975e-09 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9788\n",
            "Epoch 606/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5446e-09 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9788\n",
            "Epoch 607/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5657e-09 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 0.9787\n",
            "Epoch 608/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5710e-09 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 0.9787\n",
            "Epoch 609/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.6585e-09 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9788\n",
            "Epoch 610/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5657e-09 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 0.9787\n",
            "Epoch 611/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5922e-09 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.9789\n",
            "Epoch 612/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5816e-09 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 0.9788\n",
            "Epoch 613/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6055e-09 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9786\n",
            "Epoch 614/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6691e-09 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9787\n",
            "Epoch 615/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6108e-09 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 0.9788\n",
            "Epoch 616/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6214e-09 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 0.9787\n",
            "Epoch 617/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6479e-09 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9785\n",
            "Epoch 618/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6426e-09 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 0.9788\n",
            "Epoch 619/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6187e-09 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9786\n",
            "Epoch 620/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5472e-09 - accuracy: 1.0000 - val_loss: 0.2106 - val_accuracy: 0.9787\n",
            "Epoch 621/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6081e-09 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9786\n",
            "Epoch 622/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5949e-09 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9787\n",
            "Epoch 623/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6399e-09 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9785\n",
            "Epoch 624/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6214e-09 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9786\n",
            "Epoch 625/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6187e-09 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9787\n",
            "Epoch 626/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6399e-09 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9788\n",
            "Epoch 627/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6664e-09 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9787\n",
            "Epoch 628/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6161e-09 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9788\n",
            "Epoch 629/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6240e-09 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9787\n",
            "Epoch 630/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6479e-09 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9787\n",
            "Epoch 631/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6320e-09 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9787\n",
            "Epoch 632/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6850e-09 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9787\n",
            "Epoch 633/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6505e-09 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9784\n",
            "Epoch 634/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6532e-09 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9787\n",
            "Epoch 635/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5763e-09 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9786\n",
            "Epoch 636/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6823e-09 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9787\n",
            "Epoch 637/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7141e-09 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9787\n",
            "Epoch 638/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7194e-09 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9786\n",
            "Epoch 639/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6744e-09 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9785\n",
            "Epoch 640/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5843e-09 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9784\n",
            "Epoch 641/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7035e-09 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9786\n",
            "Epoch 642/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7379e-09 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9786\n",
            "Epoch 643/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6797e-09 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9785\n",
            "Epoch 644/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6876e-09 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9785\n",
            "Epoch 645/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7167e-09 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9786\n",
            "Epoch 646/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7062e-09 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9784\n",
            "Epoch 647/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7194e-09 - accuracy: 1.0000 - val_loss: 0.2117 - val_accuracy: 0.9785\n",
            "Epoch 648/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6558e-09 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9783\n",
            "Epoch 649/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6585e-09 - accuracy: 1.0000 - val_loss: 0.2119 - val_accuracy: 0.9783\n",
            "Epoch 650/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6770e-09 - accuracy: 1.0000 - val_loss: 0.2119 - val_accuracy: 0.9785\n",
            "Epoch 651/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7009e-09 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9782\n",
            "Epoch 652/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7459e-09 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9783\n",
            "Epoch 653/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6956e-09 - accuracy: 1.0000 - val_loss: 0.2117 - val_accuracy: 0.9784\n",
            "Epoch 654/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7724e-09 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9784\n",
            "Epoch 655/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7035e-09 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9782\n",
            "Epoch 656/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6691e-09 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9783\n",
            "Epoch 657/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7194e-09 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9784\n",
            "Epoch 658/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7406e-09 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9783\n",
            "Epoch 659/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7750e-09 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9782\n",
            "Epoch 660/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7009e-09 - accuracy: 1.0000 - val_loss: 0.2126 - val_accuracy: 0.9782\n",
            "Epoch 661/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7273e-09 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 0.9782\n",
            "Epoch 662/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7247e-09 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 0.9783\n",
            "Epoch 663/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7565e-09 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9783\n",
            "Epoch 664/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6876e-09 - accuracy: 1.0000 - val_loss: 0.2125 - val_accuracy: 0.9783\n",
            "Epoch 665/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8174e-09 - accuracy: 1.0000 - val_loss: 0.2126 - val_accuracy: 0.9783\n",
            "Epoch 666/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7326e-09 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 0.9784\n",
            "Epoch 667/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7088e-09 - accuracy: 1.0000 - val_loss: 0.2125 - val_accuracy: 0.9783\n",
            "Epoch 668/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7247e-09 - accuracy: 1.0000 - val_loss: 0.2126 - val_accuracy: 0.9783\n",
            "Epoch 669/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7432e-09 - accuracy: 1.0000 - val_loss: 0.2125 - val_accuracy: 0.9782\n",
            "Epoch 670/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7062e-09 - accuracy: 1.0000 - val_loss: 0.2126 - val_accuracy: 0.9784\n",
            "Epoch 671/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7724e-09 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 0.9784\n",
            "Epoch 672/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7936e-09 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 0.9784\n",
            "Epoch 673/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6214e-09 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9784\n",
            "Epoch 674/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7618e-09 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9782\n",
            "Epoch 675/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7830e-09 - accuracy: 1.0000 - val_loss: 0.2131 - val_accuracy: 0.9783\n",
            "Epoch 676/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7459e-09 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9783\n",
            "Epoch 677/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7777e-09 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 0.9783\n",
            "Epoch 678/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7538e-09 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9783\n",
            "Epoch 679/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7697e-09 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 0.9783\n",
            "Epoch 680/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7247e-09 - accuracy: 1.0000 - val_loss: 0.2128 - val_accuracy: 0.9783\n",
            "Epoch 681/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8307e-09 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9783\n",
            "Epoch 682/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7035e-09 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 0.9784\n",
            "Epoch 683/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7220e-09 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9783\n",
            "Epoch 684/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8121e-09 - accuracy: 1.0000 - val_loss: 0.2128 - val_accuracy: 0.9783\n",
            "Epoch 685/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7856e-09 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9783\n",
            "Epoch 686/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7379e-09 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 0.9783\n",
            "Epoch 687/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7750e-09 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9782\n",
            "Epoch 688/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6876e-09 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9781\n",
            "Epoch 689/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8360e-09 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.9783\n",
            "Epoch 690/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7485e-09 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9782\n",
            "Epoch 691/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7777e-09 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.9784\n",
            "Epoch 692/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7883e-09 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9782\n",
            "Epoch 693/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8545e-09 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9782\n",
            "Epoch 694/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8466e-09 - accuracy: 1.0000 - val_loss: 0.2133 - val_accuracy: 0.9781\n",
            "Epoch 695/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8360e-09 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9783\n",
            "Epoch 696/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8386e-09 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9781\n",
            "Epoch 697/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7167e-09 - accuracy: 1.0000 - val_loss: 0.2136 - val_accuracy: 0.9783\n",
            "Epoch 698/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7644e-09 - accuracy: 1.0000 - val_loss: 0.2133 - val_accuracy: 0.9785\n",
            "Epoch 699/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8386e-09 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9781\n",
            "Epoch 700/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8121e-09 - accuracy: 1.0000 - val_loss: 0.2138 - val_accuracy: 0.9781\n",
            "Epoch 701/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8624e-09 - accuracy: 1.0000 - val_loss: 0.2136 - val_accuracy: 0.9783\n",
            "Epoch 702/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7936e-09 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9782\n",
            "Epoch 703/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8677e-09 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.9782\n",
            "Epoch 704/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7989e-09 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9783\n",
            "Epoch 705/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8068e-09 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9781\n",
            "Epoch 706/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8492e-09 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9783\n",
            "Epoch 707/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7830e-09 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9781\n",
            "Epoch 708/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8598e-09 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9782\n",
            "Epoch 709/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8068e-09 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9781\n",
            "Epoch 710/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9340e-09 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9783\n",
            "Epoch 711/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8545e-09 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9781\n",
            "Epoch 712/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8519e-09 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9783\n",
            "Epoch 713/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8571e-09 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9781\n",
            "Epoch 714/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8068e-09 - accuracy: 1.0000 - val_loss: 0.2146 - val_accuracy: 0.9781\n",
            "Epoch 715/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8624e-09 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9780\n",
            "Epoch 716/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8492e-09 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9782\n",
            "Epoch 717/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8201e-09 - accuracy: 1.0000 - val_loss: 0.2138 - val_accuracy: 0.9782\n",
            "Epoch 718/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8201e-09 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9781\n",
            "Epoch 719/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8333e-09 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9783\n",
            "Epoch 720/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9154e-09 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.9782\n",
            "Epoch 721/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8545e-09 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9781\n",
            "Epoch 722/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9128e-09 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.9781\n",
            "Epoch 723/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8545e-09 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.9781\n",
            "Epoch 724/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8466e-09 - accuracy: 1.0000 - val_loss: 0.2148 - val_accuracy: 0.9781\n",
            "Epoch 725/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8174e-09 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9782\n",
            "Epoch 726/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8439e-09 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9781\n",
            "Epoch 727/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9260e-09 - accuracy: 1.0000 - val_loss: 0.2146 - val_accuracy: 0.9782\n",
            "Epoch 728/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8571e-09 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.9782\n",
            "Epoch 729/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8413e-09 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.9781\n",
            "Epoch 730/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8598e-09 - accuracy: 1.0000 - val_loss: 0.2146 - val_accuracy: 0.9782\n",
            "Epoch 731/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9181e-09 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9782\n",
            "Epoch 732/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9154e-09 - accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 0.9779\n",
            "Epoch 733/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9366e-09 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.9782\n",
            "Epoch 734/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8333e-09 - accuracy: 1.0000 - val_loss: 0.2148 - val_accuracy: 0.9781\n",
            "Epoch 735/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8889e-09 - accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 0.9784\n",
            "Epoch 736/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8651e-09 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9782\n",
            "Epoch 737/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8413e-09 - accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 0.9781\n",
            "Epoch 738/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9207e-09 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9780\n",
            "Epoch 739/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8466e-09 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9781\n",
            "Epoch 740/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8757e-09 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9780\n",
            "Epoch 741/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9075e-09 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9781\n",
            "Epoch 742/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9022e-09 - accuracy: 1.0000 - val_loss: 0.2155 - val_accuracy: 0.9781\n",
            "Epoch 743/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9923e-09 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 0.9783\n",
            "Epoch 744/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.9896e-09 - accuracy: 1.0000 - val_loss: 0.2155 - val_accuracy: 0.9779\n",
            "Epoch 745/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9472e-09 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9781\n",
            "Epoch 746/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8042e-09 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9779\n",
            "Epoch 747/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9260e-09 - accuracy: 1.0000 - val_loss: 0.2155 - val_accuracy: 0.9783\n",
            "Epoch 748/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9578e-09 - accuracy: 1.0000 - val_loss: 0.2151 - val_accuracy: 0.9781\n",
            "Epoch 749/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8783e-09 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9779\n",
            "Epoch 750/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0028e-09 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9781\n",
            "Epoch 751/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0664e-09 - accuracy: 1.0000 - val_loss: 0.2151 - val_accuracy: 0.9781\n",
            "Epoch 752/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8863e-09 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 0.9779\n",
            "Epoch 753/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9764e-09 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9781\n",
            "Epoch 754/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7936e-09 - accuracy: 1.0000 - val_loss: 0.2158 - val_accuracy: 0.9781\n",
            "Epoch 755/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9128e-09 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9781\n",
            "Epoch 756/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9128e-09 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9781\n",
            "Epoch 757/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8916e-09 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 0.9780\n",
            "Epoch 758/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0161e-09 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9779\n",
            "Epoch 759/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9631e-09 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9779\n",
            "Epoch 760/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9843e-09 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9781\n",
            "Epoch 761/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8889e-09 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 0.9779\n",
            "Epoch 762/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0558e-09 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 0.9780\n",
            "Epoch 763/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9260e-09 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 0.9781\n",
            "Epoch 764/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9048e-09 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9779\n",
            "Epoch 765/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0373e-09 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9782\n",
            "Epoch 766/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9790e-09 - accuracy: 1.0000 - val_loss: 0.2163 - val_accuracy: 0.9780\n",
            "Epoch 767/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9684e-09 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9779\n",
            "Epoch 768/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0161e-09 - accuracy: 1.0000 - val_loss: 0.2166 - val_accuracy: 0.9781\n",
            "Epoch 769/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8466e-09 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9778\n",
            "Epoch 770/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9472e-09 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9780\n",
            "Epoch 771/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9817e-09 - accuracy: 1.0000 - val_loss: 0.2163 - val_accuracy: 0.9782\n",
            "Epoch 772/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8810e-09 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9781\n",
            "Epoch 773/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9075e-09 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9782\n",
            "Epoch 774/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9631e-09 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9783\n",
            "Epoch 775/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9870e-09 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9780\n",
            "Epoch 776/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9101e-09 - accuracy: 1.0000 - val_loss: 0.2166 - val_accuracy: 0.9779\n",
            "Epoch 777/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9578e-09 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9779\n",
            "Epoch 778/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0399e-09 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9779\n",
            "Epoch 779/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9419e-09 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9780\n",
            "Epoch 780/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9499e-09 - accuracy: 1.0000 - val_loss: 0.2170 - val_accuracy: 0.9780\n",
            "Epoch 781/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9711e-09 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9780\n",
            "Epoch 782/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1433e-09 - accuracy: 1.0000 - val_loss: 0.2170 - val_accuracy: 0.9779\n",
            "Epoch 783/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9578e-09 - accuracy: 1.0000 - val_loss: 0.2173 - val_accuracy: 0.9781\n",
            "Epoch 784/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0585e-09 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9779\n",
            "Epoch 785/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0293e-09 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9780\n",
            "Epoch 786/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9790e-09 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9779\n",
            "Epoch 787/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8757e-09 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9779\n",
            "Epoch 788/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9658e-09 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9779\n",
            "Epoch 789/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9101e-09 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 0.9779\n",
            "Epoch 790/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0320e-09 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 0.9781\n",
            "Epoch 791/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9578e-09 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9780\n",
            "Epoch 792/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9393e-09 - accuracy: 1.0000 - val_loss: 0.2173 - val_accuracy: 0.9780\n",
            "Epoch 793/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9234e-09 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9779\n",
            "Epoch 794/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9790e-09 - accuracy: 1.0000 - val_loss: 0.2175 - val_accuracy: 0.9778\n",
            "Epoch 795/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9896e-09 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 0.9780\n",
            "Epoch 796/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0956e-09 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9778\n",
            "Epoch 797/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9552e-09 - accuracy: 1.0000 - val_loss: 0.2175 - val_accuracy: 0.9781\n",
            "Epoch 798/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0081e-09 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 0.9781\n",
            "Epoch 799/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9366e-09 - accuracy: 1.0000 - val_loss: 0.2179 - val_accuracy: 0.9779\n",
            "Epoch 800/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0664e-09 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9780\n",
            "Epoch 801/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9181e-09 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9780\n",
            "Epoch 802/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0532e-09 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9779\n",
            "Epoch 803/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0187e-09 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9779\n",
            "Epoch 804/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9896e-09 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9782\n",
            "Epoch 805/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9790e-09 - accuracy: 1.0000 - val_loss: 0.2173 - val_accuracy: 0.9779\n",
            "Epoch 806/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0108e-09 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9779\n",
            "Epoch 807/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9790e-09 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9779\n",
            "Epoch 808/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0532e-09 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9778\n",
            "Epoch 809/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9817e-09 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9781\n",
            "Epoch 810/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9817e-09 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9777\n",
            "Epoch 811/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9684e-09 - accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.9780\n",
            "Epoch 812/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0770e-09 - accuracy: 1.0000 - val_loss: 0.2189 - val_accuracy: 0.9777\n",
            "Epoch 813/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0797e-09 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 0.9781\n",
            "Epoch 814/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0134e-09 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9779\n",
            "Epoch 815/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9817e-09 - accuracy: 1.0000 - val_loss: 0.2189 - val_accuracy: 0.9780\n",
            "Epoch 816/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9843e-09 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9780\n",
            "Epoch 817/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9658e-09 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9779\n",
            "Epoch 818/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0823e-09 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9779\n",
            "Epoch 819/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0982e-09 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9779\n",
            "Epoch 820/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2227e-09 - accuracy: 1.0000 - val_loss: 0.2191 - val_accuracy: 0.9779\n",
            "Epoch 821/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0956e-09 - accuracy: 1.0000 - val_loss: 0.2191 - val_accuracy: 0.9779\n",
            "Epoch 822/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0876e-09 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9780\n",
            "Epoch 823/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9181e-09 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9778\n",
            "Epoch 824/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2413e-09 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9778\n",
            "Epoch 825/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0240e-09 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9777\n",
            "Epoch 826/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1115e-09 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9781\n",
            "Epoch 827/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0850e-09 - accuracy: 1.0000 - val_loss: 0.2194 - val_accuracy: 0.9780\n",
            "Epoch 828/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9843e-09 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9780\n",
            "Epoch 829/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9843e-09 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9781\n",
            "Epoch 830/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0214e-09 - accuracy: 1.0000 - val_loss: 0.2195 - val_accuracy: 0.9779\n",
            "Epoch 831/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0505e-09 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9781\n",
            "Epoch 832/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0426e-09 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9781\n",
            "Epoch 833/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1141e-09 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9781\n",
            "Epoch 834/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0611e-09 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9780\n",
            "Epoch 835/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0002e-09 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9781\n",
            "Epoch 836/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9764e-09 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9779\n",
            "Epoch 837/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2254e-09 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9780\n",
            "Epoch 838/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1353e-09 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9779\n",
            "Epoch 839/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0161e-09 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9779\n",
            "Epoch 840/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9313e-09 - accuracy: 1.0000 - val_loss: 0.2200 - val_accuracy: 0.9781\n",
            "Epoch 841/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9446e-09 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 0.9781\n",
            "Epoch 842/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2174e-09 - accuracy: 1.0000 - val_loss: 0.2209 - val_accuracy: 0.9779\n",
            "Epoch 843/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0406 - accuracy: 0.9948 - val_loss: 0.4707 - val_accuracy: 0.9630\n",
            "Epoch 844/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0458 - accuracy: 0.9919 - val_loss: 0.3089 - val_accuracy: 0.9735\n",
            "Epoch 845/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0106 - accuracy: 0.9975 - val_loss: 0.3042 - val_accuracy: 0.9728\n",
            "Epoch 846/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.2528 - val_accuracy: 0.9777\n",
            "Epoch 847/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.2471 - val_accuracy: 0.9779\n",
            "Epoch 848/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.6958e-04 - accuracy: 0.9998 - val_loss: 0.2576 - val_accuracy: 0.9773\n",
            "Epoch 849/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7325e-04 - accuracy: 0.9999 - val_loss: 0.2369 - val_accuracy: 0.9794\n",
            "Epoch 850/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5880e-04 - accuracy: 0.9999 - val_loss: 0.2454 - val_accuracy: 0.9785\n",
            "Epoch 851/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.6988e-06 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9793\n",
            "Epoch 852/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0688e-06 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9794\n",
            "Epoch 853/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6234e-06 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9793\n",
            "Epoch 854/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3600e-06 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9793\n",
            "Epoch 855/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1520e-06 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9793\n",
            "Epoch 856/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9791e-06 - accuracy: 1.0000 - val_loss: 0.2396 - val_accuracy: 0.9793\n",
            "Epoch 857/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8297e-06 - accuracy: 1.0000 - val_loss: 0.2395 - val_accuracy: 0.9793\n",
            "Epoch 858/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7005e-06 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9793\n",
            "Epoch 859/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5848e-06 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9793\n",
            "Epoch 860/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4819e-06 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9792\n",
            "Epoch 861/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3942e-06 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9793\n",
            "Epoch 862/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3070e-06 - accuracy: 1.0000 - val_loss: 0.2388 - val_accuracy: 0.9793\n",
            "Epoch 863/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2296e-06 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9793\n",
            "Epoch 864/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1588e-06 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9793\n",
            "Epoch 865/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0955e-06 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.9793\n",
            "Epoch 866/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0321e-06 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.9793\n",
            "Epoch 867/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.7887e-07 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 0.9793\n",
            "Epoch 868/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.2373e-07 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9793\n",
            "Epoch 869/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.7285e-07 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9793\n",
            "Epoch 870/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.2973e-07 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9793\n",
            "Epoch 871/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8503e-07 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9794\n",
            "Epoch 872/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4479e-07 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9794\n",
            "Epoch 873/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0527e-07 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9794\n",
            "Epoch 874/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7056e-07 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9794\n",
            "Epoch 875/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3602e-07 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9795\n",
            "Epoch 876/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0307e-07 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9795\n",
            "Epoch 877/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7382e-07 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9795\n",
            "Epoch 878/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4422e-07 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9794\n",
            "Epoch 879/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1696e-07 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9794\n",
            "Epoch 880/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.9148e-07 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9794\n",
            "Epoch 881/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.6662e-07 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9794\n",
            "Epoch 882/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.4346e-07 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9793\n",
            "Epoch 883/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.2139e-07 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9793\n",
            "Epoch 884/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.0039e-07 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9793\n",
            "Epoch 885/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.8151e-07 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9793\n",
            "Epoch 886/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6117e-07 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.9793\n",
            "Epoch 887/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.4374e-07 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9794\n",
            "Epoch 888/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.2700e-07 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9795\n",
            "Epoch 889/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1054e-07 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9793\n",
            "Epoch 890/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9461e-07 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 0.9794\n",
            "Epoch 891/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8027e-07 - accuracy: 1.0000 - val_loss: 0.2358 - val_accuracy: 0.9793\n",
            "Epoch 892/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6573e-07 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9795\n",
            "Epoch 893/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5255e-07 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9795\n",
            "Epoch 894/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3984e-07 - accuracy: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.9795\n",
            "Epoch 895/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2822e-07 - accuracy: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.9796\n",
            "Epoch 896/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1621e-07 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9796\n",
            "Epoch 897/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0537e-07 - accuracy: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.9797\n",
            "Epoch 898/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9477e-07 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9798\n",
            "Epoch 899/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8518e-07 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9797\n",
            "Epoch 900/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7537e-07 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9797\n",
            "Epoch 901/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6613e-07 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9798\n",
            "Epoch 902/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5776e-07 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9798\n",
            "Epoch 903/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4965e-07 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9797\n",
            "Epoch 904/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4188e-07 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9797\n",
            "Epoch 905/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3414e-07 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9797\n",
            "Epoch 906/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2750e-07 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9798\n",
            "Epoch 907/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2083e-07 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9798\n",
            "Epoch 908/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1433e-07 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9795\n",
            "Epoch 909/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0845e-07 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9797\n",
            "Epoch 910/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0291e-07 - accuracy: 1.0000 - val_loss: 0.2350 - val_accuracy: 0.9797\n",
            "Epoch 911/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.7394e-08 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9797\n",
            "Epoch 912/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.2281e-08 - accuracy: 1.0000 - val_loss: 0.2350 - val_accuracy: 0.9796\n",
            "Epoch 913/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.7701e-08 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9795\n",
            "Epoch 914/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.2813e-08 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9797\n",
            "Epoch 915/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8371e-08 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9796\n",
            "Epoch 916/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4431e-08 - accuracy: 1.0000 - val_loss: 0.2350 - val_accuracy: 0.9797\n",
            "Epoch 917/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0360e-08 - accuracy: 1.0000 - val_loss: 0.2350 - val_accuracy: 0.9796\n",
            "Epoch 918/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.6622e-08 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9797\n",
            "Epoch 919/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3062e-08 - accuracy: 1.0000 - val_loss: 0.2350 - val_accuracy: 0.9796\n",
            "Epoch 920/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9859e-08 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9797\n",
            "Epoch 921/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6881e-08 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9797\n",
            "Epoch 922/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3687e-08 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9797\n",
            "Epoch 923/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0849e-08 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9797\n",
            "Epoch 924/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.8190e-08 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9796\n",
            "Epoch 925/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.5567e-08 - accuracy: 1.0000 - val_loss: 0.2358 - val_accuracy: 0.9797\n",
            "Epoch 926/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.3249e-08 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9795\n",
            "Epoch 927/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.0934e-08 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 0.9797\n",
            "Epoch 928/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.8735e-08 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9795\n",
            "Epoch 929/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.7082e-08 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9796\n",
            "Epoch 930/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4767e-08 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9796\n",
            "Epoch 931/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3071e-08 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 0.9797\n",
            "Epoch 932/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1371e-08 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9796\n",
            "Epoch 933/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9627e-08 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9797\n",
            "Epoch 934/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8202e-08 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.9797\n",
            "Epoch 935/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6759e-08 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9798\n",
            "Epoch 936/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5286e-08 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9796\n",
            "Epoch 937/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4154e-08 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9796\n",
            "Epoch 938/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2862e-08 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9797\n",
            "Epoch 939/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1693e-08 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9797\n",
            "Epoch 940/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0713e-08 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9796\n",
            "Epoch 941/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9617e-08 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9797\n",
            "Epoch 942/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8732e-08 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9796\n",
            "Epoch 943/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7828e-08 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9797\n",
            "Epoch 944/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7111e-08 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.9798\n",
            "Epoch 945/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6263e-08 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9797\n",
            "Epoch 946/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5540e-08 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9797\n",
            "Epoch 947/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4830e-08 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9795\n",
            "Epoch 948/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4144e-08 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9795\n",
            "Epoch 949/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3603e-08 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9795\n",
            "Epoch 950/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2946e-08 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9797\n",
            "Epoch 951/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2464e-08 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9797\n",
            "Epoch 952/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1953e-08 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9795\n",
            "Epoch 953/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1391e-08 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9796\n",
            "Epoch 954/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0970e-08 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9797\n",
            "Epoch 955/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0535e-08 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9795\n",
            "Epoch 956/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0151e-08 - accuracy: 1.0000 - val_loss: 0.2398 - val_accuracy: 0.9795\n",
            "Epoch 957/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.7884e-09 - accuracy: 1.0000 - val_loss: 0.2398 - val_accuracy: 0.9795\n",
            "Epoch 958/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.3778e-09 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9795\n",
            "Epoch 959/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.0996e-09 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9795\n",
            "Epoch 960/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.7685e-09 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9796\n",
            "Epoch 961/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.5592e-09 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 0.9795\n",
            "Epoch 962/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.1380e-09 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9796\n",
            "Epoch 963/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.9234e-09 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9795\n",
            "Epoch 964/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.6850e-09 - accuracy: 1.0000 - val_loss: 0.2406 - val_accuracy: 0.9796\n",
            "Epoch 965/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4440e-09 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9795\n",
            "Epoch 966/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.1128e-09 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9795\n",
            "Epoch 967/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.9857e-09 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9793\n",
            "Epoch 968/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7949e-09 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9794\n",
            "Epoch 969/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5247e-09 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9794\n",
            "Epoch 970/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3419e-09 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9793\n",
            "Epoch 971/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2333e-09 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9793\n",
            "Epoch 972/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0161e-09 - accuracy: 1.0000 - val_loss: 0.2421 - val_accuracy: 0.9791\n",
            "Epoch 973/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8492e-09 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9793\n",
            "Epoch 974/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7247e-09 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9793\n",
            "Epoch 975/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5843e-09 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9792\n",
            "Epoch 976/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4836e-09 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9794\n",
            "Epoch 977/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3565e-09 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9793\n",
            "Epoch 978/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2187e-09 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.9794\n",
            "Epoch 979/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1154e-09 - accuracy: 1.0000 - val_loss: 0.2429 - val_accuracy: 0.9791\n",
            "Epoch 980/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.9882e-09 - accuracy: 1.0000 - val_loss: 0.2429 - val_accuracy: 0.9793\n",
            "Epoch 981/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.8134e-09 - accuracy: 1.0000 - val_loss: 0.2428 - val_accuracy: 0.9793\n",
            "Epoch 982/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.7445e-09 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9791\n",
            "Epoch 983/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.6995e-09 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9792\n",
            "Epoch 984/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.6280e-09 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9792\n",
            "Epoch 985/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5088e-09 - accuracy: 1.0000 - val_loss: 0.2437 - val_accuracy: 0.9791\n",
            "Epoch 986/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.3790e-09 - accuracy: 1.0000 - val_loss: 0.2441 - val_accuracy: 0.9789\n",
            "Epoch 987/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.3286e-09 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9791\n",
            "Epoch 988/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.2862e-09 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9795\n",
            "Epoch 989/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.1352e-09 - accuracy: 1.0000 - val_loss: 0.2443 - val_accuracy: 0.9788\n",
            "Epoch 990/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.0028e-09 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9789\n",
            "Epoch 991/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9948e-09 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9789\n",
            "Epoch 992/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9789e-09 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.9791\n",
            "Epoch 993/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9286e-09 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9791\n",
            "Epoch 994/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.8571e-09 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9791\n",
            "Epoch 995/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.7220e-09 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9790\n",
            "Epoch 996/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6796e-09 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.9789\n",
            "Epoch 997/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6240e-09 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9789\n",
            "Epoch 998/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.5736e-09 - accuracy: 1.0000 - val_loss: 0.2452 - val_accuracy: 0.9787\n",
            "Epoch 999/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.5365e-09 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9791\n",
            "Epoch 1000/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.4995e-09 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9789\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0614 - accuracy: 0.9947\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1914 - accuracy: 0.9814\n",
            "train accuracy :  0.9947333335876465 train loss :  0.06144125014543533\n",
            "test accuracy :  0.9814000129699707  test loss :  0.19138523936271667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdS1IgY3gEkQ"
      },
      "source": [
        "# 은닉층 2개(512/512) & epochs = 120 / 500 / 1000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pnjTow5yfwt2",
        "outputId": "831c87f3-44a4-4e61-dd08-a3e8d3db09aa"
      },
      "source": [
        "#신경망 학습2_1_2\n",
        "model2_1_2 = models.Sequential([\n",
        "                               Flatten(input_shape = (28, 28)),\n",
        "                               Dense(512, activation= 'relu'),\n",
        "                               Dense(512, activation= 'relu'),\n",
        "                               Dense(10, activation= 'softmax')\n",
        "                               ])\n",
        "\n",
        "model2_1_2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "hist2_1_2 = model2_1_2.fit(train_x, train_y, epochs = 120, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "#학습 그래프4\n",
        "plt.plot(hist2_1_2.history['accuracy'], 'b-')\n",
        "plt.plot(hist2_1_2.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train2_1_2 = model2_1_2.evaluate(train_x, train_y)\n",
        "sc_test2_1_2 = model2_1_2.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train2_1_2[1], \"train loss : \", sc_train2_1_2[0])\n",
        "print(\"test accuracy : \", sc_test2_1_2[1], \" test loss : \", sc_test2_1_2[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "176/176 [==============================] - 2s 7ms/step - loss: 0.2972 - accuracy: 0.9144 - val_loss: 0.1646 - val_accuracy: 0.9513\n",
            "Epoch 2/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.1050 - accuracy: 0.9685 - val_loss: 0.1087 - val_accuracy: 0.9677\n",
            "Epoch 3/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0638 - accuracy: 0.9812 - val_loss: 0.1035 - val_accuracy: 0.9678\n",
            "Epoch 4/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0410 - accuracy: 0.9875 - val_loss: 0.0903 - val_accuracy: 0.9729\n",
            "Epoch 5/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0272 - accuracy: 0.9921 - val_loss: 0.0877 - val_accuracy: 0.9747\n",
            "Epoch 6/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0208 - accuracy: 0.9934 - val_loss: 0.0895 - val_accuracy: 0.9757\n",
            "Epoch 7/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.1048 - val_accuracy: 0.9742\n",
            "Epoch 8/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.0958 - val_accuracy: 0.9762\n",
            "Epoch 9/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0074 - accuracy: 0.9980 - val_loss: 0.1120 - val_accuracy: 0.9745\n",
            "Epoch 10/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 0.1121 - val_accuracy: 0.9745\n",
            "Epoch 11/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.1088 - val_accuracy: 0.9759\n",
            "Epoch 12/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.1067 - val_accuracy: 0.9774\n",
            "Epoch 13/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0164 - accuracy: 0.9943 - val_loss: 0.1096 - val_accuracy: 0.9761\n",
            "Epoch 14/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.1111 - val_accuracy: 0.9773\n",
            "Epoch 15/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.1066 - val_accuracy: 0.9788\n",
            "Epoch 16/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.1353 - val_accuracy: 0.9747\n",
            "Epoch 17/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.1117 - val_accuracy: 0.9797\n",
            "Epoch 18/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.1271 - val_accuracy: 0.9772\n",
            "Epoch 19/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.1324 - val_accuracy: 0.9767\n",
            "Epoch 20/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.1300 - val_accuracy: 0.9759\n",
            "Epoch 21/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.1372 - val_accuracy: 0.9741\n",
            "Epoch 22/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.1214 - val_accuracy: 0.9784\n",
            "Epoch 23/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.1304 - val_accuracy: 0.9775\n",
            "Epoch 24/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.1280 - val_accuracy: 0.9789\n",
            "Epoch 25/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7544e-04 - accuracy: 0.9998 - val_loss: 0.1135 - val_accuracy: 0.9826\n",
            "Epoch 26/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1558e-04 - accuracy: 1.0000 - val_loss: 0.1156 - val_accuracy: 0.9824\n",
            "Epoch 27/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.2587e-04 - accuracy: 0.9999 - val_loss: 0.1222 - val_accuracy: 0.9823\n",
            "Epoch 28/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.1366 - val_accuracy: 0.9778\n",
            "Epoch 29/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0227 - accuracy: 0.9930 - val_loss: 0.1249 - val_accuracy: 0.9749\n",
            "Epoch 30/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.1190 - val_accuracy: 0.9775\n",
            "Epoch 31/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.1187 - val_accuracy: 0.9797\n",
            "Epoch 32/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.1177 - val_accuracy: 0.9810\n",
            "Epoch 33/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0194e-04 - accuracy: 0.9998 - val_loss: 0.1265 - val_accuracy: 0.9788\n",
            "Epoch 34/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6726e-04 - accuracy: 1.0000 - val_loss: 0.1164 - val_accuracy: 0.9812\n",
            "Epoch 35/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.4005e-05 - accuracy: 1.0000 - val_loss: 0.1177 - val_accuracy: 0.9809\n",
            "Epoch 36/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0233e-05 - accuracy: 1.0000 - val_loss: 0.1189 - val_accuracy: 0.9807\n",
            "Epoch 37/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4960e-05 - accuracy: 1.0000 - val_loss: 0.1197 - val_accuracy: 0.9810\n",
            "Epoch 38/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1308e-05 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 0.9811\n",
            "Epoch 39/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8438e-05 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 0.9809\n",
            "Epoch 40/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6166e-05 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9811\n",
            "Epoch 41/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4240e-05 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9809\n",
            "Epoch 42/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2651e-05 - accuracy: 1.0000 - val_loss: 0.1241 - val_accuracy: 0.9810\n",
            "Epoch 43/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1301e-05 - accuracy: 1.0000 - val_loss: 0.1249 - val_accuracy: 0.9811\n",
            "Epoch 44/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0134e-05 - accuracy: 1.0000 - val_loss: 0.1257 - val_accuracy: 0.9811\n",
            "Epoch 45/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.1063e-06 - accuracy: 1.0000 - val_loss: 0.1265 - val_accuracy: 0.9811\n",
            "Epoch 46/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.2332e-06 - accuracy: 1.0000 - val_loss: 0.1273 - val_accuracy: 0.9812\n",
            "Epoch 47/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4386e-06 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9812\n",
            "Epoch 48/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7506e-06 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 0.9812\n",
            "Epoch 49/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1116e-06 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9811\n",
            "Epoch 50/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5521e-06 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 0.9811\n",
            "Epoch 51/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0662e-06 - accuracy: 1.0000 - val_loss: 0.1311 - val_accuracy: 0.9812\n",
            "Epoch 52/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5947e-06 - accuracy: 1.0000 - val_loss: 0.1319 - val_accuracy: 0.9811\n",
            "Epoch 53/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.1949e-06 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 0.9812\n",
            "Epoch 54/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8175e-06 - accuracy: 1.0000 - val_loss: 0.1335 - val_accuracy: 0.9812\n",
            "Epoch 55/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.4823e-06 - accuracy: 1.0000 - val_loss: 0.1342 - val_accuracy: 0.9811\n",
            "Epoch 56/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1695e-06 - accuracy: 1.0000 - val_loss: 0.1350 - val_accuracy: 0.9811\n",
            "Epoch 57/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9002e-06 - accuracy: 1.0000 - val_loss: 0.1359 - val_accuracy: 0.9812\n",
            "Epoch 58/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6402e-06 - accuracy: 1.0000 - val_loss: 0.1366 - val_accuracy: 0.9812\n",
            "Epoch 59/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4088e-06 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.9813\n",
            "Epoch 60/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1967e-06 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9812\n",
            "Epoch 61/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0081e-06 - accuracy: 1.0000 - val_loss: 0.1390 - val_accuracy: 0.9813\n",
            "Epoch 62/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8321e-06 - accuracy: 1.0000 - val_loss: 0.1398 - val_accuracy: 0.9812\n",
            "Epoch 63/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6696e-06 - accuracy: 1.0000 - val_loss: 0.1406 - val_accuracy: 0.9812\n",
            "Epoch 64/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5255e-06 - accuracy: 1.0000 - val_loss: 0.1413 - val_accuracy: 0.9813\n",
            "Epoch 65/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3924e-06 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9813\n",
            "Epoch 66/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2701e-06 - accuracy: 1.0000 - val_loss: 0.1429 - val_accuracy: 0.9813\n",
            "Epoch 67/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1573e-06 - accuracy: 1.0000 - val_loss: 0.1437 - val_accuracy: 0.9813\n",
            "Epoch 68/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0580e-06 - accuracy: 1.0000 - val_loss: 0.1444 - val_accuracy: 0.9813\n",
            "Epoch 69/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.6434e-07 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.9814\n",
            "Epoch 70/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.8210e-07 - accuracy: 1.0000 - val_loss: 0.1461 - val_accuracy: 0.9814\n",
            "Epoch 71/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.0542e-07 - accuracy: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9814\n",
            "Epoch 72/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.3474e-07 - accuracy: 1.0000 - val_loss: 0.1480 - val_accuracy: 0.9815\n",
            "Epoch 73/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7092e-07 - accuracy: 1.0000 - val_loss: 0.1489 - val_accuracy: 0.9815\n",
            "Epoch 74/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1476e-07 - accuracy: 1.0000 - val_loss: 0.1497 - val_accuracy: 0.9815\n",
            "Epoch 75/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6211e-07 - accuracy: 1.0000 - val_loss: 0.1506 - val_accuracy: 0.9816\n",
            "Epoch 76/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1349e-07 - accuracy: 1.0000 - val_loss: 0.1515 - val_accuracy: 0.9816\n",
            "Epoch 77/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.6882e-07 - accuracy: 1.0000 - val_loss: 0.1522 - val_accuracy: 0.9815\n",
            "Epoch 78/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2892e-07 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9818\n",
            "Epoch 79/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9458e-07 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9817\n",
            "Epoch 80/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6027e-07 - accuracy: 1.0000 - val_loss: 0.1547 - val_accuracy: 0.9817\n",
            "Epoch 81/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.2904e-07 - accuracy: 1.0000 - val_loss: 0.1555 - val_accuracy: 0.9817\n",
            "Epoch 82/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0192e-07 - accuracy: 1.0000 - val_loss: 0.1563 - val_accuracy: 0.9818\n",
            "Epoch 83/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7663e-07 - accuracy: 1.0000 - val_loss: 0.1573 - val_accuracy: 0.9818\n",
            "Epoch 84/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5320e-07 - accuracy: 1.0000 - val_loss: 0.1582 - val_accuracy: 0.9817\n",
            "Epoch 85/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3138e-07 - accuracy: 1.0000 - val_loss: 0.1589 - val_accuracy: 0.9817\n",
            "Epoch 86/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1263e-07 - accuracy: 1.0000 - val_loss: 0.1598 - val_accuracy: 0.9817\n",
            "Epoch 87/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9473e-07 - accuracy: 1.0000 - val_loss: 0.1607 - val_accuracy: 0.9817\n",
            "Epoch 88/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7890e-07 - accuracy: 1.0000 - val_loss: 0.1615 - val_accuracy: 0.9817\n",
            "Epoch 89/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6344e-07 - accuracy: 1.0000 - val_loss: 0.1625 - val_accuracy: 0.9817\n",
            "Epoch 90/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5030e-07 - accuracy: 1.0000 - val_loss: 0.1634 - val_accuracy: 0.9817\n",
            "Epoch 91/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3799e-07 - accuracy: 1.0000 - val_loss: 0.1641 - val_accuracy: 0.9817\n",
            "Epoch 92/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2720e-07 - accuracy: 1.0000 - val_loss: 0.1649 - val_accuracy: 0.9816\n",
            "Epoch 93/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1655e-07 - accuracy: 1.0000 - val_loss: 0.1658 - val_accuracy: 0.9816\n",
            "Epoch 94/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0743e-07 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9817\n",
            "Epoch 95/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.8713e-08 - accuracy: 1.0000 - val_loss: 0.1676 - val_accuracy: 0.9817\n",
            "Epoch 96/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.0360e-08 - accuracy: 1.0000 - val_loss: 0.1682 - val_accuracy: 0.9817\n",
            "Epoch 97/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.3444e-08 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9817\n",
            "Epoch 98/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7163e-08 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.9817\n",
            "Epoch 99/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.0569e-08 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 0.9817\n",
            "Epoch 100/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5486e-08 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 0.9818\n",
            "Epoch 101/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0164e-08 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 0.9817\n",
            "Epoch 102/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5618e-08 - accuracy: 1.0000 - val_loss: 0.1732 - val_accuracy: 0.9817\n",
            "Epoch 103/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1157e-08 - accuracy: 1.0000 - val_loss: 0.1737 - val_accuracy: 0.9817\n",
            "Epoch 104/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.7162e-08 - accuracy: 1.0000 - val_loss: 0.1747 - val_accuracy: 0.9817\n",
            "Epoch 105/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.3752e-08 - accuracy: 1.0000 - val_loss: 0.1754 - val_accuracy: 0.9817\n",
            "Epoch 106/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0420e-08 - accuracy: 1.0000 - val_loss: 0.1761 - val_accuracy: 0.9817\n",
            "Epoch 107/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7421e-08 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9817\n",
            "Epoch 108/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.4605e-08 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 0.9817\n",
            "Epoch 109/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.2173e-08 - accuracy: 1.0000 - val_loss: 0.1783 - val_accuracy: 0.9819\n",
            "Epoch 110/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9845e-08 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.9818\n",
            "Epoch 111/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7442e-08 - accuracy: 1.0000 - val_loss: 0.1796 - val_accuracy: 0.9818\n",
            "Epoch 112/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5723e-08 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 0.9818\n",
            "Epoch 113/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3815e-08 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9818\n",
            "Epoch 114/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2213e-08 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9818\n",
            "Epoch 115/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0602e-08 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 0.9817\n",
            "Epoch 116/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9219e-08 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 0.9819\n",
            "Epoch 117/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7879e-08 - accuracy: 1.0000 - val_loss: 0.1839 - val_accuracy: 0.9819\n",
            "Epoch 118/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6628e-08 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.9819\n",
            "Epoch 119/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5418e-08 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9817\n",
            "Epoch 120/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4432e-08 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9819\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0464 - accuracy: 0.9955\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1451 - accuracy: 0.9842\n",
            "train accuracy :  0.9954833388328552 train loss :  0.04640447348356247\n",
            "test accuracy :  0.9842000007629395  test loss :  0.14507167041301727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KrkR_zWAB7zl",
        "outputId": "818bcbe1-9518-46fa-ad0d-fac20cdd9c8d"
      },
      "source": [
        "#신경망 학습2_1_3\n",
        "model2_1_3 = models.Sequential([\n",
        "                               Flatten(input_shape = (28, 28)),\n",
        "                               Dense(512, activation= 'relu'),\n",
        "                               Dense(512, activation= 'relu'),\n",
        "                               Dense(10, activation= 'softmax')\n",
        "                               ])\n",
        "\n",
        "model2_1_3.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "hist2_1_3 = model2_1_3.fit(train_x, train_y, epochs = 500, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "#학습 그래프4\n",
        "plt.plot(hist2_1_3.history['accuracy'], 'b-')\n",
        "plt.plot(hist2_1_3.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train2_1_3 = model2_1_3.evaluate(train_x, train_y)\n",
        "sc_test2_1_3 = model2_1_3.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train2_1_3[1], \"train loss : \", sc_train2_1_3[0])\n",
        "print(\"test accuracy : \", sc_test2_1_3[1], \" test loss : \", sc_test2_1_3[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "176/176 [==============================] - 2s 7ms/step - loss: 0.3107 - accuracy: 0.9103 - val_loss: 0.1500 - val_accuracy: 0.9563\n",
            "Epoch 2/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.1047 - accuracy: 0.9681 - val_loss: 0.1067 - val_accuracy: 0.9681\n",
            "Epoch 3/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0647 - accuracy: 0.9803 - val_loss: 0.0931 - val_accuracy: 0.9723\n",
            "Epoch 4/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0433 - accuracy: 0.9868 - val_loss: 0.0969 - val_accuracy: 0.9711\n",
            "Epoch 5/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0302 - accuracy: 0.9905 - val_loss: 0.0842 - val_accuracy: 0.9752\n",
            "Epoch 6/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.0873 - val_accuracy: 0.9739\n",
            "Epoch 7/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.0972 - val_accuracy: 0.9739\n",
            "Epoch 8/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.1066 - val_accuracy: 0.9707\n",
            "Epoch 9/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.1096 - val_accuracy: 0.9739\n",
            "Epoch 10/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.1116 - val_accuracy: 0.9749\n",
            "Epoch 11/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0108 - accuracy: 0.9962 - val_loss: 0.1101 - val_accuracy: 0.9747\n",
            "Epoch 12/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.1083 - val_accuracy: 0.9758\n",
            "Epoch 13/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.1104 - val_accuracy: 0.9751\n",
            "Epoch 14/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.1159 - val_accuracy: 0.9747\n",
            "Epoch 15/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.1309 - val_accuracy: 0.9739\n",
            "Epoch 16/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.1125 - val_accuracy: 0.9775\n",
            "Epoch 17/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.1349 - val_accuracy: 0.9752\n",
            "Epoch 18/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.1213 - val_accuracy: 0.9770\n",
            "Epoch 19/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.1278 - val_accuracy: 0.9760\n",
            "Epoch 20/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.1209 - val_accuracy: 0.9788\n",
            "Epoch 21/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.1273 - val_accuracy: 0.9764\n",
            "Epoch 22/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.1532 - val_accuracy: 0.9722\n",
            "Epoch 23/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.1195 - val_accuracy: 0.9783\n",
            "Epoch 24/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.1268 - val_accuracy: 0.9762\n",
            "Epoch 25/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.1423 - val_accuracy: 0.9733\n",
            "Epoch 26/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.1369 - val_accuracy: 0.9750\n",
            "Epoch 27/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.1307 - val_accuracy: 0.9779\n",
            "Epoch 28/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.1322 - val_accuracy: 0.9785\n",
            "Epoch 29/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.1475 - val_accuracy: 0.9750\n",
            "Epoch 30/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1337 - val_accuracy: 0.9775\n",
            "Epoch 31/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.1365 - val_accuracy: 0.9769\n",
            "Epoch 32/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.1382 - val_accuracy: 0.9775\n",
            "Epoch 33/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.8093e-04 - accuracy: 0.9998 - val_loss: 0.1149 - val_accuracy: 0.9808\n",
            "Epoch 34/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8110e-05 - accuracy: 1.0000 - val_loss: 0.1158 - val_accuracy: 0.9811\n",
            "Epoch 35/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3332e-05 - accuracy: 1.0000 - val_loss: 0.1178 - val_accuracy: 0.9813\n",
            "Epoch 36/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5598e-05 - accuracy: 1.0000 - val_loss: 0.1192 - val_accuracy: 0.9814\n",
            "Epoch 37/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1235e-05 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9814\n",
            "Epoch 38/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8122e-05 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9815\n",
            "Epoch 39/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5734e-05 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9815\n",
            "Epoch 40/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3815e-05 - accuracy: 1.0000 - val_loss: 0.1231 - val_accuracy: 0.9815\n",
            "Epoch 41/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2244e-05 - accuracy: 1.0000 - val_loss: 0.1240 - val_accuracy: 0.9816\n",
            "Epoch 42/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0895e-05 - accuracy: 1.0000 - val_loss: 0.1249 - val_accuracy: 0.9817\n",
            "Epoch 43/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.7784e-06 - accuracy: 1.0000 - val_loss: 0.1257 - val_accuracy: 0.9817\n",
            "Epoch 44/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7688e-06 - accuracy: 1.0000 - val_loss: 0.1265 - val_accuracy: 0.9818\n",
            "Epoch 45/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.9157e-06 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9817\n",
            "Epoch 46/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1442e-06 - accuracy: 1.0000 - val_loss: 0.1282 - val_accuracy: 0.9818\n",
            "Epoch 47/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4924e-06 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 0.9817\n",
            "Epoch 48/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8608e-06 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.9817\n",
            "Epoch 49/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3386e-06 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 0.9817\n",
            "Epoch 50/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.8615e-06 - accuracy: 1.0000 - val_loss: 0.1315 - val_accuracy: 0.9816\n",
            "Epoch 51/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.4283e-06 - accuracy: 1.0000 - val_loss: 0.1323 - val_accuracy: 0.9818\n",
            "Epoch 52/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0423e-06 - accuracy: 1.0000 - val_loss: 0.1330 - val_accuracy: 0.9818\n",
            "Epoch 53/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6929e-06 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.9819\n",
            "Epoch 54/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3705e-06 - accuracy: 1.0000 - val_loss: 0.1346 - val_accuracy: 0.9818\n",
            "Epoch 55/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0858e-06 - accuracy: 1.0000 - val_loss: 0.1353 - val_accuracy: 0.9819\n",
            "Epoch 56/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8136e-06 - accuracy: 1.0000 - val_loss: 0.1361 - val_accuracy: 0.9821\n",
            "Epoch 57/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5757e-06 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9822\n",
            "Epoch 58/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3556e-06 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9822\n",
            "Epoch 59/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1610e-06 - accuracy: 1.0000 - val_loss: 0.1384 - val_accuracy: 0.9821\n",
            "Epoch 60/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9701e-06 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9821\n",
            "Epoch 61/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8003e-06 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.9820\n",
            "Epoch 62/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6541e-06 - accuracy: 1.0000 - val_loss: 0.1409 - val_accuracy: 0.9820\n",
            "Epoch 63/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5130e-06 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 0.9820\n",
            "Epoch 64/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3860e-06 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 0.9819\n",
            "Epoch 65/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2669e-06 - accuracy: 1.0000 - val_loss: 0.1434 - val_accuracy: 0.9821\n",
            "Epoch 66/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1599e-06 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9820\n",
            "Epoch 67/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0629e-06 - accuracy: 1.0000 - val_loss: 0.1449 - val_accuracy: 0.9821\n",
            "Epoch 68/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7137e-07 - accuracy: 1.0000 - val_loss: 0.1457 - val_accuracy: 0.9822\n",
            "Epoch 69/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.9104e-07 - accuracy: 1.0000 - val_loss: 0.1466 - val_accuracy: 0.9821\n",
            "Epoch 70/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.1393e-07 - accuracy: 1.0000 - val_loss: 0.1474 - val_accuracy: 0.9821\n",
            "Epoch 71/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4433e-07 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 0.9822\n",
            "Epoch 72/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8204e-07 - accuracy: 1.0000 - val_loss: 0.1490 - val_accuracy: 0.9821\n",
            "Epoch 73/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2401e-07 - accuracy: 1.0000 - val_loss: 0.1498 - val_accuracy: 0.9821\n",
            "Epoch 74/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7021e-07 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9821\n",
            "Epoch 75/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2250e-07 - accuracy: 1.0000 - val_loss: 0.1516 - val_accuracy: 0.9822\n",
            "Epoch 76/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.7941e-07 - accuracy: 1.0000 - val_loss: 0.1524 - val_accuracy: 0.9822\n",
            "Epoch 77/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4015e-07 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9821\n",
            "Epoch 78/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.0230e-07 - accuracy: 1.0000 - val_loss: 0.1542 - val_accuracy: 0.9822\n",
            "Epoch 79/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6944e-07 - accuracy: 1.0000 - val_loss: 0.1550 - val_accuracy: 0.9821\n",
            "Epoch 80/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3722e-07 - accuracy: 1.0000 - val_loss: 0.1559 - val_accuracy: 0.9822\n",
            "Epoch 81/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1031e-07 - accuracy: 1.0000 - val_loss: 0.1565 - val_accuracy: 0.9823\n",
            "Epoch 82/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8404e-07 - accuracy: 1.0000 - val_loss: 0.1575 - val_accuracy: 0.9821\n",
            "Epoch 83/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6050e-07 - accuracy: 1.0000 - val_loss: 0.1584 - val_accuracy: 0.9822\n",
            "Epoch 84/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3802e-07 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 0.9823\n",
            "Epoch 85/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2055e-07 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 0.9823\n",
            "Epoch 86/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0069e-07 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9821\n",
            "Epoch 87/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8434e-07 - accuracy: 1.0000 - val_loss: 0.1617 - val_accuracy: 0.9821\n",
            "Epoch 88/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6766e-07 - accuracy: 1.0000 - val_loss: 0.1626 - val_accuracy: 0.9823\n",
            "Epoch 89/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5542e-07 - accuracy: 1.0000 - val_loss: 0.1635 - val_accuracy: 0.9822\n",
            "Epoch 90/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4187e-07 - accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 0.9821\n",
            "Epoch 91/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3028e-07 - accuracy: 1.0000 - val_loss: 0.1652 - val_accuracy: 0.9821\n",
            "Epoch 92/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1961e-07 - accuracy: 1.0000 - val_loss: 0.1662 - val_accuracy: 0.9821\n",
            "Epoch 93/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1058e-07 - accuracy: 1.0000 - val_loss: 0.1669 - val_accuracy: 0.9821\n",
            "Epoch 94/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0132e-07 - accuracy: 1.0000 - val_loss: 0.1679 - val_accuracy: 0.9821\n",
            "Epoch 95/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2665e-08 - accuracy: 1.0000 - val_loss: 0.1687 - val_accuracy: 0.9823\n",
            "Epoch 96/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.4824e-08 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 0.9821\n",
            "Epoch 97/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8148e-08 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 0.9822\n",
            "Epoch 98/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.2333e-08 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 0.9822\n",
            "Epoch 99/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6119e-08 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 0.9823\n",
            "Epoch 100/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0974e-08 - accuracy: 1.0000 - val_loss: 0.1732 - val_accuracy: 0.9822\n",
            "Epoch 101/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6336e-08 - accuracy: 1.0000 - val_loss: 0.1738 - val_accuracy: 0.9823\n",
            "Epoch 102/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2033e-08 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9823\n",
            "Epoch 103/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.8036e-08 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 0.9821\n",
            "Epoch 104/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.4280e-08 - accuracy: 1.0000 - val_loss: 0.1761 - val_accuracy: 0.9823\n",
            "Epoch 105/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.0899e-08 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.9822\n",
            "Epoch 106/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7728e-08 - accuracy: 1.0000 - val_loss: 0.1778 - val_accuracy: 0.9823\n",
            "Epoch 107/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.4931e-08 - accuracy: 1.0000 - val_loss: 0.1783 - val_accuracy: 0.9825\n",
            "Epoch 108/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2229e-08 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 0.9821\n",
            "Epoch 109/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9940e-08 - accuracy: 1.0000 - val_loss: 0.1801 - val_accuracy: 0.9823\n",
            "Epoch 110/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7916e-08 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 0.9822\n",
            "Epoch 111/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5797e-08 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 0.9821\n",
            "Epoch 112/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3823e-08 - accuracy: 1.0000 - val_loss: 0.1824 - val_accuracy: 0.9821\n",
            "Epoch 113/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2038e-08 - accuracy: 1.0000 - val_loss: 0.1826 - val_accuracy: 0.9822\n",
            "Epoch 114/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0554e-08 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9821\n",
            "Epoch 115/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9105e-08 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 0.9822\n",
            "Epoch 116/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7876e-08 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 0.9822\n",
            "Epoch 117/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6589e-08 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9822\n",
            "Epoch 118/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5471e-08 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 0.9821\n",
            "Epoch 119/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4446e-08 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9822\n",
            "Epoch 120/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3561e-08 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9822\n",
            "Epoch 121/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2705e-08 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9823\n",
            "Epoch 122/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1828e-08 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9821\n",
            "Epoch 123/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1084e-08 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9821\n",
            "Epoch 124/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0419e-08 - accuracy: 1.0000 - val_loss: 0.1895 - val_accuracy: 0.9822\n",
            "Epoch 125/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6374e-09 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9822\n",
            "Epoch 126/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0864e-09 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9821\n",
            "Epoch 127/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4294e-09 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9819\n",
            "Epoch 128/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9870e-09 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9818\n",
            "Epoch 129/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.5075e-09 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9821\n",
            "Epoch 130/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1181e-09 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 0.9821\n",
            "Epoch 131/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8055e-09 - accuracy: 1.0000 - val_loss: 0.1931 - val_accuracy: 0.9820\n",
            "Epoch 132/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3737e-09 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 0.9819\n",
            "Epoch 133/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0002e-09 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9821\n",
            "Epoch 134/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6638e-09 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9819\n",
            "Epoch 135/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3406e-09 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9821\n",
            "Epoch 136/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0969e-09 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9820\n",
            "Epoch 137/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.7763e-09 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.9819\n",
            "Epoch 138/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5617e-09 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 0.9820\n",
            "Epoch 139/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.3525e-09 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.9819\n",
            "Epoch 140/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.1193e-09 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9823\n",
            "Epoch 141/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9021e-09 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9819\n",
            "Epoch 142/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.7405e-09 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9821\n",
            "Epoch 143/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5153e-09 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9821\n",
            "Epoch 144/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3749e-09 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9819\n",
            "Epoch 145/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1657e-09 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.9821\n",
            "Epoch 146/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0014e-09 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.9820\n",
            "Epoch 147/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8796e-09 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.9819\n",
            "Epoch 148/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7392e-09 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9822\n",
            "Epoch 149/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6358e-09 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9822\n",
            "Epoch 150/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5140e-09 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9821\n",
            "Epoch 151/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4054e-09 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9822\n",
            "Epoch 152/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3233e-09 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9822\n",
            "Epoch 153/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2491e-09 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.9822\n",
            "Epoch 154/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1034e-09 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.9823\n",
            "Epoch 155/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0319e-09 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9822\n",
            "Epoch 156/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9471e-09 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9822\n",
            "Epoch 157/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8729e-09 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9821\n",
            "Epoch 158/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8093e-09 - accuracy: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.9822\n",
            "Epoch 159/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7537e-09 - accuracy: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.9821\n",
            "Epoch 160/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6901e-09 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9821\n",
            "Epoch 161/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6159e-09 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9821\n",
            "Epoch 162/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5683e-09 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9821\n",
            "Epoch 163/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5126e-09 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9821\n",
            "Epoch 164/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4755e-09 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9821\n",
            "Epoch 165/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4332e-09 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9821\n",
            "Epoch 166/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3749e-09 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9821\n",
            "Epoch 167/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3749e-09 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9821\n",
            "Epoch 168/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3034e-09 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9821\n",
            "Epoch 169/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2742e-09 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9821\n",
            "Epoch 170/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2345e-09 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9821\n",
            "Epoch 171/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2133e-09 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9821\n",
            "Epoch 172/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2133e-09 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9822\n",
            "Epoch 173/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1868e-09 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9821\n",
            "Epoch 174/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1047e-09 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9822\n",
            "Epoch 175/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0676e-09 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9822\n",
            "Epoch 176/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0914e-09 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9821\n",
            "Epoch 177/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0093e-09 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9822\n",
            "Epoch 178/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9606e-10 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9821\n",
            "Epoch 179/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0040e-09 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9822\n",
            "Epoch 180/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.6957e-10 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9822\n",
            "Epoch 181/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.5897e-10 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9823\n",
            "Epoch 182/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.7222e-10 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9823\n",
            "Epoch 183/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.0864e-10 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9823\n",
            "Epoch 184/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2189e-10 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9823\n",
            "Epoch 185/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.7155e-10 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9823\n",
            "Epoch 186/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.2983e-10 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9822\n",
            "Epoch 187/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.4771e-10 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9823\n",
            "Epoch 188/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4241e-10 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9823\n",
            "Epoch 189/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.4241e-10 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9824\n",
            "Epoch 190/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1327e-10 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9824\n",
            "Epoch 191/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.2917e-10 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9823\n",
            "Epoch 192/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1592e-10 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9824\n",
            "Epoch 193/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6559e-10 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9824\n",
            "Epoch 194/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.1857e-10 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9823\n",
            "Epoch 195/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.5234e-10 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9823\n",
            "Epoch 196/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.9208e-10 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9823\n",
            "Epoch 197/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8678e-10 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9822\n",
            "Epoch 198/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.6294e-10 - accuracy: 1.0000 - val_loss: 0.2025 - val_accuracy: 0.9823\n",
            "Epoch 199/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5499e-10 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.9822\n",
            "Epoch 200/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.3910e-10 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9822\n",
            "Epoch 201/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0996e-10 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.9822\n",
            "Epoch 202/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4704e-10 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9821\n",
            "Epoch 203/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0731e-10 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9822\n",
            "Epoch 204/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1790e-10 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 0.9821\n",
            "Epoch 205/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.1261e-10 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9821\n",
            "Epoch 206/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.9406e-10 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9821\n",
            "Epoch 207/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8876e-10 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9821\n",
            "Epoch 208/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.0996e-10 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9821\n",
            "Epoch 209/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8612e-10 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9821\n",
            "Epoch 210/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.6757e-10 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9821\n",
            "Epoch 211/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.6227e-10 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 0.9821\n",
            "Epoch 212/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6492e-10 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9820\n",
            "Epoch 213/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5168e-10 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9821\n",
            "Epoch 214/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5168e-10 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9820\n",
            "Epoch 215/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7022e-10 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.9821\n",
            "Epoch 216/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5433e-10 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.9820\n",
            "Epoch 217/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3578e-10 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9821\n",
            "Epoch 218/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3843e-10 - accuracy: 1.0000 - val_loss: 0.2046 - val_accuracy: 0.9821\n",
            "Epoch 219/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8347e-10 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.9821\n",
            "Epoch 220/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3578e-10 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 0.9821\n",
            "Epoch 221/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4108e-10 - accuracy: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.9821\n",
            "Epoch 222/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8810e-10 - accuracy: 1.0000 - val_loss: 0.2053 - val_accuracy: 0.9821\n",
            "Epoch 223/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4903e-10 - accuracy: 1.0000 - val_loss: 0.2052 - val_accuracy: 0.9820\n",
            "Epoch 224/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.4108e-10 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9821\n",
            "Epoch 225/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4903e-10 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9820\n",
            "Epoch 226/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1194e-10 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9819\n",
            "Epoch 227/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0929e-10 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9819\n",
            "Epoch 228/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2254e-10 - accuracy: 1.0000 - val_loss: 0.2062 - val_accuracy: 0.9819\n",
            "Epoch 229/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2519e-10 - accuracy: 1.0000 - val_loss: 0.2064 - val_accuracy: 0.9819\n",
            "Epoch 230/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0929e-10 - accuracy: 1.0000 - val_loss: 0.2066 - val_accuracy: 0.9819\n",
            "Epoch 231/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4638e-10 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9819\n",
            "Epoch 232/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2784e-10 - accuracy: 1.0000 - val_loss: 0.2070 - val_accuracy: 0.9819\n",
            "Epoch 233/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1989e-10 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9818\n",
            "Epoch 234/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0399e-10 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9818\n",
            "Epoch 235/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0929e-10 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9818\n",
            "Epoch 236/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1459e-10 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9817\n",
            "Epoch 237/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1724e-10 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9817\n",
            "Epoch 238/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0399e-10 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.9818\n",
            "Epoch 239/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1194e-10 - accuracy: 1.0000 - val_loss: 0.2083 - val_accuracy: 0.9818\n",
            "Epoch 240/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0929e-10 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9818\n",
            "Epoch 241/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5962e-10 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9817\n",
            "Epoch 242/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3578e-10 - accuracy: 1.0000 - val_loss: 0.2089 - val_accuracy: 0.9817\n",
            "Epoch 243/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3578e-10 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 0.9817\n",
            "Epoch 244/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0929e-10 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9817\n",
            "Epoch 245/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0929e-10 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9817\n",
            "Epoch 246/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.4903e-10 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9817\n",
            "Epoch 247/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9870e-10 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9818\n",
            "Epoch 248/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2254e-10 - accuracy: 1.0000 - val_loss: 0.2104 - val_accuracy: 0.9817\n",
            "Epoch 249/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1989e-10 - accuracy: 1.0000 - val_loss: 0.2106 - val_accuracy: 0.9816\n",
            "Epoch 250/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2784e-10 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9817\n",
            "Epoch 251/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3578e-10 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9817\n",
            "Epoch 252/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5168e-10 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9817\n",
            "Epoch 253/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1459e-10 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9816\n",
            "Epoch 254/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4108e-10 - accuracy: 1.0000 - val_loss: 0.2119 - val_accuracy: 0.9817\n",
            "Epoch 255/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3578e-10 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9816\n",
            "Epoch 256/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3843e-10 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 0.9816\n",
            "Epoch 257/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.4903e-10 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 0.9815\n",
            "Epoch 258/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3048e-10 - accuracy: 1.0000 - val_loss: 0.2128 - val_accuracy: 0.9816\n",
            "Epoch 259/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5962e-10 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9814\n",
            "Epoch 260/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3843e-10 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9814\n",
            "Epoch 261/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5962e-10 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9814\n",
            "Epoch 262/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.6757e-10 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9813\n",
            "Epoch 263/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8876e-10 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9813\n",
            "Epoch 264/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7287e-10 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9814\n",
            "Epoch 265/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2254e-10 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9814\n",
            "Epoch 266/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7817e-10 - accuracy: 1.0000 - val_loss: 0.2149 - val_accuracy: 0.9813\n",
            "Epoch 267/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7022e-10 - accuracy: 1.0000 - val_loss: 0.2151 - val_accuracy: 0.9814\n",
            "Epoch 268/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7287e-10 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9813\n",
            "Epoch 269/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.9671e-10 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9814\n",
            "Epoch 270/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2320e-10 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9815\n",
            "Epoch 271/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8612e-10 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 0.9813\n",
            "Epoch 272/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7817e-10 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9813\n",
            "Epoch 273/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3115e-10 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9812\n",
            "Epoch 274/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4440e-10 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9811\n",
            "Epoch 275/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1526e-10 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9811\n",
            "Epoch 276/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1261e-10 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9811\n",
            "Epoch 277/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.9141e-10 - accuracy: 1.0000 - val_loss: 0.2179 - val_accuracy: 0.9813\n",
            "Epoch 278/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.0466e-10 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9813\n",
            "Epoch 279/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2585e-10 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 0.9812\n",
            "Epoch 280/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6029e-10 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9812\n",
            "Epoch 281/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5499e-10 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9813\n",
            "Epoch 282/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8148e-10 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9812\n",
            "Epoch 283/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6559e-10 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9811\n",
            "Epoch 284/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.4175e-10 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9811\n",
            "Epoch 285/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4440e-10 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9810\n",
            "Epoch 286/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5764e-10 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9811\n",
            "Epoch 287/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9473e-10 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 0.9811\n",
            "Epoch 288/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0003e-10 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9810\n",
            "Epoch 289/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.9473e-10 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9810\n",
            "Epoch 290/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3711e-10 - accuracy: 1.0000 - val_loss: 0.2215 - val_accuracy: 0.9811\n",
            "Epoch 291/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1062e-10 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 0.9811\n",
            "Epoch 292/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.1062e-10 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9810\n",
            "Epoch 293/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.3446e-10 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9809\n",
            "Epoch 294/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3182e-10 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9809\n",
            "Epoch 295/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4506e-10 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9809\n",
            "Epoch 296/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1592e-10 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9809\n",
            "Epoch 297/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6361e-10 - accuracy: 1.0000 - val_loss: 0.2237 - val_accuracy: 0.9810\n",
            "Epoch 298/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4506e-10 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9809\n",
            "Epoch 299/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.5566e-10 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9811\n",
            "Epoch 300/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1327e-10 - accuracy: 1.0000 - val_loss: 0.2247 - val_accuracy: 0.9809\n",
            "Epoch 301/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7420e-10 - accuracy: 1.0000 - val_loss: 0.2252 - val_accuracy: 0.9810\n",
            "Epoch 302/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0069e-10 - accuracy: 1.0000 - val_loss: 0.2255 - val_accuracy: 0.9811\n",
            "Epoch 303/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0599e-10 - accuracy: 1.0000 - val_loss: 0.2257 - val_accuracy: 0.9809\n",
            "Epoch 304/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0599e-10 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9809\n",
            "Epoch 305/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7685e-10 - accuracy: 1.0000 - val_loss: 0.2265 - val_accuracy: 0.9809\n",
            "Epoch 306/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7950e-10 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 0.9811\n",
            "Epoch 307/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3513e-10 - accuracy: 1.0000 - val_loss: 0.2268 - val_accuracy: 0.9809\n",
            "Epoch 308/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9275e-10 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9809\n",
            "Epoch 309/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.9539e-10 - accuracy: 1.0000 - val_loss: 0.2273 - val_accuracy: 0.9809\n",
            "Epoch 310/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5632e-10 - accuracy: 1.0000 - val_loss: 0.2274 - val_accuracy: 0.9808\n",
            "Epoch 311/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6096e-10 - accuracy: 1.0000 - val_loss: 0.2280 - val_accuracy: 0.9808\n",
            "Epoch 312/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5897e-10 - accuracy: 1.0000 - val_loss: 0.2282 - val_accuracy: 0.9809\n",
            "Epoch 313/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4838e-10 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9807\n",
            "Epoch 314/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.8281e-10 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.9807\n",
            "Epoch 315/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9871e-10 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9807\n",
            "Epoch 316/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2453e-10 - accuracy: 1.0000 - val_loss: 0.2294 - val_accuracy: 0.9807\n",
            "Epoch 317/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4573e-10 - accuracy: 1.0000 - val_loss: 0.2302 - val_accuracy: 0.9808\n",
            "Epoch 318/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.2718e-10 - accuracy: 1.0000 - val_loss: 0.2296 - val_accuracy: 0.9807\n",
            "Epoch 319/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3248e-10 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.9807\n",
            "Epoch 320/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0014e-09 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 0.9807\n",
            "Epoch 321/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.8546e-10 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9807\n",
            "Epoch 322/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6427e-10 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.9806\n",
            "Epoch 323/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6427e-10 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.9805\n",
            "Epoch 324/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2189e-10 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.9806\n",
            "Epoch 325/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0226e-09 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9808\n",
            "Epoch 326/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0093e-09 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.9805\n",
            "Epoch 327/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0146e-09 - accuracy: 1.0000 - val_loss: 0.2328 - val_accuracy: 0.9808\n",
            "Epoch 328/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0093e-09 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.9807\n",
            "Epoch 329/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0146e-09 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9807\n",
            "Epoch 330/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0358e-09 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9807\n",
            "Epoch 331/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0464e-09 - accuracy: 1.0000 - val_loss: 0.2348 - val_accuracy: 0.9807\n",
            "Epoch 332/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0358e-09 - accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 0.9809\n",
            "Epoch 333/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0199e-09 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9809\n",
            "Epoch 334/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0596e-09 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9805\n",
            "Epoch 335/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0384e-09 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9808\n",
            "Epoch 336/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0755e-09 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9807\n",
            "Epoch 337/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0994e-09 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9807\n",
            "Epoch 338/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0702e-09 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9805\n",
            "Epoch 339/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0517e-09 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 0.9806\n",
            "Epoch 340/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0835e-09 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9809\n",
            "Epoch 341/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0994e-09 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 0.9805\n",
            "Epoch 342/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0861e-09 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9807\n",
            "Epoch 343/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1100e-09 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9807\n",
            "Epoch 344/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0994e-09 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9807\n",
            "Epoch 345/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0729e-09 - accuracy: 1.0000 - val_loss: 0.2396 - val_accuracy: 0.9807\n",
            "Epoch 346/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1206e-09 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 0.9808\n",
            "Epoch 347/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1206e-09 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9808\n",
            "Epoch 348/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1391e-09 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9807\n",
            "Epoch 349/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1418e-09 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9808\n",
            "Epoch 350/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1020e-09 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9806\n",
            "Epoch 351/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1100e-09 - accuracy: 1.0000 - val_loss: 0.2420 - val_accuracy: 0.9807\n",
            "Epoch 352/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1656e-09 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9807\n",
            "Epoch 353/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1471e-09 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9807\n",
            "Epoch 354/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1603e-09 - accuracy: 1.0000 - val_loss: 0.2429 - val_accuracy: 0.9807\n",
            "Epoch 355/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2000e-09 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9805\n",
            "Epoch 356/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1471e-09 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9806\n",
            "Epoch 357/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2186e-09 - accuracy: 1.0000 - val_loss: 0.2437 - val_accuracy: 0.9805\n",
            "Epoch 358/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2106e-09 - accuracy: 1.0000 - val_loss: 0.2442 - val_accuracy: 0.9806\n",
            "Epoch 359/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1947e-09 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9805\n",
            "Epoch 360/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1921e-09 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9804\n",
            "Epoch 361/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2557e-09 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.9807\n",
            "Epoch 362/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2159e-09 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9808\n",
            "Epoch 363/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2133e-09 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9807\n",
            "Epoch 364/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2027e-09 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9803\n",
            "Epoch 365/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2663e-09 - accuracy: 1.0000 - val_loss: 0.2472 - val_accuracy: 0.9807\n",
            "Epoch 366/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2318e-09 - accuracy: 1.0000 - val_loss: 0.2474 - val_accuracy: 0.9805\n",
            "Epoch 367/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2689e-09 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.9807\n",
            "Epoch 368/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3140e-09 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.9805\n",
            "Epoch 369/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2424e-09 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9805\n",
            "Epoch 370/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3245e-09 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9805\n",
            "Epoch 371/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3140e-09 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.9806\n",
            "Epoch 372/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2981e-09 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9803\n",
            "Epoch 373/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3034e-09 - accuracy: 1.0000 - val_loss: 0.2496 - val_accuracy: 0.9806\n",
            "Epoch 374/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3007e-09 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9805\n",
            "Epoch 375/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3272e-09 - accuracy: 1.0000 - val_loss: 0.2511 - val_accuracy: 0.9803\n",
            "Epoch 376/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3484e-09 - accuracy: 1.0000 - val_loss: 0.2516 - val_accuracy: 0.9803\n",
            "Epoch 377/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3007e-09 - accuracy: 1.0000 - val_loss: 0.2509 - val_accuracy: 0.9805\n",
            "Epoch 378/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3537e-09 - accuracy: 1.0000 - val_loss: 0.2517 - val_accuracy: 0.9805\n",
            "Epoch 379/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3775e-09 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9803\n",
            "Epoch 380/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3378e-09 - accuracy: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.9801\n",
            "Epoch 381/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3616e-09 - accuracy: 1.0000 - val_loss: 0.2531 - val_accuracy: 0.9802\n",
            "Epoch 382/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4755e-09 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9801\n",
            "Epoch 383/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3908e-09 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.9807\n",
            "Epoch 384/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4888e-09 - accuracy: 1.0000 - val_loss: 0.2546 - val_accuracy: 0.9801\n",
            "Epoch 385/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4994e-09 - accuracy: 1.0000 - val_loss: 0.2514 - val_accuracy: 0.9800\n",
            "Epoch 386/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5312e-09 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.9802\n",
            "Epoch 387/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4782e-09 - accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 0.9799\n",
            "Epoch 388/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3590e-09 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.9800\n",
            "Epoch 389/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4438e-09 - accuracy: 1.0000 - val_loss: 0.2567 - val_accuracy: 0.9799\n",
            "Epoch 390/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4755e-09 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9801\n",
            "Epoch 391/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4967e-09 - accuracy: 1.0000 - val_loss: 0.2565 - val_accuracy: 0.9799\n",
            "Epoch 392/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7299e-09 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9799\n",
            "Epoch 393/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5762e-09 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9797\n",
            "Epoch 394/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.2304 - accuracy: 0.9835 - val_loss: 0.2196 - val_accuracy: 0.9767\n",
            "Epoch 395/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.1852 - val_accuracy: 0.9783\n",
            "Epoch 396/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.1878 - val_accuracy: 0.9781\n",
            "Epoch 397/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3081e-04 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9792\n",
            "Epoch 398/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4109e-05 - accuracy: 1.0000 - val_loss: 0.1839 - val_accuracy: 0.9791\n",
            "Epoch 399/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4925e-05 - accuracy: 1.0000 - val_loss: 0.1837 - val_accuracy: 0.9793\n",
            "Epoch 400/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0617e-05 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9792\n",
            "Epoch 401/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7665e-05 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 0.9795\n",
            "Epoch 402/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5427e-05 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 0.9795\n",
            "Epoch 403/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3659e-05 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 0.9796\n",
            "Epoch 404/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1981e-05 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 0.9796\n",
            "Epoch 405/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0737e-05 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 0.9798\n",
            "Epoch 406/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6045e-06 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9797\n",
            "Epoch 407/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6811e-06 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9798\n",
            "Epoch 408/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.8358e-06 - accuracy: 1.0000 - val_loss: 0.1837 - val_accuracy: 0.9797\n",
            "Epoch 409/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1090e-06 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.9799\n",
            "Epoch 410/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4801e-06 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.9799\n",
            "Epoch 411/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.9094e-06 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.9799\n",
            "Epoch 412/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.3802e-06 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.9799\n",
            "Epoch 413/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.9228e-06 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 0.9799\n",
            "Epoch 414/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5101e-06 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.9800\n",
            "Epoch 415/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1292e-06 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9801\n",
            "Epoch 416/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.8017e-06 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9801\n",
            "Epoch 417/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.4899e-06 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9801\n",
            "Epoch 418/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2104e-06 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9801\n",
            "Epoch 419/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9562e-06 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9801\n",
            "Epoch 420/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7360e-06 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9801\n",
            "Epoch 421/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5243e-06 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9801\n",
            "Epoch 422/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3296e-06 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9801\n",
            "Epoch 423/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1508e-06 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9800\n",
            "Epoch 424/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9822e-06 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9799\n",
            "Epoch 425/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8253e-06 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9801\n",
            "Epoch 426/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6824e-06 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9801\n",
            "Epoch 427/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5598e-06 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9801\n",
            "Epoch 428/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4411e-06 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9801\n",
            "Epoch 429/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3263e-06 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.9801\n",
            "Epoch 430/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2322e-06 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9804\n",
            "Epoch 431/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1375e-06 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9805\n",
            "Epoch 432/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0515e-06 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 0.9803\n",
            "Epoch 433/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.7096e-07 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9802\n",
            "Epoch 434/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.0068e-07 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9803\n",
            "Epoch 435/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3481e-07 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9803\n",
            "Epoch 436/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7296e-07 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9801\n",
            "Epoch 437/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1233e-07 - accuracy: 1.0000 - val_loss: 0.1922 - val_accuracy: 0.9805\n",
            "Epoch 438/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6475e-07 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9802\n",
            "Epoch 439/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.1087e-07 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9803\n",
            "Epoch 440/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.6594e-07 - accuracy: 1.0000 - val_loss: 0.1935 - val_accuracy: 0.9803\n",
            "Epoch 441/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2464e-07 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 0.9803\n",
            "Epoch 442/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.8505e-07 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9804\n",
            "Epoch 443/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4908e-07 - accuracy: 1.0000 - val_loss: 0.1954 - val_accuracy: 0.9803\n",
            "Epoch 444/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1707e-07 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 0.9804\n",
            "Epoch 445/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8711e-07 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 0.9804\n",
            "Epoch 446/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.5896e-07 - accuracy: 1.0000 - val_loss: 0.1969 - val_accuracy: 0.9803\n",
            "Epoch 447/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3397e-07 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9805\n",
            "Epoch 448/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0959e-07 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9805\n",
            "Epoch 449/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8763e-07 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9805\n",
            "Epoch 450/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6718e-07 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9805\n",
            "Epoch 451/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4808e-07 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9804\n",
            "Epoch 452/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3052e-07 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9807\n",
            "Epoch 453/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1399e-07 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9805\n",
            "Epoch 454/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9895e-07 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9807\n",
            "Epoch 455/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8452e-07 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9808\n",
            "Epoch 456/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7154e-07 - accuracy: 1.0000 - val_loss: 0.2025 - val_accuracy: 0.9807\n",
            "Epoch 457/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5963e-07 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 0.9807\n",
            "Epoch 458/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4819e-07 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9807\n",
            "Epoch 459/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3746e-07 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 0.9807\n",
            "Epoch 460/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2788e-07 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9807\n",
            "Epoch 461/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1887e-07 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9807\n",
            "Epoch 462/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1028e-07 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9805\n",
            "Epoch 463/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0269e-07 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9807\n",
            "Epoch 464/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5587e-08 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9806\n",
            "Epoch 465/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8827e-08 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9805\n",
            "Epoch 466/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.2379e-08 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9805\n",
            "Epoch 467/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.6498e-08 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.9805\n",
            "Epoch 468/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1327e-08 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9804\n",
            "Epoch 469/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6113e-08 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 0.9803\n",
            "Epoch 470/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1745e-08 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9802\n",
            "Epoch 471/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.7329e-08 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9806\n",
            "Epoch 472/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3215e-08 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 0.9804\n",
            "Epoch 473/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9514e-08 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9803\n",
            "Epoch 474/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6057e-08 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9804\n",
            "Epoch 475/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2889e-08 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9805\n",
            "Epoch 476/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.9824e-08 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9805\n",
            "Epoch 477/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7146e-08 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9805\n",
            "Epoch 478/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.4510e-08 - accuracy: 1.0000 - val_loss: 0.2163 - val_accuracy: 0.9805\n",
            "Epoch 479/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2128e-08 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9805\n",
            "Epoch 480/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9866e-08 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9805\n",
            "Epoch 481/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7940e-08 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9805\n",
            "Epoch 482/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5990e-08 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9805\n",
            "Epoch 483/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4186e-08 - accuracy: 1.0000 - val_loss: 0.2194 - val_accuracy: 0.9805\n",
            "Epoch 484/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2459e-08 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 0.9806\n",
            "Epoch 485/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0875e-08 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9805\n",
            "Epoch 486/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9574e-08 - accuracy: 1.0000 - val_loss: 0.2215 - val_accuracy: 0.9806\n",
            "Epoch 487/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8069e-08 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9807\n",
            "Epoch 488/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6981e-08 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9807\n",
            "Epoch 489/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5783e-08 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9807\n",
            "Epoch 490/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4726e-08 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9805\n",
            "Epoch 491/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3738e-08 - accuracy: 1.0000 - val_loss: 0.2245 - val_accuracy: 0.9807\n",
            "Epoch 492/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2806e-08 - accuracy: 1.0000 - val_loss: 0.2252 - val_accuracy: 0.9807\n",
            "Epoch 493/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2067e-08 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9807\n",
            "Epoch 494/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1134e-08 - accuracy: 1.0000 - val_loss: 0.2265 - val_accuracy: 0.9807\n",
            "Epoch 495/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0392e-08 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9806\n",
            "Epoch 496/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7752e-09 - accuracy: 1.0000 - val_loss: 0.2278 - val_accuracy: 0.9807\n",
            "Epoch 497/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0943e-09 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9807\n",
            "Epoch 498/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5725e-09 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9808\n",
            "Epoch 499/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9817e-09 - accuracy: 1.0000 - val_loss: 0.2298 - val_accuracy: 0.9807\n",
            "Epoch 500/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.4810e-09 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 0.9808\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0576 - accuracy: 0.9952\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1875 - accuracy: 0.9835\n",
            "train accuracy :  0.995199978351593 train loss :  0.057611025869846344\n",
            "test accuracy :  0.9835000038146973  test loss :  0.187482550740242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UQcfQBlHB74M",
        "outputId": "cb9e19c4-890c-4d34-e4ad-a4988b5cbcb3"
      },
      "source": [
        "#신경망 학습2_1_4\n",
        "model2_1_4 = models.Sequential([\n",
        "                               Flatten(input_shape = (28, 28)),\n",
        "                               Dense(512, activation= 'relu'),\n",
        "                               Dense(512, activation= 'relu'),\n",
        "                               Dense(10, activation= 'softmax')\n",
        "                               ])\n",
        "\n",
        "model2_1_4.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "hist2_1_4 = model2_1_4.fit(train_x, train_y, epochs = 1000, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "#학습 그래프4\n",
        "plt.plot(hist2_1_4.history['accuracy'], 'b-')\n",
        "plt.plot(hist2_1_4.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train2_1_4 = model2_1_4.evaluate(train_x, train_y)\n",
        "sc_test2_1_4 = model2_1_4.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train2_1_4[1], \"train loss : \", sc_train2_1_4[0])\n",
        "print(\"test accuracy : \", sc_test2_1_4[1], \" test loss : \", sc_test2_1_4[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "176/176 [==============================] - 2s 7ms/step - loss: 0.3058 - accuracy: 0.9132 - val_loss: 0.1477 - val_accuracy: 0.9569\n",
            "Epoch 2/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.1050 - accuracy: 0.9688 - val_loss: 0.1042 - val_accuracy: 0.9693\n",
            "Epoch 3/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0647 - accuracy: 0.9802 - val_loss: 0.0917 - val_accuracy: 0.9721\n",
            "Epoch 4/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0441 - accuracy: 0.9863 - val_loss: 0.0966 - val_accuracy: 0.9705\n",
            "Epoch 5/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0295 - accuracy: 0.9907 - val_loss: 0.1008 - val_accuracy: 0.9696\n",
            "Epoch 6/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.1017 - val_accuracy: 0.9722\n",
            "Epoch 7/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.0937 - val_accuracy: 0.9758\n",
            "Epoch 8/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0144 - accuracy: 0.9952 - val_loss: 0.0997 - val_accuracy: 0.9752\n",
            "Epoch 9/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.0922 - val_accuracy: 0.9768\n",
            "Epoch 10/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.1044 - val_accuracy: 0.9746\n",
            "Epoch 11/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.1136 - val_accuracy: 0.9727\n",
            "Epoch 12/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.1083 - val_accuracy: 0.9753\n",
            "Epoch 13/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.1094 - val_accuracy: 0.9765\n",
            "Epoch 14/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.0976 - val_accuracy: 0.9783\n",
            "Epoch 15/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.1157 - val_accuracy: 0.9759\n",
            "Epoch 16/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.1302 - val_accuracy: 0.9727\n",
            "Epoch 17/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.1462 - val_accuracy: 0.9707\n",
            "Epoch 18/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.1219 - val_accuracy: 0.9757\n",
            "Epoch 19/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.1173 - val_accuracy: 0.9757\n",
            "Epoch 20/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.1180 - val_accuracy: 0.9769\n",
            "Epoch 21/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.1171 - val_accuracy: 0.9775\n",
            "Epoch 22/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1359 - val_accuracy: 0.9758\n",
            "Epoch 23/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.1470 - val_accuracy: 0.9721\n",
            "Epoch 24/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.1348 - val_accuracy: 0.9749\n",
            "Epoch 25/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.1239 - val_accuracy: 0.9771\n",
            "Epoch 26/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.1223 - val_accuracy: 0.9787\n",
            "Epoch 27/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.1552 - val_accuracy: 0.9742\n",
            "Epoch 28/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.1178 - val_accuracy: 0.9778\n",
            "Epoch 29/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.1402 - val_accuracy: 0.9776\n",
            "Epoch 30/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.1244 - val_accuracy: 0.9794\n",
            "Epoch 31/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.8910e-04 - accuracy: 0.9998 - val_loss: 0.1231 - val_accuracy: 0.9791\n",
            "Epoch 32/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5386e-04 - accuracy: 0.9997 - val_loss: 0.1171 - val_accuracy: 0.9796\n",
            "Epoch 33/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.9709e-05 - accuracy: 1.0000 - val_loss: 0.1161 - val_accuracy: 0.9805\n",
            "Epoch 34/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8426e-05 - accuracy: 1.0000 - val_loss: 0.1167 - val_accuracy: 0.9805\n",
            "Epoch 35/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2583e-05 - accuracy: 1.0000 - val_loss: 0.1175 - val_accuracy: 0.9807\n",
            "Epoch 36/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9133e-05 - accuracy: 1.0000 - val_loss: 0.1183 - val_accuracy: 0.9807\n",
            "Epoch 37/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6557e-05 - accuracy: 1.0000 - val_loss: 0.1191 - val_accuracy: 0.9807\n",
            "Epoch 38/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4522e-05 - accuracy: 1.0000 - val_loss: 0.1198 - val_accuracy: 0.9805\n",
            "Epoch 39/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2860e-05 - accuracy: 1.0000 - val_loss: 0.1204 - val_accuracy: 0.9808\n",
            "Epoch 40/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1472e-05 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9807\n",
            "Epoch 41/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0296e-05 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 0.9805\n",
            "Epoch 42/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2633e-06 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 0.9805\n",
            "Epoch 43/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3571e-06 - accuracy: 1.0000 - val_loss: 0.1235 - val_accuracy: 0.9806\n",
            "Epoch 44/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5834e-06 - accuracy: 1.0000 - val_loss: 0.1242 - val_accuracy: 0.9805\n",
            "Epoch 45/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8769e-06 - accuracy: 1.0000 - val_loss: 0.1249 - val_accuracy: 0.9805\n",
            "Epoch 46/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2479e-06 - accuracy: 1.0000 - val_loss: 0.1256 - val_accuracy: 0.9805\n",
            "Epoch 47/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6974e-06 - accuracy: 1.0000 - val_loss: 0.1264 - val_accuracy: 0.9805\n",
            "Epoch 48/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1800e-06 - accuracy: 1.0000 - val_loss: 0.1271 - val_accuracy: 0.9806\n",
            "Epoch 49/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7262e-06 - accuracy: 1.0000 - val_loss: 0.1278 - val_accuracy: 0.9805\n",
            "Epoch 50/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3188e-06 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9805\n",
            "Epoch 51/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9444e-06 - accuracy: 1.0000 - val_loss: 0.1293 - val_accuracy: 0.9805\n",
            "Epoch 52/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6128e-06 - accuracy: 1.0000 - val_loss: 0.1300 - val_accuracy: 0.9807\n",
            "Epoch 53/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.2986e-06 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9805\n",
            "Epoch 54/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0184e-06 - accuracy: 1.0000 - val_loss: 0.1314 - val_accuracy: 0.9806\n",
            "Epoch 55/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7663e-06 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.9807\n",
            "Epoch 56/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5303e-06 - accuracy: 1.0000 - val_loss: 0.1330 - val_accuracy: 0.9808\n",
            "Epoch 57/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3200e-06 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.9807\n",
            "Epoch 58/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1277e-06 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.9809\n",
            "Epoch 59/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9490e-06 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.9808\n",
            "Epoch 60/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7851e-06 - accuracy: 1.0000 - val_loss: 0.1360 - val_accuracy: 0.9809\n",
            "Epoch 61/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6390e-06 - accuracy: 1.0000 - val_loss: 0.1367 - val_accuracy: 0.9807\n",
            "Epoch 62/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5045e-06 - accuracy: 1.0000 - val_loss: 0.1374 - val_accuracy: 0.9807\n",
            "Epoch 63/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3780e-06 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9807\n",
            "Epoch 64/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2661e-06 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9807\n",
            "Epoch 65/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1600e-06 - accuracy: 1.0000 - val_loss: 0.1398 - val_accuracy: 0.9807\n",
            "Epoch 66/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0676e-06 - accuracy: 1.0000 - val_loss: 0.1405 - val_accuracy: 0.9808\n",
            "Epoch 67/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7715e-07 - accuracy: 1.0000 - val_loss: 0.1413 - val_accuracy: 0.9807\n",
            "Epoch 68/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.9623e-07 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9808\n",
            "Epoch 69/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.2278e-07 - accuracy: 1.0000 - val_loss: 0.1428 - val_accuracy: 0.9807\n",
            "Epoch 70/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5588e-07 - accuracy: 1.0000 - val_loss: 0.1436 - val_accuracy: 0.9807\n",
            "Epoch 71/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.9497e-07 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9808\n",
            "Epoch 72/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3787e-07 - accuracy: 1.0000 - val_loss: 0.1451 - val_accuracy: 0.9808\n",
            "Epoch 73/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8580e-07 - accuracy: 1.0000 - val_loss: 0.1458 - val_accuracy: 0.9808\n",
            "Epoch 74/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3840e-07 - accuracy: 1.0000 - val_loss: 0.1466 - val_accuracy: 0.9808\n",
            "Epoch 75/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.9353e-07 - accuracy: 1.0000 - val_loss: 0.1474 - val_accuracy: 0.9808\n",
            "Epoch 76/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.5482e-07 - accuracy: 1.0000 - val_loss: 0.1481 - val_accuracy: 0.9808\n",
            "Epoch 77/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1663e-07 - accuracy: 1.0000 - val_loss: 0.1488 - val_accuracy: 0.9808\n",
            "Epoch 78/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.8487e-07 - accuracy: 1.0000 - val_loss: 0.1497 - val_accuracy: 0.9807\n",
            "Epoch 79/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.5226e-07 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 0.9808\n",
            "Epoch 80/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.2443e-07 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9809\n",
            "Epoch 81/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9852e-07 - accuracy: 1.0000 - val_loss: 0.1518 - val_accuracy: 0.9808\n",
            "Epoch 82/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7446e-07 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9806\n",
            "Epoch 83/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5227e-07 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9805\n",
            "Epoch 84/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3180e-07 - accuracy: 1.0000 - val_loss: 0.1541 - val_accuracy: 0.9805\n",
            "Epoch 85/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1266e-07 - accuracy: 1.0000 - val_loss: 0.1548 - val_accuracy: 0.9807\n",
            "Epoch 86/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9688e-07 - accuracy: 1.0000 - val_loss: 0.1558 - val_accuracy: 0.9805\n",
            "Epoch 87/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8029e-07 - accuracy: 1.0000 - val_loss: 0.1563 - val_accuracy: 0.9805\n",
            "Epoch 88/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6637e-07 - accuracy: 1.0000 - val_loss: 0.1573 - val_accuracy: 0.9806\n",
            "Epoch 89/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5317e-07 - accuracy: 1.0000 - val_loss: 0.1579 - val_accuracy: 0.9805\n",
            "Epoch 90/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4118e-07 - accuracy: 1.0000 - val_loss: 0.1589 - val_accuracy: 0.9803\n",
            "Epoch 91/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2989e-07 - accuracy: 1.0000 - val_loss: 0.1593 - val_accuracy: 0.9803\n",
            "Epoch 92/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2021e-07 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9805\n",
            "Epoch 93/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1030e-07 - accuracy: 1.0000 - val_loss: 0.1607 - val_accuracy: 0.9803\n",
            "Epoch 94/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0172e-07 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.9802\n",
            "Epoch 95/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4390e-08 - accuracy: 1.0000 - val_loss: 0.1624 - val_accuracy: 0.9803\n",
            "Epoch 96/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.6972e-08 - accuracy: 1.0000 - val_loss: 0.1630 - val_accuracy: 0.9803\n",
            "Epoch 97/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9952e-08 - accuracy: 1.0000 - val_loss: 0.1638 - val_accuracy: 0.9803\n",
            "Epoch 98/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3979e-08 - accuracy: 1.0000 - val_loss: 0.1644 - val_accuracy: 0.9803\n",
            "Epoch 99/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8182e-08 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9803\n",
            "Epoch 100/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3038e-08 - accuracy: 1.0000 - val_loss: 0.1658 - val_accuracy: 0.9801\n",
            "Epoch 101/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8405e-08 - accuracy: 1.0000 - val_loss: 0.1665 - val_accuracy: 0.9803\n",
            "Epoch 102/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3835e-08 - accuracy: 1.0000 - val_loss: 0.1674 - val_accuracy: 0.9801\n",
            "Epoch 103/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9790e-08 - accuracy: 1.0000 - val_loss: 0.1681 - val_accuracy: 0.9801\n",
            "Epoch 104/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.6142e-08 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9802\n",
            "Epoch 105/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.2801e-08 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 0.9803\n",
            "Epoch 106/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9495e-08 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 0.9803\n",
            "Epoch 107/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6489e-08 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9803\n",
            "Epoch 108/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3906e-08 - accuracy: 1.0000 - val_loss: 0.1714 - val_accuracy: 0.9803\n",
            "Epoch 109/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1416e-08 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 0.9803\n",
            "Epoch 110/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9140e-08 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 0.9804\n",
            "Epoch 111/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7074e-08 - accuracy: 1.0000 - val_loss: 0.1733 - val_accuracy: 0.9803\n",
            "Epoch 112/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5156e-08 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 0.9805\n",
            "Epoch 113/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3455e-08 - accuracy: 1.0000 - val_loss: 0.1747 - val_accuracy: 0.9803\n",
            "Epoch 114/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1842e-08 - accuracy: 1.0000 - val_loss: 0.1754 - val_accuracy: 0.9805\n",
            "Epoch 115/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0231e-08 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 0.9804\n",
            "Epoch 116/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8936e-08 - accuracy: 1.0000 - val_loss: 0.1762 - val_accuracy: 0.9805\n",
            "Epoch 117/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7630e-08 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.9806\n",
            "Epoch 118/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6459e-08 - accuracy: 1.0000 - val_loss: 0.1776 - val_accuracy: 0.9805\n",
            "Epoch 119/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5349e-08 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 0.9809\n",
            "Epoch 120/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4355e-08 - accuracy: 1.0000 - val_loss: 0.1787 - val_accuracy: 0.9807\n",
            "Epoch 121/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3439e-08 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 0.9807\n",
            "Epoch 122/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2520e-08 - accuracy: 1.0000 - val_loss: 0.1798 - val_accuracy: 0.9807\n",
            "Epoch 123/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1770e-08 - accuracy: 1.0000 - val_loss: 0.1804 - val_accuracy: 0.9807\n",
            "Epoch 124/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1055e-08 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9807\n",
            "Epoch 125/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0390e-08 - accuracy: 1.0000 - val_loss: 0.1813 - val_accuracy: 0.9807\n",
            "Epoch 126/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.7381e-09 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9808\n",
            "Epoch 127/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.1208e-09 - accuracy: 1.0000 - val_loss: 0.1826 - val_accuracy: 0.9807\n",
            "Epoch 128/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5645e-09 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 0.9809\n",
            "Epoch 129/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.0797e-09 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 0.9807\n",
            "Epoch 130/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.5923e-09 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9809\n",
            "Epoch 131/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1367e-09 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.9807\n",
            "Epoch 132/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7525e-09 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 0.9808\n",
            "Epoch 133/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3287e-09 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9809\n",
            "Epoch 134/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.9976e-09 - accuracy: 1.0000 - val_loss: 0.1853 - val_accuracy: 0.9808\n",
            "Epoch 135/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7485e-09 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 0.9809\n",
            "Epoch 136/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4095e-09 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9808\n",
            "Epoch 137/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1392e-09 - accuracy: 1.0000 - val_loss: 0.1864 - val_accuracy: 0.9809\n",
            "Epoch 138/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.8902e-09 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 0.9809\n",
            "Epoch 139/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6094e-09 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9809\n",
            "Epoch 140/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4134e-09 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9809\n",
            "Epoch 141/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1829e-09 - accuracy: 1.0000 - val_loss: 0.1879 - val_accuracy: 0.9807\n",
            "Epoch 142/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.0187e-09 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9808\n",
            "Epoch 143/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7829e-09 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 0.9807\n",
            "Epoch 144/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6213e-09 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.9809\n",
            "Epoch 145/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4465e-09 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9807\n",
            "Epoch 146/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2637e-09 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9808\n",
            "Epoch 147/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1180e-09 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.9810\n",
            "Epoch 148/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9882e-09 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9809\n",
            "Epoch 149/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8875e-09 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9809\n",
            "Epoch 150/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7921e-09 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9809\n",
            "Epoch 151/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6782e-09 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9807\n",
            "Epoch 152/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5696e-09 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9809\n",
            "Epoch 153/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4716e-09 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.9808\n",
            "Epoch 154/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3656e-09 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9809\n",
            "Epoch 155/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2703e-09 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9809\n",
            "Epoch 156/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2014e-09 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9808\n",
            "Epoch 157/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1378e-09 - accuracy: 1.0000 - val_loss: 0.1916 - val_accuracy: 0.9809\n",
            "Epoch 158/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0319e-09 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 0.9809\n",
            "Epoch 159/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9683e-09 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 0.9810\n",
            "Epoch 160/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9418e-09 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9808\n",
            "Epoch 161/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8491e-09 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9810\n",
            "Epoch 162/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7749e-09 - accuracy: 1.0000 - val_loss: 0.1922 - val_accuracy: 0.9809\n",
            "Epoch 163/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7060e-09 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9810\n",
            "Epoch 164/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6716e-09 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9809\n",
            "Epoch 165/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6159e-09 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9809\n",
            "Epoch 166/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5471e-09 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 0.9809\n",
            "Epoch 167/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4967e-09 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9810\n",
            "Epoch 168/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4888e-09 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9809\n",
            "Epoch 169/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4199e-09 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9809\n",
            "Epoch 170/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3987e-09 - accuracy: 1.0000 - val_loss: 0.1932 - val_accuracy: 0.9808\n",
            "Epoch 171/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3669e-09 - accuracy: 1.0000 - val_loss: 0.1932 - val_accuracy: 0.9809\n",
            "Epoch 172/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3510e-09 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9808\n",
            "Epoch 173/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3113e-09 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9809\n",
            "Epoch 174/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2557e-09 - accuracy: 1.0000 - val_loss: 0.1935 - val_accuracy: 0.9809\n",
            "Epoch 175/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2292e-09 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 0.9809\n",
            "Epoch 176/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2239e-09 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 0.9809\n",
            "Epoch 177/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1524e-09 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 0.9809\n",
            "Epoch 178/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1762e-09 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 0.9809\n",
            "Epoch 179/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1179e-09 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 0.9809\n",
            "Epoch 180/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1285e-09 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9809\n",
            "Epoch 181/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0914e-09 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9809\n",
            "Epoch 182/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0649e-09 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9809\n",
            "Epoch 183/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0570e-09 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9809\n",
            "Epoch 184/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0173e-09 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 0.9809\n",
            "Epoch 185/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0040e-09 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9809\n",
            "Epoch 186/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.8811e-10 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9809\n",
            "Epoch 187/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.5632e-10 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9809\n",
            "Epoch 188/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.3778e-10 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9807\n",
            "Epoch 189/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.7222e-10 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 0.9809\n",
            "Epoch 190/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4838e-10 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9809\n",
            "Epoch 191/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1129e-10 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 0.9808\n",
            "Epoch 192/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2453e-10 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9808\n",
            "Epoch 193/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.1129e-10 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9809\n",
            "Epoch 194/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.9539e-10 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.9807\n",
            "Epoch 195/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9010e-10 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 0.9807\n",
            "Epoch 196/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.4506e-10 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9808\n",
            "Epoch 197/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6890e-10 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 0.9809\n",
            "Epoch 198/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.1857e-10 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9809\n",
            "Epoch 199/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5036e-10 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9808\n",
            "Epoch 200/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.6890e-10 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9809\n",
            "Epoch 201/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.1592e-10 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.9809\n",
            "Epoch 202/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.5831e-10 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9808\n",
            "Epoch 203/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2122e-10 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9809\n",
            "Epoch 204/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.2122e-10 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 0.9807\n",
            "Epoch 205/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.0797e-10 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 0.9807\n",
            "Epoch 206/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.6294e-10 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 0.9809\n",
            "Epoch 207/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.0797e-10 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.9807\n",
            "Epoch 208/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8413e-10 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9807\n",
            "Epoch 209/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.3380e-10 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9807\n",
            "Epoch 210/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.0003e-10 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.9806\n",
            "Epoch 211/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7354e-10 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.9806\n",
            "Epoch 212/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7883e-10 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.9806\n",
            "Epoch 213/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.6824e-10 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9805\n",
            "Epoch 214/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4175e-10 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 0.9805\n",
            "Epoch 215/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8148e-10 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9805\n",
            "Epoch 216/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7618e-10 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9805\n",
            "Epoch 217/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.1790e-10 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9807\n",
            "Epoch 218/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8678e-10 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9807\n",
            "Epoch 219/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.3115e-10 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9804\n",
            "Epoch 220/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.2055e-10 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9805\n",
            "Epoch 221/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4704e-10 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9805\n",
            "Epoch 222/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.3115e-10 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 0.9805\n",
            "Epoch 223/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.3380e-10 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9805\n",
            "Epoch 224/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3115e-10 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.9805\n",
            "Epoch 225/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4969e-10 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9805\n",
            "Epoch 226/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.2850e-10 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.9805\n",
            "Epoch 227/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4440e-10 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9805\n",
            "Epoch 228/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.2320e-10 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9805\n",
            "Epoch 229/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2055e-10 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9805\n",
            "Epoch 230/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.1790e-10 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9805\n",
            "Epoch 231/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.2585e-10 - accuracy: 1.0000 - val_loss: 0.1996 - val_accuracy: 0.9806\n",
            "Epoch 232/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0731e-10 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.9805\n",
            "Epoch 233/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.6559e-10 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9805\n",
            "Epoch 234/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.2585e-10 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.9805\n",
            "Epoch 235/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1790e-10 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9807\n",
            "Epoch 236/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.1526e-10 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9806\n",
            "Epoch 237/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.5499e-10 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9807\n",
            "Epoch 238/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0996e-10 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9806\n",
            "Epoch 239/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5234e-10 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9806\n",
            "Epoch 240/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4969e-10 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9807\n",
            "Epoch 241/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.5234e-10 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9807\n",
            "Epoch 242/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7089e-10 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9805\n",
            "Epoch 243/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.1526e-10 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9805\n",
            "Epoch 244/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.3910e-10 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9805\n",
            "Epoch 245/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4704e-10 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9805\n",
            "Epoch 246/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4704e-10 - accuracy: 1.0000 - val_loss: 0.2025 - val_accuracy: 0.9806\n",
            "Epoch 247/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.6559e-10 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9805\n",
            "Epoch 248/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4440e-10 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9805\n",
            "Epoch 249/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6559e-10 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9805\n",
            "Epoch 250/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.6824e-10 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9804\n",
            "Epoch 251/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1261e-10 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9804\n",
            "Epoch 252/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8413e-10 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.9805\n",
            "Epoch 253/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4704e-10 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9805\n",
            "Epoch 254/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7089e-10 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 0.9804\n",
            "Epoch 255/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2585e-10 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 0.9805\n",
            "Epoch 256/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9473e-10 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9804\n",
            "Epoch 257/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.5234e-10 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9804\n",
            "Epoch 258/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.6294e-10 - accuracy: 1.0000 - val_loss: 0.2051 - val_accuracy: 0.9804\n",
            "Epoch 259/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7618e-10 - accuracy: 1.0000 - val_loss: 0.2053 - val_accuracy: 0.9804\n",
            "Epoch 260/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7354e-10 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9804\n",
            "Epoch 261/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4704e-10 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9803\n",
            "Epoch 262/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.0268e-10 - accuracy: 1.0000 - val_loss: 0.2062 - val_accuracy: 0.9803\n",
            "Epoch 263/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.0003e-10 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9803\n",
            "Epoch 264/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.0268e-10 - accuracy: 1.0000 - val_loss: 0.2064 - val_accuracy: 0.9803\n",
            "Epoch 265/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1062e-10 - accuracy: 1.0000 - val_loss: 0.2066 - val_accuracy: 0.9803\n",
            "Epoch 266/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.0003e-10 - accuracy: 1.0000 - val_loss: 0.2070 - val_accuracy: 0.9803\n",
            "Epoch 267/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8943e-10 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9803\n",
            "Epoch 268/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.1327e-10 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9802\n",
            "Epoch 269/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0797e-10 - accuracy: 1.0000 - val_loss: 0.2078 - val_accuracy: 0.9803\n",
            "Epoch 270/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.0268e-10 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9803\n",
            "Epoch 271/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2917e-10 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9802\n",
            "Epoch 272/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.4241e-10 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9803\n",
            "Epoch 273/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1062e-10 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9801\n",
            "Epoch 274/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.1062e-10 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.9802\n",
            "Epoch 275/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.5831e-10 - accuracy: 1.0000 - val_loss: 0.2093 - val_accuracy: 0.9802\n",
            "Epoch 276/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.3976e-10 - accuracy: 1.0000 - val_loss: 0.2097 - val_accuracy: 0.9802\n",
            "Epoch 277/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2652e-10 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 0.9803\n",
            "Epoch 278/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2122e-10 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 0.9804\n",
            "Epoch 279/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.1129e-10 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 0.9804\n",
            "Epoch 280/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2917e-10 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9804\n",
            "Epoch 281/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0334e-10 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9803\n",
            "Epoch 282/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5831e-10 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9803\n",
            "Epoch 283/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.6096e-10 - accuracy: 1.0000 - val_loss: 0.2117 - val_accuracy: 0.9803\n",
            "Epoch 284/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.9010e-10 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9805\n",
            "Epoch 285/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9804e-10 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 0.9805\n",
            "Epoch 286/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.6096e-10 - accuracy: 1.0000 - val_loss: 0.2126 - val_accuracy: 0.9804\n",
            "Epoch 287/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.2189e-10 - accuracy: 1.0000 - val_loss: 0.2131 - val_accuracy: 0.9803\n",
            "Epoch 288/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.1659e-10 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9805\n",
            "Epoch 289/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0599e-10 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9803\n",
            "Epoch 290/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.2983e-10 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9805\n",
            "Epoch 291/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1659e-10 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9803\n",
            "Epoch 292/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.3248e-10 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9803\n",
            "Epoch 293/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3513e-10 - accuracy: 1.0000 - val_loss: 0.2149 - val_accuracy: 0.9803\n",
            "Epoch 294/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3248e-10 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 0.9803\n",
            "Epoch 295/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.8281e-10 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9803\n",
            "Epoch 296/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.2983e-10 - accuracy: 1.0000 - val_loss: 0.2158 - val_accuracy: 0.9802\n",
            "Epoch 297/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7222e-10 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 0.9802\n",
            "Epoch 298/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9076e-10 - accuracy: 1.0000 - val_loss: 0.2166 - val_accuracy: 0.9804\n",
            "Epoch 299/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7487e-10 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9802\n",
            "Epoch 300/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.8017e-10 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9802\n",
            "Epoch 301/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.8811e-10 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9803\n",
            "Epoch 302/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.9871e-10 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9803\n",
            "Epoch 303/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0067e-09 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9803\n",
            "Epoch 304/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0437e-09 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9803\n",
            "Epoch 305/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9341e-10 - accuracy: 1.0000 - val_loss: 0.2191 - val_accuracy: 0.9803\n",
            "Epoch 306/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0384e-09 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 0.9803\n",
            "Epoch 307/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0676e-09 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9803\n",
            "Epoch 308/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0384e-09 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9804\n",
            "Epoch 309/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0146e-09 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9803\n",
            "Epoch 310/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0755e-09 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9803\n",
            "Epoch 311/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0782e-09 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9803\n",
            "Epoch 312/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0252e-09 - accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 0.9804\n",
            "Epoch 313/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0835e-09 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9804\n",
            "Epoch 314/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0623e-09 - accuracy: 1.0000 - val_loss: 0.2226 - val_accuracy: 0.9804\n",
            "Epoch 315/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1285e-09 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9803\n",
            "Epoch 316/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0941e-09 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.9803\n",
            "Epoch 317/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1047e-09 - accuracy: 1.0000 - val_loss: 0.2239 - val_accuracy: 0.9803\n",
            "Epoch 318/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1418e-09 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.9803\n",
            "Epoch 319/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1126e-09 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9803\n",
            "Epoch 320/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1391e-09 - accuracy: 1.0000 - val_loss: 0.2249 - val_accuracy: 0.9802\n",
            "Epoch 321/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1259e-09 - accuracy: 1.0000 - val_loss: 0.2251 - val_accuracy: 0.9802\n",
            "Epoch 322/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1418e-09 - accuracy: 1.0000 - val_loss: 0.2257 - val_accuracy: 0.9802\n",
            "Epoch 323/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1709e-09 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9801\n",
            "Epoch 324/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1418e-09 - accuracy: 1.0000 - val_loss: 0.2265 - val_accuracy: 0.9801\n",
            "Epoch 325/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1683e-09 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9803\n",
            "Epoch 326/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1603e-09 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9801\n",
            "Epoch 327/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1709e-09 - accuracy: 1.0000 - val_loss: 0.2278 - val_accuracy: 0.9802\n",
            "Epoch 328/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1894e-09 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 0.9801\n",
            "Epoch 329/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1444e-09 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9801\n",
            "Epoch 330/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1868e-09 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.9802\n",
            "Epoch 331/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1921e-09 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9801\n",
            "Epoch 332/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2159e-09 - accuracy: 1.0000 - val_loss: 0.2296 - val_accuracy: 0.9800\n",
            "Epoch 333/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1974e-09 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.9801\n",
            "Epoch 334/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2000e-09 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 0.9803\n",
            "Epoch 335/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2106e-09 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9801\n",
            "Epoch 336/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1947e-09 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9801\n",
            "Epoch 337/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2424e-09 - accuracy: 1.0000 - val_loss: 0.2315 - val_accuracy: 0.9802\n",
            "Epoch 338/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2186e-09 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9803\n",
            "Epoch 339/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2000e-09 - accuracy: 1.0000 - val_loss: 0.2327 - val_accuracy: 0.9801\n",
            "Epoch 340/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2477e-09 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.9801\n",
            "Epoch 341/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2345e-09 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9801\n",
            "Epoch 342/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2530e-09 - accuracy: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9803\n",
            "Epoch 343/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2477e-09 - accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 0.9801\n",
            "Epoch 344/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2557e-09 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9802\n",
            "Epoch 345/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3325e-09 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9803\n",
            "Epoch 346/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2053e-09 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9802\n",
            "Epoch 347/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3404e-09 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9801\n",
            "Epoch 348/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2663e-09 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9801\n",
            "Epoch 349/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2928e-09 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9802\n",
            "Epoch 350/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2769e-09 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9801\n",
            "Epoch 351/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2981e-09 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9800\n",
            "Epoch 352/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3298e-09 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9801\n",
            "Epoch 353/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3510e-09 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9799\n",
            "Epoch 354/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2954e-09 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9798\n",
            "Epoch 355/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3192e-09 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9799\n",
            "Epoch 356/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3378e-09 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9798\n",
            "Epoch 357/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3510e-09 - accuracy: 1.0000 - val_loss: 0.2407 - val_accuracy: 0.9797\n",
            "Epoch 358/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3537e-09 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9797\n",
            "Epoch 359/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3802e-09 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 0.9796\n",
            "Epoch 360/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3272e-09 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9796\n",
            "Epoch 361/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4040e-09 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9796\n",
            "Epoch 362/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4014e-09 - accuracy: 1.0000 - val_loss: 0.2429 - val_accuracy: 0.9795\n",
            "Epoch 363/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3802e-09 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9797\n",
            "Epoch 364/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4067e-09 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9794\n",
            "Epoch 365/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3934e-09 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9795\n",
            "Epoch 366/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4067e-09 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9795\n",
            "Epoch 367/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4040e-09 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9793\n",
            "Epoch 368/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4226e-09 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9797\n",
            "Epoch 369/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4411e-09 - accuracy: 1.0000 - val_loss: 0.2461 - val_accuracy: 0.9797\n",
            "Epoch 370/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4491e-09 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9793\n",
            "Epoch 371/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4464e-09 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9795\n",
            "Epoch 372/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4623e-09 - accuracy: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.9797\n",
            "Epoch 373/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4676e-09 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9795\n",
            "Epoch 374/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4623e-09 - accuracy: 1.0000 - val_loss: 0.2486 - val_accuracy: 0.9797\n",
            "Epoch 375/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4332e-09 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.9795\n",
            "Epoch 376/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4888e-09 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9795\n",
            "Epoch 377/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4808e-09 - accuracy: 1.0000 - val_loss: 0.2496 - val_accuracy: 0.9791\n",
            "Epoch 378/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5126e-09 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9796\n",
            "Epoch 379/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4570e-09 - accuracy: 1.0000 - val_loss: 0.2499 - val_accuracy: 0.9793\n",
            "Epoch 380/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5603e-09 - accuracy: 1.0000 - val_loss: 0.2507 - val_accuracy: 0.9793\n",
            "Epoch 381/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5444e-09 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.9794\n",
            "Epoch 382/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5683e-09 - accuracy: 1.0000 - val_loss: 0.2520 - val_accuracy: 0.9793\n",
            "Epoch 383/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5365e-09 - accuracy: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.9790\n",
            "Epoch 384/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5550e-09 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9791\n",
            "Epoch 385/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6663e-09 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.9791\n",
            "Epoch 386/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5789e-09 - accuracy: 1.0000 - val_loss: 0.2537 - val_accuracy: 0.9792\n",
            "Epoch 387/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5683e-09 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.9791\n",
            "Epoch 388/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6106e-09 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.9791\n",
            "Epoch 389/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6345e-09 - accuracy: 1.0000 - val_loss: 0.2554 - val_accuracy: 0.9791\n",
            "Epoch 390/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5709e-09 - accuracy: 1.0000 - val_loss: 0.2547 - val_accuracy: 0.9791\n",
            "Epoch 391/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5895e-09 - accuracy: 1.0000 - val_loss: 0.2561 - val_accuracy: 0.9789\n",
            "Epoch 392/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6451e-09 - accuracy: 1.0000 - val_loss: 0.2572 - val_accuracy: 0.9789\n",
            "Epoch 393/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6159e-09 - accuracy: 1.0000 - val_loss: 0.2570 - val_accuracy: 0.9789\n",
            "Epoch 394/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6822e-09 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.9790\n",
            "Epoch 395/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6848e-09 - accuracy: 1.0000 - val_loss: 0.2577 - val_accuracy: 0.9790\n",
            "Epoch 396/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6530e-09 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9789\n",
            "Epoch 397/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8093e-09 - accuracy: 1.0000 - val_loss: 0.2588 - val_accuracy: 0.9791\n",
            "Epoch 398/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7722e-09 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9788\n",
            "Epoch 399/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7484e-09 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.9788\n",
            "Epoch 400/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8835e-09 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.9790\n",
            "Epoch 401/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8358e-09 - accuracy: 1.0000 - val_loss: 0.2610 - val_accuracy: 0.9789\n",
            "Epoch 402/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7802e-09 - accuracy: 1.0000 - val_loss: 0.2616 - val_accuracy: 0.9787\n",
            "Epoch 403/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7961e-09 - accuracy: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.9789\n",
            "Epoch 404/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7378e-09 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9787\n",
            "Epoch 405/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8385e-09 - accuracy: 1.0000 - val_loss: 0.2622 - val_accuracy: 0.9789\n",
            "Epoch 406/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.1632 - accuracy: 0.9863 - val_loss: 0.1691 - val_accuracy: 0.9775\n",
            "Epoch 407/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.1538 - val_accuracy: 0.9784\n",
            "Epoch 408/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.1514 - val_accuracy: 0.9801\n",
            "Epoch 409/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2773e-04 - accuracy: 0.9999 - val_loss: 0.1475 - val_accuracy: 0.9802\n",
            "Epoch 410/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1892e-05 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 0.9805\n",
            "Epoch 411/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9480e-05 - accuracy: 1.0000 - val_loss: 0.1480 - val_accuracy: 0.9806\n",
            "Epoch 412/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3018e-05 - accuracy: 1.0000 - val_loss: 0.1481 - val_accuracy: 0.9806\n",
            "Epoch 413/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8311e-05 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 0.9807\n",
            "Epoch 414/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4625e-05 - accuracy: 1.0000 - val_loss: 0.1485 - val_accuracy: 0.9806\n",
            "Epoch 415/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1680e-05 - accuracy: 1.0000 - val_loss: 0.1488 - val_accuracy: 0.9805\n",
            "Epoch 416/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9213e-05 - accuracy: 1.0000 - val_loss: 0.1490 - val_accuracy: 0.9805\n",
            "Epoch 417/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7169e-05 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.9804\n",
            "Epoch 418/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5454e-05 - accuracy: 1.0000 - val_loss: 0.1495 - val_accuracy: 0.9804\n",
            "Epoch 419/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3922e-05 - accuracy: 1.0000 - val_loss: 0.1498 - val_accuracy: 0.9805\n",
            "Epoch 420/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2636e-05 - accuracy: 1.0000 - val_loss: 0.1502 - val_accuracy: 0.9805\n",
            "Epoch 421/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1495e-05 - accuracy: 1.0000 - val_loss: 0.1505 - val_accuracy: 0.9806\n",
            "Epoch 422/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0481e-05 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 0.9807\n",
            "Epoch 423/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5808e-06 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 0.9807\n",
            "Epoch 424/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7758e-06 - accuracy: 1.0000 - val_loss: 0.1513 - val_accuracy: 0.9807\n",
            "Epoch 425/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0479e-06 - accuracy: 1.0000 - val_loss: 0.1515 - val_accuracy: 0.9808\n",
            "Epoch 426/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4018e-06 - accuracy: 1.0000 - val_loss: 0.1519 - val_accuracy: 0.9809\n",
            "Epoch 427/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7653e-06 - accuracy: 1.0000 - val_loss: 0.1522 - val_accuracy: 0.9808\n",
            "Epoch 428/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2324e-06 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 0.9808\n",
            "Epoch 429/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7281e-06 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9808\n",
            "Epoch 430/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2603e-06 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9809\n",
            "Epoch 431/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.8435e-06 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9805\n",
            "Epoch 432/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.4523e-06 - accuracy: 1.0000 - val_loss: 0.1541 - val_accuracy: 0.9807\n",
            "Epoch 433/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1013e-06 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 0.9805\n",
            "Epoch 434/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7729e-06 - accuracy: 1.0000 - val_loss: 0.1548 - val_accuracy: 0.9805\n",
            "Epoch 435/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.4777e-06 - accuracy: 1.0000 - val_loss: 0.1551 - val_accuracy: 0.9803\n",
            "Epoch 436/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2023e-06 - accuracy: 1.0000 - val_loss: 0.1557 - val_accuracy: 0.9805\n",
            "Epoch 437/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9399e-06 - accuracy: 1.0000 - val_loss: 0.1561 - val_accuracy: 0.9806\n",
            "Epoch 438/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7044e-06 - accuracy: 1.0000 - val_loss: 0.1564 - val_accuracy: 0.9807\n",
            "Epoch 439/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4868e-06 - accuracy: 1.0000 - val_loss: 0.1569 - val_accuracy: 0.9806\n",
            "Epoch 440/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2880e-06 - accuracy: 1.0000 - val_loss: 0.1572 - val_accuracy: 0.9808\n",
            "Epoch 441/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1052e-06 - accuracy: 1.0000 - val_loss: 0.1579 - val_accuracy: 0.9807\n",
            "Epoch 442/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9320e-06 - accuracy: 1.0000 - val_loss: 0.1582 - val_accuracy: 0.9809\n",
            "Epoch 443/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7783e-06 - accuracy: 1.0000 - val_loss: 0.1587 - val_accuracy: 0.9809\n",
            "Epoch 444/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6383e-06 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 0.9807\n",
            "Epoch 445/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5063e-06 - accuracy: 1.0000 - val_loss: 0.1597 - val_accuracy: 0.9809\n",
            "Epoch 446/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3835e-06 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9809\n",
            "Epoch 447/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2765e-06 - accuracy: 1.0000 - val_loss: 0.1607 - val_accuracy: 0.9809\n",
            "Epoch 448/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1683e-06 - accuracy: 1.0000 - val_loss: 0.1610 - val_accuracy: 0.9811\n",
            "Epoch 449/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0774e-06 - accuracy: 1.0000 - val_loss: 0.1616 - val_accuracy: 0.9811\n",
            "Epoch 450/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.8939e-07 - accuracy: 1.0000 - val_loss: 0.1623 - val_accuracy: 0.9810\n",
            "Epoch 451/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.1377e-07 - accuracy: 1.0000 - val_loss: 0.1629 - val_accuracy: 0.9810\n",
            "Epoch 452/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3999e-07 - accuracy: 1.0000 - val_loss: 0.1634 - val_accuracy: 0.9809\n",
            "Epoch 453/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7611e-07 - accuracy: 1.0000 - val_loss: 0.1639 - val_accuracy: 0.9808\n",
            "Epoch 454/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1195e-07 - accuracy: 1.0000 - val_loss: 0.1644 - val_accuracy: 0.9809\n",
            "Epoch 455/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5642e-07 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9808\n",
            "Epoch 456/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0445e-07 - accuracy: 1.0000 - val_loss: 0.1657 - val_accuracy: 0.9811\n",
            "Epoch 457/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5528e-07 - accuracy: 1.0000 - val_loss: 0.1662 - val_accuracy: 0.9810\n",
            "Epoch 458/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1225e-07 - accuracy: 1.0000 - val_loss: 0.1667 - val_accuracy: 0.9809\n",
            "Epoch 459/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7145e-07 - accuracy: 1.0000 - val_loss: 0.1674 - val_accuracy: 0.9810\n",
            "Epoch 460/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.3434e-07 - accuracy: 1.0000 - val_loss: 0.1680 - val_accuracy: 0.9810\n",
            "Epoch 461/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0036e-07 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9811\n",
            "Epoch 462/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6808e-07 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 0.9810\n",
            "Epoch 463/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3890e-07 - accuracy: 1.0000 - val_loss: 0.1700 - val_accuracy: 0.9810\n",
            "Epoch 464/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1287e-07 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 0.9812\n",
            "Epoch 465/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8718e-07 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 0.9809\n",
            "Epoch 466/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6450e-07 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 0.9809\n",
            "Epoch 467/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4299e-07 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 0.9810\n",
            "Epoch 468/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2408e-07 - accuracy: 1.0000 - val_loss: 0.1733 - val_accuracy: 0.9811\n",
            "Epoch 469/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0666e-07 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 0.9810\n",
            "Epoch 470/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9045e-07 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9809\n",
            "Epoch 471/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7474e-07 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 0.9809\n",
            "Epoch 472/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6150e-07 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 0.9809\n",
            "Epoch 473/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4873e-07 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 0.9809\n",
            "Epoch 474/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3721e-07 - accuracy: 1.0000 - val_loss: 0.1773 - val_accuracy: 0.9810\n",
            "Epoch 475/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2681e-07 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 0.9812\n",
            "Epoch 476/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1677e-07 - accuracy: 1.0000 - val_loss: 0.1785 - val_accuracy: 0.9813\n",
            "Epoch 477/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0819e-07 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.9811\n",
            "Epoch 478/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9812e-08 - accuracy: 1.0000 - val_loss: 0.1798 - val_accuracy: 0.9812\n",
            "Epoch 479/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2225e-08 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 0.9811\n",
            "Epoch 480/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.5205e-08 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 0.9812\n",
            "Epoch 481/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.8659e-08 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9811\n",
            "Epoch 482/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.2585e-08 - accuracy: 1.0000 - val_loss: 0.1823 - val_accuracy: 0.9811\n",
            "Epoch 483/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7112e-08 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 0.9812\n",
            "Epoch 484/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.2121e-08 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9812\n",
            "Epoch 485/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7528e-08 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9811\n",
            "Epoch 486/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.3260e-08 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9812\n",
            "Epoch 487/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.9398e-08 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9813\n",
            "Epoch 488/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5570e-08 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9813\n",
            "Epoch 489/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.2322e-08 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9813\n",
            "Epoch 490/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.9066e-08 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9813\n",
            "Epoch 491/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6444e-08 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.9813\n",
            "Epoch 492/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3768e-08 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 0.9813\n",
            "Epoch 493/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1320e-08 - accuracy: 1.0000 - val_loss: 0.1892 - val_accuracy: 0.9813\n",
            "Epoch 494/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9220e-08 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9813\n",
            "Epoch 495/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7050e-08 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 0.9813\n",
            "Epoch 496/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5092e-08 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9813\n",
            "Epoch 497/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3421e-08 - accuracy: 1.0000 - val_loss: 0.1916 - val_accuracy: 0.9814\n",
            "Epoch 498/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1651e-08 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9816\n",
            "Epoch 499/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0189e-08 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9815\n",
            "Epoch 500/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8774e-08 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9816\n",
            "Epoch 501/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7540e-08 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9815\n",
            "Epoch 502/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6340e-08 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9815\n",
            "Epoch 503/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5338e-08 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9815\n",
            "Epoch 504/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4157e-08 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9815\n",
            "Epoch 505/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3293e-08 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.9815\n",
            "Epoch 506/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2350e-08 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9815\n",
            "Epoch 507/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1537e-08 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 0.9815\n",
            "Epoch 508/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0782e-08 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 0.9815\n",
            "Epoch 509/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0104e-08 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.9815\n",
            "Epoch 510/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.5103e-09 - accuracy: 1.0000 - val_loss: 0.1996 - val_accuracy: 0.9816\n",
            "Epoch 511/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8612e-09 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.9816\n",
            "Epoch 512/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.2705e-09 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9815\n",
            "Epoch 513/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.7618e-09 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9815\n",
            "Epoch 514/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2373e-09 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9815\n",
            "Epoch 515/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7737e-09 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.9816\n",
            "Epoch 516/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3764e-09 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9815\n",
            "Epoch 517/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.9287e-09 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9816\n",
            "Epoch 518/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.6134e-09 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 0.9816\n",
            "Epoch 519/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2717e-09 - accuracy: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.9815\n",
            "Epoch 520/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9644e-09 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9814\n",
            "Epoch 521/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6836e-09 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9815\n",
            "Epoch 522/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.4266e-09 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9815\n",
            "Epoch 523/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.2041e-09 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9814\n",
            "Epoch 524/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9816e-09 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9815\n",
            "Epoch 525/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7458e-09 - accuracy: 1.0000 - val_loss: 0.2087 - val_accuracy: 0.9814\n",
            "Epoch 526/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5233e-09 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 0.9815\n",
            "Epoch 527/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3061e-09 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9814\n",
            "Epoch 528/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0915e-09 - accuracy: 1.0000 - val_loss: 0.2106 - val_accuracy: 0.9814\n",
            "Epoch 529/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9590e-09 - accuracy: 1.0000 - val_loss: 0.2112 - val_accuracy: 0.9814\n",
            "Epoch 530/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7630e-09 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9814\n",
            "Epoch 531/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6200e-09 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 0.9815\n",
            "Epoch 532/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4822e-09 - accuracy: 1.0000 - val_loss: 0.2131 - val_accuracy: 0.9815\n",
            "Epoch 533/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3471e-09 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9814\n",
            "Epoch 534/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2252e-09 - accuracy: 1.0000 - val_loss: 0.2146 - val_accuracy: 0.9815\n",
            "Epoch 535/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0610e-09 - accuracy: 1.0000 - val_loss: 0.2155 - val_accuracy: 0.9815\n",
            "Epoch 536/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9524e-09 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 0.9815\n",
            "Epoch 537/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8676e-09 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9817\n",
            "Epoch 538/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8014e-09 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9817\n",
            "Epoch 539/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7193e-09 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9817\n",
            "Epoch 540/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6424e-09 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9817\n",
            "Epoch 541/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6265e-09 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9817\n",
            "Epoch 542/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5206e-09 - accuracy: 1.0000 - val_loss: 0.2206 - val_accuracy: 0.9817\n",
            "Epoch 543/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4782e-09 - accuracy: 1.0000 - val_loss: 0.2215 - val_accuracy: 0.9815\n",
            "Epoch 544/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4093e-09 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9815\n",
            "Epoch 545/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3510e-09 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9815\n",
            "Epoch 546/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3325e-09 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9815\n",
            "Epoch 547/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2795e-09 - accuracy: 1.0000 - val_loss: 0.2247 - val_accuracy: 0.9813\n",
            "Epoch 548/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2318e-09 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.9813\n",
            "Epoch 549/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2027e-09 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9814\n",
            "Epoch 550/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1577e-09 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9813\n",
            "Epoch 551/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1444e-09 - accuracy: 1.0000 - val_loss: 0.2277 - val_accuracy: 0.9812\n",
            "Epoch 552/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1285e-09 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9811\n",
            "Epoch 553/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1206e-09 - accuracy: 1.0000 - val_loss: 0.2294 - val_accuracy: 0.9811\n",
            "Epoch 554/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0808e-09 - accuracy: 1.0000 - val_loss: 0.2301 - val_accuracy: 0.9811\n",
            "Epoch 555/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0914e-09 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.9811\n",
            "Epoch 556/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0570e-09 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9809\n",
            "Epoch 557/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0120e-09 - accuracy: 1.0000 - val_loss: 0.2324 - val_accuracy: 0.9809\n",
            "Epoch 558/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0411e-09 - accuracy: 1.0000 - val_loss: 0.2332 - val_accuracy: 0.9809\n",
            "Epoch 559/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0278e-09 - accuracy: 1.0000 - val_loss: 0.2337 - val_accuracy: 0.9809\n",
            "Epoch 560/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.9341e-10 - accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 0.9807\n",
            "Epoch 561/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0067e-09 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9808\n",
            "Epoch 562/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.4838e-10 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9807\n",
            "Epoch 563/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4838e-10 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9806\n",
            "Epoch 564/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.8811e-10 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.9807\n",
            "Epoch 565/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.6692e-10 - accuracy: 1.0000 - val_loss: 0.2384 - val_accuracy: 0.9806\n",
            "Epoch 566/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7222e-10 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9806\n",
            "Epoch 567/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2189e-10 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9806\n",
            "Epoch 568/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.4838e-10 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9807\n",
            "Epoch 569/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.5367e-10 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9807\n",
            "Epoch 570/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4573e-10 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9807\n",
            "Epoch 571/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3778e-10 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9807\n",
            "Epoch 572/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1394e-10 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9807\n",
            "Epoch 573/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.2718e-10 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9806\n",
            "Epoch 574/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.6957e-10 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9806\n",
            "Epoch 575/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5897e-10 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9806\n",
            "Epoch 576/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1129e-10 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9805\n",
            "Epoch 577/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2189e-10 - accuracy: 1.0000 - val_loss: 0.2472 - val_accuracy: 0.9805\n",
            "Epoch 578/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2718e-10 - accuracy: 1.0000 - val_loss: 0.2478 - val_accuracy: 0.9806\n",
            "Epoch 579/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3778e-10 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9804\n",
            "Epoch 580/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.8546e-10 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9805\n",
            "Epoch 581/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4043e-10 - accuracy: 1.0000 - val_loss: 0.2499 - val_accuracy: 0.9804\n",
            "Epoch 582/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.7950e-10 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9804\n",
            "Epoch 583/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6427e-10 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9804\n",
            "Epoch 584/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.5103e-10 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.9803\n",
            "Epoch 585/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.5632e-10 - accuracy: 1.0000 - val_loss: 0.2528 - val_accuracy: 0.9805\n",
            "Epoch 586/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.4838e-10 - accuracy: 1.0000 - val_loss: 0.2535 - val_accuracy: 0.9805\n",
            "Epoch 587/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4838e-10 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.9805\n",
            "Epoch 588/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6427e-10 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9805\n",
            "Epoch 589/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3778e-10 - accuracy: 1.0000 - val_loss: 0.2557 - val_accuracy: 0.9806\n",
            "Epoch 590/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7487e-10 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9805\n",
            "Epoch 591/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9341e-10 - accuracy: 1.0000 - val_loss: 0.2571 - val_accuracy: 0.9804\n",
            "Epoch 592/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.7222e-10 - accuracy: 1.0000 - val_loss: 0.2574 - val_accuracy: 0.9803\n",
            "Epoch 593/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3248e-10 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.9804\n",
            "Epoch 594/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7752e-10 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9805\n",
            "Epoch 595/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6427e-10 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.9805\n",
            "Epoch 596/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5632e-10 - accuracy: 1.0000 - val_loss: 0.2598 - val_accuracy: 0.9805\n",
            "Epoch 597/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5632e-10 - accuracy: 1.0000 - val_loss: 0.2603 - val_accuracy: 0.9805\n",
            "Epoch 598/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.8546e-10 - accuracy: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.9803\n",
            "Epoch 599/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.6692e-10 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.9806\n",
            "Epoch 600/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.6957e-10 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.9803\n",
            "Epoch 601/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3778e-10 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9806\n",
            "Epoch 602/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.6957e-10 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9805\n",
            "Epoch 603/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.8546e-10 - accuracy: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.9805\n",
            "Epoch 604/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4573e-10 - accuracy: 1.0000 - val_loss: 0.2644 - val_accuracy: 0.9804\n",
            "Epoch 605/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6957e-10 - accuracy: 1.0000 - val_loss: 0.2645 - val_accuracy: 0.9803\n",
            "Epoch 606/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0014e-09 - accuracy: 1.0000 - val_loss: 0.2656 - val_accuracy: 0.9805\n",
            "Epoch 607/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5367e-10 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.9805\n",
            "Epoch 608/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.9076e-10 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.9804\n",
            "Epoch 609/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6427e-10 - accuracy: 1.0000 - val_loss: 0.2679 - val_accuracy: 0.9804\n",
            "Epoch 610/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6162e-10 - accuracy: 1.0000 - val_loss: 0.2683 - val_accuracy: 0.9804\n",
            "Epoch 611/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0173e-09 - accuracy: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.9803\n",
            "Epoch 612/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.8281e-10 - accuracy: 1.0000 - val_loss: 0.2700 - val_accuracy: 0.9803\n",
            "Epoch 613/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0014e-09 - accuracy: 1.0000 - val_loss: 0.2700 - val_accuracy: 0.9804\n",
            "Epoch 614/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9076e-10 - accuracy: 1.0000 - val_loss: 0.2708 - val_accuracy: 0.9804\n",
            "Epoch 615/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.8281e-10 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.9803\n",
            "Epoch 616/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.9871e-10 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9800\n",
            "Epoch 617/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9606e-10 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9801\n",
            "Epoch 618/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0199e-09 - accuracy: 1.0000 - val_loss: 0.2734 - val_accuracy: 0.9803\n",
            "Epoch 619/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.9606e-10 - accuracy: 1.0000 - val_loss: 0.2734 - val_accuracy: 0.9803\n",
            "Epoch 620/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.8281e-10 - accuracy: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.9801\n",
            "Epoch 621/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0252e-09 - accuracy: 1.0000 - val_loss: 0.2753 - val_accuracy: 0.9799\n",
            "Epoch 622/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0305e-09 - accuracy: 1.0000 - val_loss: 0.2757 - val_accuracy: 0.9803\n",
            "Epoch 623/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0226e-09 - accuracy: 1.0000 - val_loss: 0.2761 - val_accuracy: 0.9802\n",
            "Epoch 624/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0173e-09 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9801\n",
            "Epoch 625/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0146e-09 - accuracy: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.9803\n",
            "Epoch 626/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0173e-09 - accuracy: 1.0000 - val_loss: 0.2778 - val_accuracy: 0.9803\n",
            "Epoch 627/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0384e-09 - accuracy: 1.0000 - val_loss: 0.2787 - val_accuracy: 0.9800\n",
            "Epoch 628/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0676e-09 - accuracy: 1.0000 - val_loss: 0.2791 - val_accuracy: 0.9802\n",
            "Epoch 629/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0543e-09 - accuracy: 1.0000 - val_loss: 0.2805 - val_accuracy: 0.9802\n",
            "Epoch 630/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0384e-09 - accuracy: 1.0000 - val_loss: 0.2797 - val_accuracy: 0.9803\n",
            "Epoch 631/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0305e-09 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9801\n",
            "Epoch 632/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0596e-09 - accuracy: 1.0000 - val_loss: 0.2810 - val_accuracy: 0.9802\n",
            "Epoch 633/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0278e-09 - accuracy: 1.0000 - val_loss: 0.2812 - val_accuracy: 0.9802\n",
            "Epoch 634/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0331e-09 - accuracy: 1.0000 - val_loss: 0.2827 - val_accuracy: 0.9802\n",
            "Epoch 635/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0517e-09 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.9801\n",
            "Epoch 636/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0835e-09 - accuracy: 1.0000 - val_loss: 0.2830 - val_accuracy: 0.9803\n",
            "Epoch 637/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0808e-09 - accuracy: 1.0000 - val_loss: 0.2845 - val_accuracy: 0.9799\n",
            "Epoch 638/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1073e-09 - accuracy: 1.0000 - val_loss: 0.2845 - val_accuracy: 0.9801\n",
            "Epoch 639/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1232e-09 - accuracy: 1.0000 - val_loss: 0.2850 - val_accuracy: 0.9802\n",
            "Epoch 640/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0729e-09 - accuracy: 1.0000 - val_loss: 0.2852 - val_accuracy: 0.9799\n",
            "Epoch 641/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0994e-09 - accuracy: 1.0000 - val_loss: 0.2858 - val_accuracy: 0.9802\n",
            "Epoch 642/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1312e-09 - accuracy: 1.0000 - val_loss: 0.2869 - val_accuracy: 0.9800\n",
            "Epoch 643/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1153e-09 - accuracy: 1.0000 - val_loss: 0.2869 - val_accuracy: 0.9801\n",
            "Epoch 644/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1179e-09 - accuracy: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.9801\n",
            "Epoch 645/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1312e-09 - accuracy: 1.0000 - val_loss: 0.2889 - val_accuracy: 0.9803\n",
            "Epoch 646/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0941e-09 - accuracy: 1.0000 - val_loss: 0.2903 - val_accuracy: 0.9802\n",
            "Epoch 647/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1497e-09 - accuracy: 1.0000 - val_loss: 0.2898 - val_accuracy: 0.9804\n",
            "Epoch 648/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1338e-09 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.9800\n",
            "Epoch 649/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2159e-09 - accuracy: 1.0000 - val_loss: 0.2910 - val_accuracy: 0.9803\n",
            "Epoch 650/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1947e-09 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9802\n",
            "Epoch 651/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1312e-09 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.9802\n",
            "Epoch 652/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1524e-09 - accuracy: 1.0000 - val_loss: 0.2910 - val_accuracy: 0.9803\n",
            "Epoch 653/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2159e-09 - accuracy: 1.0000 - val_loss: 0.2932 - val_accuracy: 0.9803\n",
            "Epoch 654/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2133e-09 - accuracy: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.9803\n",
            "Epoch 655/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2000e-09 - accuracy: 1.0000 - val_loss: 0.2948 - val_accuracy: 0.9800\n",
            "Epoch 656/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2239e-09 - accuracy: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.9799\n",
            "Epoch 657/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1630e-09 - accuracy: 1.0000 - val_loss: 0.2944 - val_accuracy: 0.9802\n",
            "Epoch 658/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1206e-09 - accuracy: 1.0000 - val_loss: 0.2961 - val_accuracy: 0.9801\n",
            "Epoch 659/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2371e-09 - accuracy: 1.0000 - val_loss: 0.2958 - val_accuracy: 0.9802\n",
            "Epoch 660/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1921e-09 - accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.9803\n",
            "Epoch 661/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1735e-09 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.9799\n",
            "Epoch 662/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2000e-09 - accuracy: 1.0000 - val_loss: 0.2993 - val_accuracy: 0.9801\n",
            "Epoch 663/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2451e-09 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.9801\n",
            "Epoch 664/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0720 - accuracy: 0.9948 - val_loss: 0.6291 - val_accuracy: 0.9613\n",
            "Epoch 665/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0604 - accuracy: 0.9907 - val_loss: 0.2002 - val_accuracy: 0.9755\n",
            "Epoch 666/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.1824 - val_accuracy: 0.9786\n",
            "Epoch 667/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6063e-04 - accuracy: 0.9997 - val_loss: 0.1836 - val_accuracy: 0.9780\n",
            "Epoch 668/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.8903e-04 - accuracy: 0.9999 - val_loss: 0.1744 - val_accuracy: 0.9792\n",
            "Epoch 669/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9776e-04 - accuracy: 0.9999 - val_loss: 0.1790 - val_accuracy: 0.9789\n",
            "Epoch 670/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7706e-05 - accuracy: 1.0000 - val_loss: 0.1767 - val_accuracy: 0.9790\n",
            "Epoch 671/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6538e-05 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9791\n",
            "Epoch 672/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3927e-05 - accuracy: 1.0000 - val_loss: 0.1773 - val_accuracy: 0.9789\n",
            "Epoch 673/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1989e-05 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 0.9790\n",
            "Epoch 674/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0614e-05 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 0.9789\n",
            "Epoch 675/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.5486e-06 - accuracy: 1.0000 - val_loss: 0.1781 - val_accuracy: 0.9789\n",
            "Epoch 676/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.6131e-06 - accuracy: 1.0000 - val_loss: 0.1783 - val_accuracy: 0.9791\n",
            "Epoch 677/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.8115e-06 - accuracy: 1.0000 - val_loss: 0.1787 - val_accuracy: 0.9792\n",
            "Epoch 678/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1191e-06 - accuracy: 1.0000 - val_loss: 0.1784 - val_accuracy: 0.9791\n",
            "Epoch 679/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5836e-06 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 0.9793\n",
            "Epoch 680/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.8924e-06 - accuracy: 1.0000 - val_loss: 0.1794 - val_accuracy: 0.9793\n",
            "Epoch 681/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.4015e-06 - accuracy: 1.0000 - val_loss: 0.1799 - val_accuracy: 0.9793\n",
            "Epoch 682/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.9181e-06 - accuracy: 1.0000 - val_loss: 0.1801 - val_accuracy: 0.9795\n",
            "Epoch 683/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4770e-06 - accuracy: 1.0000 - val_loss: 0.1808 - val_accuracy: 0.9797\n",
            "Epoch 684/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0983e-06 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9797\n",
            "Epoch 685/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.7031e-06 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9798\n",
            "Epoch 686/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3467e-06 - accuracy: 1.0000 - val_loss: 0.1826 - val_accuracy: 0.9798\n",
            "Epoch 687/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8428e-06 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9797\n",
            "Epoch 688/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0840e-06 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 0.9795\n",
            "Epoch 689/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5163e-06 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 0.9798\n",
            "Epoch 690/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1149e-06 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 0.9798\n",
            "Epoch 691/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.4952e-07 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9800\n",
            "Epoch 692/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.9007e-07 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9801\n",
            "Epoch 693/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6290e-07 - accuracy: 1.0000 - val_loss: 0.2158 - val_accuracy: 0.9801\n",
            "Epoch 694/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2633e-07 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9801\n",
            "Epoch 695/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.8222e-07 - accuracy: 1.0000 - val_loss: 0.2215 - val_accuracy: 0.9803\n",
            "Epoch 696/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3202e-07 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9802\n",
            "Epoch 697/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8225e-07 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9803\n",
            "Epoch 698/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8297e-07 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9802\n",
            "Epoch 699/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2674e-07 - accuracy: 1.0000 - val_loss: 0.2268 - val_accuracy: 0.9805\n",
            "Epoch 700/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9716e-07 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.9804\n",
            "Epoch 701/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7363e-07 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9803\n",
            "Epoch 702/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4916e-07 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.9805\n",
            "Epoch 703/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3572e-07 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.9804\n",
            "Epoch 704/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1671e-07 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9805\n",
            "Epoch 705/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0406e-07 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9803\n",
            "Epoch 706/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9522e-07 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9804\n",
            "Epoch 707/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7400e-07 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.9803\n",
            "Epoch 708/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7143e-07 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9804\n",
            "Epoch 709/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5433e-07 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9805\n",
            "Epoch 710/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1414e-07 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 0.9805\n",
            "Epoch 711/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7099e-07 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9805\n",
            "Epoch 712/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4125e-07 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9805\n",
            "Epoch 713/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2724e-07 - accuracy: 1.0000 - val_loss: 0.2388 - val_accuracy: 0.9804\n",
            "Epoch 714/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1951e-07 - accuracy: 1.0000 - val_loss: 0.2395 - val_accuracy: 0.9804\n",
            "Epoch 715/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0969e-07 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9804\n",
            "Epoch 716/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0472e-07 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9805\n",
            "Epoch 717/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6564e-08 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9805\n",
            "Epoch 718/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.2307e-08 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9804\n",
            "Epoch 719/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.5865e-08 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9804\n",
            "Epoch 720/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0283e-08 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.9804\n",
            "Epoch 721/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.5176e-08 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9804\n",
            "Epoch 722/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2150e-08 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.9804\n",
            "Epoch 723/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.7946e-08 - accuracy: 1.0000 - val_loss: 0.2471 - val_accuracy: 0.9804\n",
            "Epoch 724/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3462e-08 - accuracy: 1.0000 - val_loss: 0.2473 - val_accuracy: 0.9803\n",
            "Epoch 725/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.8993e-08 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9801\n",
            "Epoch 726/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7422e-08 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.9804\n",
            "Epoch 727/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.2049e-08 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.9803\n",
            "Epoch 728/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9488e-08 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.9803\n",
            "Epoch 729/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6144e-08 - accuracy: 1.0000 - val_loss: 0.2507 - val_accuracy: 0.9803\n",
            "Epoch 730/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.3999e-08 - accuracy: 1.0000 - val_loss: 0.2507 - val_accuracy: 0.9803\n",
            "Epoch 731/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0499e-08 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.9801\n",
            "Epoch 732/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.9106e-08 - accuracy: 1.0000 - val_loss: 0.2523 - val_accuracy: 0.9802\n",
            "Epoch 733/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6934e-08 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9801\n",
            "Epoch 734/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4160e-08 - accuracy: 1.0000 - val_loss: 0.2535 - val_accuracy: 0.9801\n",
            "Epoch 735/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3334e-08 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.9802\n",
            "Epoch 736/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0412e-08 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.9803\n",
            "Epoch 737/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8035e-08 - accuracy: 1.0000 - val_loss: 0.2554 - val_accuracy: 0.9801\n",
            "Epoch 738/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6970e-08 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9801\n",
            "Epoch 739/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5105e-08 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9801\n",
            "Epoch 740/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3135e-08 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9803\n",
            "Epoch 741/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2337e-08 - accuracy: 1.0000 - val_loss: 0.2574 - val_accuracy: 0.9800\n",
            "Epoch 742/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0568e-08 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9803\n",
            "Epoch 743/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9569e-08 - accuracy: 1.0000 - val_loss: 0.2582 - val_accuracy: 0.9801\n",
            "Epoch 744/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8075e-08 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.9803\n",
            "Epoch 745/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7028e-08 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.9799\n",
            "Epoch 746/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6125e-08 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.9805\n",
            "Epoch 747/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4959e-08 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9801\n",
            "Epoch 748/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4035e-08 - accuracy: 1.0000 - val_loss: 0.2616 - val_accuracy: 0.9801\n",
            "Epoch 749/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3317e-08 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.9801\n",
            "Epoch 750/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2353e-08 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9802\n",
            "Epoch 751/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1537e-08 - accuracy: 1.0000 - val_loss: 0.2633 - val_accuracy: 0.9801\n",
            "Epoch 752/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0890e-08 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9803\n",
            "Epoch 753/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0167e-08 - accuracy: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.9801\n",
            "Epoch 754/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.5103e-09 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9800\n",
            "Epoch 755/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.9990e-09 - accuracy: 1.0000 - val_loss: 0.2662 - val_accuracy: 0.9801\n",
            "Epoch 756/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.4003e-09 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9801\n",
            "Epoch 757/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8334e-09 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9801\n",
            "Epoch 758/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3194e-09 - accuracy: 1.0000 - val_loss: 0.2683 - val_accuracy: 0.9800\n",
            "Epoch 759/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.9115e-09 - accuracy: 1.0000 - val_loss: 0.2688 - val_accuracy: 0.9801\n",
            "Epoch 760/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.5009e-09 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.9801\n",
            "Epoch 761/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1115e-09 - accuracy: 1.0000 - val_loss: 0.2702 - val_accuracy: 0.9801\n",
            "Epoch 762/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.7644e-09 - accuracy: 1.0000 - val_loss: 0.2706 - val_accuracy: 0.9800\n",
            "Epoch 763/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3459e-09 - accuracy: 1.0000 - val_loss: 0.2714 - val_accuracy: 0.9801\n",
            "Epoch 764/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0730e-09 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9800\n",
            "Epoch 765/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7313e-09 - accuracy: 1.0000 - val_loss: 0.2729 - val_accuracy: 0.9800\n",
            "Epoch 766/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4796e-09 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.9800\n",
            "Epoch 767/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.1909e-09 - accuracy: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.9799\n",
            "Epoch 768/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9313e-09 - accuracy: 1.0000 - val_loss: 0.2747 - val_accuracy: 0.9799\n",
            "Epoch 769/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7326e-09 - accuracy: 1.0000 - val_loss: 0.2757 - val_accuracy: 0.9801\n",
            "Epoch 770/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5153e-09 - accuracy: 1.0000 - val_loss: 0.2767 - val_accuracy: 0.9799\n",
            "Epoch 771/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3352e-09 - accuracy: 1.0000 - val_loss: 0.2771 - val_accuracy: 0.9799\n",
            "Epoch 772/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1418e-09 - accuracy: 1.0000 - val_loss: 0.2778 - val_accuracy: 0.9799\n",
            "Epoch 773/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9617e-09 - accuracy: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.9799\n",
            "Epoch 774/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7895e-09 - accuracy: 1.0000 - val_loss: 0.2794 - val_accuracy: 0.9799\n",
            "Epoch 775/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6464e-09 - accuracy: 1.0000 - val_loss: 0.2800 - val_accuracy: 0.9801\n",
            "Epoch 776/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5484e-09 - accuracy: 1.0000 - val_loss: 0.2804 - val_accuracy: 0.9801\n",
            "Epoch 777/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3815e-09 - accuracy: 1.0000 - val_loss: 0.2815 - val_accuracy: 0.9799\n",
            "Epoch 778/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2199e-09 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.9800\n",
            "Epoch 779/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1802e-09 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.9799\n",
            "Epoch 780/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0213e-09 - accuracy: 1.0000 - val_loss: 0.2840 - val_accuracy: 0.9798\n",
            "Epoch 781/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9418e-09 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.9799\n",
            "Epoch 782/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8650e-09 - accuracy: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.9799\n",
            "Epoch 783/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7696e-09 - accuracy: 1.0000 - val_loss: 0.2864 - val_accuracy: 0.9801\n",
            "Epoch 784/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7034e-09 - accuracy: 1.0000 - val_loss: 0.2869 - val_accuracy: 0.9799\n",
            "Epoch 785/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6477e-09 - accuracy: 1.0000 - val_loss: 0.2878 - val_accuracy: 0.9800\n",
            "Epoch 786/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5656e-09 - accuracy: 1.0000 - val_loss: 0.2888 - val_accuracy: 0.9801\n",
            "Epoch 787/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4994e-09 - accuracy: 1.0000 - val_loss: 0.2893 - val_accuracy: 0.9801\n",
            "Epoch 788/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4252e-09 - accuracy: 1.0000 - val_loss: 0.2899 - val_accuracy: 0.9799\n",
            "Epoch 789/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3537e-09 - accuracy: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.9802\n",
            "Epoch 790/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2769e-09 - accuracy: 1.0000 - val_loss: 0.2925 - val_accuracy: 0.9800\n",
            "Epoch 791/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3219e-09 - accuracy: 1.0000 - val_loss: 0.2925 - val_accuracy: 0.9799\n",
            "Epoch 792/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2027e-09 - accuracy: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.9800\n",
            "Epoch 793/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1868e-09 - accuracy: 1.0000 - val_loss: 0.2945 - val_accuracy: 0.9798\n",
            "Epoch 794/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1391e-09 - accuracy: 1.0000 - val_loss: 0.2955 - val_accuracy: 0.9799\n",
            "Epoch 795/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0888e-09 - accuracy: 1.0000 - val_loss: 0.2965 - val_accuracy: 0.9799\n",
            "Epoch 796/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0702e-09 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.9799\n",
            "Epoch 797/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0252e-09 - accuracy: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.9799\n",
            "Epoch 798/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0384e-09 - accuracy: 1.0000 - val_loss: 0.2994 - val_accuracy: 0.9799\n",
            "Epoch 799/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0120e-09 - accuracy: 1.0000 - val_loss: 0.3005 - val_accuracy: 0.9797\n",
            "Epoch 800/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0093e-09 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.9797\n",
            "Epoch 801/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.8281e-10 - accuracy: 1.0000 - val_loss: 0.3022 - val_accuracy: 0.9797\n",
            "Epoch 802/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5103e-10 - accuracy: 1.0000 - val_loss: 0.3022 - val_accuracy: 0.9796\n",
            "Epoch 803/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1129e-10 - accuracy: 1.0000 - val_loss: 0.3036 - val_accuracy: 0.9796\n",
            "Epoch 804/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4573e-10 - accuracy: 1.0000 - val_loss: 0.3045 - val_accuracy: 0.9797\n",
            "Epoch 805/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3513e-10 - accuracy: 1.0000 - val_loss: 0.3052 - val_accuracy: 0.9795\n",
            "Epoch 806/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0599e-10 - accuracy: 1.0000 - val_loss: 0.3064 - val_accuracy: 0.9795\n",
            "Epoch 807/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.7420e-10 - accuracy: 1.0000 - val_loss: 0.3072 - val_accuracy: 0.9795\n",
            "Epoch 808/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5831e-10 - accuracy: 1.0000 - val_loss: 0.3080 - val_accuracy: 0.9796\n",
            "Epoch 809/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.9010e-10 - accuracy: 1.0000 - val_loss: 0.3089 - val_accuracy: 0.9795\n",
            "Epoch 810/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.8745e-10 - accuracy: 1.0000 - val_loss: 0.3104 - val_accuracy: 0.9795\n",
            "Epoch 811/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7420e-10 - accuracy: 1.0000 - val_loss: 0.3107 - val_accuracy: 0.9796\n",
            "Epoch 812/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7950e-10 - accuracy: 1.0000 - val_loss: 0.3111 - val_accuracy: 0.9796\n",
            "Epoch 813/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9010e-10 - accuracy: 1.0000 - val_loss: 0.3128 - val_accuracy: 0.9795\n",
            "Epoch 814/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5301e-10 - accuracy: 1.0000 - val_loss: 0.3123 - val_accuracy: 0.9797\n",
            "Epoch 815/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.2122e-10 - accuracy: 1.0000 - val_loss: 0.3144 - val_accuracy: 0.9793\n",
            "Epoch 816/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.2453e-10 - accuracy: 1.0000 - val_loss: 0.3150 - val_accuracy: 0.9793\n",
            "Epoch 817/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5831e-10 - accuracy: 1.0000 - val_loss: 0.3151 - val_accuracy: 0.9794\n",
            "Epoch 818/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5036e-10 - accuracy: 1.0000 - val_loss: 0.3162 - val_accuracy: 0.9795\n",
            "Epoch 819/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1592e-10 - accuracy: 1.0000 - val_loss: 0.3169 - val_accuracy: 0.9793\n",
            "Epoch 820/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2122e-10 - accuracy: 1.0000 - val_loss: 0.3185 - val_accuracy: 0.9793\n",
            "Epoch 821/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3446e-10 - accuracy: 1.0000 - val_loss: 0.3184 - val_accuracy: 0.9793\n",
            "Epoch 822/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7155e-10 - accuracy: 1.0000 - val_loss: 0.3195 - val_accuracy: 0.9796\n",
            "Epoch 823/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2387e-10 - accuracy: 1.0000 - val_loss: 0.3207 - val_accuracy: 0.9794\n",
            "Epoch 824/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3976e-10 - accuracy: 1.0000 - val_loss: 0.3206 - val_accuracy: 0.9796\n",
            "Epoch 825/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.1857e-10 - accuracy: 1.0000 - val_loss: 0.3216 - val_accuracy: 0.9795\n",
            "Epoch 826/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6824e-10 - accuracy: 1.0000 - val_loss: 0.3226 - val_accuracy: 0.9797\n",
            "Epoch 827/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.1592e-10 - accuracy: 1.0000 - val_loss: 0.3228 - val_accuracy: 0.9793\n",
            "Epoch 828/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8148e-10 - accuracy: 1.0000 - val_loss: 0.3235 - val_accuracy: 0.9794\n",
            "Epoch 829/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.8943e-10 - accuracy: 1.0000 - val_loss: 0.3248 - val_accuracy: 0.9796\n",
            "Epoch 830/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0268e-10 - accuracy: 1.0000 - val_loss: 0.3251 - val_accuracy: 0.9795\n",
            "Epoch 831/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1327e-10 - accuracy: 1.0000 - val_loss: 0.3253 - val_accuracy: 0.9795\n",
            "Epoch 832/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4771e-10 - accuracy: 1.0000 - val_loss: 0.3265 - val_accuracy: 0.9791\n",
            "Epoch 833/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.1327e-10 - accuracy: 1.0000 - val_loss: 0.3276 - val_accuracy: 0.9794\n",
            "Epoch 834/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0797e-10 - accuracy: 1.0000 - val_loss: 0.3279 - val_accuracy: 0.9795\n",
            "Epoch 835/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4506e-10 - accuracy: 1.0000 - val_loss: 0.3295 - val_accuracy: 0.9795\n",
            "Epoch 836/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0543e-09 - accuracy: 1.0000 - val_loss: 0.3292 - val_accuracy: 0.9793\n",
            "Epoch 837/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7420e-10 - accuracy: 1.0000 - val_loss: 0.3299 - val_accuracy: 0.9797\n",
            "Epoch 838/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.7883e-10 - accuracy: 1.0000 - val_loss: 0.3310 - val_accuracy: 0.9796\n",
            "Epoch 839/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8943e-10 - accuracy: 1.0000 - val_loss: 0.3319 - val_accuracy: 0.9793\n",
            "Epoch 840/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.4969e-10 - accuracy: 1.0000 - val_loss: 0.3319 - val_accuracy: 0.9794\n",
            "Epoch 841/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.0268e-10 - accuracy: 1.0000 - val_loss: 0.3337 - val_accuracy: 0.9793\n",
            "Epoch 842/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1129e-10 - accuracy: 1.0000 - val_loss: 0.3349 - val_accuracy: 0.9791\n",
            "Epoch 843/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1259 - accuracy: 0.9869 - val_loss: 0.1767 - val_accuracy: 0.9747\n",
            "Epoch 844/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.1526 - val_accuracy: 0.9800\n",
            "Epoch 845/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.4984e-04 - accuracy: 0.9997 - val_loss: 0.1501 - val_accuracy: 0.9805\n",
            "Epoch 846/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7888e-04 - accuracy: 1.0000 - val_loss: 0.1487 - val_accuracy: 0.9812\n",
            "Epoch 847/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5620e-05 - accuracy: 1.0000 - val_loss: 0.1479 - val_accuracy: 0.9814\n",
            "Epoch 848/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0513e-05 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9815\n",
            "Epoch 849/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9742e-05 - accuracy: 1.0000 - val_loss: 0.1673 - val_accuracy: 0.9813\n",
            "Epoch 850/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.8285e-06 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 0.9811\n",
            "Epoch 851/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2709e-06 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.9810\n",
            "Epoch 852/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5166e-06 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 0.9808\n",
            "Epoch 853/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9772e-06 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9810\n",
            "Epoch 854/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7192e-06 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9813\n",
            "Epoch 855/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0969e-06 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9814\n",
            "Epoch 856/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6483e-06 - accuracy: 1.0000 - val_loss: 0.2060 - val_accuracy: 0.9812\n",
            "Epoch 857/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4057e-06 - accuracy: 1.0000 - val_loss: 0.2089 - val_accuracy: 0.9812\n",
            "Epoch 858/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2305e-06 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9811\n",
            "Epoch 859/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0598e-06 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9812\n",
            "Epoch 860/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1698e-07 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9812\n",
            "Epoch 861/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.6632e-07 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9812\n",
            "Epoch 862/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.4780e-07 - accuracy: 1.0000 - val_loss: 0.2195 - val_accuracy: 0.9811\n",
            "Epoch 863/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7091e-07 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9811\n",
            "Epoch 864/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1320e-07 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9812\n",
            "Epoch 865/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5745e-07 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9810\n",
            "Epoch 866/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.0385e-07 - accuracy: 1.0000 - val_loss: 0.2257 - val_accuracy: 0.9809\n",
            "Epoch 867/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6944e-07 - accuracy: 1.0000 - val_loss: 0.2260 - val_accuracy: 0.9811\n",
            "Epoch 868/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.2568e-07 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9809\n",
            "Epoch 869/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.9542e-07 - accuracy: 1.0000 - val_loss: 0.2296 - val_accuracy: 0.9812\n",
            "Epoch 870/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6873e-07 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.9813\n",
            "Epoch 871/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3002e-07 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.9811\n",
            "Epoch 872/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0606e-07 - accuracy: 1.0000 - val_loss: 0.2331 - val_accuracy: 0.9812\n",
            "Epoch 873/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8278e-07 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9813\n",
            "Epoch 874/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6557e-07 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9813\n",
            "Epoch 875/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3768e-07 - accuracy: 1.0000 - val_loss: 0.2348 - val_accuracy: 0.9813\n",
            "Epoch 876/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3436e-07 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9813\n",
            "Epoch 877/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1142e-07 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9811\n",
            "Epoch 878/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9687e-07 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9812\n",
            "Epoch 879/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8279e-07 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9810\n",
            "Epoch 880/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7294e-07 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9811\n",
            "Epoch 881/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5690e-07 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9813\n",
            "Epoch 882/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5001e-07 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9812\n",
            "Epoch 883/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3736e-07 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9811\n",
            "Epoch 884/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2726e-07 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9812\n",
            "Epoch 885/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1955e-07 - accuracy: 1.0000 - val_loss: 0.2441 - val_accuracy: 0.9812\n",
            "Epoch 886/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0895e-07 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9809\n",
            "Epoch 887/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0633e-07 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9812\n",
            "Epoch 888/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0399e-07 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.9812\n",
            "Epoch 889/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2469e-08 - accuracy: 1.0000 - val_loss: 0.2471 - val_accuracy: 0.9812\n",
            "Epoch 890/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6818e-08 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.9811\n",
            "Epoch 891/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.1033e-08 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9811\n",
            "Epoch 892/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9003e-08 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9811\n",
            "Epoch 893/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3557e-08 - accuracy: 1.0000 - val_loss: 0.2507 - val_accuracy: 0.9811\n",
            "Epoch 894/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1462e-08 - accuracy: 1.0000 - val_loss: 0.2507 - val_accuracy: 0.9811\n",
            "Epoch 895/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3557e-08 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.9814\n",
            "Epoch 896/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.9159e-08 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9810\n",
            "Epoch 897/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.6751e-08 - accuracy: 1.0000 - val_loss: 0.2531 - val_accuracy: 0.9811\n",
            "Epoch 898/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2290e-08 - accuracy: 1.0000 - val_loss: 0.2543 - val_accuracy: 0.9811\n",
            "Epoch 899/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0725e-08 - accuracy: 1.0000 - val_loss: 0.2554 - val_accuracy: 0.9812\n",
            "Epoch 900/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.7000e-08 - accuracy: 1.0000 - val_loss: 0.2558 - val_accuracy: 0.9810\n",
            "Epoch 901/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5233e-08 - accuracy: 1.0000 - val_loss: 0.2557 - val_accuracy: 0.9813\n",
            "Epoch 902/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.2958e-08 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9813\n",
            "Epoch 903/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.0113e-08 - accuracy: 1.0000 - val_loss: 0.2568 - val_accuracy: 0.9812\n",
            "Epoch 904/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6732e-08 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9813\n",
            "Epoch 905/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4499e-08 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.9812\n",
            "Epoch 906/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2496e-08 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.9811\n",
            "Epoch 907/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0430e-08 - accuracy: 1.0000 - val_loss: 0.2596 - val_accuracy: 0.9811\n",
            "Epoch 908/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8441e-08 - accuracy: 1.0000 - val_loss: 0.2612 - val_accuracy: 0.9813\n",
            "Epoch 909/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7209e-08 - accuracy: 1.0000 - val_loss: 0.2616 - val_accuracy: 0.9812\n",
            "Epoch 910/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5301e-08 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9813\n",
            "Epoch 911/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3434e-08 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9813\n",
            "Epoch 912/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2202e-08 - accuracy: 1.0000 - val_loss: 0.2636 - val_accuracy: 0.9812\n",
            "Epoch 913/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1156e-08 - accuracy: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.9815\n",
            "Epoch 914/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9624e-08 - accuracy: 1.0000 - val_loss: 0.2652 - val_accuracy: 0.9811\n",
            "Epoch 915/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8578e-08 - accuracy: 1.0000 - val_loss: 0.2664 - val_accuracy: 0.9816\n",
            "Epoch 916/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7595e-08 - accuracy: 1.0000 - val_loss: 0.2656 - val_accuracy: 0.9813\n",
            "Epoch 917/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6785e-08 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9814\n",
            "Epoch 918/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5540e-08 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.9815\n",
            "Epoch 919/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4453e-08 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.9815\n",
            "Epoch 920/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3741e-08 - accuracy: 1.0000 - val_loss: 0.2691 - val_accuracy: 0.9814\n",
            "Epoch 921/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2888e-08 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.9814\n",
            "Epoch 922/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2302e-08 - accuracy: 1.0000 - val_loss: 0.2701 - val_accuracy: 0.9815\n",
            "Epoch 923/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1619e-08 - accuracy: 1.0000 - val_loss: 0.2707 - val_accuracy: 0.9817\n",
            "Epoch 924/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0694e-08 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.9817\n",
            "Epoch 925/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0204e-08 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9816\n",
            "Epoch 926/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7725e-09 - accuracy: 1.0000 - val_loss: 0.2725 - val_accuracy: 0.9815\n",
            "Epoch 927/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0308e-09 - accuracy: 1.0000 - val_loss: 0.2733 - val_accuracy: 0.9815\n",
            "Epoch 928/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.5009e-09 - accuracy: 1.0000 - val_loss: 0.2743 - val_accuracy: 0.9816\n",
            "Epoch 929/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.0135e-09 - accuracy: 1.0000 - val_loss: 0.2750 - val_accuracy: 0.9816\n",
            "Epoch 930/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.5234e-09 - accuracy: 1.0000 - val_loss: 0.2757 - val_accuracy: 0.9816\n",
            "Epoch 931/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1579e-09 - accuracy: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.9815\n",
            "Epoch 932/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6015e-09 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.9817\n",
            "Epoch 933/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.3366e-09 - accuracy: 1.0000 - val_loss: 0.2774 - val_accuracy: 0.9817\n",
            "Epoch 934/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8466e-09 - accuracy: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.9815\n",
            "Epoch 935/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.5287e-09 - accuracy: 1.0000 - val_loss: 0.2793 - val_accuracy: 0.9818\n",
            "Epoch 936/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.2982e-09 - accuracy: 1.0000 - val_loss: 0.2799 - val_accuracy: 0.9816\n",
            "Epoch 937/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.9962e-09 - accuracy: 1.0000 - val_loss: 0.2808 - val_accuracy: 0.9816\n",
            "Epoch 938/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.6306e-09 - accuracy: 1.0000 - val_loss: 0.2815 - val_accuracy: 0.9817\n",
            "Epoch 939/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.3737e-09 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.9817\n",
            "Epoch 940/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0982e-09 - accuracy: 1.0000 - val_loss: 0.2830 - val_accuracy: 0.9815\n",
            "Epoch 941/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9286e-09 - accuracy: 1.0000 - val_loss: 0.2839 - val_accuracy: 0.9816\n",
            "Epoch 942/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6981e-09 - accuracy: 1.0000 - val_loss: 0.2845 - val_accuracy: 0.9816\n",
            "Epoch 943/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.4650e-09 - accuracy: 1.0000 - val_loss: 0.2851 - val_accuracy: 0.9816\n",
            "Epoch 944/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2690e-09 - accuracy: 1.0000 - val_loss: 0.2859 - val_accuracy: 0.9815\n",
            "Epoch 945/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0703e-09 - accuracy: 1.0000 - val_loss: 0.2871 - val_accuracy: 0.9817\n",
            "Epoch 946/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8875e-09 - accuracy: 1.0000 - val_loss: 0.2878 - val_accuracy: 0.9816\n",
            "Epoch 947/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7471e-09 - accuracy: 1.0000 - val_loss: 0.2884 - val_accuracy: 0.9815\n",
            "Epoch 948/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6358e-09 - accuracy: 1.0000 - val_loss: 0.2892 - val_accuracy: 0.9816\n",
            "Epoch 949/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4186e-09 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.9817\n",
            "Epoch 950/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2703e-09 - accuracy: 1.0000 - val_loss: 0.2910 - val_accuracy: 0.9814\n",
            "Epoch 951/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1908e-09 - accuracy: 1.0000 - val_loss: 0.2919 - val_accuracy: 0.9815\n",
            "Epoch 952/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1352e-09 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.9813\n",
            "Epoch 953/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9709e-09 - accuracy: 1.0000 - val_loss: 0.2930 - val_accuracy: 0.9815\n",
            "Epoch 954/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8623e-09 - accuracy: 1.0000 - val_loss: 0.2942 - val_accuracy: 0.9814\n",
            "Epoch 955/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7590e-09 - accuracy: 1.0000 - val_loss: 0.2950 - val_accuracy: 0.9814\n",
            "Epoch 956/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6583e-09 - accuracy: 1.0000 - val_loss: 0.2959 - val_accuracy: 0.9814\n",
            "Epoch 957/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5577e-09 - accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.9814\n",
            "Epoch 958/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5206e-09 - accuracy: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.9814\n",
            "Epoch 959/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4570e-09 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.9814\n",
            "Epoch 960/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3802e-09 - accuracy: 1.0000 - val_loss: 0.2994 - val_accuracy: 0.9815\n",
            "Epoch 961/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3060e-09 - accuracy: 1.0000 - val_loss: 0.3004 - val_accuracy: 0.9813\n",
            "Epoch 962/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2451e-09 - accuracy: 1.0000 - val_loss: 0.3015 - val_accuracy: 0.9814\n",
            "Epoch 963/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1921e-09 - accuracy: 1.0000 - val_loss: 0.3024 - val_accuracy: 0.9814\n",
            "Epoch 964/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1524e-09 - accuracy: 1.0000 - val_loss: 0.3035 - val_accuracy: 0.9814\n",
            "Epoch 965/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1020e-09 - accuracy: 1.0000 - val_loss: 0.3044 - val_accuracy: 0.9813\n",
            "Epoch 966/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0702e-09 - accuracy: 1.0000 - val_loss: 0.3053 - val_accuracy: 0.9813\n",
            "Epoch 967/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0437e-09 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.9813\n",
            "Epoch 968/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0067e-09 - accuracy: 1.0000 - val_loss: 0.3073 - val_accuracy: 0.9813\n",
            "Epoch 969/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9871e-10 - accuracy: 1.0000 - val_loss: 0.3083 - val_accuracy: 0.9813\n",
            "Epoch 970/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5103e-10 - accuracy: 1.0000 - val_loss: 0.3095 - val_accuracy: 0.9813\n",
            "Epoch 971/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2453e-10 - accuracy: 1.0000 - val_loss: 0.3104 - val_accuracy: 0.9813\n",
            "Epoch 972/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8215e-10 - accuracy: 1.0000 - val_loss: 0.3117 - val_accuracy: 0.9813\n",
            "Epoch 973/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0069e-10 - accuracy: 1.0000 - val_loss: 0.3129 - val_accuracy: 0.9812\n",
            "Epoch 974/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.7950e-10 - accuracy: 1.0000 - val_loss: 0.3132 - val_accuracy: 0.9813\n",
            "Epoch 975/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5831e-10 - accuracy: 1.0000 - val_loss: 0.3143 - val_accuracy: 0.9813\n",
            "Epoch 976/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.9473e-10 - accuracy: 1.0000 - val_loss: 0.3156 - val_accuracy: 0.9814\n",
            "Epoch 977/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1327e-10 - accuracy: 1.0000 - val_loss: 0.3163 - val_accuracy: 0.9814\n",
            "Epoch 978/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6559e-10 - accuracy: 1.0000 - val_loss: 0.3173 - val_accuracy: 0.9813\n",
            "Epoch 979/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2055e-10 - accuracy: 1.0000 - val_loss: 0.3188 - val_accuracy: 0.9813\n",
            "Epoch 980/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5234e-10 - accuracy: 1.0000 - val_loss: 0.3197 - val_accuracy: 0.9814\n",
            "Epoch 981/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5234e-10 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 0.9815\n",
            "Epoch 982/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.5234e-10 - accuracy: 1.0000 - val_loss: 0.3215 - val_accuracy: 0.9812\n",
            "Epoch 983/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1790e-10 - accuracy: 1.0000 - val_loss: 0.3228 - val_accuracy: 0.9813\n",
            "Epoch 984/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6029e-10 - accuracy: 1.0000 - val_loss: 0.3235 - val_accuracy: 0.9814\n",
            "Epoch 985/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.9406e-10 - accuracy: 1.0000 - val_loss: 0.3241 - val_accuracy: 0.9812\n",
            "Epoch 986/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6757e-10 - accuracy: 1.0000 - val_loss: 0.3253 - val_accuracy: 0.9815\n",
            "Epoch 987/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5168e-10 - accuracy: 1.0000 - val_loss: 0.3258 - val_accuracy: 0.9814\n",
            "Epoch 988/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.9141e-10 - accuracy: 1.0000 - val_loss: 0.3263 - val_accuracy: 0.9816\n",
            "Epoch 989/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.3048e-10 - accuracy: 1.0000 - val_loss: 0.3279 - val_accuracy: 0.9810\n",
            "Epoch 990/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.3578e-10 - accuracy: 1.0000 - val_loss: 0.3288 - val_accuracy: 0.9815\n",
            "Epoch 991/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.2254e-10 - accuracy: 1.0000 - val_loss: 0.3305 - val_accuracy: 0.9813\n",
            "Epoch 992/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4903e-10 - accuracy: 1.0000 - val_loss: 0.3308 - val_accuracy: 0.9813\n",
            "Epoch 993/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8876e-10 - accuracy: 1.0000 - val_loss: 0.3311 - val_accuracy: 0.9813\n",
            "Epoch 994/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3843e-10 - accuracy: 1.0000 - val_loss: 0.3326 - val_accuracy: 0.9813\n",
            "Epoch 995/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2254e-10 - accuracy: 1.0000 - val_loss: 0.3330 - val_accuracy: 0.9810\n",
            "Epoch 996/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4108e-10 - accuracy: 1.0000 - val_loss: 0.3349 - val_accuracy: 0.9810\n",
            "Epoch 997/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.2254e-10 - accuracy: 1.0000 - val_loss: 0.3353 - val_accuracy: 0.9812\n",
            "Epoch 998/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0929e-10 - accuracy: 1.0000 - val_loss: 0.3361 - val_accuracy: 0.9809\n",
            "Epoch 999/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.2254e-10 - accuracy: 1.0000 - val_loss: 0.3370 - val_accuracy: 0.9811\n",
            "Epoch 1000/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.3578e-10 - accuracy: 1.0000 - val_loss: 0.3384 - val_accuracy: 0.9810\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0846 - accuracy: 0.9952\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2703 - accuracy: 0.9822\n",
            "train accuracy :  0.9952499866485596 train loss :  0.08460886776447296\n",
            "test accuracy :  0.982200026512146  test loss :  0.2703184485435486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix9iGMCaDvUG"
      },
      "source": [
        "# 은닉층 2개(512/256) & epochs = 120 / 500 / 1000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n5FiE2JsDv8u",
        "outputId": "f929573e-0d7e-4ea8-eb89-491c5f90d9fb"
      },
      "source": [
        "#신경망 학습2_2_2\n",
        "model2_2_2 = models.Sequential([\n",
        "                               Flatten(input_shape = (28, 28)),\n",
        "                               Dense(512, activation= 'relu'),\n",
        "                               Dense(256, activation= 'relu'),\n",
        "                               Dense(10, activation= 'softmax')\n",
        "                               ])\n",
        "\n",
        "model2_2_2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "hist2_2_2 = model2_2_2.fit(train_x, train_y, epochs = 120, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "#학습 그래프4\n",
        "plt.plot(hist2_2_2.history['accuracy'], 'b-')\n",
        "plt.plot(hist2_2_2.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train2_2_2 = model2_2_2.evaluate(train_x, train_y)\n",
        "sc_test2_2_2 = model2_2_2.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train2_2_2[1], \"train loss : \", sc_train2_2_2[0])\n",
        "print(\"test accuracy : \", sc_test2_2_2[1], \" test loss : \", sc_test2_2_2[0])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3250 - accuracy: 0.9074 - val_loss: 0.1575 - val_accuracy: 0.9529\n",
            "Epoch 2/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.1176 - accuracy: 0.9646 - val_loss: 0.1223 - val_accuracy: 0.9627\n",
            "Epoch 3/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0723 - accuracy: 0.9782 - val_loss: 0.1054 - val_accuracy: 0.9685\n",
            "Epoch 4/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0501 - accuracy: 0.9849 - val_loss: 0.1086 - val_accuracy: 0.9680\n",
            "Epoch 5/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0342 - accuracy: 0.9896 - val_loss: 0.0871 - val_accuracy: 0.9751\n",
            "Epoch 6/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0249 - accuracy: 0.9924 - val_loss: 0.0870 - val_accuracy: 0.9757\n",
            "Epoch 7/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0163 - accuracy: 0.9955 - val_loss: 0.0876 - val_accuracy: 0.9770\n",
            "Epoch 8/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0915 - val_accuracy: 0.9767\n",
            "Epoch 9/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 0.0972 - val_accuracy: 0.9766\n",
            "Epoch 10/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 0.1025 - val_accuracy: 0.9755\n",
            "Epoch 11/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.1191 - val_accuracy: 0.9719\n",
            "Epoch 12/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1054 - val_accuracy: 0.9751\n",
            "Epoch 13/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.1159 - val_accuracy: 0.9739\n",
            "Epoch 14/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.1094 - val_accuracy: 0.9758\n",
            "Epoch 15/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.1124 - val_accuracy: 0.9760\n",
            "Epoch 16/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1155 - val_accuracy: 0.9769\n",
            "Epoch 17/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.1088 - val_accuracy: 0.9777\n",
            "Epoch 18/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.1182 - val_accuracy: 0.9748\n",
            "Epoch 19/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.1200 - val_accuracy: 0.9772\n",
            "Epoch 20/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.1215 - val_accuracy: 0.9771\n",
            "Epoch 21/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.1307 - val_accuracy: 0.9760\n",
            "Epoch 22/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.1257 - val_accuracy: 0.9763\n",
            "Epoch 23/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.1249 - val_accuracy: 0.9785\n",
            "Epoch 24/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.1395 - val_accuracy: 0.9725\n",
            "Epoch 25/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0069 - accuracy: 0.9973 - val_loss: 0.1563 - val_accuracy: 0.9719\n",
            "Epoch 26/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0057 - accuracy: 0.9978 - val_loss: 0.1346 - val_accuracy: 0.9765\n",
            "Epoch 27/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.1343 - val_accuracy: 0.9771\n",
            "Epoch 28/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.1313 - val_accuracy: 0.9783\n",
            "Epoch 29/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.1357 - val_accuracy: 0.9780\n",
            "Epoch 30/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.1496 - val_accuracy: 0.9742\n",
            "Epoch 31/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.1449 - val_accuracy: 0.9739\n",
            "Epoch 32/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.1298 - val_accuracy: 0.9787\n",
            "Epoch 33/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2809e-04 - accuracy: 0.9999 - val_loss: 0.1209 - val_accuracy: 0.9797\n",
            "Epoch 34/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.1389 - val_accuracy: 0.9771\n",
            "Epoch 35/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.1393 - val_accuracy: 0.9775\n",
            "Epoch 36/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.1475 - val_accuracy: 0.9758\n",
            "Epoch 37/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.1463 - val_accuracy: 0.9775\n",
            "Epoch 38/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.1345 - val_accuracy: 0.9774\n",
            "Epoch 39/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.1280 - val_accuracy: 0.9799\n",
            "Epoch 40/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.1503 - val_accuracy: 0.9767\n",
            "Epoch 41/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.1585 - val_accuracy: 0.9759\n",
            "Epoch 42/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1372 - val_accuracy: 0.9787\n",
            "Epoch 43/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.1395 - val_accuracy: 0.9802\n",
            "Epoch 44/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.9260e-04 - accuracy: 0.9998 - val_loss: 0.1467 - val_accuracy: 0.9798\n",
            "Epoch 45/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.6545e-04 - accuracy: 0.9999 - val_loss: 0.1486 - val_accuracy: 0.9797\n",
            "Epoch 46/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.1466 - val_accuracy: 0.9799\n",
            "Epoch 47/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.1528 - val_accuracy: 0.9767\n",
            "Epoch 48/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.1621 - val_accuracy: 0.9754\n",
            "Epoch 49/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.1470 - val_accuracy: 0.9785\n",
            "Epoch 50/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.1498 - val_accuracy: 0.9773\n",
            "Epoch 51/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.1358 - val_accuracy: 0.9801\n",
            "Epoch 52/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.1743e-04 - accuracy: 0.9998 - val_loss: 0.1390 - val_accuracy: 0.9807\n",
            "Epoch 53/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9140e-04 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9804\n",
            "Epoch 54/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2164e-04 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 0.9802\n",
            "Epoch 55/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4782e-05 - accuracy: 1.0000 - val_loss: 0.1378 - val_accuracy: 0.9811\n",
            "Epoch 56/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5513e-05 - accuracy: 1.0000 - val_loss: 0.1383 - val_accuracy: 0.9813\n",
            "Epoch 57/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3233e-05 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9813\n",
            "Epoch 58/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1580e-05 - accuracy: 1.0000 - val_loss: 0.1393 - val_accuracy: 0.9813\n",
            "Epoch 59/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0278e-05 - accuracy: 1.0000 - val_loss: 0.1398 - val_accuracy: 0.9814\n",
            "Epoch 60/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.1974e-06 - accuracy: 1.0000 - val_loss: 0.1404 - val_accuracy: 0.9813\n",
            "Epoch 61/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.2776e-06 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9814\n",
            "Epoch 62/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4931e-06 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9816\n",
            "Epoch 63/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8120e-06 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9816\n",
            "Epoch 64/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1939e-06 - accuracy: 1.0000 - val_loss: 0.1428 - val_accuracy: 0.9816\n",
            "Epoch 65/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6458e-06 - accuracy: 1.0000 - val_loss: 0.1434 - val_accuracy: 0.9817\n",
            "Epoch 66/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1544e-06 - accuracy: 1.0000 - val_loss: 0.1440 - val_accuracy: 0.9817\n",
            "Epoch 67/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.7186e-06 - accuracy: 1.0000 - val_loss: 0.1445 - val_accuracy: 0.9818\n",
            "Epoch 68/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.3134e-06 - accuracy: 1.0000 - val_loss: 0.1451 - val_accuracy: 0.9819\n",
            "Epoch 69/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9462e-06 - accuracy: 1.0000 - val_loss: 0.1459 - val_accuracy: 0.9819\n",
            "Epoch 70/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6195e-06 - accuracy: 1.0000 - val_loss: 0.1465 - val_accuracy: 0.9819\n",
            "Epoch 71/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3235e-06 - accuracy: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9819\n",
            "Epoch 72/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0458e-06 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 0.9819\n",
            "Epoch 73/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7970e-06 - accuracy: 1.0000 - val_loss: 0.1483 - val_accuracy: 0.9820\n",
            "Epoch 74/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5674e-06 - accuracy: 1.0000 - val_loss: 0.1490 - val_accuracy: 0.9821\n",
            "Epoch 75/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3554e-06 - accuracy: 1.0000 - val_loss: 0.1496 - val_accuracy: 0.9822\n",
            "Epoch 76/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1631e-06 - accuracy: 1.0000 - val_loss: 0.1503 - val_accuracy: 0.9823\n",
            "Epoch 77/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9853e-06 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 0.9823\n",
            "Epoch 78/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8248e-06 - accuracy: 1.0000 - val_loss: 0.1517 - val_accuracy: 0.9823\n",
            "Epoch 79/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6715e-06 - accuracy: 1.0000 - val_loss: 0.1523 - val_accuracy: 0.9824\n",
            "Epoch 80/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5350e-06 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9823\n",
            "Epoch 81/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4092e-06 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9824\n",
            "Epoch 82/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2921e-06 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 0.9822\n",
            "Epoch 83/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1832e-06 - accuracy: 1.0000 - val_loss: 0.1551 - val_accuracy: 0.9823\n",
            "Epoch 84/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0847e-06 - accuracy: 1.0000 - val_loss: 0.1558 - val_accuracy: 0.9822\n",
            "Epoch 85/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9172e-07 - accuracy: 1.0000 - val_loss: 0.1566 - val_accuracy: 0.9822\n",
            "Epoch 86/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.0720e-07 - accuracy: 1.0000 - val_loss: 0.1574 - val_accuracy: 0.9822\n",
            "Epoch 87/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.3046e-07 - accuracy: 1.0000 - val_loss: 0.1581 - val_accuracy: 0.9821\n",
            "Epoch 88/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.5858e-07 - accuracy: 1.0000 - val_loss: 0.1589 - val_accuracy: 0.9821\n",
            "Epoch 89/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.9357e-07 - accuracy: 1.0000 - val_loss: 0.1597 - val_accuracy: 0.9821\n",
            "Epoch 90/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3406e-07 - accuracy: 1.0000 - val_loss: 0.1606 - val_accuracy: 0.9821\n",
            "Epoch 91/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7870e-07 - accuracy: 1.0000 - val_loss: 0.1614 - val_accuracy: 0.9820\n",
            "Epoch 92/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2772e-07 - accuracy: 1.0000 - val_loss: 0.1624 - val_accuracy: 0.9821\n",
            "Epoch 93/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.8162e-07 - accuracy: 1.0000 - val_loss: 0.1632 - val_accuracy: 0.9821\n",
            "Epoch 94/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3943e-07 - accuracy: 1.0000 - val_loss: 0.1641 - val_accuracy: 0.9821\n",
            "Epoch 95/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.0057e-07 - accuracy: 1.0000 - val_loss: 0.1650 - val_accuracy: 0.9821\n",
            "Epoch 96/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6378e-07 - accuracy: 1.0000 - val_loss: 0.1661 - val_accuracy: 0.9821\n",
            "Epoch 97/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3051e-07 - accuracy: 1.0000 - val_loss: 0.1670 - val_accuracy: 0.9821\n",
            "Epoch 98/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0081e-07 - accuracy: 1.0000 - val_loss: 0.1680 - val_accuracy: 0.9821\n",
            "Epoch 99/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7327e-07 - accuracy: 1.0000 - val_loss: 0.1690 - val_accuracy: 0.9823\n",
            "Epoch 100/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4835e-07 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 0.9823\n",
            "Epoch 101/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2571e-07 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 0.9823\n",
            "Epoch 102/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0491e-07 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 0.9823\n",
            "Epoch 103/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8692e-07 - accuracy: 1.0000 - val_loss: 0.1732 - val_accuracy: 0.9823\n",
            "Epoch 104/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7009e-07 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9824\n",
            "Epoch 105/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5466e-07 - accuracy: 1.0000 - val_loss: 0.1754 - val_accuracy: 0.9825\n",
            "Epoch 106/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4031e-07 - accuracy: 1.0000 - val_loss: 0.1764 - val_accuracy: 0.9825\n",
            "Epoch 107/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2830e-07 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 0.9825\n",
            "Epoch 108/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1693e-07 - accuracy: 1.0000 - val_loss: 0.1784 - val_accuracy: 0.9825\n",
            "Epoch 109/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0699e-07 - accuracy: 1.0000 - val_loss: 0.1795 - val_accuracy: 0.9825\n",
            "Epoch 110/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7889e-08 - accuracy: 1.0000 - val_loss: 0.1804 - val_accuracy: 0.9825\n",
            "Epoch 111/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.9579e-08 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 0.9825\n",
            "Epoch 112/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.1754e-08 - accuracy: 1.0000 - val_loss: 0.1825 - val_accuracy: 0.9824\n",
            "Epoch 113/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.5067e-08 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9823\n",
            "Epoch 114/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8800e-08 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9825\n",
            "Epoch 115/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3138e-08 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9825\n",
            "Epoch 116/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8158e-08 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9825\n",
            "Epoch 117/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3557e-08 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9825\n",
            "Epoch 118/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.9239e-08 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9826\n",
            "Epoch 119/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.5265e-08 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.9825\n",
            "Epoch 120/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1954e-08 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9825\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhU9fX48fchhB3ZAghECFZUwAUEkdYFxFJBFMWd1lZbH7G1tm60lVZta79U29pF675QlaroD+tSixpkKVZBAUF2BEFMwhICkrAFspzfH+cOmUlmkglkMlnO63nuM3P3z83APfezXlFVnHPOufKaJDsBzjnn6iYPEM4556LyAOGccy4qDxDOOeei8gDhnHMuqqbJTkBNSUtL04yMjGQnwznn6pXFixfnqWrnaOsaTIDIyMhg0aJFyU6Gc87VKyKyKdY6L2JyzjkXlQcI55xzUXmAcM45F1WDqYOIpqioiOzsbAoLC5OdlIRr0aIF6enppKamJjspzrkGokEHiOzsbNq2bUtGRgYikuzkJIyqsmPHDrKzs+ndu3eyk+OcayAadBFTYWEhnTp1atDBAUBE6NSpU6PIKTnnak+DDhBAgw8OIY3lOp1ztafBBwjnnHOHxwNEgu3atYtHH3202vtdcMEF7Nq1KwEpcs65+HiASLBYAaK4uLjS/WbMmEH79u0TlSznnKtSg27FVBfceeedfP755wwYMIDU1FRatGhBhw4dWLNmDZ999hmXXHIJWVlZFBYWcssttzBhwgSgbOiQPXv2MHr0aM466yw+/PBDevTowRtvvEHLli2TfGXOuYau0QSIW2+FpUtr9pgDBsDf/lb5Nvfffz8rVqxg6dKlzJ07lzFjxrBixYpDzVGnTJlCx44d2b9/P6effjqXXXYZnTp1ijjGunXreOmll3jqqae48sorefXVV7nmmmtq9mKcc66chBUxicgUEckVkRUx1ouIPCQi60VkmYicFrbuWhFZF0zXJiqNyTBkyJCIvgoPPfQQp556KkOHDiUrK4t169ZV2Kd3794MGDAAgEGDBvHFF1/UVnKdc41YInMQzwIPA8/HWD8a6BNMZwCPAWeISEfg18BgQIHFIvKmqn51JImp6km/trRu3frQ97lz5/Lee+8xf/58WrVqxfDhw6P2ZWjevPmh7ykpKezfv79W0uqca9wSFiBUdZ6IZFSyycXA86qqwAIRaS8i3YDhwExV3QkgIjOBUcBLiUprIrVt25bdu3dHXZefn0+HDh1o1aoVa9asYcGCBbWcuppTWgqZmXDGGdChQ+2cc/9+yM2F/HybP/ZYaNPmyI85dy7Mng0HDkCLFiBi5ygogCraFjiXFH36wOTJNX/cZNZB9ACywuazg2WxllcgIhOACQA9e/ZMTCqPUKdOnTjzzDM56aSTaNmyJV27dj20btSoUTz++OP07duXE044gaFDhyYxpRVt3AjTpkFeHtxzD7RrF3vbqVPhuuvshnr11XDHHXDSSfGdp7gY/vpX2LIFeva0/c47z27MsaxcCWedBeVbAnfvbse68sr4zg2wbx+89Ra89BK8+64FiebNoWVLKCwEVbv2o44CH+rK1UVNElVZoKoJm4AMYEWMdW8BZ4XNz8KKlSYCd4UtvxuYWNW5Bg0apOWtWrWqwrKGrKaud98+1fPPV7Vbo2qTJqonnaT65ZfRty8pUT3xRNV+/VRvvFG1TRvVdu1UN2yo+lxbt6oOG2bnadmy7JyPPhp7n4MHVQcNUk1LU336adXp01Vffll18mTVAQNU27ZV3bSp8vOWlqq+/77qD35g6QXVo49Wvflm1XfeUd2/v+q0O9cQAIs01j081oqamKoIEE8A48Pm1wLdgPHAE7G2izV5gIh9vWvWxHezDpk40f5l/OY3qhs3qr73nupRR6l266a6bFnF7f/1L9v+xRdtfsMGCxCnn6564EDs8yxdqtqjhwWGqVPtpr1jh+ro0arNmql+8kn0/X73Ozvf9OkV123YoNq6tQW40tLY577uOjtG69aq3/++6qxZqsXFsbd3rqGqqwFiDPA2IMBQ4ONgeUdgI9AhmDYCHas6lweIitdbWqr64IOqqamqKSmqEyaoZmVVfoz58y3HcOONkcuXL7cn7DPOiLzxlpaqDhmieuyxqkVFZctDQePWW6Of58svLeD06KG6ZEnkuu3bbflxx6nm50euW7LErmf8+NjX8PDDdu4pU6Kv37FDtWlT1WuvVd29O/ZxnGsMkhIgsErlLUARVo9wPfBD4IfBegEeAT4HlgODw/b9AbA+mL4fz/kac4AoLbWbc/j1FhSoXn65/cIXXmhFJ6mpqi1aqH70UfTj7N9vRUXHHFPxxqyq+vjjdrz33itbNmuWLXv88Yrb//Sntm727Mjl+fmqp5xiRUHRciSqqvPmWVA7/XTV115T3btX9fe/tyf+o49WzcuL/fcoKbFiq3btVLOzK65/+mlL16JFsY/hXGORtBxEbU51KUAUF6vu2qW6c6dN4U/W1ZGba2XplZWH79+vumqV3ew+/tiud8sW1YED7Qb7pz+VPfFv3KjavbvqaadVLE7Jy1MdN87+Rbz7bvRzFRba/sOH2/y+fZZ7OPro6GksLLSiqeuvL1tWWqo6Zoyl7Z13Kr/+f/5TtWdPS1OzZvZ5ySXxFZetW2dFV2PHVixq+ta3VL/2tcqLoJxrLDxA1KLSUrthL1xYNi1dagEj1vbR5OdHHuOzzyqW5+fmqi5ebGX1q1apvv32Kp0wQbV3b9VWrVTffrvicadNs1/9kUfKlv3rX6pdulgO409/qvz6/vY323/OHMuZiKi+8krs7a+6SrVrV3uqV7W0gur991d+npCiIqtr+MEPVGfOjG+fkAcesHO9/HLZstxcC06TJlXvWM41VB4gatGWLXZD37rVikXy81VXrLBla9bYtHy5BY3Fi+3Jf80a1c2b7Ylc1QLBkiW2XWGhak6ObbtyZdmNNjfXjrl2rW1fWqr6v/+tUrDWPbGKkUpLVc87T7V9e2vFc8EF9q9gwADVTz+t+vr27lXt3LmsxVFlrY1ULRcAqgsW2Pwdd1ggqqyIqKYUFVkRVefOZed74glLT/l6D+caq8oChI/mWoMKCyEnB9q3hy5doFUrKC3dxdy5j9KtGxQVWSPOli2tXX3nzjYVF9t+K1fCmjXw+efW8eztt/9GSck+une3TmD79sGmTdZpa9MmO0afPtCsmfUZ6NgRZs6EhQthyJDoaRSBhx+GvXvh7LPh/ffhgQfg44/hlFOqvsZWrWDiROsrMHky/OhHlW8/ejSkpMC//w0lJdbXYNQoKDfcVEI0bQrPPANffWXpWLkSXn7Z/mannpr48ztX78WKHPVtSnYOorRUdfVqK0IJLwrauHGj9u/fv8r9Dx603MeyZZYz2L5dtVevXrp9+/ZD2+Tk2LpFiyxXUr4eoTrX+/jjVnG9dWvcuxxSUmI5oHjL8M85xyqlQxXa06ZV/5xHYvp01U6dLOfSpInqXXfV7vmdq8uoJAfRaEZzTbSdO2HPHsjIsCf6kPDhvkeOHEmXLl145ZVXOHDgAOPGjeO3v/0te/fu5corryQ7O5uSkhLuvPNuPvxwG5s3b+bcc88lLS2NOXPm0K2bPbnv3WtPwSkph5/eG288/H2bNKneE/jYsZbruO8+GwrjoosO/9yH47LL4Jxz4PbbYfp0+M53avf8ztVXjStADB9ecdmVV8JNN1n5zQUXVFx/3XU25eXB5ZdHrps7F7DioJwcK34pX3QSPtx3ZmYm06dP5+OPP0ZVGTt2LPPmzWP79u10796d//znP4CN0dSuXTv+8pe/MGfOHNLS0gArHjr2WCumSljX+gS46CILEO+9B9/7nv2dalvnzjYcyD/+YUVPzrmq1aPbTN2VlwcHD0KPHpWPH5SZmUlmZiYDBw7ktNNOY82aNaxbt46TTz6ZmTNn8otf/IL333+fdpUMeiRSv4IDwPHH2wTJf3r34OBc/BrXf5fgiT+qVq0qX5+WFnV9SYkNMte2rQ3mVhlVZdKkSdwYpXznk08+YcaMGdx1112cd9553HPPPZUfrJ757nfh+edhxIhkp8Q5F6969ixa9+TmWuukWLmH8OG+zz//fKZMmcKePXsAyMnJITc3l82bN9OqVSuuueYafvazn/HJJ59U2Le+u+suWLvWn+Cdq0/8v+sR2rHDcg+x3kMQPtz36NGj+fa3v83Xv/51ANq0acM///lP1q9fz89+9jOaNGlCamoqjz32GAATJkxg1KhRdO/enTlz5tTWJSVMZcVvzrm6R6yVU/03ePBgXbRoUcSy1atX07dv34Sd8+BBWLYM0tPh6KMTdpq4Jfp6nXMNj4gsVtXB0dZ5EdMRCJX+tG2b3HQ451wieIA4Anv2WF+EZDTbdM65RGvwASKRRWi7d1vdQ10oW28oRYXOubqjQQeIFi1asGPHjoTcPA8etLGX6kLxkqqyY8cOWrRokeykOOcakAbdiik9PZ3s7Gy2b99e48feu9c6yKWm2mBwydaiRQvS09OTnQznXAPSoANEamoqvXv3TsixJ0yAV16xZq5HMiaSc87VVQ26iCmR5s61AeA8ODjnGioPEIchJwfWrYs+9p9zzjUUHiAOw+zZ9ukBwjnXkHmAOAwzZ9rYfQMGJDslzjmXOB4gqkkVMjNh5Mj6N+y2c85Vh9/iqmn5cti2Db71rWSnxDnnEssDRDVlZtrnyJHJTYdzziVaQgOEiIwSkbUisl5E7oyyvpeIzBKRZSIyV0TSw9b9QURWBNNViUxndWRmQv/+9v4H55xryBIWIEQkBXgEGA30A8aLSL9ymz0APK+qpwD3AvcF+44BTgMGAGcAE0Wkive1Jd7+/TBvnhcvOecah0TmIIYA61V1g6oeBKYBF5fbph8QNBplTtj6fsA8VS1W1b3AMmBUAtMal/ffhwMHPEA45xqHRAaIHkBW2Hx2sCzcp8ClwfdxQFsR6RQsHyUirUQkDTgXOCaBaY1LZiY0a2Y9qJ1zrqFLdiX1RGCYiCwBhgE5QImqZgIzgA+Bl4D5QEn5nUVkgogsEpFFiRiQr7xZs+DMM/39D865xiGRASKHyKf+9GDZIaq6WVUvVdWBwK+CZbuCz8mqOkBVRwICfFb+BKr6pKoOVtXBnTt3TtR1AFBcDCtXwpAhCT2Nc87VGYkMEAuBPiLSW0SaAVcDb4ZvICJpIhJKwyRgSrA8JShqQkROAU4BMhOY1ipt2ABFReCvfHbONRYJG+5bVYtF5GbgXSAFmKKqK0XkXmCRqr4JDAfuExEF5gE/DnZPBd4Xe1VbAXCNqhYnKq3xWLXKPvuVb4flnHMNVELfB6GqM7C6hPBl94R9nw5Mj7JfIdaSqc5Yvdo+TzwxuelwzrnakuxK6npj1So45pi68YpR55yrDR4g4rRqldc/OOcaFw8QcSgthTVrvP7BOde4eICIw5dfwr59noNwzjUuHiDiEKqg9hyEc64x8QARh1ATV89BOOcaEw8QcVi1Crp0gU6dkp0S55yrPR4g4rB6tecenHONjweIKqhaDsLrH5xzjY0HiCps3Qr5+Z6DcM41Ph4gquBjMDnnGisPEFVYu9Y+fQwm51xj4wGiCl9+Camp0K1bslPinHO1ywNEFbKyoEcPaOJ/KedcI+O3vSpkZdkors4519h4gKiCBwjnXGPlAaISpaWQk+MBwjnXOHmAqMS2bfYeag8QzrnGKKGvHK3vsrLs0wOEc46SEti9G9q3t/ncXGjdGvbvt++7d1tzx549y7YP16QJiEQ/dmmpDdsgYtup2v67dtmxc3PtifWEE2DAACguhv/9D5oGt/BvfCMhLWk8QFTCA4RrkEI3IoD//hc2b7abT24u7N0LAwfCddfZduefbzeq/v2tt+j27XD66TBqlK3/8ENo08b2LSiwES3794fOnaGw0JaHtGtnUzLs2QMrV1qZ8aWX2rJnn4UlSyK3a9cO7r3Xvv/mNzBvXtkNOi/Pbs6ffGLrL7wQFi6M3H/4cJgzx7736QMbN5ata9YMrroKnn/e5m+7zY67fLm9kayoCG6+Gf7+dzh4EFq0qHgdv/ylpWHrVjj33LLl+/dH3/4IeYCohAcIV+eo2mfoBp+XB1u22NNrSMuWdpMHePtt+Owzm5Yvt56fQ4bAv/9t66+5BrKz7XvTpvZEvGePBQgRW5afD1OmWPAQgV/8wgLEypVw1lkV0/jss3DttbBoEZx9duS69HT4xz/gm9+E116D22+3YNK1KzRvbtvcfz8cd5wd//HHLd2ff25P2WBBqVcvmD4dHnzQbrJ79pSdY/16+xv8+tfw9NMW4LZts3WtWpUFiHnzLA3huncvCxB5eXaj7tPHrrNLF/ja18q2/fnPLV0tW9q6tm0tWIbcdpvlAEL27IHjjy+bf+stO/5JJ9nfs21bC74AKSmWjnbt7G8T+hulp9v6jh1h1qyyv0lqasXfoQZ4gKhEVpYFZR/m29WonTutmKJJE7uB7N5tN/5QccJXX8EVV9i2L79sN/k1a+ypMTcXOnSwJ2GAb38bZs6MPH6/fnZzBZg8GT74AI46Ck4+GcaOhcGDy7Z9/XW7wXXtasctX0wxY4Z9lpZaIOnUyYIIQEYGvPGGPfl26WLn2LGjbNiBPn3gmWfKjpWbCytW2E04tP9ZZ1muJCfHbpZgOQ+A2bPhuefsBjpihD2Bq0Jamq3PybEANnCg3ZhDQTN0DX37wgUX2PeePe36+/Yty0FNmWJTLA8/HHsdwOWXV77+Jz+pfP26dbHXNW0Kd98de32rVvY3STDR0BNJPTd48GBdtGhRjR7zyith6VJ7+HIuqtxc2LDBvhcV2VPntm1W/JCebk8ZS5aUFSW8954N8FVQYE+MEyfCn/8ceUyRsifDH/3IbuL9+9uNtWtXK+e+/XZbP3OmBZajjiq7QbZuDWeead9DTzlpabHLv+uqoiK7Uda3dNczIrJYVQdHW+c5iEp4Hwh3iCo89hhkZtqNfupUqxicMweuvrri9kOHWoB46y246SZb1rKlFbl897tlxSlXXFE2VHC7dvYk3rFj2XEeesjOG8vIkZWnuz7/A05QsYmLnweISmRlWVGpczz4oJUpH3+8FdGEbvAjRlgREFi5cVqaPeV37WrLxo2zcuWuXeHooyve9M44w6ZY/CbpkiihAUJERgEPAinA06p6f7n1vYApQGdgJ3CNqmYH6/4IjMH6aswEbtFaLA8rLra6v/r8AOaqIScHbrzRyu7HjYPx4y0QiFiu4Y47bPn06ZHl9J07WwVjLEcfbZNz9VDCOsqJSArwCDAa6AeMF5Hyb1V4AHheVU8B7gXuC/b9BnAmcApwEnA6MCxRaY1m82YrBvYAUcesW2c37Jp+Vli8GObOtXbmDz9sLX0yMuxJoVkzGDbMmif6qI2uEUlkDmIIsF5VNwCIyDTgYmBV2Db9gKC2jTnA68F3BVoAzQABUoFtCUxrBd7EtQ4qLYVLLrFK3hkzYPToyPX79lkb9VNPtQrg6hg71iqbu3SxVkRvvGH/CJo2tbbtw4Z5ZalrdBL5ONQDyAqbzw6WhfsUCBolMw5oKyKdVHU+FjC2BNO7qrq6/AlEZIKILBKRRdu3b6/RxHuAqKaVK63lTHjHoHjt22fNxarKFUyfbsHhjjusAxfAT39qFcLDhlkzzbPPhv/7v/jP/dRT1hyxtNSCA9hxrrsuspmhBwfXCCU7vzwRGCYiS7AipBygRESOA/oC6VhQGSEiZ5ffWVWfVNXBqjq4c+fONZowDxDVsH+/teT58ENrt19d775rbdkffbSseWd5paXWcahfP/jDH8qKejIyrE34/v0WLK64Ai66KP5zv/ii9RPwoiPnKkhkEVMOEH57TQ+WHaKqmwlyECLSBrhMVXeJyA3AAlXdE6x7G/g68H4C0xshK8tKKZI1MkC90qQJfOtb1pFrxgy4887q7R/q1XvzzXDOOdahqbzXX7dcyrRp1loo5Pbby/oEVNfevRYcbr318PZ3roFL5GPTQqCPiPQWkWbA1cCb4RuISJqIhNIwCWvRBPAllrNoKiKpWO6iQhFTInkfiDipWpPPP/8ZJkywXET48AJVKSmxvgJDh9r8+zGeAcaMsUriqnqvFhXZMUKd1yrz/vu2vbdldi6qhAUIVS0GbgbexW7ur6jqShG5V0TGBpsNB9aKyGdAV2BysHw68DmwHKun+FRV/52otEbToALESy9ZD97qyM0tG/qgMpdfbqNKgo3rM3WqtfqJ18cf21ALP/mJvds1VoBo3tw6mIXnHqLZv98qlZ97LvY2obqO996z45YfL8g5B8RRxCQiFwH/UdUYhcOxqeoMYEa5ZfeEfZ+OBYPy+5UAN1b3fDUpK6tsvLN6bd8+G68H4m8aumYNnHaajRf04x9bziBaHU9JiRUp9e5tY+r07VvWKzheb71lN/3Ro62oad68yNFGwQZsKyiwwdGqctRRNtplrEBzzz02dsq0aTYkxaWXWg9n51wF8eQgrgLWicgfReTERCeoLigttYfaBtG/6d/VzHiVllpAaNHC6gLuuss6ghUXV9x20yYbWC08KHz5JTzySOzK5vJ++UsblK1DB6t/2Ly5YkuoRx+1iux4nX02zJ9fMQf0n/9Y78eXX4Z33oHf/tYqqZ1zUVUZIFT1GmAgVuTzrIjMD5qXVrOhef2xd689xNaZCuryLx6pjmXL7HP8+PhyEPn51vb/gQfspvzFFzZsc9Momc3VQbXQiWHPDXPmWGXzp5/GPsfUqTYM80cfWU7hnHNs+dixlqMIj8w5OTb2UWW9lcs75xwLXIsXly0rKrLRF5s0seEyrr++bNRQ51xUcdVBqGoBVhQ0DeiG9Vn4RESqGM+2fioosM+jjkpuOgB7uh440DqAhd/wwEbynDnTWg/FuvlPnmzDSb/4Ynxt+Tt0sHHmv/99m+/VK/Z+a9bYZ3gOInQj/8MfbKjl8HH6wUY2/d734IYbrGJ68uSy3EmPHlYZ3apV2faZmZHHjUfoHQXhxUyLF1tx28iR1lN682YrWmogoxk7lwjx1EGMBb4PHAc8DwxR1VwRaYX1iv57YpNY+/Lz7TPuHMTDD9uY9WefXXUlanWsWGHj/xxzjHUO27SprHXOhg3WtDSkf397O1j4yytKS+2JOfQSk/Jl++G2brXmon//e8UXYNx8swWO3/0ucvm+ffYClfDRR7t2hUGDrBinZ097ocpxx1kOpHlz+Otfrez/gw8sd6IamTtZscKu48c/tvl33rFhrk86Ke4/G126WOX3KaeULZs3zz7PPtvSeMstkUNkO+cqUtVKJ+A54JwY686rav/amgYNGqQ1Zf58VVCdMSOOjffvV+3QwXbo1k31kktU775b9aOPjiwRWVmq6emq3burbtqk+tBDdo4NG2z9kiWq3/ym6rRpqg88oJqaqnrrrZHHGD1a9Uc/Us3OVu3USXXKlOjnWrVKtVcv1VatVP/734rrR41SPeWU6PuWllZcNn++6jPPqBYWqm7cqNqxo+pTT9m2V11VMZ3h/vhHu84VK2x+/HjVm26KvX28xoxRPfHEIz+Ocw0MsEhj3f9jrTi0AfQGWoTNtwQyqtqvtqeaDBDvvGN/mf/9r5KNSktVly2z73v22I366qvtJiSies89h5+AXbtUTz5ZtW1b1aVLbdnKlZaop56Kvs+sWar79pXNZ2erNmmietddqgcP2vdoadq5027gXbuqLlwY/di/+pVqSkrk8eNVWqo6cKDqCSeolpSULYtl0ybVzp0tOG7cWP3zhRw4YIHoiSfsvO3bq06YcPjHc66BOtIAsQhoFjbfDFhY1X61PdVkgHjlFfvLLF9eyUZTp1ogiPbEXVh4eCcuLbVp2zbVoUNVMzMj1x19tAWhggLV3Nzox/jyS9WRI1VbtLCb+qpVtrxnT9Xvfrfi9pmZdrHvvhs7Xa+9ZtssWFC2LFoaY3nxRdv/gQeq3lbVgmKHDqrHHKOakxPfPuWVlqqOGGGBYds2m7788vCO5VwDVlmAiKeSuqmqHmovGHyvRk+o+qfKSuqdO+1VkaefHv2l7aGXycyeDU88Ed9J//IXq2v4/HMrQ//gg8i3hYnYy2lmz4YXXrCWPuV7C6tan4elS62VzoIFZRXIGRlW5l9eqCXSgAGx0zZokH2Gv9J19Wo7vsZRyRt6v/LEidYiqSqnnmp1D1lZVldwOESsbmjvXhv6o0uXBtTz0bnaEc9YTNtFZKyqvgkgIhcDeYlNVnJVWkn9xRfWOuerr6xdfWWDvD3xBLz2mgWR/v1jb5eTY53AzjjDmmNC9OPefTf85jdWaXzssdZBLZyINU1t1qxis9Teva11Unk/+YlVhFc22GF6Opx7bmTrolBgiadjXNOm8Oqr1uIq3srmIUOsUj5a89p49e1rFe9/+IMd58knD/9YzjVC8eQgfgj8UkS+FJEs4BckuZdzooVyEKHGP4fs3m3vId6yxZpfhp6sY3n4YfucOjVy+Rdf2JAQIc88Y30dnn++8hvuiSfajXz2bOsBHK0FTqtW0W+qY8ZY7qL8E7+IPVlX1ppHxM4ZavoKFiBat7bgEY9LL7V3K1en1VDPntaC6UjcfbcFTB+t1blqq/LxTFU/B4YGo62iwQirDVl+vgWHCi1W27a1pp7f+EZ8T86dO1txyUcflS0rKrKn+RNOsJtsSYk92Z5/vjUZrcoNN1i/gXHjqnVNXHFFWVFPiKo1J7300vgGrAv1jm7SxNJ+4ol1v5lo69Y2eGB1xodyzgFxdpQTkTHATcDtInKPiNxT1T71WUFBJX0grr++euMNDR1qZffhvaHPOw/WroUpU6yn844d8MMfxne8UP3GkCHxpyFk716bQrZutaf61XEMlPvBB9bfYcECmz/22PozCmrLljXbP8W5RqLKACEij2PjMf0Ee/3nFUCvBKcrqQoKolRQ79plo4l+8EH1DhYaxC70xrvUVCueGj4cbrsN0tKsDuLCC+M73rPPWge16haZZGdbtuiFF8qWrVxpn5XVj4RkZFjWav58m3/8cbj//uqlwTlXr8Rzl/mGqn4P+EpVf4u9uOf4xCYrufLzo+QgNm2Cf6n+rKAAABSFSURBVP7T6h+q46qrrFdvaHyhV16xcYqmTLGiokmT7Mk83srYpk0Pb/TRbt1s3/CWTKuC14P361f1/t27W5HSxIlWnxHeosk51yDFEyBCI5rtE5HuQBE2HlODFTUHkRO8DC/eStnyVK2Y6YYbrHVT795WvFNaemSD8cUrJcUqfcNHSl250oJT165V7y9iQ2D8+tc2xPcFF9g7I5xzDVY8AeLfItIe+BPwCfAF0KDHSI6ag8jOts8ePap/wJ//3OoiPv3Uok9o9NJrr7VB9GqrfLx378gAsWePjVcUb0Vzly7WzLaw0F4S1KVLQpLpnKsbKi3XCF4HOktVdwGvishb2LAb+bWSuiSJmoPIzrZy/8N5SUSbNrBwoQ1lDWUBAmq3FVDv3vBm2FtfX3gh/vc2hGve3IbMds41aJUGCFUtFZFHsPdBoKoHgAO1kbBkys+PEiCKi21U0tTU6h/wjDOsiOnPf7bWP4dbTHWkrrzSXgKkYaO6ev8A51wM8dwdZonIZSJ1vcF7zSgpsZagFYqYfv97a5p6OEJNUgsKYNiwI0rfERk5En76UwsOH35ow4WvW5e89Djn6rR4ms7cCNwOFItIIdbUVVW1LrxOp8bt3m2fNfqyoA4drGNcr17Jbxq6a5d1ssvIsKEv2jbYFwM6545QPD2pG9UdJOY4TGPGWJPV733v8A58441WGZ3sit1t26zJ7ty5FrjiacHknGuU4nmj3DnRlqvqvJpPTvJFHcl1925r2nkkxUO33XZE6aoxJ5xgfRh++EMLVo2j5NA5dxjiKWL6Wdj3FsAQYDEwIiEpSrJQDiIiQIT6QBxOE9e6qGNH67DnnHOViKeI6aLweRE5BvhbwlKUZKEcREQRU6gPRLJaHznnXBIcThvHbCCu0epEZJSIrBWR9SJyZ5T1vURklogsE5G5IpIeLD9XRJaGTYUicslhpLXaohYxeYBwzjVC8dRB/B0IvUSgCTAA61Fd1X4pwCPASCyoLBSRN1V1VdhmDwDPq+pzIjICuA/4rqrOCc6DiHQE1gOZcV/VEYhaSZ2aagPuHem7CZxzrh6Jpw4ifFS2YuAlVY1nSNMhwHpV3QAgItOAi4HwANEPa0ILMAd4PcpxLgfeVtV9cZzziEXNQXznOzY551wjEk+AmA4UqmoJWM5ARFrFccPuAWSFzWcDZ5Tb5lPgUuBBYBzQVkQ6qeqOsG2uBv4S7QQiMgGYANCzZ884LqVq+fnWubh16xo5nHPO1Vtx9aQGwseXbgm8V0PnnwgME5ElwDAgBzg0tKmIdANOBt6NtrOqPqmqg1V1cOfK3qlcDaFxmCJaf15yib343jnnGpF4chAtwl8zqqp7RKRVZTsEcoBjwubTg2WHqOpmLAdB8ErTy4KBAUOuBF5T1aI4zlcjog7U9+GH3qHMOdfoxJOD2Csip4VmRGQQsD+O/RYCfUSkt4g0w4qK3gzfQETSghFjASYBU8odYzzwUhznqjEVhvo+cMDeBuctmJxzjUw8OYhbgf8nIpuxcZiOxl5BWilVLRaRm7HioRRgiqquFJF7gUWq+iYwHLhPRBSYB/w4tL+IZGA5kP9W54KO1KEcREGBvblt82Zb4QHCOdfIxNNRbqGInAicECxaG2+Rj6rOAGaUW3ZP2PfpWCV4tH2/wCq6a1V+PnTprDYkRbNmMHWqrWgovaidcy5OVRYxiciPgdaqukJVVwBtROSmxCctOQoKIKP5Fti61UY8bd7chsk+9thkJ80552pVPHUQN4RXHKvqV8ANiUtSchUUQIZ13YBJk+xlP5mZ9rIg55xrROIJECnhLwsKekg3S1ySkis/H3oWBQHCcw3OuUYsnkrqd4CXReSJYP5G4O3EJSl5Dh6EwkLoVrjROkL06pXsJDnnXNLEk4P4BTAb+GEwLSey41yDERpmY9nFd9sQ382bJzdBzjmXRFUGCFUtBT4CvsDGVxoBrE5sspLj0DhM7ZtAt27JTYxzziVZzCImETke66g2HsgDXgZQ1XNrJ2m1LzSS65mv3g5p59lrRp1zrpGqLAexBsstXKiqZ6nq3wkbJ6khKiiAluzjuH//FZYuTXZynHMuqSoLEJcCW4A5IvKUiJyH9aRusAoKIIMvbMZbMDnnGrmYAUJVX1fVq4ETsXc13Ap0EZHHRORbtZXA2pSfD8fiTVydcw7iq6Teq6ovBu+mTgeWYC2bGpyCAvgan9uMBwjnXCNXrXdSq+pXwTsYzktUgpIpPx/aswvt0AHS0pKdHOecS6pqBYiGbvdumJzya9ieV+6NQc451/h4gAhTXGwDuEqK/1mcc87vhGGKi5RXD14Er76a7KQ451zSeYAI03r3VkaXvAXbtiU7Kc45l3QeIMK03+lNXJ1zLsQDRJiOu7yJq3POhXiACNMpfyOl+DDfzjkHHiAiFEpLlqcO8mG+nXMODxAR3ur3c8alL0x2Mpxzrk7wABGmuBhSUpKdCuecqxvieeVoo/HT969g8f6+wL3JTopzziWd5yDCHJ/3AV1LtiQ7Gc45Vyd4gAhRpe2BPPJTfZA+55yDBAcIERklImtFZL2I3BllfS8RmSUiy0Rkroikh63rKSKZIrJaRFaJSEYi08ru3aRqEQXNPEA45xwkMECISArwCDAa6AeMF5F+5TZ7AHheVU/BCv7vC1v3PPAnVe0LDAFyE5VWAPLyADxAOOdcIJE5iCHAelXdoKoHgWnAxeW26QfMDr7PCa0PAklTVZ0JoKp7VHVfAtMKpaUsa38O21pmJPQ0zjlXXyQyQPQAssLms4Nl4T7F3n0NMA5oKyKdgOOBXSLyLxFZIiJ/CnIkEURkgogsEpFF27dvP7LUHncctw78L8s7Djuy4zjnXAOR7ErqicAwEVkCDANygBKs+e3ZwfrTgWOB68rvHLzdbrCqDu7cufMRJ6akxPtBOOdcSCIDRA5wTNh8erDsEFXdrKqXqupA4FfBsl1YbmNpUDxVDLwOnJbAtMITT/Dcwr60YU9CT+Occ/VFIgPEQqCPiPQWkWbA1cCb4RuISJqIhNIwCZgStm97EQllC0YAqxKYVti0ifT96yhq1jqhp3HOufoiYQEiePK/GXgXWA28oqorReReERkbbDYcWCsinwFdgcnBviVY8dIsEVkOCPBUotIKQF4e+U3TaJrq76J2zjlI8FAbqjoDmFFu2T1h36cD02PsOxM4JZHpi5CXx86mnb0OwjnnAsmupK478vL4KiWNpj46lXPOAT5YX5mhQ1mwuq3nIJxzLuABIuSPf+SRN2CgBwjnnAO8iClCcTFexOSccwEPEAA7d8JRR3Fp/hQvYnLOuYAHCLCB+nbvplCbew7COecCHiDg0EiuO7ST5yCccy7gAQIOBYjt6s1cnXMuxAMEHAoQuaVpnoNwzrmABwiA3r3h2mvJVe9J7ZxzIR4gAM49F559loKS1l7E5JxzAQ8QAAcPgqq/D8I558L48zLA5ZfDli2UlCz0HIRzzgU8BwGwYwe0a0dxsecgnHMuxAMEQF4e2ikN8KE2nHMuxAMEQF4epR0tQHgOwjnnjAeI4mL46itKO9nbTT0H4ZxzxgNEcTFMmkTR188BPAfhnHMh/rzcogVMnszBXTbrAcI554znIAIlJfbpRUzOOWc8QASKi+3TcxDOOWc8QAQ8B+Gcc5E8QAQ8B+Gcc5E8QAQ8B+Gcc5ESGiBEZJSIrBWR9SJyZ5T1vURklogsE5G5IpIetq5ERJYG05uJTCd4DsI558pL2POyiKQAjwAjgWxgoYi8qaqrwjZ7AHheVZ8TkRHAfcB3g3X7VXVAotJXXigH4QHCOedMInMQQ4D1qrpBVQ8C04CLy23TD5gdfJ8TZX2t8SIm55yLlMgA0QPICpvPDpaF+xS4NPg+DmgrIp2C+RYiskhEFojIJdFOICITgm0Wbd++/YgS60VMzjkXKdmV1BOBYSKyBBgG5ADBszy9VHUw8G3gbyLytfI7q+qTqjpYVQd37tz5iBLiOQjnnIuUyNthDnBM2Hx6sOwQVd1MkIMQkTbAZaq6K1iXE3xuEJG5wEDg80Ql1nMQzjkXKZE5iIVAHxHpLSLNgKuBiNZIIpImIqE0TAKmBMs7iEjz0DbAmUB45XaN8xyEc85FSliAUNVi4GbgXWA18IqqrhSRe0VkbLDZcGCtiHwGdAUmB8v7AotE5FOs8vr+cq2fapznIJxzLlJCn5dVdQYwo9yye8K+TwemR9nvQ+DkRKatPG/m6pxzkZJdSV1neBGTc85F8gAR8CIm55yL5AEi4DkI55yL5AEi4DkI55yL5AEi4DkI55yL5AEi4DkI55yL5AEi4M1cnXMukgeIgBcxOedcJA8QAS9ics65SB4gAp6DcM65SB4gAp6DcM65SB4gAp6DcM65SB4gAp6DcM65SB4gAt7M1TnnInmACHgRk3PORfIAEfAiJueci+QBIuA5COeci+QBIuA5COeci+QBIhDKQTTxv4hzzgEeIA4pLrbcg0iyU+Kcc3WDB4hASYkXLznnXDgPEIGSEq+gds65cB4gAqEiJuecc8YDRMBzEM45F8kDRMBzEM45FymhAUJERonIWhFZLyJ3RlnfS0RmicgyEZkrIunl1h8lItki8nAi0wmeg3DOufISFiBEJAV4BBgN9APGi0i/cps9ADyvqqcA9wL3lVv/O2BeotIYznMQzjkXKZE5iCHAelXdoKoHgWnAxeW26QfMDr7PCV8vIoOArkBmAtN4iDdzdc65SIksVOkBZIXNZwNnlNvmU+BS4EFgHNBWRDoBXwF/Bq4BvhnrBCIyAZgQzO4RkbVHkN40IK+BdJRLA/KSnYga4tdSN/m11F3VvZ5esVYku9R9IvCwiFyHFSXlACXATcAMVc2WSu7Yqvok8GRNJEREFqnq4Jo4VrL5tdRNfi11U0O6FqjZ60lkgMgBjgmbTw+WHaKqm7EcBCLSBrhMVXeJyNeBs0XkJqAN0ExE9qhqhYpu55xziZHIALEQ6CMivbHAcDXw7fANRCQN2KmqpcAkYAqAqn4nbJvrgMEeHJxzrnYlrJJaVYuBm4F3gdXAK6q6UkTuFZGxwWbDgbUi8hlWIT05UemJQ40UVdURfi11k19L3dSQrgVq8HpEVWvqWM455xoQ70ntnHMuKg8Qzjnnomr0AaKq4UDqMhE5RkTmiMgqEVkpIrcEyzuKyEwRWRd8dkh2WuMlIikiskRE3grme4vIR8Hv87KINEt2GuMlIu1FZLqIrBGR1SLy9fr624jIbcG/sRUi8pKItKgvv42ITBGRXBFZEbYs6u8g5qHgmpaJyGnJS3lFMa7lT8G/sWUi8pqItA9bNym4lrUicn51z9eoA0Scw4HUZcXAHaraDxgK/DhI/53ALFXtA8wK5uuLW7BGDSF/AP6qqsdhHSivT0qqDs+DwDuqeiJwKnZd9e63EZEewE+x1oQnASlYq8T68ts8C4wqtyzW7zAa6BNME4DHaimN8XqWitcyEzgpGLLoM6xFKMG94Gqgf7DPo8E9L26NOkAQ33AgdZaqblHVT4Lvu7EbUA/sGp4LNnsOuCQ5KayeYLDGMcDTwbwAI4DpwSb16VraAecAzwCo6kFV3UU9/W2wJvEtRaQp0ArYQj35bVR1HrCz3OJYv8PF2PhwqqoLgPYi0q12Ulq1aNeiqplBq1GABVifM7BrmaaqB1R1I7Aeu+fFrbEHiGjDgfRIUlqOiIhkAAOBj4CuqrolWLUVa0JcH/wN+DlQGsx3AnaF/eOvT79Pb2A78I+gyOxpEWlNPfxtVDUHG1jzSyww5AOLqb+/DcT+Her7PeEHwNvB9yO+lsYeIBqEoBf6q8CtqloQvk6tHXOdb8ssIhcCuaq6ONlpqSFNgdOAx1R1ILCXcsVJ9ei36YA9jfYGugOtqVjMUW/Vl9+hKiLyK6zY+YWaOmZjDxBVDgdS14lIKhYcXlDVfwWLt4WyxcFnbrLSVw1nAmNF5AusqG8EVobfPijWgPr1+2QD2ar6UTA/HQsY9fG3+SawUVW3q2oR8C/s96qvvw3E/h3q5T0hGHHiQuA7Wta57YivpbEHiEPDgQQtMK4G3kxymuIWlNE/A6xW1b+ErXoTuDb4fi3wRm2nrbpUdZKqpqtqBvY7zA6GXJkDXB5sVi+uBUBVtwJZInJCsOg8YBX18LfBipaGikir4N9c6Frq5W8TiPU7vAl8L2jNNBTIDyuKqpNEZBRWNDtWVfeFrXoTuFpEmgdDHvUBPq7WwVW1UU/ABVjN/+fAr5Kdnmqm/Swsa7wMWBpMF2Bl97OAdcB7QMdkp7Wa1zUceCv4fmzwj3o98P+A5slOXzWuYwCwKPh9Xgc61NffBvgtsAZYAUwFmteX3wZ4Cas7KcJydtfH+h0AwVo2fg4sx1puJf0aqriW9VhdQ+ge8HjY9r8KrmUtMLq65/OhNpxzzkXV2IuYnHPOxeABwjnnXFQeIJxzzkXlAcI551xUHiCcc85F5QHCuWoQkRIRWRo21dhgeyKSET5Kp3PJlsh3UjvXEO1X1QHJToRztcFzEM7VABH5QkT+KCLLReRjETkuWJ4hIrODsfpniUjPYHnXYOz+T4PpG8GhUkTkqeDdC5ki0jJpF+UaPQ8QzlVPy3JFTFeFrctX1ZOBh7GRaQH+DjynNlb/C8BDwfKHgP+q6qnYGE0rg+V9gEdUtT+wC7gswdfjXEzek9q5ahCRParaJsryL4ARqrohGEBxq6p2EpE8oJuqFgXLt6hqmohsB9JV9UDYMTKAmWovsUFEfgGkqur/Jf7KnKvIcxDO1RyN8b06DoR9L8HrCV0SeYBwruZcFfY5P/j+ITY6LcB3gPeD77OAH8Gh93C3q61EOhcvfzpxrnpaisjSsPl3VDXU1LWDiCzDcgHjg2U/wd4q9zPsDXPfD5bfAjwpItdjOYUfYaN0OldneB2EczUgqIMYrKp5yU6LczXFi5icc85F5TkI55xzUXkOwjnnXFQeIJxzzkXlAcI551xUHiCcc85F5QHCOedcVP8fBXY6xMr5Yv4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0475 - accuracy: 0.9956\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1393 - accuracy: 0.9841\n",
            "train accuracy :  0.9956333041191101 train loss :  0.047478754073381424\n",
            "test accuracy :  0.9840999841690063  test loss :  0.13929954171180725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S9hjov62D_6a",
        "outputId": "efec7806-2e56-43e5-c796-6bc94320a3ed"
      },
      "source": [
        "#신경망 학습2_2_3\n",
        "model2_2_3 = models.Sequential([\n",
        "                               Flatten(input_shape = (28, 28)),\n",
        "                               Dense(512, activation= 'relu'),\n",
        "                               Dense(256, activation= 'relu'),\n",
        "                               Dense(10, activation= 'softmax')\n",
        "                               ])\n",
        "\n",
        "model2_2_3.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "hist2_2_3 = model2_2_3.fit(train_x, train_y, epochs = 500, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "#학습 그래프4\n",
        "plt.plot(hist2_2_3.history['accuracy'], 'b-')\n",
        "plt.plot(hist2_2_3.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train2_2_3 = model2_2_3.evaluate(train_x, train_y)\n",
        "sc_test2_2_3 = model2_2_3.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train2_2_3[1], \"train loss : \", sc_train2_2_3[0])\n",
        "print(\"test accuracy : \", sc_test2_2_3[1], \" test loss : \", sc_test2_2_3[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "176/176 [==============================] - 2s 7ms/step - loss: 0.3199 - accuracy: 0.9092 - val_loss: 0.1670 - val_accuracy: 0.9485\n",
            "Epoch 2/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.1149 - accuracy: 0.9659 - val_loss: 0.1148 - val_accuracy: 0.9655\n",
            "Epoch 3/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0706 - accuracy: 0.9790 - val_loss: 0.0997 - val_accuracy: 0.9705\n",
            "Epoch 4/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0488 - accuracy: 0.9855 - val_loss: 0.0883 - val_accuracy: 0.9747\n",
            "Epoch 5/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0320 - accuracy: 0.9906 - val_loss: 0.0860 - val_accuracy: 0.9752\n",
            "Epoch 6/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0244 - accuracy: 0.9928 - val_loss: 0.0910 - val_accuracy: 0.9746\n",
            "Epoch 7/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0180 - accuracy: 0.9949 - val_loss: 0.0970 - val_accuracy: 0.9739\n",
            "Epoch 8/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0124 - accuracy: 0.9967 - val_loss: 0.1056 - val_accuracy: 0.9709\n",
            "Epoch 9/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 0.0999 - val_accuracy: 0.9753\n",
            "Epoch 10/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.0997 - val_accuracy: 0.9757\n",
            "Epoch 11/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0971 - val_accuracy: 0.9776\n",
            "Epoch 12/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.1093 - val_accuracy: 0.9729\n",
            "Epoch 13/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.1253 - val_accuracy: 0.9717\n",
            "Epoch 14/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.1175 - val_accuracy: 0.9759\n",
            "Epoch 15/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.1086 - val_accuracy: 0.9766\n",
            "Epoch 16/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.1129 - val_accuracy: 0.9770\n",
            "Epoch 17/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.1146 - val_accuracy: 0.9775\n",
            "Epoch 18/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.1212 - val_accuracy: 0.9753\n",
            "Epoch 19/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.1227 - val_accuracy: 0.9760\n",
            "Epoch 20/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.1256 - val_accuracy: 0.9752\n",
            "Epoch 21/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.1244 - val_accuracy: 0.9774\n",
            "Epoch 22/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.1413 - val_accuracy: 0.9749\n",
            "Epoch 23/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0039 - accuracy: 0.9985 - val_loss: 0.1346 - val_accuracy: 0.9781\n",
            "Epoch 24/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.1346 - val_accuracy: 0.9756\n",
            "Epoch 25/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.1369 - val_accuracy: 0.9755\n",
            "Epoch 26/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 0.1288 - val_accuracy: 0.9765\n",
            "Epoch 27/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.1289 - val_accuracy: 0.9767\n",
            "Epoch 28/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.1338 - val_accuracy: 0.9772\n",
            "Epoch 29/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.1251 - val_accuracy: 0.9794\n",
            "Epoch 30/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6506e-04 - accuracy: 1.0000 - val_loss: 0.1190 - val_accuracy: 0.9803\n",
            "Epoch 31/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1754e-05 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9803\n",
            "Epoch 32/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6907e-05 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9805\n",
            "Epoch 33/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0362e-05 - accuracy: 1.0000 - val_loss: 0.1219 - val_accuracy: 0.9804\n",
            "Epoch 34/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6255e-05 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 0.9803\n",
            "Epoch 35/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3032e-05 - accuracy: 1.0000 - val_loss: 0.1236 - val_accuracy: 0.9805\n",
            "Epoch 36/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0412e-05 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9806\n",
            "Epoch 37/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8255e-05 - accuracy: 1.0000 - val_loss: 0.1253 - val_accuracy: 0.9807\n",
            "Epoch 38/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6454e-05 - accuracy: 1.0000 - val_loss: 0.1259 - val_accuracy: 0.9808\n",
            "Epoch 39/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4863e-05 - accuracy: 1.0000 - val_loss: 0.1268 - val_accuracy: 0.9807\n",
            "Epoch 40/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3482e-05 - accuracy: 1.0000 - val_loss: 0.1275 - val_accuracy: 0.9808\n",
            "Epoch 41/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2275e-05 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.9807\n",
            "Epoch 42/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1203e-05 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 0.9808\n",
            "Epoch 43/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0238e-05 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.9808\n",
            "Epoch 44/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.3900e-06 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 0.9808\n",
            "Epoch 45/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.5959e-06 - accuracy: 1.0000 - val_loss: 0.1312 - val_accuracy: 0.9807\n",
            "Epoch 46/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8875e-06 - accuracy: 1.0000 - val_loss: 0.1318 - val_accuracy: 0.9807\n",
            "Epoch 47/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.2433e-06 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 0.9809\n",
            "Epoch 48/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.6763e-06 - accuracy: 1.0000 - val_loss: 0.1335 - val_accuracy: 0.9808\n",
            "Epoch 49/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1157e-06 - accuracy: 1.0000 - val_loss: 0.1341 - val_accuracy: 0.9808\n",
            "Epoch 50/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6531e-06 - accuracy: 1.0000 - val_loss: 0.1349 - val_accuracy: 0.9809\n",
            "Epoch 51/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2074e-06 - accuracy: 1.0000 - val_loss: 0.1354 - val_accuracy: 0.9807\n",
            "Epoch 52/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.8316e-06 - accuracy: 1.0000 - val_loss: 0.1364 - val_accuracy: 0.9808\n",
            "Epoch 53/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.4204e-06 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.9807\n",
            "Epoch 54/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0615e-06 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9808\n",
            "Epoch 55/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7623e-06 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9807\n",
            "Epoch 56/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.4581e-06 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9806\n",
            "Epoch 57/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1929e-06 - accuracy: 1.0000 - val_loss: 0.1399 - val_accuracy: 0.9809\n",
            "Epoch 58/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9724e-06 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 0.9808\n",
            "Epoch 59/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7388e-06 - accuracy: 1.0000 - val_loss: 0.1416 - val_accuracy: 0.9807\n",
            "Epoch 60/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5164e-06 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9809\n",
            "Epoch 61/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3285e-06 - accuracy: 1.0000 - val_loss: 0.1432 - val_accuracy: 0.9808\n",
            "Epoch 62/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1469e-06 - accuracy: 1.0000 - val_loss: 0.1437 - val_accuracy: 0.9809\n",
            "Epoch 63/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9786e-06 - accuracy: 1.0000 - val_loss: 0.1446 - val_accuracy: 0.9809\n",
            "Epoch 64/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8491e-06 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.9809\n",
            "Epoch 65/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6887e-06 - accuracy: 1.0000 - val_loss: 0.1460 - val_accuracy: 0.9809\n",
            "Epoch 66/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5658e-06 - accuracy: 1.0000 - val_loss: 0.1465 - val_accuracy: 0.9808\n",
            "Epoch 67/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4400e-06 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9809\n",
            "Epoch 68/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3307e-06 - accuracy: 1.0000 - val_loss: 0.1483 - val_accuracy: 0.9808\n",
            "Epoch 69/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2256e-06 - accuracy: 1.0000 - val_loss: 0.1490 - val_accuracy: 0.9808\n",
            "Epoch 70/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1211e-06 - accuracy: 1.0000 - val_loss: 0.1499 - val_accuracy: 0.9810\n",
            "Epoch 71/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0467e-06 - accuracy: 1.0000 - val_loss: 0.1509 - val_accuracy: 0.9810\n",
            "Epoch 72/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.6192e-07 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 0.9809\n",
            "Epoch 73/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.9033e-07 - accuracy: 1.0000 - val_loss: 0.1523 - val_accuracy: 0.9807\n",
            "Epoch 74/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.2202e-07 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9811\n",
            "Epoch 75/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.5361e-07 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9809\n",
            "Epoch 76/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.9305e-07 - accuracy: 1.0000 - val_loss: 0.1545 - val_accuracy: 0.9809\n",
            "Epoch 77/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.4664e-07 - accuracy: 1.0000 - val_loss: 0.1550 - val_accuracy: 0.9808\n",
            "Epoch 78/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9019e-07 - accuracy: 1.0000 - val_loss: 0.1562 - val_accuracy: 0.9809\n",
            "Epoch 79/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4320e-07 - accuracy: 1.0000 - val_loss: 0.1566 - val_accuracy: 0.9810\n",
            "Epoch 80/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0306e-07 - accuracy: 1.0000 - val_loss: 0.1571 - val_accuracy: 0.9809\n",
            "Epoch 81/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.6114e-07 - accuracy: 1.0000 - val_loss: 0.1581 - val_accuracy: 0.9810\n",
            "Epoch 82/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.2212e-07 - accuracy: 1.0000 - val_loss: 0.1586 - val_accuracy: 0.9811\n",
            "Epoch 83/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9347e-07 - accuracy: 1.0000 - val_loss: 0.1594 - val_accuracy: 0.9808\n",
            "Epoch 84/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6410e-07 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 0.9810\n",
            "Epoch 85/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3397e-07 - accuracy: 1.0000 - val_loss: 0.1612 - val_accuracy: 0.9810\n",
            "Epoch 86/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0683e-07 - accuracy: 1.0000 - val_loss: 0.1618 - val_accuracy: 0.9810\n",
            "Epoch 87/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8292e-07 - accuracy: 1.0000 - val_loss: 0.1630 - val_accuracy: 0.9811\n",
            "Epoch 88/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6019e-07 - accuracy: 1.0000 - val_loss: 0.1637 - val_accuracy: 0.9809\n",
            "Epoch 89/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4310e-07 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 0.9811\n",
            "Epoch 90/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1915e-07 - accuracy: 1.0000 - val_loss: 0.1652 - val_accuracy: 0.9811\n",
            "Epoch 91/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0297e-07 - accuracy: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9809\n",
            "Epoch 92/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8675e-07 - accuracy: 1.0000 - val_loss: 0.1666 - val_accuracy: 0.9809\n",
            "Epoch 93/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7420e-07 - accuracy: 1.0000 - val_loss: 0.1674 - val_accuracy: 0.9810\n",
            "Epoch 94/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5968e-07 - accuracy: 1.0000 - val_loss: 0.1679 - val_accuracy: 0.9810\n",
            "Epoch 95/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4673e-07 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9812\n",
            "Epoch 96/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3460e-07 - accuracy: 1.0000 - val_loss: 0.1692 - val_accuracy: 0.9811\n",
            "Epoch 97/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2452e-07 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 0.9811\n",
            "Epoch 98/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1462e-07 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 0.9812\n",
            "Epoch 99/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0593e-07 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 0.9811\n",
            "Epoch 100/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.7799e-08 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 0.9811\n",
            "Epoch 101/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.0323e-08 - accuracy: 1.0000 - val_loss: 0.1736 - val_accuracy: 0.9811\n",
            "Epoch 102/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.3719e-08 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9812\n",
            "Epoch 103/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7038e-08 - accuracy: 1.0000 - val_loss: 0.1749 - val_accuracy: 0.9812\n",
            "Epoch 104/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.1149e-08 - accuracy: 1.0000 - val_loss: 0.1758 - val_accuracy: 0.9811\n",
            "Epoch 105/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5766e-08 - accuracy: 1.0000 - val_loss: 0.1767 - val_accuracy: 0.9812\n",
            "Epoch 106/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0370e-08 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 0.9811\n",
            "Epoch 107/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6230e-08 - accuracy: 1.0000 - val_loss: 0.1781 - val_accuracy: 0.9812\n",
            "Epoch 108/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1673e-08 - accuracy: 1.0000 - val_loss: 0.1783 - val_accuracy: 0.9813\n",
            "Epoch 109/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.8312e-08 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9813\n",
            "Epoch 110/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4587e-08 - accuracy: 1.0000 - val_loss: 0.1797 - val_accuracy: 0.9811\n",
            "Epoch 111/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.1291e-08 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9811\n",
            "Epoch 112/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.8332e-08 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9812\n",
            "Epoch 113/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.5665e-08 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 0.9811\n",
            "Epoch 114/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2873e-08 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 0.9813\n",
            "Epoch 115/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0451e-08 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 0.9813\n",
            "Epoch 116/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8266e-08 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.9812\n",
            "Epoch 117/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6385e-08 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 0.9813\n",
            "Epoch 118/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4515e-08 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9812\n",
            "Epoch 119/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2819e-08 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9813\n",
            "Epoch 120/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1270e-08 - accuracy: 1.0000 - val_loss: 0.1870 - val_accuracy: 0.9815\n",
            "Epoch 121/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9850e-08 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 0.9814\n",
            "Epoch 122/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8454e-08 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.9815\n",
            "Epoch 123/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7314e-08 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9816\n",
            "Epoch 124/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6114e-08 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 0.9815\n",
            "Epoch 125/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5060e-08 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9813\n",
            "Epoch 126/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4141e-08 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 0.9815\n",
            "Epoch 127/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3362e-08 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9814\n",
            "Epoch 128/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2464e-08 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 0.9814\n",
            "Epoch 129/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1722e-08 - accuracy: 1.0000 - val_loss: 0.1922 - val_accuracy: 0.9812\n",
            "Epoch 130/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0922e-08 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 0.9813\n",
            "Epoch 131/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0278e-08 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9815\n",
            "Epoch 132/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.6824e-09 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9814\n",
            "Epoch 133/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.1685e-09 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9814\n",
            "Epoch 134/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.5804e-09 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9815\n",
            "Epoch 135/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.0983e-09 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9813\n",
            "Epoch 136/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.6479e-09 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.9813\n",
            "Epoch 137/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.1764e-09 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 0.9814\n",
            "Epoch 138/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.9009e-09 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9815\n",
            "Epoch 139/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5724e-09 - accuracy: 1.0000 - val_loss: 0.1971 - val_accuracy: 0.9815\n",
            "Epoch 140/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2121e-09 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9813\n",
            "Epoch 141/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8730e-09 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9814\n",
            "Epoch 142/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.6028e-09 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9813\n",
            "Epoch 143/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2849e-09 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.9814\n",
            "Epoch 144/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.9935e-09 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9815\n",
            "Epoch 145/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.7869e-09 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.9813\n",
            "Epoch 146/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.5935e-09 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9814\n",
            "Epoch 147/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3684e-09 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9814\n",
            "Epoch 148/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.1485e-09 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9813\n",
            "Epoch 149/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9736e-09 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9815\n",
            "Epoch 150/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.7352e-09 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9815\n",
            "Epoch 151/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6107e-09 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9815\n",
            "Epoch 152/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.5021e-09 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9815\n",
            "Epoch 153/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.2690e-09 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9814\n",
            "Epoch 154/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1551e-09 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9814\n",
            "Epoch 155/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0994e-09 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9815\n",
            "Epoch 156/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9272e-09 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 0.9815\n",
            "Epoch 157/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8266e-09 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9815\n",
            "Epoch 158/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7471e-09 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9815\n",
            "Epoch 159/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5935e-09 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 0.9815\n",
            "Epoch 160/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5776e-09 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9814\n",
            "Epoch 161/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4584e-09 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 0.9815\n",
            "Epoch 162/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4292e-09 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.9815\n",
            "Epoch 163/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3206e-09 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9815\n",
            "Epoch 164/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2597e-09 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9814\n",
            "Epoch 165/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1405e-09 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 0.9814\n",
            "Epoch 166/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0875e-09 - accuracy: 1.0000 - val_loss: 0.2051 - val_accuracy: 0.9813\n",
            "Epoch 167/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0425e-09 - accuracy: 1.0000 - val_loss: 0.2053 - val_accuracy: 0.9815\n",
            "Epoch 168/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0186e-09 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 0.9814\n",
            "Epoch 169/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9365e-09 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 0.9815\n",
            "Epoch 170/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9100e-09 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9813\n",
            "Epoch 171/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8411e-09 - accuracy: 1.0000 - val_loss: 0.2061 - val_accuracy: 0.9815\n",
            "Epoch 172/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8226e-09 - accuracy: 1.0000 - val_loss: 0.2062 - val_accuracy: 0.9813\n",
            "Epoch 173/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8040e-09 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9814\n",
            "Epoch 174/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7405e-09 - accuracy: 1.0000 - val_loss: 0.2065 - val_accuracy: 0.9813\n",
            "Epoch 175/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7113e-09 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9813\n",
            "Epoch 176/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6769e-09 - accuracy: 1.0000 - val_loss: 0.2070 - val_accuracy: 0.9813\n",
            "Epoch 177/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6292e-09 - accuracy: 1.0000 - val_loss: 0.2071 - val_accuracy: 0.9813\n",
            "Epoch 178/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6239e-09 - accuracy: 1.0000 - val_loss: 0.2071 - val_accuracy: 0.9813\n",
            "Epoch 179/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6133e-09 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 0.9813\n",
            "Epoch 180/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5603e-09 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 0.9814\n",
            "Epoch 181/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5126e-09 - accuracy: 1.0000 - val_loss: 0.2078 - val_accuracy: 0.9814\n",
            "Epoch 182/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4888e-09 - accuracy: 1.0000 - val_loss: 0.2078 - val_accuracy: 0.9814\n",
            "Epoch 183/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4729e-09 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9814\n",
            "Epoch 184/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4491e-09 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.9813\n",
            "Epoch 185/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4385e-09 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.9813\n",
            "Epoch 186/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3961e-09 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9813\n",
            "Epoch 187/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4040e-09 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9813\n",
            "Epoch 188/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4120e-09 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 0.9813\n",
            "Epoch 189/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3537e-09 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9813\n",
            "Epoch 190/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3616e-09 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.9814\n",
            "Epoch 191/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3192e-09 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9813\n",
            "Epoch 192/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3060e-09 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9815\n",
            "Epoch 193/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3272e-09 - accuracy: 1.0000 - val_loss: 0.2097 - val_accuracy: 0.9814\n",
            "Epoch 194/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2769e-09 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.9815\n",
            "Epoch 195/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3272e-09 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.9813\n",
            "Epoch 196/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2636e-09 - accuracy: 1.0000 - val_loss: 0.2104 - val_accuracy: 0.9814\n",
            "Epoch 197/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2477e-09 - accuracy: 1.0000 - val_loss: 0.2106 - val_accuracy: 0.9814\n",
            "Epoch 198/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2557e-09 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9814\n",
            "Epoch 199/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2398e-09 - accuracy: 1.0000 - val_loss: 0.2112 - val_accuracy: 0.9814\n",
            "Epoch 200/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1947e-09 - accuracy: 1.0000 - val_loss: 0.2112 - val_accuracy: 0.9814\n",
            "Epoch 201/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2398e-09 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9813\n",
            "Epoch 202/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2477e-09 - accuracy: 1.0000 - val_loss: 0.2117 - val_accuracy: 0.9813\n",
            "Epoch 203/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2318e-09 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9813\n",
            "Epoch 204/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2053e-09 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9813\n",
            "Epoch 205/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2239e-09 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 0.9814\n",
            "Epoch 206/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2318e-09 - accuracy: 1.0000 - val_loss: 0.2126 - val_accuracy: 0.9812\n",
            "Epoch 207/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1974e-09 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 0.9815\n",
            "Epoch 208/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2133e-09 - accuracy: 1.0000 - val_loss: 0.2131 - val_accuracy: 0.9814\n",
            "Epoch 209/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1815e-09 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.9814\n",
            "Epoch 210/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2265e-09 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.9814\n",
            "Epoch 211/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1974e-09 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9815\n",
            "Epoch 212/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2106e-09 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9813\n",
            "Epoch 213/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1894e-09 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9813\n",
            "Epoch 214/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1947e-09 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.9813\n",
            "Epoch 215/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1683e-09 - accuracy: 1.0000 - val_loss: 0.2149 - val_accuracy: 0.9814\n",
            "Epoch 216/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2053e-09 - accuracy: 1.0000 - val_loss: 0.2151 - val_accuracy: 0.9813\n",
            "Epoch 217/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2212e-09 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9813\n",
            "Epoch 218/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2186e-09 - accuracy: 1.0000 - val_loss: 0.2155 - val_accuracy: 0.9814\n",
            "Epoch 219/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1815e-09 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 0.9815\n",
            "Epoch 220/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1841e-09 - accuracy: 1.0000 - val_loss: 0.2163 - val_accuracy: 0.9813\n",
            "Epoch 221/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2318e-09 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 0.9814\n",
            "Epoch 222/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1709e-09 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9813\n",
            "Epoch 223/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2159e-09 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9814\n",
            "Epoch 224/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2212e-09 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 0.9813\n",
            "Epoch 225/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1788e-09 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9814\n",
            "Epoch 226/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2133e-09 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9813\n",
            "Epoch 227/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1815e-09 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9813\n",
            "Epoch 228/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2212e-09 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9813\n",
            "Epoch 229/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2106e-09 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9814\n",
            "Epoch 230/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2133e-09 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9815\n",
            "Epoch 231/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2265e-09 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 0.9815\n",
            "Epoch 232/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2000e-09 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9813\n",
            "Epoch 233/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2106e-09 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9814\n",
            "Epoch 234/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2212e-09 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9813\n",
            "Epoch 235/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2398e-09 - accuracy: 1.0000 - val_loss: 0.2206 - val_accuracy: 0.9814\n",
            "Epoch 236/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2504e-09 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9815\n",
            "Epoch 237/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2636e-09 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9814\n",
            "Epoch 238/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2477e-09 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9815\n",
            "Epoch 239/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2530e-09 - accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 0.9815\n",
            "Epoch 240/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2583e-09 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9815\n",
            "Epoch 241/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2610e-09 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.9815\n",
            "Epoch 242/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2822e-09 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9815\n",
            "Epoch 243/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2875e-09 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.9815\n",
            "Epoch 244/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2663e-09 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9815\n",
            "Epoch 245/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2689e-09 - accuracy: 1.0000 - val_loss: 0.2240 - val_accuracy: 0.9815\n",
            "Epoch 246/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2557e-09 - accuracy: 1.0000 - val_loss: 0.2240 - val_accuracy: 0.9815\n",
            "Epoch 247/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3060e-09 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9813\n",
            "Epoch 248/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2875e-09 - accuracy: 1.0000 - val_loss: 0.2251 - val_accuracy: 0.9813\n",
            "Epoch 249/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3087e-09 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9813\n",
            "Epoch 250/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2981e-09 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9813\n",
            "Epoch 251/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3325e-09 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9813\n",
            "Epoch 252/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3245e-09 - accuracy: 1.0000 - val_loss: 0.2264 - val_accuracy: 0.9813\n",
            "Epoch 253/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3431e-09 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 0.9811\n",
            "Epoch 254/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3484e-09 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 0.9813\n",
            "Epoch 255/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3378e-09 - accuracy: 1.0000 - val_loss: 0.2273 - val_accuracy: 0.9814\n",
            "Epoch 256/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3140e-09 - accuracy: 1.0000 - val_loss: 0.2277 - val_accuracy: 0.9813\n",
            "Epoch 257/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3245e-09 - accuracy: 1.0000 - val_loss: 0.2282 - val_accuracy: 0.9813\n",
            "Epoch 258/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3219e-09 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9813\n",
            "Epoch 259/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3908e-09 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9813\n",
            "Epoch 260/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3749e-09 - accuracy: 1.0000 - val_loss: 0.2293 - val_accuracy: 0.9813\n",
            "Epoch 261/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3563e-09 - accuracy: 1.0000 - val_loss: 0.2295 - val_accuracy: 0.9813\n",
            "Epoch 262/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3828e-09 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 0.9813\n",
            "Epoch 263/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3563e-09 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 0.9813\n",
            "Epoch 264/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3696e-09 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 0.9813\n",
            "Epoch 265/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4040e-09 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.9811\n",
            "Epoch 266/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4199e-09 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.9811\n",
            "Epoch 267/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3722e-09 - accuracy: 1.0000 - val_loss: 0.2318 - val_accuracy: 0.9811\n",
            "Epoch 268/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4279e-09 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9811\n",
            "Epoch 269/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4676e-09 - accuracy: 1.0000 - val_loss: 0.2327 - val_accuracy: 0.9812\n",
            "Epoch 270/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3961e-09 - accuracy: 1.0000 - val_loss: 0.2333 - val_accuracy: 0.9812\n",
            "Epoch 271/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3881e-09 - accuracy: 1.0000 - val_loss: 0.2331 - val_accuracy: 0.9811\n",
            "Epoch 272/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4438e-09 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9812\n",
            "Epoch 273/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4385e-09 - accuracy: 1.0000 - val_loss: 0.2344 - val_accuracy: 0.9812\n",
            "Epoch 274/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4570e-09 - accuracy: 1.0000 - val_loss: 0.2345 - val_accuracy: 0.9811\n",
            "Epoch 275/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4093e-09 - accuracy: 1.0000 - val_loss: 0.2350 - val_accuracy: 0.9811\n",
            "Epoch 276/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4755e-09 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9811\n",
            "Epoch 277/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4649e-09 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9811\n",
            "Epoch 278/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4305e-09 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.9811\n",
            "Epoch 279/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4941e-09 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9812\n",
            "Epoch 280/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4782e-09 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9811\n",
            "Epoch 281/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4385e-09 - accuracy: 1.0000 - val_loss: 0.2373 - val_accuracy: 0.9811\n",
            "Epoch 282/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5073e-09 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9811\n",
            "Epoch 283/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4755e-09 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9811\n",
            "Epoch 284/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5047e-09 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9811\n",
            "Epoch 285/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5020e-09 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.9811\n",
            "Epoch 286/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4914e-09 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9811\n",
            "Epoch 287/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5047e-09 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.9811\n",
            "Epoch 288/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5153e-09 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9811\n",
            "Epoch 289/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5312e-09 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9811\n",
            "Epoch 290/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5179e-09 - accuracy: 1.0000 - val_loss: 0.2415 - val_accuracy: 0.9811\n",
            "Epoch 291/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5153e-09 - accuracy: 1.0000 - val_loss: 0.2421 - val_accuracy: 0.9811\n",
            "Epoch 292/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5444e-09 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9810\n",
            "Epoch 293/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5179e-09 - accuracy: 1.0000 - val_loss: 0.2428 - val_accuracy: 0.9809\n",
            "Epoch 294/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5338e-09 - accuracy: 1.0000 - val_loss: 0.2432 - val_accuracy: 0.9810\n",
            "Epoch 295/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6027e-09 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9810\n",
            "Epoch 296/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6106e-09 - accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 0.9810\n",
            "Epoch 297/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6186e-09 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9809\n",
            "Epoch 298/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6001e-09 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9811\n",
            "Epoch 299/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5444e-09 - accuracy: 1.0000 - val_loss: 0.2452 - val_accuracy: 0.9810\n",
            "Epoch 300/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6398e-09 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.9811\n",
            "Epoch 301/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6504e-09 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9811\n",
            "Epoch 302/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6318e-09 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.9810\n",
            "Epoch 303/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6371e-09 - accuracy: 1.0000 - val_loss: 0.2465 - val_accuracy: 0.9811\n",
            "Epoch 304/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6504e-09 - accuracy: 1.0000 - val_loss: 0.2468 - val_accuracy: 0.9811\n",
            "Epoch 305/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6928e-09 - accuracy: 1.0000 - val_loss: 0.2474 - val_accuracy: 0.9809\n",
            "Epoch 306/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6398e-09 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9810\n",
            "Epoch 307/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6663e-09 - accuracy: 1.0000 - val_loss: 0.2474 - val_accuracy: 0.9808\n",
            "Epoch 308/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6822e-09 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.9809\n",
            "Epoch 309/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7140e-09 - accuracy: 1.0000 - val_loss: 0.2491 - val_accuracy: 0.9808\n",
            "Epoch 310/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6371e-09 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.9806\n",
            "Epoch 311/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7325e-09 - accuracy: 1.0000 - val_loss: 0.2499 - val_accuracy: 0.9807\n",
            "Epoch 312/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7325e-09 - accuracy: 1.0000 - val_loss: 0.2508 - val_accuracy: 0.9807\n",
            "Epoch 313/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7299e-09 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9805\n",
            "Epoch 314/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7299e-09 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9803\n",
            "Epoch 315/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7564e-09 - accuracy: 1.0000 - val_loss: 0.2511 - val_accuracy: 0.9807\n",
            "Epoch 316/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7775e-09 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9805\n",
            "Epoch 317/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7828e-09 - accuracy: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.9803\n",
            "Epoch 318/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7987e-09 - accuracy: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.9804\n",
            "Epoch 319/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7458e-09 - accuracy: 1.0000 - val_loss: 0.2537 - val_accuracy: 0.9804\n",
            "Epoch 320/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7987e-09 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.9803\n",
            "Epoch 321/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8411e-09 - accuracy: 1.0000 - val_loss: 0.2543 - val_accuracy: 0.9803\n",
            "Epoch 322/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8650e-09 - accuracy: 1.0000 - val_loss: 0.2547 - val_accuracy: 0.9803\n",
            "Epoch 323/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8226e-09 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9804\n",
            "Epoch 324/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8915e-09 - accuracy: 1.0000 - val_loss: 0.2554 - val_accuracy: 0.9803\n",
            "Epoch 325/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9577e-09 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.9802\n",
            "Epoch 326/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8888e-09 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9801\n",
            "Epoch 327/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8862e-09 - accuracy: 1.0000 - val_loss: 0.2561 - val_accuracy: 0.9802\n",
            "Epoch 328/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8782e-09 - accuracy: 1.0000 - val_loss: 0.2565 - val_accuracy: 0.9801\n",
            "Epoch 329/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9312e-09 - accuracy: 1.0000 - val_loss: 0.2570 - val_accuracy: 0.9803\n",
            "Epoch 330/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9206e-09 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9803\n",
            "Epoch 331/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9259e-09 - accuracy: 1.0000 - val_loss: 0.2588 - val_accuracy: 0.9801\n",
            "Epoch 332/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9126e-09 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9800\n",
            "Epoch 333/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9550e-09 - accuracy: 1.0000 - val_loss: 0.2587 - val_accuracy: 0.9803\n",
            "Epoch 334/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9338e-09 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.9801\n",
            "Epoch 335/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0186e-09 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.9797\n",
            "Epoch 336/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0080e-09 - accuracy: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.9801\n",
            "Epoch 337/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0372e-09 - accuracy: 1.0000 - val_loss: 0.2604 - val_accuracy: 0.9800\n",
            "Epoch 338/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0054e-09 - accuracy: 1.0000 - val_loss: 0.2610 - val_accuracy: 0.9801\n",
            "Epoch 339/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9921e-09 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.9802\n",
            "Epoch 340/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9948e-09 - accuracy: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.9801\n",
            "Epoch 341/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0133e-09 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.9803\n",
            "Epoch 342/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0689e-09 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.9801\n",
            "Epoch 343/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1511e-09 - accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 0.9798\n",
            "Epoch 344/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1378e-09 - accuracy: 1.0000 - val_loss: 0.2644 - val_accuracy: 0.9796\n",
            "Epoch 345/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1670e-09 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9798\n",
            "Epoch 346/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1670e-09 - accuracy: 1.0000 - val_loss: 0.2647 - val_accuracy: 0.9798\n",
            "Epoch 347/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2464e-09 - accuracy: 1.0000 - val_loss: 0.2662 - val_accuracy: 0.9794\n",
            "Epoch 348/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2941e-09 - accuracy: 1.0000 - val_loss: 0.2659 - val_accuracy: 0.9798\n",
            "Epoch 349/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3365e-09 - accuracy: 1.0000 - val_loss: 0.2665 - val_accuracy: 0.9799\n",
            "Epoch 350/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2093e-09 - accuracy: 1.0000 - val_loss: 0.2660 - val_accuracy: 0.9797\n",
            "Epoch 351/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3233e-09 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9797\n",
            "Epoch 352/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2040e-09 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9799\n",
            "Epoch 353/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3259e-09 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.9797\n",
            "Epoch 354/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1882e-09 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.9795\n",
            "Epoch 355/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5776e-09 - accuracy: 1.0000 - val_loss: 0.2672 - val_accuracy: 0.9797\n",
            "Epoch 356/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2756e-09 - accuracy: 1.0000 - val_loss: 0.2682 - val_accuracy: 0.9795\n",
            "Epoch 357/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4080e-09 - accuracy: 1.0000 - val_loss: 0.2689 - val_accuracy: 0.9797\n",
            "Epoch 358/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5590e-09 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.9797\n",
            "Epoch 359/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3127e-09 - accuracy: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.9794\n",
            "Epoch 360/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.1299e-09 - accuracy: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.9798\n",
            "Epoch 361/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5511e-09 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.9797\n",
            "Epoch 362/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1882e-09 - accuracy: 1.0000 - val_loss: 0.2716 - val_accuracy: 0.9797\n",
            "Epoch 363/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2968e-09 - accuracy: 1.0000 - val_loss: 0.2704 - val_accuracy: 0.9799\n",
            "Epoch 364/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3524e-09 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9794\n",
            "Epoch 365/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3021e-09 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9798\n",
            "Epoch 366/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4027e-09 - accuracy: 1.0000 - val_loss: 0.2759 - val_accuracy: 0.9793\n",
            "Epoch 367/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0963 - accuracy: 0.9965 - val_loss: 1.1566 - val_accuracy: 0.9333\n",
            "Epoch 368/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.1006 - accuracy: 0.9897 - val_loss: 0.2079 - val_accuracy: 0.9755\n",
            "Epoch 369/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.1985 - val_accuracy: 0.9778\n",
            "Epoch 370/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.4836e-04 - accuracy: 0.9999 - val_loss: 0.1997 - val_accuracy: 0.9771\n",
            "Epoch 371/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.5159e-04 - accuracy: 0.9999 - val_loss: 0.1957 - val_accuracy: 0.9777\n",
            "Epoch 372/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.8010e-05 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9778\n",
            "Epoch 373/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1126e-05 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9777\n",
            "Epoch 374/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6286e-05 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9779\n",
            "Epoch 375/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2934e-05 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9779\n",
            "Epoch 376/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0197e-05 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9781\n",
            "Epoch 377/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8044e-05 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9781\n",
            "Epoch 378/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6270e-05 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9782\n",
            "Epoch 379/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4724e-05 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9783\n",
            "Epoch 380/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3316e-05 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9786\n",
            "Epoch 381/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2104e-05 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9785\n",
            "Epoch 382/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1026e-05 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9783\n",
            "Epoch 383/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0092e-05 - accuracy: 1.0000 - val_loss: 0.1954 - val_accuracy: 0.9784\n",
            "Epoch 384/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.2288e-06 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.9783\n",
            "Epoch 385/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.4779e-06 - accuracy: 1.0000 - val_loss: 0.1958 - val_accuracy: 0.9783\n",
            "Epoch 386/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7840e-06 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 0.9782\n",
            "Epoch 387/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.1489e-06 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9782\n",
            "Epoch 388/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5803e-06 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9782\n",
            "Epoch 389/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0775e-06 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9783\n",
            "Epoch 390/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5903e-06 - accuracy: 1.0000 - val_loss: 0.1971 - val_accuracy: 0.9783\n",
            "Epoch 391/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1731e-06 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 0.9783\n",
            "Epoch 392/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7756e-06 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 0.9785\n",
            "Epoch 393/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.4213e-06 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9785\n",
            "Epoch 394/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.0824e-06 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.9787\n",
            "Epoch 395/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7756e-06 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.9787\n",
            "Epoch 396/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.4982e-06 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9787\n",
            "Epoch 397/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2343e-06 - accuracy: 1.0000 - val_loss: 0.1994 - val_accuracy: 0.9787\n",
            "Epoch 398/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9861e-06 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9787\n",
            "Epoch 399/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7637e-06 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9789\n",
            "Epoch 400/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5510e-06 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9789\n",
            "Epoch 401/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3656e-06 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9789\n",
            "Epoch 402/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1894e-06 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9789\n",
            "Epoch 403/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0245e-06 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9790\n",
            "Epoch 404/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8709e-06 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9791\n",
            "Epoch 405/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7305e-06 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9790\n",
            "Epoch 406/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6023e-06 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9791\n",
            "Epoch 407/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4800e-06 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 0.9792\n",
            "Epoch 408/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3734e-06 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.9791\n",
            "Epoch 409/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2702e-06 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.9793\n",
            "Epoch 410/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1754e-06 - accuracy: 1.0000 - val_loss: 0.2051 - val_accuracy: 0.9791\n",
            "Epoch 411/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0916e-06 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.9793\n",
            "Epoch 412/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0084e-06 - accuracy: 1.0000 - val_loss: 0.2061 - val_accuracy: 0.9793\n",
            "Epoch 413/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.3247e-07 - accuracy: 1.0000 - val_loss: 0.2066 - val_accuracy: 0.9793\n",
            "Epoch 414/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.6174e-07 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9794\n",
            "Epoch 415/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.9827e-07 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9795\n",
            "Epoch 416/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.3684e-07 - accuracy: 1.0000 - val_loss: 0.2083 - val_accuracy: 0.9795\n",
            "Epoch 417/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8199e-07 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9795\n",
            "Epoch 418/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3085e-07 - accuracy: 1.0000 - val_loss: 0.2093 - val_accuracy: 0.9794\n",
            "Epoch 419/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8585e-07 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9795\n",
            "Epoch 420/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4023e-07 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 0.9793\n",
            "Epoch 421/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.9911e-07 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9793\n",
            "Epoch 422/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6185e-07 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9793\n",
            "Epoch 423/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.2608e-07 - accuracy: 1.0000 - val_loss: 0.2119 - val_accuracy: 0.9793\n",
            "Epoch 424/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9381e-07 - accuracy: 1.0000 - val_loss: 0.2125 - val_accuracy: 0.9793\n",
            "Epoch 425/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6506e-07 - accuracy: 1.0000 - val_loss: 0.2131 - val_accuracy: 0.9792\n",
            "Epoch 426/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3691e-07 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9792\n",
            "Epoch 427/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1198e-07 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.9793\n",
            "Epoch 428/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8826e-07 - accuracy: 1.0000 - val_loss: 0.2148 - val_accuracy: 0.9794\n",
            "Epoch 429/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6631e-07 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9793\n",
            "Epoch 430/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4639e-07 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9794\n",
            "Epoch 431/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2799e-07 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9794\n",
            "Epoch 432/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1118e-07 - accuracy: 1.0000 - val_loss: 0.2173 - val_accuracy: 0.9794\n",
            "Epoch 433/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9514e-07 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9797\n",
            "Epoch 434/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8028e-07 - accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.9795\n",
            "Epoch 435/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6707e-07 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9795\n",
            "Epoch 436/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5448e-07 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9797\n",
            "Epoch 437/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4246e-07 - accuracy: 1.0000 - val_loss: 0.2204 - val_accuracy: 0.9797\n",
            "Epoch 438/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3222e-07 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9797\n",
            "Epoch 439/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2251e-07 - accuracy: 1.0000 - val_loss: 0.2217 - val_accuracy: 0.9797\n",
            "Epoch 440/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1303e-07 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.9795\n",
            "Epoch 441/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0482e-07 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 0.9796\n",
            "Epoch 442/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.7002e-08 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.9797\n",
            "Epoch 443/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.9982e-08 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9797\n",
            "Epoch 444/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.3200e-08 - accuracy: 1.0000 - val_loss: 0.2249 - val_accuracy: 0.9797\n",
            "Epoch 445/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7134e-08 - accuracy: 1.0000 - val_loss: 0.2255 - val_accuracy: 0.9797\n",
            "Epoch 446/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.1536e-08 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9797\n",
            "Epoch 447/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.6203e-08 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 0.9797\n",
            "Epoch 448/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1448e-08 - accuracy: 1.0000 - val_loss: 0.2274 - val_accuracy: 0.9797\n",
            "Epoch 449/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7152e-08 - accuracy: 1.0000 - val_loss: 0.2280 - val_accuracy: 0.9797\n",
            "Epoch 450/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2992e-08 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9796\n",
            "Epoch 451/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.9223e-08 - accuracy: 1.0000 - val_loss: 0.2293 - val_accuracy: 0.9797\n",
            "Epoch 452/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.5451e-08 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 0.9797\n",
            "Epoch 453/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.2354e-08 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 0.9797\n",
            "Epoch 454/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9191e-08 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9798\n",
            "Epoch 455/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6377e-08 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9798\n",
            "Epoch 456/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3935e-08 - accuracy: 1.0000 - val_loss: 0.2328 - val_accuracy: 0.9798\n",
            "Epoch 457/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1347e-08 - accuracy: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.9798\n",
            "Epoch 458/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9246e-08 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9797\n",
            "Epoch 459/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7095e-08 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9797\n",
            "Epoch 460/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5211e-08 - accuracy: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.9798\n",
            "Epoch 461/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3556e-08 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9798\n",
            "Epoch 462/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1913e-08 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9798\n",
            "Epoch 463/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0337e-08 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9798\n",
            "Epoch 464/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8981e-08 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9797\n",
            "Epoch 465/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7677e-08 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9798\n",
            "Epoch 466/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6488e-08 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 0.9797\n",
            "Epoch 467/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5346e-08 - accuracy: 1.0000 - val_loss: 0.2407 - val_accuracy: 0.9798\n",
            "Epoch 468/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4438e-08 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9798\n",
            "Epoch 469/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3399e-08 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9799\n",
            "Epoch 470/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2488e-08 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9797\n",
            "Epoch 471/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1696e-08 - accuracy: 1.0000 - val_loss: 0.2441 - val_accuracy: 0.9797\n",
            "Epoch 472/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0914e-08 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9798\n",
            "Epoch 473/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0255e-08 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9800\n",
            "Epoch 474/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.5659e-09 - accuracy: 1.0000 - val_loss: 0.2465 - val_accuracy: 0.9799\n",
            "Epoch 475/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.0308e-09 - accuracy: 1.0000 - val_loss: 0.2472 - val_accuracy: 0.9799\n",
            "Epoch 476/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.4453e-09 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9800\n",
            "Epoch 477/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.9314e-09 - accuracy: 1.0000 - val_loss: 0.2486 - val_accuracy: 0.9799\n",
            "Epoch 478/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.3671e-09 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9800\n",
            "Epoch 479/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.9963e-09 - accuracy: 1.0000 - val_loss: 0.2507 - val_accuracy: 0.9799\n",
            "Epoch 480/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.6307e-09 - accuracy: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.9799\n",
            "Epoch 481/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1962e-09 - accuracy: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.9799\n",
            "Epoch 482/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8651e-09 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.9799\n",
            "Epoch 483/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5181e-09 - accuracy: 1.0000 - val_loss: 0.2538 - val_accuracy: 0.9799\n",
            "Epoch 484/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1790e-09 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.9800\n",
            "Epoch 485/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.9379e-09 - accuracy: 1.0000 - val_loss: 0.2558 - val_accuracy: 0.9800\n",
            "Epoch 486/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.6359e-09 - accuracy: 1.0000 - val_loss: 0.2568 - val_accuracy: 0.9801\n",
            "Epoch 487/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.3922e-09 - accuracy: 1.0000 - val_loss: 0.2575 - val_accuracy: 0.9801\n",
            "Epoch 488/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.1697e-09 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.9801\n",
            "Epoch 489/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9392e-09 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.9801\n",
            "Epoch 490/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.7882e-09 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.9801\n",
            "Epoch 491/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5392e-09 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.9800\n",
            "Epoch 492/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.4306e-09 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9801\n",
            "Epoch 493/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.2372e-09 - accuracy: 1.0000 - val_loss: 0.2636 - val_accuracy: 0.9799\n",
            "Epoch 494/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1074e-09 - accuracy: 1.0000 - val_loss: 0.2647 - val_accuracy: 0.9799\n",
            "Epoch 495/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9776e-09 - accuracy: 1.0000 - val_loss: 0.2656 - val_accuracy: 0.9799\n",
            "Epoch 496/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8902e-09 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9799\n",
            "Epoch 497/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7100e-09 - accuracy: 1.0000 - val_loss: 0.2678 - val_accuracy: 0.9798\n",
            "Epoch 498/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6200e-09 - accuracy: 1.0000 - val_loss: 0.2687 - val_accuracy: 0.9798\n",
            "Epoch 499/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5113e-09 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.9797\n",
            "Epoch 500/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4345e-09 - accuracy: 1.0000 - val_loss: 0.2707 - val_accuracy: 0.9797\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0677 - accuracy: 0.9949\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1941 - accuracy: 0.9825\n",
            "train accuracy :  0.9949166774749756 train loss :  0.06766366213560104\n",
            "test accuracy :  0.9825000166893005  test loss :  0.19414091110229492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rleAnH3dPoUo",
        "outputId": "94f9b2fd-8e66-45dc-8149-90a16f207947"
      },
      "source": [
        "#신경망 학습2_2_3\n",
        "model2_2_4 = models.Sequential([\n",
        "                               Flatten(input_shape = (28, 28)),\n",
        "                               Dense(512, activation= 'relu'),\n",
        "                               Dense(256, activation= 'relu'),\n",
        "                               Dense(10, activation= 'softmax')\n",
        "                               ])\n",
        "\n",
        "model2_2_4.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "hist2_2_4 = model2_2_4.fit(train_x, train_y, epochs = 1000, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "#학습 그래프4\n",
        "plt.plot(hist2_2_4.history['accuracy'], 'b-')\n",
        "plt.plot(hist2_2_4.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train2_2_4 = model2_2_4.evaluate(train_x, train_y)\n",
        "sc_test2_2_4 = model2_2_4.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train2_2_4[1], \"train loss : \", sc_train2_2_4[0])\n",
        "print(\"test accuracy : \", sc_test2_2_4[1], \" test loss : \", sc_test2_2_4[0])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3189 - accuracy: 0.9102 - val_loss: 0.1624 - val_accuracy: 0.9516\n",
            "Epoch 2/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.1138 - accuracy: 0.9663 - val_loss: 0.1126 - val_accuracy: 0.9668\n",
            "Epoch 3/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0689 - accuracy: 0.9794 - val_loss: 0.0997 - val_accuracy: 0.9689\n",
            "Epoch 4/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0466 - accuracy: 0.9861 - val_loss: 0.0894 - val_accuracy: 0.9727\n",
            "Epoch 5/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0305 - accuracy: 0.9905 - val_loss: 0.0881 - val_accuracy: 0.9751\n",
            "Epoch 6/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0221 - accuracy: 0.9936 - val_loss: 0.0859 - val_accuracy: 0.9765\n",
            "Epoch 7/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0159 - accuracy: 0.9956 - val_loss: 0.0905 - val_accuracy: 0.9747\n",
            "Epoch 8/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.0931 - val_accuracy: 0.9757\n",
            "Epoch 9/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.0870 - val_accuracy: 0.9771\n",
            "Epoch 10/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 0.1133 - val_accuracy: 0.9742\n",
            "Epoch 11/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.1150 - val_accuracy: 0.9741\n",
            "Epoch 12/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.1151 - val_accuracy: 0.9738\n",
            "Epoch 13/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.1073 - val_accuracy: 0.9764\n",
            "Epoch 14/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.1092 - val_accuracy: 0.9758\n",
            "Epoch 15/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.1091 - val_accuracy: 0.9772\n",
            "Epoch 16/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.1058 - val_accuracy: 0.9785\n",
            "Epoch 17/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1025 - val_accuracy: 0.9801\n",
            "Epoch 18/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.1059 - val_accuracy: 0.9792\n",
            "Epoch 19/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 0.1173 - val_accuracy: 0.9751\n",
            "Epoch 20/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.1226 - val_accuracy: 0.9763\n",
            "Epoch 21/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.1134 - val_accuracy: 0.9771\n",
            "Epoch 22/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.1240 - val_accuracy: 0.9770\n",
            "Epoch 23/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.1282 - val_accuracy: 0.9755\n",
            "Epoch 24/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.1064 - val_accuracy: 0.9812\n",
            "Epoch 25/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5134e-04 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 0.9815\n",
            "Epoch 26/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7251e-05 - accuracy: 1.0000 - val_loss: 0.1098 - val_accuracy: 0.9818\n",
            "Epoch 27/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8357e-05 - accuracy: 1.0000 - val_loss: 0.1111 - val_accuracy: 0.9815\n",
            "Epoch 28/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.8404e-05 - accuracy: 1.0000 - val_loss: 0.1123 - val_accuracy: 0.9816\n",
            "Epoch 29/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.1436e-05 - accuracy: 1.0000 - val_loss: 0.1135 - val_accuracy: 0.9815\n",
            "Epoch 30/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6056e-05 - accuracy: 1.0000 - val_loss: 0.1148 - val_accuracy: 0.9818\n",
            "Epoch 31/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1822e-05 - accuracy: 1.0000 - val_loss: 0.1157 - val_accuracy: 0.9816\n",
            "Epoch 32/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8334e-05 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 0.9817\n",
            "Epoch 33/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5307e-05 - accuracy: 1.0000 - val_loss: 0.1174 - val_accuracy: 0.9819\n",
            "Epoch 34/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2707e-05 - accuracy: 1.0000 - val_loss: 0.1186 - val_accuracy: 0.9817\n",
            "Epoch 35/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0582e-05 - accuracy: 1.0000 - val_loss: 0.1193 - val_accuracy: 0.9819\n",
            "Epoch 36/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8551e-05 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9817\n",
            "Epoch 37/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6888e-05 - accuracy: 1.0000 - val_loss: 0.1210 - val_accuracy: 0.9819\n",
            "Epoch 38/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5361e-05 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9816\n",
            "Epoch 39/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4080e-05 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9815\n",
            "Epoch 40/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2829e-05 - accuracy: 1.0000 - val_loss: 0.1236 - val_accuracy: 0.9817\n",
            "Epoch 41/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1715e-05 - accuracy: 1.0000 - val_loss: 0.1243 - val_accuracy: 0.9817\n",
            "Epoch 42/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0771e-05 - accuracy: 1.0000 - val_loss: 0.1249 - val_accuracy: 0.9816\n",
            "Epoch 43/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.9015e-06 - accuracy: 1.0000 - val_loss: 0.1257 - val_accuracy: 0.9818\n",
            "Epoch 44/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.0814e-06 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9817\n",
            "Epoch 45/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.3746e-06 - accuracy: 1.0000 - val_loss: 0.1271 - val_accuracy: 0.9815\n",
            "Epoch 46/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.6423e-06 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9817\n",
            "Epoch 47/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0476e-06 - accuracy: 1.0000 - val_loss: 0.1287 - val_accuracy: 0.9815\n",
            "Epoch 48/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.4816e-06 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.9815\n",
            "Epoch 49/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0156e-06 - accuracy: 1.0000 - val_loss: 0.1305 - val_accuracy: 0.9817\n",
            "Epoch 50/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5352e-06 - accuracy: 1.0000 - val_loss: 0.1314 - val_accuracy: 0.9817\n",
            "Epoch 51/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0924e-06 - accuracy: 1.0000 - val_loss: 0.1319 - val_accuracy: 0.9818\n",
            "Epoch 52/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.7146e-06 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 0.9817\n",
            "Epoch 53/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.3049e-06 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.9818\n",
            "Epoch 54/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9821e-06 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.9817\n",
            "Epoch 55/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6767e-06 - accuracy: 1.0000 - val_loss: 0.1350 - val_accuracy: 0.9817\n",
            "Epoch 56/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3893e-06 - accuracy: 1.0000 - val_loss: 0.1358 - val_accuracy: 0.9817\n",
            "Epoch 57/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1276e-06 - accuracy: 1.0000 - val_loss: 0.1365 - val_accuracy: 0.9817\n",
            "Epoch 58/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8637e-06 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.9819\n",
            "Epoch 59/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6838e-06 - accuracy: 1.0000 - val_loss: 0.1381 - val_accuracy: 0.9819\n",
            "Epoch 60/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4481e-06 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9819\n",
            "Epoch 61/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2813e-06 - accuracy: 1.0000 - val_loss: 0.1395 - val_accuracy: 0.9818\n",
            "Epoch 62/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0796e-06 - accuracy: 1.0000 - val_loss: 0.1404 - val_accuracy: 0.9819\n",
            "Epoch 63/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9197e-06 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 0.9818\n",
            "Epoch 64/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7688e-06 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9821\n",
            "Epoch 65/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6124e-06 - accuracy: 1.0000 - val_loss: 0.1428 - val_accuracy: 0.9817\n",
            "Epoch 66/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4969e-06 - accuracy: 1.0000 - val_loss: 0.1435 - val_accuracy: 0.9817\n",
            "Epoch 67/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3785e-06 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9822\n",
            "Epoch 68/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2718e-06 - accuracy: 1.0000 - val_loss: 0.1449 - val_accuracy: 0.9817\n",
            "Epoch 69/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1717e-06 - accuracy: 1.0000 - val_loss: 0.1461 - val_accuracy: 0.9815\n",
            "Epoch 70/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0841e-06 - accuracy: 1.0000 - val_loss: 0.1463 - val_accuracy: 0.9817\n",
            "Epoch 71/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.8372e-07 - accuracy: 1.0000 - val_loss: 0.1467 - val_accuracy: 0.9817\n",
            "Epoch 72/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.1190e-07 - accuracy: 1.0000 - val_loss: 0.1479 - val_accuracy: 0.9821\n",
            "Epoch 73/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.4181e-07 - accuracy: 1.0000 - val_loss: 0.1488 - val_accuracy: 0.9817\n",
            "Epoch 74/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.6598e-07 - accuracy: 1.0000 - val_loss: 0.1496 - val_accuracy: 0.9819\n",
            "Epoch 75/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.1017e-07 - accuracy: 1.0000 - val_loss: 0.1501 - val_accuracy: 0.9816\n",
            "Epoch 76/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5183e-07 - accuracy: 1.0000 - val_loss: 0.1509 - val_accuracy: 0.9816\n",
            "Epoch 77/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0063e-07 - accuracy: 1.0000 - val_loss: 0.1516 - val_accuracy: 0.9817\n",
            "Epoch 78/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.4656e-07 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9819\n",
            "Epoch 79/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0922e-07 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9818\n",
            "Epoch 80/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.6532e-07 - accuracy: 1.0000 - val_loss: 0.1542 - val_accuracy: 0.9819\n",
            "Epoch 81/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.2718e-07 - accuracy: 1.0000 - val_loss: 0.1549 - val_accuracy: 0.9819\n",
            "Epoch 82/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9101e-07 - accuracy: 1.0000 - val_loss: 0.1559 - val_accuracy: 0.9817\n",
            "Epoch 83/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5903e-07 - accuracy: 1.0000 - val_loss: 0.1568 - val_accuracy: 0.9816\n",
            "Epoch 84/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.2832e-07 - accuracy: 1.0000 - val_loss: 0.1573 - val_accuracy: 0.9817\n",
            "Epoch 85/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0255e-07 - accuracy: 1.0000 - val_loss: 0.1577 - val_accuracy: 0.9819\n",
            "Epoch 86/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7833e-07 - accuracy: 1.0000 - val_loss: 0.1593 - val_accuracy: 0.9817\n",
            "Epoch 87/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5531e-07 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9817\n",
            "Epoch 88/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3670e-07 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 0.9815\n",
            "Epoch 89/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1763e-07 - accuracy: 1.0000 - val_loss: 0.1611 - val_accuracy: 0.9815\n",
            "Epoch 90/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9953e-07 - accuracy: 1.0000 - val_loss: 0.1623 - val_accuracy: 0.9817\n",
            "Epoch 91/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8232e-07 - accuracy: 1.0000 - val_loss: 0.1633 - val_accuracy: 0.9817\n",
            "Epoch 92/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6801e-07 - accuracy: 1.0000 - val_loss: 0.1636 - val_accuracy: 0.9819\n",
            "Epoch 93/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5406e-07 - accuracy: 1.0000 - val_loss: 0.1652 - val_accuracy: 0.9817\n",
            "Epoch 94/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4168e-07 - accuracy: 1.0000 - val_loss: 0.1649 - val_accuracy: 0.9818\n",
            "Epoch 95/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3085e-07 - accuracy: 1.0000 - val_loss: 0.1665 - val_accuracy: 0.9814\n",
            "Epoch 96/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2054e-07 - accuracy: 1.0000 - val_loss: 0.1665 - val_accuracy: 0.9818\n",
            "Epoch 97/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1040e-07 - accuracy: 1.0000 - val_loss: 0.1677 - val_accuracy: 0.9816\n",
            "Epoch 98/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0229e-07 - accuracy: 1.0000 - val_loss: 0.1682 - val_accuracy: 0.9817\n",
            "Epoch 99/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.3569e-08 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 0.9818\n",
            "Epoch 100/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.5741e-08 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 0.9815\n",
            "Epoch 101/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.9224e-08 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 0.9817\n",
            "Epoch 102/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.3563e-08 - accuracy: 1.0000 - val_loss: 0.1716 - val_accuracy: 0.9817\n",
            "Epoch 103/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7923e-08 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 0.9817\n",
            "Epoch 104/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3234e-08 - accuracy: 1.0000 - val_loss: 0.1733 - val_accuracy: 0.9817\n",
            "Epoch 105/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7472e-08 - accuracy: 1.0000 - val_loss: 0.1738 - val_accuracy: 0.9817\n",
            "Epoch 106/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3178e-08 - accuracy: 1.0000 - val_loss: 0.1744 - val_accuracy: 0.9816\n",
            "Epoch 107/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.9384e-08 - accuracy: 1.0000 - val_loss: 0.1748 - val_accuracy: 0.9817\n",
            "Epoch 108/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.5506e-08 - accuracy: 1.0000 - val_loss: 0.1756 - val_accuracy: 0.9817\n",
            "Epoch 109/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.2595e-08 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 0.9817\n",
            "Epoch 110/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9066e-08 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 0.9818\n",
            "Epoch 111/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6666e-08 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 0.9819\n",
            "Epoch 112/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3911e-08 - accuracy: 1.0000 - val_loss: 0.1784 - val_accuracy: 0.9817\n",
            "Epoch 113/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1114e-08 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.9817\n",
            "Epoch 114/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9010e-08 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 0.9816\n",
            "Epoch 115/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6817e-08 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 0.9816\n",
            "Epoch 116/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4870e-08 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9817\n",
            "Epoch 117/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3180e-08 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 0.9816\n",
            "Epoch 118/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1569e-08 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 0.9816\n",
            "Epoch 119/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0046e-08 - accuracy: 1.0000 - val_loss: 0.1831 - val_accuracy: 0.9815\n",
            "Epoch 120/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8986e-08 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 0.9817\n",
            "Epoch 121/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7550e-08 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 0.9816\n",
            "Epoch 122/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6554e-08 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 0.9817\n",
            "Epoch 123/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5439e-08 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9816\n",
            "Epoch 124/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4480e-08 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9819\n",
            "Epoch 125/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3582e-08 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 0.9817\n",
            "Epoch 126/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2626e-08 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9816\n",
            "Epoch 127/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1836e-08 - accuracy: 1.0000 - val_loss: 0.1879 - val_accuracy: 0.9817\n",
            "Epoch 128/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1259e-08 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9817\n",
            "Epoch 129/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0498e-08 - accuracy: 1.0000 - val_loss: 0.1885 - val_accuracy: 0.9815\n",
            "Epoch 130/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.8440e-09 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9817\n",
            "Epoch 131/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.3487e-09 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.9817\n",
            "Epoch 132/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7844e-09 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9818\n",
            "Epoch 133/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.1989e-09 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9817\n",
            "Epoch 134/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8784e-09 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9815\n",
            "Epoch 135/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4069e-09 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9816\n",
            "Epoch 136/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.9857e-09 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9815\n",
            "Epoch 137/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6068e-09 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9817\n",
            "Epoch 138/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3048e-09 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9816\n",
            "Epoch 139/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0161e-09 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9816\n",
            "Epoch 140/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7220e-09 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9818\n",
            "Epoch 141/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4174e-09 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9816\n",
            "Epoch 142/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1181e-09 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9818\n",
            "Epoch 143/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.9300e-09 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9816\n",
            "Epoch 144/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6174e-09 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.9815\n",
            "Epoch 145/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.4240e-09 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9817\n",
            "Epoch 146/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.2809e-09 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9816\n",
            "Epoch 147/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.0796e-09 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9815\n",
            "Epoch 148/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.8995e-09 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9816\n",
            "Epoch 149/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.7379e-09 - accuracy: 1.0000 - val_loss: 0.1971 - val_accuracy: 0.9815\n",
            "Epoch 150/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.5365e-09 - accuracy: 1.0000 - val_loss: 0.1971 - val_accuracy: 0.9816\n",
            "Epoch 151/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.4730e-09 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 0.9815\n",
            "Epoch 152/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.2928e-09 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9817\n",
            "Epoch 153/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1975e-09 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 0.9817\n",
            "Epoch 154/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0518e-09 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 0.9817\n",
            "Epoch 155/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9696e-09 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9817\n",
            "Epoch 156/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8292e-09 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.9816\n",
            "Epoch 157/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7604e-09 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9816\n",
            "Epoch 158/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6094e-09 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9817\n",
            "Epoch 159/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5590e-09 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.9817\n",
            "Epoch 160/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5193e-09 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.9817\n",
            "Epoch 161/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3974e-09 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9817\n",
            "Epoch 162/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3021e-09 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9817\n",
            "Epoch 163/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2597e-09 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9817\n",
            "Epoch 164/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1882e-09 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9817\n",
            "Epoch 165/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1670e-09 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9816\n",
            "Epoch 166/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0689e-09 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9816\n",
            "Epoch 167/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0636e-09 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9815\n",
            "Epoch 168/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9418e-09 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9817\n",
            "Epoch 169/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9736e-09 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9816\n",
            "Epoch 170/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8915e-09 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9816\n",
            "Epoch 171/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8862e-09 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9815\n",
            "Epoch 172/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8491e-09 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9817\n",
            "Epoch 173/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8173e-09 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9815\n",
            "Epoch 174/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7511e-09 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9815\n",
            "Epoch 175/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7246e-09 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9817\n",
            "Epoch 176/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6769e-09 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9817\n",
            "Epoch 177/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6636e-09 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.9815\n",
            "Epoch 178/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6212e-09 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9816\n",
            "Epoch 179/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6001e-09 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9816\n",
            "Epoch 180/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6212e-09 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9816\n",
            "Epoch 181/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5895e-09 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 0.9815\n",
            "Epoch 182/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5550e-09 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.9815\n",
            "Epoch 183/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5179e-09 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9815\n",
            "Epoch 184/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5444e-09 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.9815\n",
            "Epoch 185/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5391e-09 - accuracy: 1.0000 - val_loss: 0.2052 - val_accuracy: 0.9815\n",
            "Epoch 186/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5153e-09 - accuracy: 1.0000 - val_loss: 0.2054 - val_accuracy: 0.9815\n",
            "Epoch 187/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4597e-09 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 0.9815\n",
            "Epoch 188/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4729e-09 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.9814\n",
            "Epoch 189/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4808e-09 - accuracy: 1.0000 - val_loss: 0.2060 - val_accuracy: 0.9815\n",
            "Epoch 190/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4093e-09 - accuracy: 1.0000 - val_loss: 0.2061 - val_accuracy: 0.9814\n",
            "Epoch 191/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4597e-09 - accuracy: 1.0000 - val_loss: 0.2066 - val_accuracy: 0.9813\n",
            "Epoch 192/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4544e-09 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9814\n",
            "Epoch 193/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4093e-09 - accuracy: 1.0000 - val_loss: 0.2070 - val_accuracy: 0.9814\n",
            "Epoch 194/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4464e-09 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9813\n",
            "Epoch 195/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4120e-09 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 0.9814\n",
            "Epoch 196/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4438e-09 - accuracy: 1.0000 - val_loss: 0.2077 - val_accuracy: 0.9814\n",
            "Epoch 197/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3934e-09 - accuracy: 1.0000 - val_loss: 0.2077 - val_accuracy: 0.9813\n",
            "Epoch 198/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3510e-09 - accuracy: 1.0000 - val_loss: 0.2083 - val_accuracy: 0.9813\n",
            "Epoch 199/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4040e-09 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.9814\n",
            "Epoch 200/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3590e-09 - accuracy: 1.0000 - val_loss: 0.2087 - val_accuracy: 0.9815\n",
            "Epoch 201/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3484e-09 - accuracy: 1.0000 - val_loss: 0.2089 - val_accuracy: 0.9815\n",
            "Epoch 202/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4093e-09 - accuracy: 1.0000 - val_loss: 0.2093 - val_accuracy: 0.9815\n",
            "Epoch 203/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3855e-09 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9815\n",
            "Epoch 204/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3749e-09 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9815\n",
            "Epoch 205/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3908e-09 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9814\n",
            "Epoch 206/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3961e-09 - accuracy: 1.0000 - val_loss: 0.2104 - val_accuracy: 0.9816\n",
            "Epoch 207/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3961e-09 - accuracy: 1.0000 - val_loss: 0.2106 - val_accuracy: 0.9814\n",
            "Epoch 208/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4279e-09 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9814\n",
            "Epoch 209/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3961e-09 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9814\n",
            "Epoch 210/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4093e-09 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9813\n",
            "Epoch 211/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4332e-09 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9812\n",
            "Epoch 212/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4146e-09 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9813\n",
            "Epoch 213/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4464e-09 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 0.9813\n",
            "Epoch 214/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4332e-09 - accuracy: 1.0000 - val_loss: 0.2128 - val_accuracy: 0.9812\n",
            "Epoch 215/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3987e-09 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9812\n",
            "Epoch 216/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4146e-09 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9811\n",
            "Epoch 217/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4597e-09 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9811\n",
            "Epoch 218/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4305e-09 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9811\n",
            "Epoch 219/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4623e-09 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9811\n",
            "Epoch 220/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4385e-09 - accuracy: 1.0000 - val_loss: 0.2149 - val_accuracy: 0.9811\n",
            "Epoch 221/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5047e-09 - accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 0.9810\n",
            "Epoch 222/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4226e-09 - accuracy: 1.0000 - val_loss: 0.2151 - val_accuracy: 0.9811\n",
            "Epoch 223/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5206e-09 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 0.9811\n",
            "Epoch 224/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4941e-09 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9811\n",
            "Epoch 225/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4994e-09 - accuracy: 1.0000 - val_loss: 0.2163 - val_accuracy: 0.9811\n",
            "Epoch 226/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4623e-09 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9810\n",
            "Epoch 227/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4888e-09 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9807\n",
            "Epoch 228/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5577e-09 - accuracy: 1.0000 - val_loss: 0.2173 - val_accuracy: 0.9809\n",
            "Epoch 229/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5073e-09 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9807\n",
            "Epoch 230/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5603e-09 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9807\n",
            "Epoch 231/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5630e-09 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9806\n",
            "Epoch 232/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5259e-09 - accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.9805\n",
            "Epoch 233/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5312e-09 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9807\n",
            "Epoch 234/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5736e-09 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9805\n",
            "Epoch 235/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5789e-09 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9804\n",
            "Epoch 236/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6265e-09 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9805\n",
            "Epoch 237/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5736e-09 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9803\n",
            "Epoch 238/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5815e-09 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9804\n",
            "Epoch 239/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6080e-09 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9803\n",
            "Epoch 240/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5789e-09 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9804\n",
            "Epoch 241/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6186e-09 - accuracy: 1.0000 - val_loss: 0.2216 - val_accuracy: 0.9804\n",
            "Epoch 242/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6133e-09 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9804\n",
            "Epoch 243/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5656e-09 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9805\n",
            "Epoch 244/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5815e-09 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.9805\n",
            "Epoch 245/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6557e-09 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9803\n",
            "Epoch 246/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6345e-09 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.9803\n",
            "Epoch 247/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6265e-09 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.9805\n",
            "Epoch 248/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6742e-09 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9804\n",
            "Epoch 249/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6292e-09 - accuracy: 1.0000 - val_loss: 0.2240 - val_accuracy: 0.9803\n",
            "Epoch 250/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6398e-09 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9803\n",
            "Epoch 251/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6610e-09 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9803\n",
            "Epoch 252/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6636e-09 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9803\n",
            "Epoch 253/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6822e-09 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.9803\n",
            "Epoch 254/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6583e-09 - accuracy: 1.0000 - val_loss: 0.2255 - val_accuracy: 0.9803\n",
            "Epoch 255/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6928e-09 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9805\n",
            "Epoch 256/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7484e-09 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 0.9803\n",
            "Epoch 257/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7007e-09 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9803\n",
            "Epoch 258/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7537e-09 - accuracy: 1.0000 - val_loss: 0.2274 - val_accuracy: 0.9802\n",
            "Epoch 259/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7511e-09 - accuracy: 1.0000 - val_loss: 0.2273 - val_accuracy: 0.9804\n",
            "Epoch 260/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7246e-09 - accuracy: 1.0000 - val_loss: 0.2276 - val_accuracy: 0.9803\n",
            "Epoch 261/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7749e-09 - accuracy: 1.0000 - val_loss: 0.2280 - val_accuracy: 0.9805\n",
            "Epoch 262/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6928e-09 - accuracy: 1.0000 - val_loss: 0.2280 - val_accuracy: 0.9805\n",
            "Epoch 263/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7802e-09 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.9803\n",
            "Epoch 264/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7696e-09 - accuracy: 1.0000 - val_loss: 0.2289 - val_accuracy: 0.9805\n",
            "Epoch 265/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8040e-09 - accuracy: 1.0000 - val_loss: 0.2295 - val_accuracy: 0.9804\n",
            "Epoch 266/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7669e-09 - accuracy: 1.0000 - val_loss: 0.2296 - val_accuracy: 0.9805\n",
            "Epoch 267/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8358e-09 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 0.9804\n",
            "Epoch 268/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8093e-09 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 0.9804\n",
            "Epoch 269/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8782e-09 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.9804\n",
            "Epoch 270/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8093e-09 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.9803\n",
            "Epoch 271/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8862e-09 - accuracy: 1.0000 - val_loss: 0.2318 - val_accuracy: 0.9803\n",
            "Epoch 272/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8438e-09 - accuracy: 1.0000 - val_loss: 0.2324 - val_accuracy: 0.9804\n",
            "Epoch 273/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8358e-09 - accuracy: 1.0000 - val_loss: 0.2327 - val_accuracy: 0.9803\n",
            "Epoch 274/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8809e-09 - accuracy: 1.0000 - val_loss: 0.2332 - val_accuracy: 0.9803\n",
            "Epoch 275/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8782e-09 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.9803\n",
            "Epoch 276/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8703e-09 - accuracy: 1.0000 - val_loss: 0.2341 - val_accuracy: 0.9802\n",
            "Epoch 277/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9418e-09 - accuracy: 1.0000 - val_loss: 0.2339 - val_accuracy: 0.9804\n",
            "Epoch 278/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9391e-09 - accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 0.9802\n",
            "Epoch 279/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9736e-09 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9801\n",
            "Epoch 280/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9179e-09 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9804\n",
            "Epoch 281/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0080e-09 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9800\n",
            "Epoch 282/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0954e-09 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9801\n",
            "Epoch 283/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0928e-09 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9801\n",
            "Epoch 284/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9842e-09 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9801\n",
            "Epoch 285/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0478e-09 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9801\n",
            "Epoch 286/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0372e-09 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9802\n",
            "Epoch 287/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0292e-09 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 0.9801\n",
            "Epoch 288/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0954e-09 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9800\n",
            "Epoch 289/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0266e-09 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9803\n",
            "Epoch 290/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1855e-09 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.9803\n",
            "Epoch 291/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1166e-09 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9801\n",
            "Epoch 292/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1007e-09 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.9799\n",
            "Epoch 293/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1643e-09 - accuracy: 1.0000 - val_loss: 0.2406 - val_accuracy: 0.9801\n",
            "Epoch 294/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1113e-09 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9799\n",
            "Epoch 295/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0875e-09 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9798\n",
            "Epoch 296/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2199e-09 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9799\n",
            "Epoch 297/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2120e-09 - accuracy: 1.0000 - val_loss: 0.2421 - val_accuracy: 0.9798\n",
            "Epoch 298/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2040e-09 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9800\n",
            "Epoch 299/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2782e-09 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9799\n",
            "Epoch 300/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2120e-09 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9801\n",
            "Epoch 301/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2067e-09 - accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 0.9799\n",
            "Epoch 302/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6385e-09 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9797\n",
            "Epoch 303/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4107e-09 - accuracy: 1.0000 - val_loss: 0.2429 - val_accuracy: 0.9801\n",
            "Epoch 304/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2597e-09 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9794\n",
            "Epoch 305/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2544e-09 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9797\n",
            "Epoch 306/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5431e-09 - accuracy: 1.0000 - val_loss: 0.2471 - val_accuracy: 0.9797\n",
            "Epoch 307/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8504e-09 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9798\n",
            "Epoch 308/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2968e-09 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.9798\n",
            "Epoch 309/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2756e-09 - accuracy: 1.0000 - val_loss: 0.2474 - val_accuracy: 0.9797\n",
            "Epoch 310/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3656e-09 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9793\n",
            "Epoch 311/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3339e-09 - accuracy: 1.0000 - val_loss: 0.2488 - val_accuracy: 0.9799\n",
            "Epoch 312/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8716e-09 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9796\n",
            "Epoch 313/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3683e-09 - accuracy: 1.0000 - val_loss: 0.2505 - val_accuracy: 0.9796\n",
            "Epoch 314/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0200 - accuracy: 0.9991 - val_loss: 4.2978 - val_accuracy: 0.8700\n",
            "Epoch 315/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.1189 - accuracy: 0.9858 - val_loss: 0.1658 - val_accuracy: 0.9779\n",
            "Epoch 316/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.1487 - val_accuracy: 0.9802\n",
            "Epoch 317/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2171e-04 - accuracy: 0.9999 - val_loss: 0.1481 - val_accuracy: 0.9799\n",
            "Epoch 318/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9307e-04 - accuracy: 1.0000 - val_loss: 0.1495 - val_accuracy: 0.9803\n",
            "Epoch 319/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0992e-05 - accuracy: 1.0000 - val_loss: 0.1492 - val_accuracy: 0.9805\n",
            "Epoch 320/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.8902e-05 - accuracy: 1.0000 - val_loss: 0.1494 - val_accuracy: 0.9804\n",
            "Epoch 321/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3092e-05 - accuracy: 1.0000 - val_loss: 0.1498 - val_accuracy: 0.9805\n",
            "Epoch 322/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8919e-05 - accuracy: 1.0000 - val_loss: 0.1502 - val_accuracy: 0.9805\n",
            "Epoch 323/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5546e-05 - accuracy: 1.0000 - val_loss: 0.1506 - val_accuracy: 0.9807\n",
            "Epoch 324/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2876e-05 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 0.9806\n",
            "Epoch 325/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0584e-05 - accuracy: 1.0000 - val_loss: 0.1515 - val_accuracy: 0.9806\n",
            "Epoch 326/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8597e-05 - accuracy: 1.0000 - val_loss: 0.1518 - val_accuracy: 0.9805\n",
            "Epoch 327/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6869e-05 - accuracy: 1.0000 - val_loss: 0.1523 - val_accuracy: 0.9807\n",
            "Epoch 328/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5401e-05 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 0.9806\n",
            "Epoch 329/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4054e-05 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9806\n",
            "Epoch 330/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2862e-05 - accuracy: 1.0000 - val_loss: 0.1536 - val_accuracy: 0.9807\n",
            "Epoch 331/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1754e-05 - accuracy: 1.0000 - val_loss: 0.1540 - val_accuracy: 0.9806\n",
            "Epoch 332/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0786e-05 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 0.9805\n",
            "Epoch 333/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.8911e-06 - accuracy: 1.0000 - val_loss: 0.1549 - val_accuracy: 0.9806\n",
            "Epoch 334/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0851e-06 - accuracy: 1.0000 - val_loss: 0.1554 - val_accuracy: 0.9806\n",
            "Epoch 335/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.3531e-06 - accuracy: 1.0000 - val_loss: 0.1559 - val_accuracy: 0.9806\n",
            "Epoch 336/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.6985e-06 - accuracy: 1.0000 - val_loss: 0.1564 - val_accuracy: 0.9806\n",
            "Epoch 337/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0852e-06 - accuracy: 1.0000 - val_loss: 0.1569 - val_accuracy: 0.9806\n",
            "Epoch 338/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5396e-06 - accuracy: 1.0000 - val_loss: 0.1574 - val_accuracy: 0.9808\n",
            "Epoch 339/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0283e-06 - accuracy: 1.0000 - val_loss: 0.1578 - val_accuracy: 0.9809\n",
            "Epoch 340/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5612e-06 - accuracy: 1.0000 - val_loss: 0.1583 - val_accuracy: 0.9810\n",
            "Epoch 341/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1289e-06 - accuracy: 1.0000 - val_loss: 0.1588 - val_accuracy: 0.9810\n",
            "Epoch 342/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.7370e-06 - accuracy: 1.0000 - val_loss: 0.1593 - val_accuracy: 0.9810\n",
            "Epoch 343/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3719e-06 - accuracy: 1.0000 - val_loss: 0.1598 - val_accuracy: 0.9810\n",
            "Epoch 344/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.0367e-06 - accuracy: 1.0000 - val_loss: 0.1604 - val_accuracy: 0.9811\n",
            "Epoch 345/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.7266e-06 - accuracy: 1.0000 - val_loss: 0.1609 - val_accuracy: 0.9811\n",
            "Epoch 346/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.4433e-06 - accuracy: 1.0000 - val_loss: 0.1615 - val_accuracy: 0.9809\n",
            "Epoch 347/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1772e-06 - accuracy: 1.0000 - val_loss: 0.1620 - val_accuracy: 0.9809\n",
            "Epoch 348/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9376e-06 - accuracy: 1.0000 - val_loss: 0.1625 - val_accuracy: 0.9809\n",
            "Epoch 349/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7139e-06 - accuracy: 1.0000 - val_loss: 0.1630 - val_accuracy: 0.9810\n",
            "Epoch 350/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5102e-06 - accuracy: 1.0000 - val_loss: 0.1635 - val_accuracy: 0.9809\n",
            "Epoch 351/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3178e-06 - accuracy: 1.0000 - val_loss: 0.1641 - val_accuracy: 0.9808\n",
            "Epoch 352/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1388e-06 - accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 0.9809\n",
            "Epoch 353/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9739e-06 - accuracy: 1.0000 - val_loss: 0.1652 - val_accuracy: 0.9808\n",
            "Epoch 354/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8234e-06 - accuracy: 1.0000 - val_loss: 0.1658 - val_accuracy: 0.9807\n",
            "Epoch 355/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6769e-06 - accuracy: 1.0000 - val_loss: 0.1664 - val_accuracy: 0.9806\n",
            "Epoch 356/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5503e-06 - accuracy: 1.0000 - val_loss: 0.1669 - val_accuracy: 0.9805\n",
            "Epoch 357/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4283e-06 - accuracy: 1.0000 - val_loss: 0.1674 - val_accuracy: 0.9806\n",
            "Epoch 358/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3191e-06 - accuracy: 1.0000 - val_loss: 0.1679 - val_accuracy: 0.9806\n",
            "Epoch 359/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2151e-06 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9804\n",
            "Epoch 360/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1213e-06 - accuracy: 1.0000 - val_loss: 0.1692 - val_accuracy: 0.9805\n",
            "Epoch 361/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0326e-06 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 0.9802\n",
            "Epoch 362/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.5099e-07 - accuracy: 1.0000 - val_loss: 0.1704 - val_accuracy: 0.9806\n",
            "Epoch 363/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.7714e-07 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 0.9805\n",
            "Epoch 364/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.1110e-07 - accuracy: 1.0000 - val_loss: 0.1715 - val_accuracy: 0.9805\n",
            "Epoch 365/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4445e-07 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 0.9805\n",
            "Epoch 366/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8871e-07 - accuracy: 1.0000 - val_loss: 0.1727 - val_accuracy: 0.9807\n",
            "Epoch 367/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3280e-07 - accuracy: 1.0000 - val_loss: 0.1735 - val_accuracy: 0.9805\n",
            "Epoch 368/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8240e-07 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 0.9806\n",
            "Epoch 369/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3694e-07 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9806\n",
            "Epoch 370/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.9609e-07 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 0.9807\n",
            "Epoch 371/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.5616e-07 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 0.9807\n",
            "Epoch 372/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.2182e-07 - accuracy: 1.0000 - val_loss: 0.1764 - val_accuracy: 0.9807\n",
            "Epoch 373/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.8814e-07 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.9806\n",
            "Epoch 374/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5753e-07 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 0.9806\n",
            "Epoch 375/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3009e-07 - accuracy: 1.0000 - val_loss: 0.1781 - val_accuracy: 0.9806\n",
            "Epoch 376/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0492e-07 - accuracy: 1.0000 - val_loss: 0.1787 - val_accuracy: 0.9805\n",
            "Epoch 377/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8137e-07 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 0.9806\n",
            "Epoch 378/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5949e-07 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 0.9806\n",
            "Epoch 379/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3922e-07 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 0.9807\n",
            "Epoch 380/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2108e-07 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 0.9805\n",
            "Epoch 381/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0400e-07 - accuracy: 1.0000 - val_loss: 0.1817 - val_accuracy: 0.9806\n",
            "Epoch 382/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8842e-07 - accuracy: 1.0000 - val_loss: 0.1824 - val_accuracy: 0.9808\n",
            "Epoch 383/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7407e-07 - accuracy: 1.0000 - val_loss: 0.1830 - val_accuracy: 0.9808\n",
            "Epoch 384/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6051e-07 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9809\n",
            "Epoch 385/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4852e-07 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.9808\n",
            "Epoch 386/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3657e-07 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 0.9808\n",
            "Epoch 387/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2569e-07 - accuracy: 1.0000 - val_loss: 0.1853 - val_accuracy: 0.9809\n",
            "Epoch 388/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1611e-07 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9809\n",
            "Epoch 389/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0774e-07 - accuracy: 1.0000 - val_loss: 0.1866 - val_accuracy: 0.9810\n",
            "Epoch 390/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.9399e-08 - accuracy: 1.0000 - val_loss: 0.1873 - val_accuracy: 0.9811\n",
            "Epoch 391/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.1484e-08 - accuracy: 1.0000 - val_loss: 0.1879 - val_accuracy: 0.9810\n",
            "Epoch 392/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.4726e-08 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 0.9811\n",
            "Epoch 393/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8320e-08 - accuracy: 1.0000 - val_loss: 0.1892 - val_accuracy: 0.9811\n",
            "Epoch 394/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.2254e-08 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9812\n",
            "Epoch 395/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7104e-08 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9810\n",
            "Epoch 396/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2018e-08 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9810\n",
            "Epoch 397/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7737e-08 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9811\n",
            "Epoch 398/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3265e-08 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9811\n",
            "Epoch 399/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.9162e-08 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9811\n",
            "Epoch 400/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.5665e-08 - accuracy: 1.0000 - val_loss: 0.1935 - val_accuracy: 0.9813\n",
            "Epoch 401/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.2250e-08 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9811\n",
            "Epoch 402/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9122e-08 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.9811\n",
            "Epoch 403/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6293e-08 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9813\n",
            "Epoch 404/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3614e-08 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9813\n",
            "Epoch 405/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1114e-08 - accuracy: 1.0000 - val_loss: 0.1971 - val_accuracy: 0.9811\n",
            "Epoch 406/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8907e-08 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9811\n",
            "Epoch 407/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6883e-08 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9811\n",
            "Epoch 408/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4907e-08 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.9811\n",
            "Epoch 409/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3333e-08 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.9812\n",
            "Epoch 410/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1635e-08 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9812\n",
            "Epoch 411/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0077e-08 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9811\n",
            "Epoch 412/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8748e-08 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9811\n",
            "Epoch 413/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7537e-08 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9811\n",
            "Epoch 414/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6265e-08 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9811\n",
            "Epoch 415/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5190e-08 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9811\n",
            "Epoch 416/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4136e-08 - accuracy: 1.0000 - val_loss: 0.2038 - val_accuracy: 0.9811\n",
            "Epoch 417/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3161e-08 - accuracy: 1.0000 - val_loss: 0.2046 - val_accuracy: 0.9812\n",
            "Epoch 418/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2353e-08 - accuracy: 1.0000 - val_loss: 0.2054 - val_accuracy: 0.9813\n",
            "Epoch 419/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1545e-08 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9813\n",
            "Epoch 420/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0784e-08 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9813\n",
            "Epoch 421/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0106e-08 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9813\n",
            "Epoch 422/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.4838e-09 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.9813\n",
            "Epoch 423/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.8851e-09 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9813\n",
            "Epoch 424/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.3446e-09 - accuracy: 1.0000 - val_loss: 0.2093 - val_accuracy: 0.9812\n",
            "Epoch 425/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8042e-09 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 0.9813\n",
            "Epoch 426/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4254e-09 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9813\n",
            "Epoch 427/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.9194e-09 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9812\n",
            "Epoch 428/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5353e-09 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9811\n",
            "Epoch 429/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1565e-09 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.9812\n",
            "Epoch 430/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7777e-09 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9811\n",
            "Epoch 431/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4200e-09 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9811\n",
            "Epoch 432/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1498e-09 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 0.9812\n",
            "Epoch 433/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.8955e-09 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9812\n",
            "Epoch 434/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.6094e-09 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9812\n",
            "Epoch 435/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.3869e-09 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9811\n",
            "Epoch 436/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.1273e-09 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9809\n",
            "Epoch 437/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9233e-09 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9811\n",
            "Epoch 438/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.7087e-09 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9811\n",
            "Epoch 439/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.5101e-09 - accuracy: 1.0000 - val_loss: 0.2205 - val_accuracy: 0.9810\n",
            "Epoch 440/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3564e-09 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9811\n",
            "Epoch 441/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1842e-09 - accuracy: 1.0000 - val_loss: 0.2221 - val_accuracy: 0.9809\n",
            "Epoch 442/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0306e-09 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9809\n",
            "Epoch 443/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9034e-09 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9809\n",
            "Epoch 444/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7683e-09 - accuracy: 1.0000 - val_loss: 0.2247 - val_accuracy: 0.9807\n",
            "Epoch 445/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7021e-09 - accuracy: 1.0000 - val_loss: 0.2255 - val_accuracy: 0.9808\n",
            "Epoch 446/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5617e-09 - accuracy: 1.0000 - val_loss: 0.2260 - val_accuracy: 0.9808\n",
            "Epoch 447/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5034e-09 - accuracy: 1.0000 - val_loss: 0.2268 - val_accuracy: 0.9808\n",
            "Epoch 448/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3471e-09 - accuracy: 1.0000 - val_loss: 0.2276 - val_accuracy: 0.9807\n",
            "Epoch 449/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2623e-09 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9807\n",
            "Epoch 450/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2332e-09 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.9807\n",
            "Epoch 451/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1193e-09 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 0.9806\n",
            "Epoch 452/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0398e-09 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 0.9806\n",
            "Epoch 453/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9974e-09 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.9806\n",
            "Epoch 454/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9047e-09 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9807\n",
            "Epoch 455/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9126e-09 - accuracy: 1.0000 - val_loss: 0.2327 - val_accuracy: 0.9805\n",
            "Epoch 456/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8358e-09 - accuracy: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.9805\n",
            "Epoch 457/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8173e-09 - accuracy: 1.0000 - val_loss: 0.2344 - val_accuracy: 0.9806\n",
            "Epoch 458/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7458e-09 - accuracy: 1.0000 - val_loss: 0.2350 - val_accuracy: 0.9805\n",
            "Epoch 459/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6981e-09 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9806\n",
            "Epoch 460/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6610e-09 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9806\n",
            "Epoch 461/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6371e-09 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 0.9804\n",
            "Epoch 462/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6398e-09 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9805\n",
            "Epoch 463/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5974e-09 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9803\n",
            "Epoch 464/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5815e-09 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9804\n",
            "Epoch 465/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5550e-09 - accuracy: 1.0000 - val_loss: 0.2398 - val_accuracy: 0.9803\n",
            "Epoch 466/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5365e-09 - accuracy: 1.0000 - val_loss: 0.2406 - val_accuracy: 0.9805\n",
            "Epoch 467/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4861e-09 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9803\n",
            "Epoch 468/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4702e-09 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9805\n",
            "Epoch 469/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4385e-09 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9804\n",
            "Epoch 470/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4332e-09 - accuracy: 1.0000 - val_loss: 0.2432 - val_accuracy: 0.9804\n",
            "Epoch 471/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4252e-09 - accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 0.9804\n",
            "Epoch 472/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4279e-09 - accuracy: 1.0000 - val_loss: 0.2442 - val_accuracy: 0.9803\n",
            "Epoch 473/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4226e-09 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.9803\n",
            "Epoch 474/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3510e-09 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9803\n",
            "Epoch 475/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4014e-09 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9803\n",
            "Epoch 476/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3590e-09 - accuracy: 1.0000 - val_loss: 0.2468 - val_accuracy: 0.9803\n",
            "Epoch 477/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3881e-09 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.9803\n",
            "Epoch 478/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3325e-09 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9803\n",
            "Epoch 479/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3510e-09 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9803\n",
            "Epoch 480/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3828e-09 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.9802\n",
            "Epoch 481/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3669e-09 - accuracy: 1.0000 - val_loss: 0.2499 - val_accuracy: 0.9802\n",
            "Epoch 482/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3272e-09 - accuracy: 1.0000 - val_loss: 0.2509 - val_accuracy: 0.9803\n",
            "Epoch 483/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3669e-09 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9802\n",
            "Epoch 484/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3351e-09 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9802\n",
            "Epoch 485/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3219e-09 - accuracy: 1.0000 - val_loss: 0.2519 - val_accuracy: 0.9802\n",
            "Epoch 486/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3325e-09 - accuracy: 1.0000 - val_loss: 0.2523 - val_accuracy: 0.9802\n",
            "Epoch 487/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4014e-09 - accuracy: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.9803\n",
            "Epoch 488/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3643e-09 - accuracy: 1.0000 - val_loss: 0.2537 - val_accuracy: 0.9803\n",
            "Epoch 489/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3855e-09 - accuracy: 1.0000 - val_loss: 0.2538 - val_accuracy: 0.9803\n",
            "Epoch 490/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4199e-09 - accuracy: 1.0000 - val_loss: 0.2551 - val_accuracy: 0.9803\n",
            "Epoch 491/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3563e-09 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9802\n",
            "Epoch 492/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4014e-09 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9801\n",
            "Epoch 493/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3934e-09 - accuracy: 1.0000 - val_loss: 0.2562 - val_accuracy: 0.9803\n",
            "Epoch 494/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3802e-09 - accuracy: 1.0000 - val_loss: 0.2575 - val_accuracy: 0.9801\n",
            "Epoch 495/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3696e-09 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.9803\n",
            "Epoch 496/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4226e-09 - accuracy: 1.0000 - val_loss: 0.2582 - val_accuracy: 0.9800\n",
            "Epoch 497/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4491e-09 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.9801\n",
            "Epoch 498/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4517e-09 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.9800\n",
            "Epoch 499/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4544e-09 - accuracy: 1.0000 - val_loss: 0.2604 - val_accuracy: 0.9803\n",
            "Epoch 500/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3802e-09 - accuracy: 1.0000 - val_loss: 0.2604 - val_accuracy: 0.9801\n",
            "Epoch 501/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4438e-09 - accuracy: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.9801\n",
            "Epoch 502/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4570e-09 - accuracy: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.9801\n",
            "Epoch 503/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4491e-09 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9803\n",
            "Epoch 504/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5179e-09 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9801\n",
            "Epoch 505/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4623e-09 - accuracy: 1.0000 - val_loss: 0.2639 - val_accuracy: 0.9802\n",
            "Epoch 506/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4279e-09 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9803\n",
            "Epoch 507/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4491e-09 - accuracy: 1.0000 - val_loss: 0.2647 - val_accuracy: 0.9802\n",
            "Epoch 508/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4676e-09 - accuracy: 1.0000 - val_loss: 0.2656 - val_accuracy: 0.9803\n",
            "Epoch 509/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5577e-09 - accuracy: 1.0000 - val_loss: 0.2663 - val_accuracy: 0.9803\n",
            "Epoch 510/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5471e-09 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9802\n",
            "Epoch 511/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4941e-09 - accuracy: 1.0000 - val_loss: 0.2674 - val_accuracy: 0.9802\n",
            "Epoch 512/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4808e-09 - accuracy: 1.0000 - val_loss: 0.2678 - val_accuracy: 0.9801\n",
            "Epoch 513/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6451e-09 - accuracy: 1.0000 - val_loss: 0.2683 - val_accuracy: 0.9799\n",
            "Epoch 514/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4808e-09 - accuracy: 1.0000 - val_loss: 0.2693 - val_accuracy: 0.9800\n",
            "Epoch 515/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5047e-09 - accuracy: 1.0000 - val_loss: 0.2698 - val_accuracy: 0.9796\n",
            "Epoch 516/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5259e-09 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.9801\n",
            "Epoch 517/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5153e-09 - accuracy: 1.0000 - val_loss: 0.2706 - val_accuracy: 0.9799\n",
            "Epoch 518/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5259e-09 - accuracy: 1.0000 - val_loss: 0.2730 - val_accuracy: 0.9799\n",
            "Epoch 519/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6212e-09 - accuracy: 1.0000 - val_loss: 0.2724 - val_accuracy: 0.9800\n",
            "Epoch 520/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6398e-09 - accuracy: 1.0000 - val_loss: 0.2728 - val_accuracy: 0.9799\n",
            "Epoch 521/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6716e-09 - accuracy: 1.0000 - val_loss: 0.2734 - val_accuracy: 0.9798\n",
            "Epoch 522/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5338e-09 - accuracy: 1.0000 - val_loss: 0.2744 - val_accuracy: 0.9798\n",
            "Epoch 523/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7034e-09 - accuracy: 1.0000 - val_loss: 0.2763 - val_accuracy: 0.9799\n",
            "Epoch 524/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6663e-09 - accuracy: 1.0000 - val_loss: 0.2759 - val_accuracy: 0.9798\n",
            "Epoch 525/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5206e-09 - accuracy: 1.0000 - val_loss: 0.2755 - val_accuracy: 0.9797\n",
            "Epoch 526/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7590e-09 - accuracy: 1.0000 - val_loss: 0.2770 - val_accuracy: 0.9799\n",
            "Epoch 527/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6239e-09 - accuracy: 1.0000 - val_loss: 0.2775 - val_accuracy: 0.9799\n",
            "Epoch 528/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6954e-09 - accuracy: 1.0000 - val_loss: 0.2787 - val_accuracy: 0.9797\n",
            "Epoch 529/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8146e-09 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9799\n",
            "Epoch 530/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6318e-09 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9799\n",
            "Epoch 531/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5418e-09 - accuracy: 1.0000 - val_loss: 0.2778 - val_accuracy: 0.9797\n",
            "Epoch 532/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6451e-09 - accuracy: 1.0000 - val_loss: 0.2794 - val_accuracy: 0.9798\n",
            "Epoch 533/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8862e-09 - accuracy: 1.0000 - val_loss: 0.2806 - val_accuracy: 0.9796\n",
            "Epoch 534/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6848e-09 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9795\n",
            "Epoch 535/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8093e-09 - accuracy: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.9797\n",
            "Epoch 536/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6054e-09 - accuracy: 1.0000 - val_loss: 0.2832 - val_accuracy: 0.9796\n",
            "Epoch 537/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0485 - accuracy: 0.9961 - val_loss: 0.7383 - val_accuracy: 0.9591\n",
            "Epoch 538/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0768 - accuracy: 0.9894 - val_loss: 0.2314 - val_accuracy: 0.9756\n",
            "Epoch 539/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.2322 - val_accuracy: 0.9773\n",
            "Epoch 540/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.2162 - val_accuracy: 0.9781\n",
            "Epoch 541/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7639e-04 - accuracy: 0.9999 - val_loss: 0.2194 - val_accuracy: 0.9780\n",
            "Epoch 542/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.7526e-05 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9786\n",
            "Epoch 543/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3087e-05 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 0.9787\n",
            "Epoch 544/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0202e-05 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 0.9789\n",
            "Epoch 545/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.7258e-06 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9789\n",
            "Epoch 546/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7131e-06 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9791\n",
            "Epoch 547/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.9204e-06 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9791\n",
            "Epoch 548/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2706e-06 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9791\n",
            "Epoch 549/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7177e-06 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9792\n",
            "Epoch 550/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2077e-06 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9793\n",
            "Epoch 551/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7963e-06 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9791\n",
            "Epoch 552/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4118e-06 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9790\n",
            "Epoch 553/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.0641e-06 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9791\n",
            "Epoch 554/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7478e-06 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9791\n",
            "Epoch 555/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.4655e-06 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9791\n",
            "Epoch 556/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.2110e-06 - accuracy: 1.0000 - val_loss: 0.2097 - val_accuracy: 0.9790\n",
            "Epoch 557/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9653e-06 - accuracy: 1.0000 - val_loss: 0.2097 - val_accuracy: 0.9792\n",
            "Epoch 558/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7470e-06 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9792\n",
            "Epoch 559/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5528e-06 - accuracy: 1.0000 - val_loss: 0.2097 - val_accuracy: 0.9790\n",
            "Epoch 560/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3602e-06 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9790\n",
            "Epoch 561/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1803e-06 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9791\n",
            "Epoch 562/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0192e-06 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9793\n",
            "Epoch 563/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8703e-06 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9793\n",
            "Epoch 564/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7361e-06 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9794\n",
            "Epoch 565/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6068e-06 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9793\n",
            "Epoch 566/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4866e-06 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9794\n",
            "Epoch 567/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3695e-06 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 0.9795\n",
            "Epoch 568/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2729e-06 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 0.9795\n",
            "Epoch 569/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1781e-06 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 0.9794\n",
            "Epoch 570/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0870e-06 - accuracy: 1.0000 - val_loss: 0.2106 - val_accuracy: 0.9796\n",
            "Epoch 571/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0159e-06 - accuracy: 1.0000 - val_loss: 0.2106 - val_accuracy: 0.9795\n",
            "Epoch 572/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3090e-07 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9795\n",
            "Epoch 573/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5186e-07 - accuracy: 1.0000 - val_loss: 0.2117 - val_accuracy: 0.9793\n",
            "Epoch 574/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.6853e-07 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 0.9795\n",
            "Epoch 575/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8113e-07 - accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 0.9796\n",
            "Epoch 576/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8869e-07 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9795\n",
            "Epoch 577/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.9785e-07 - accuracy: 1.0000 - val_loss: 0.2210 - val_accuracy: 0.9795\n",
            "Epoch 578/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1853e-07 - accuracy: 1.0000 - val_loss: 0.2245 - val_accuracy: 0.9795\n",
            "Epoch 579/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6640e-07 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9799\n",
            "Epoch 580/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3162e-07 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9793\n",
            "Epoch 581/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8779e-07 - accuracy: 1.0000 - val_loss: 0.2303 - val_accuracy: 0.9791\n",
            "Epoch 582/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6231e-07 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9790\n",
            "Epoch 583/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4600e-07 - accuracy: 1.0000 - val_loss: 0.2329 - val_accuracy: 0.9791\n",
            "Epoch 584/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2067e-07 - accuracy: 1.0000 - val_loss: 0.2341 - val_accuracy: 0.9791\n",
            "Epoch 585/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0073e-07 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9791\n",
            "Epoch 586/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8595e-07 - accuracy: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.9794\n",
            "Epoch 587/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7754e-07 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9791\n",
            "Epoch 588/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6013e-07 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9793\n",
            "Epoch 589/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5001e-07 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9794\n",
            "Epoch 590/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4244e-07 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9795\n",
            "Epoch 591/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3166e-07 - accuracy: 1.0000 - val_loss: 0.2395 - val_accuracy: 0.9792\n",
            "Epoch 592/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2347e-07 - accuracy: 1.0000 - val_loss: 0.2398 - val_accuracy: 0.9793\n",
            "Epoch 593/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1485e-07 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.9793\n",
            "Epoch 594/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0809e-07 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9793\n",
            "Epoch 595/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0150e-07 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9795\n",
            "Epoch 596/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4013e-08 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9791\n",
            "Epoch 597/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.8575e-08 - accuracy: 1.0000 - val_loss: 0.2428 - val_accuracy: 0.9796\n",
            "Epoch 598/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.3568e-08 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9793\n",
            "Epoch 599/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9160e-08 - accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 0.9796\n",
            "Epoch 600/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3091e-08 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9796\n",
            "Epoch 601/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.9276e-08 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9799\n",
            "Epoch 602/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4564e-08 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.9797\n",
            "Epoch 603/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1194e-08 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9795\n",
            "Epoch 604/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7128e-08 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9797\n",
            "Epoch 605/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2833e-08 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.9798\n",
            "Epoch 606/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0306e-08 - accuracy: 1.0000 - val_loss: 0.2478 - val_accuracy: 0.9797\n",
            "Epoch 607/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6897e-08 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.9795\n",
            "Epoch 608/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.4359e-08 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9797\n",
            "Epoch 609/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.1668e-08 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 0.9798\n",
            "Epoch 610/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9061e-08 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.9797\n",
            "Epoch 611/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6255e-08 - accuracy: 1.0000 - val_loss: 0.2503 - val_accuracy: 0.9797\n",
            "Epoch 612/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4642e-08 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9796\n",
            "Epoch 613/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2279e-08 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9797\n",
            "Epoch 614/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0329e-08 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.9797\n",
            "Epoch 615/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8348e-08 - accuracy: 1.0000 - val_loss: 0.2523 - val_accuracy: 0.9795\n",
            "Epoch 616/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6586e-08 - accuracy: 1.0000 - val_loss: 0.2528 - val_accuracy: 0.9797\n",
            "Epoch 617/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5185e-08 - accuracy: 1.0000 - val_loss: 0.2531 - val_accuracy: 0.9795\n",
            "Epoch 618/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3389e-08 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.9799\n",
            "Epoch 619/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1797e-08 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.9795\n",
            "Epoch 620/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0591e-08 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.9798\n",
            "Epoch 621/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9381e-08 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.9798\n",
            "Epoch 622/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8157e-08 - accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 0.9799\n",
            "Epoch 623/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7042e-08 - accuracy: 1.0000 - val_loss: 0.2562 - val_accuracy: 0.9798\n",
            "Epoch 624/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6006e-08 - accuracy: 1.0000 - val_loss: 0.2563 - val_accuracy: 0.9797\n",
            "Epoch 625/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4999e-08 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.9798\n",
            "Epoch 626/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3990e-08 - accuracy: 1.0000 - val_loss: 0.2573 - val_accuracy: 0.9796\n",
            "Epoch 627/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3171e-08 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.9797\n",
            "Epoch 628/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2279e-08 - accuracy: 1.0000 - val_loss: 0.2588 - val_accuracy: 0.9795\n",
            "Epoch 629/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1712e-08 - accuracy: 1.0000 - val_loss: 0.2592 - val_accuracy: 0.9795\n",
            "Epoch 630/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0994e-08 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.9795\n",
            "Epoch 631/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0265e-08 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.9795\n",
            "Epoch 632/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.7010e-09 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.9795\n",
            "Epoch 633/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.1420e-09 - accuracy: 1.0000 - val_loss: 0.2608 - val_accuracy: 0.9797\n",
            "Epoch 634/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.5910e-09 - accuracy: 1.0000 - val_loss: 0.2619 - val_accuracy: 0.9797\n",
            "Epoch 635/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0930e-09 - accuracy: 1.0000 - val_loss: 0.2621 - val_accuracy: 0.9797\n",
            "Epoch 636/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.6347e-09 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9796\n",
            "Epoch 637/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.1632e-09 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9797\n",
            "Epoch 638/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6996e-09 - accuracy: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.9797\n",
            "Epoch 639/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2784e-09 - accuracy: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.9798\n",
            "Epoch 640/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.9472e-09 - accuracy: 1.0000 - val_loss: 0.2649 - val_accuracy: 0.9798\n",
            "Epoch 641/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5340e-09 - accuracy: 1.0000 - val_loss: 0.2656 - val_accuracy: 0.9798\n",
            "Epoch 642/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2876e-09 - accuracy: 1.0000 - val_loss: 0.2661 - val_accuracy: 0.9800\n",
            "Epoch 643/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0200e-09 - accuracy: 1.0000 - val_loss: 0.2665 - val_accuracy: 0.9798\n",
            "Epoch 644/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6810e-09 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9797\n",
            "Epoch 645/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4584e-09 - accuracy: 1.0000 - val_loss: 0.2679 - val_accuracy: 0.9797\n",
            "Epoch 646/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1909e-09 - accuracy: 1.0000 - val_loss: 0.2688 - val_accuracy: 0.9799\n",
            "Epoch 647/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9498e-09 - accuracy: 1.0000 - val_loss: 0.2698 - val_accuracy: 0.9798\n",
            "Epoch 648/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6796e-09 - accuracy: 1.0000 - val_loss: 0.2704 - val_accuracy: 0.9798\n",
            "Epoch 649/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4968e-09 - accuracy: 1.0000 - val_loss: 0.2709 - val_accuracy: 0.9797\n",
            "Epoch 650/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3458e-09 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9797\n",
            "Epoch 651/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1816e-09 - accuracy: 1.0000 - val_loss: 0.2725 - val_accuracy: 0.9797\n",
            "Epoch 652/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0041e-09 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9797\n",
            "Epoch 653/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8690e-09 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9799\n",
            "Epoch 654/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7418e-09 - accuracy: 1.0000 - val_loss: 0.2752 - val_accuracy: 0.9797\n",
            "Epoch 655/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6279e-09 - accuracy: 1.0000 - val_loss: 0.2756 - val_accuracy: 0.9799\n",
            "Epoch 656/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4478e-09 - accuracy: 1.0000 - val_loss: 0.2766 - val_accuracy: 0.9797\n",
            "Epoch 657/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3868e-09 - accuracy: 1.0000 - val_loss: 0.2774 - val_accuracy: 0.9798\n",
            "Epoch 658/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2252e-09 - accuracy: 1.0000 - val_loss: 0.2782 - val_accuracy: 0.9799\n",
            "Epoch 659/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1590e-09 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9797\n",
            "Epoch 660/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0080e-09 - accuracy: 1.0000 - val_loss: 0.2797 - val_accuracy: 0.9797\n",
            "Epoch 661/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9815e-09 - accuracy: 1.0000 - val_loss: 0.2807 - val_accuracy: 0.9798\n",
            "Epoch 662/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8623e-09 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9798\n",
            "Epoch 663/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7855e-09 - accuracy: 1.0000 - val_loss: 0.2823 - val_accuracy: 0.9798\n",
            "Epoch 664/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6928e-09 - accuracy: 1.0000 - val_loss: 0.2827 - val_accuracy: 0.9796\n",
            "Epoch 665/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6371e-09 - accuracy: 1.0000 - val_loss: 0.2842 - val_accuracy: 0.9797\n",
            "Epoch 666/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5736e-09 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.9797\n",
            "Epoch 667/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5577e-09 - accuracy: 1.0000 - val_loss: 0.2856 - val_accuracy: 0.9795\n",
            "Epoch 668/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4755e-09 - accuracy: 1.0000 - val_loss: 0.2866 - val_accuracy: 0.9795\n",
            "Epoch 669/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4146e-09 - accuracy: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.9796\n",
            "Epoch 670/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3563e-09 - accuracy: 1.0000 - val_loss: 0.2886 - val_accuracy: 0.9796\n",
            "Epoch 671/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3060e-09 - accuracy: 1.0000 - val_loss: 0.2895 - val_accuracy: 0.9797\n",
            "Epoch 672/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3166e-09 - accuracy: 1.0000 - val_loss: 0.2904 - val_accuracy: 0.9793\n",
            "Epoch 673/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2530e-09 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.9795\n",
            "Epoch 674/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2345e-09 - accuracy: 1.0000 - val_loss: 0.2923 - val_accuracy: 0.9795\n",
            "Epoch 675/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2106e-09 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.9795\n",
            "Epoch 676/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1524e-09 - accuracy: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.9795\n",
            "Epoch 677/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1285e-09 - accuracy: 1.0000 - val_loss: 0.2948 - val_accuracy: 0.9795\n",
            "Epoch 678/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1100e-09 - accuracy: 1.0000 - val_loss: 0.2960 - val_accuracy: 0.9794\n",
            "Epoch 679/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0835e-09 - accuracy: 1.0000 - val_loss: 0.2970 - val_accuracy: 0.9795\n",
            "Epoch 680/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1047e-09 - accuracy: 1.0000 - val_loss: 0.2970 - val_accuracy: 0.9796\n",
            "Epoch 681/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0411e-09 - accuracy: 1.0000 - val_loss: 0.2976 - val_accuracy: 0.9796\n",
            "Epoch 682/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0093e-09 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.9795\n",
            "Epoch 683/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0146e-09 - accuracy: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.9793\n",
            "Epoch 684/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0120e-09 - accuracy: 1.0000 - val_loss: 0.3003 - val_accuracy: 0.9793\n",
            "Epoch 685/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.4838e-10 - accuracy: 1.0000 - val_loss: 0.3015 - val_accuracy: 0.9795\n",
            "Epoch 686/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9871e-10 - accuracy: 1.0000 - val_loss: 0.3016 - val_accuracy: 0.9794\n",
            "Epoch 687/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7222e-10 - accuracy: 1.0000 - val_loss: 0.3024 - val_accuracy: 0.9795\n",
            "Epoch 688/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2453e-10 - accuracy: 1.0000 - val_loss: 0.3034 - val_accuracy: 0.9796\n",
            "Epoch 689/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5103e-10 - accuracy: 1.0000 - val_loss: 0.3048 - val_accuracy: 0.9794\n",
            "Epoch 690/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2453e-10 - accuracy: 1.0000 - val_loss: 0.3044 - val_accuracy: 0.9795\n",
            "Epoch 691/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8480e-10 - accuracy: 1.0000 - val_loss: 0.3058 - val_accuracy: 0.9794\n",
            "Epoch 692/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9010e-10 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 0.9795\n",
            "Epoch 693/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.0069e-10 - accuracy: 1.0000 - val_loss: 0.3072 - val_accuracy: 0.9794\n",
            "Epoch 694/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.8480e-10 - accuracy: 1.0000 - val_loss: 0.3076 - val_accuracy: 0.9795\n",
            "Epoch 695/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.0864e-10 - accuracy: 1.0000 - val_loss: 0.3088 - val_accuracy: 0.9796\n",
            "Epoch 696/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.8480e-10 - accuracy: 1.0000 - val_loss: 0.3093 - val_accuracy: 0.9794\n",
            "Epoch 697/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.0334e-10 - accuracy: 1.0000 - val_loss: 0.3097 - val_accuracy: 0.9792\n",
            "Epoch 698/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8745e-10 - accuracy: 1.0000 - val_loss: 0.3107 - val_accuracy: 0.9791\n",
            "Epoch 699/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7950e-10 - accuracy: 1.0000 - val_loss: 0.3117 - val_accuracy: 0.9794\n",
            "Epoch 700/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8215e-10 - accuracy: 1.0000 - val_loss: 0.3126 - val_accuracy: 0.9795\n",
            "Epoch 701/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8215e-10 - accuracy: 1.0000 - val_loss: 0.3127 - val_accuracy: 0.9795\n",
            "Epoch 702/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3976e-10 - accuracy: 1.0000 - val_loss: 0.3134 - val_accuracy: 0.9793\n",
            "Epoch 703/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0334e-10 - accuracy: 1.0000 - val_loss: 0.3143 - val_accuracy: 0.9791\n",
            "Epoch 704/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.3976e-10 - accuracy: 1.0000 - val_loss: 0.3143 - val_accuracy: 0.9793\n",
            "Epoch 705/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8745e-10 - accuracy: 1.0000 - val_loss: 0.3156 - val_accuracy: 0.9791\n",
            "Epoch 706/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5831e-10 - accuracy: 1.0000 - val_loss: 0.3165 - val_accuracy: 0.9791\n",
            "Epoch 707/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6361e-10 - accuracy: 1.0000 - val_loss: 0.3165 - val_accuracy: 0.9791\n",
            "Epoch 708/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1924e-10 - accuracy: 1.0000 - val_loss: 0.3176 - val_accuracy: 0.9791\n",
            "Epoch 709/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7950e-10 - accuracy: 1.0000 - val_loss: 0.3173 - val_accuracy: 0.9791\n",
            "Epoch 710/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7420e-10 - accuracy: 1.0000 - val_loss: 0.3179 - val_accuracy: 0.9791\n",
            "Epoch 711/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8215e-10 - accuracy: 1.0000 - val_loss: 0.3192 - val_accuracy: 0.9791\n",
            "Epoch 712/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.5831e-10 - accuracy: 1.0000 - val_loss: 0.3196 - val_accuracy: 0.9793\n",
            "Epoch 713/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2718e-10 - accuracy: 1.0000 - val_loss: 0.3197 - val_accuracy: 0.9792\n",
            "Epoch 714/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.8215e-10 - accuracy: 1.0000 - val_loss: 0.3204 - val_accuracy: 0.9791\n",
            "Epoch 715/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3513e-10 - accuracy: 1.0000 - val_loss: 0.3207 - val_accuracy: 0.9793\n",
            "Epoch 716/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5301e-10 - accuracy: 1.0000 - val_loss: 0.3214 - val_accuracy: 0.9791\n",
            "Epoch 717/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7685e-10 - accuracy: 1.0000 - val_loss: 0.3216 - val_accuracy: 0.9791\n",
            "Epoch 718/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.3446e-10 - accuracy: 1.0000 - val_loss: 0.3219 - val_accuracy: 0.9788\n",
            "Epoch 719/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7155e-10 - accuracy: 1.0000 - val_loss: 0.3228 - val_accuracy: 0.9789\n",
            "Epoch 720/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.0864e-10 - accuracy: 1.0000 - val_loss: 0.3234 - val_accuracy: 0.9790\n",
            "Epoch 721/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.7487e-10 - accuracy: 1.0000 - val_loss: 0.3242 - val_accuracy: 0.9790\n",
            "Epoch 722/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.0864e-10 - accuracy: 1.0000 - val_loss: 0.3244 - val_accuracy: 0.9790\n",
            "Epoch 723/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.0334e-10 - accuracy: 1.0000 - val_loss: 0.3237 - val_accuracy: 0.9790\n",
            "Epoch 724/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6890e-10 - accuracy: 1.0000 - val_loss: 0.3256 - val_accuracy: 0.9794\n",
            "Epoch 725/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.1924e-10 - accuracy: 1.0000 - val_loss: 0.3256 - val_accuracy: 0.9791\n",
            "Epoch 726/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3778e-10 - accuracy: 1.0000 - val_loss: 0.3255 - val_accuracy: 0.9789\n",
            "Epoch 727/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.6692e-10 - accuracy: 1.0000 - val_loss: 0.3275 - val_accuracy: 0.9786\n",
            "Epoch 728/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0599e-10 - accuracy: 1.0000 - val_loss: 0.3280 - val_accuracy: 0.9790\n",
            "Epoch 729/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3778e-10 - accuracy: 1.0000 - val_loss: 0.3287 - val_accuracy: 0.9789\n",
            "Epoch 730/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0623e-09 - accuracy: 1.0000 - val_loss: 0.3280 - val_accuracy: 0.9791\n",
            "Epoch 731/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.7685e-10 - accuracy: 1.0000 - val_loss: 0.3282 - val_accuracy: 0.9792\n",
            "Epoch 732/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.1458 - accuracy: 0.9862 - val_loss: 0.2725 - val_accuracy: 0.9730\n",
            "Epoch 733/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0113 - accuracy: 0.9975 - val_loss: 0.2187 - val_accuracy: 0.9787\n",
            "Epoch 734/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.2101 - val_accuracy: 0.9786\n",
            "Epoch 735/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6397e-04 - accuracy: 0.9998 - val_loss: 0.2105 - val_accuracy: 0.9796\n",
            "Epoch 736/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.0593e-05 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9794\n",
            "Epoch 737/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6099e-05 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9794\n",
            "Epoch 738/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2846e-05 - accuracy: 1.0000 - val_loss: 0.2112 - val_accuracy: 0.9795\n",
            "Epoch 739/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0789e-05 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9796\n",
            "Epoch 740/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3998e-06 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9795\n",
            "Epoch 741/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.2888e-06 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9795\n",
            "Epoch 742/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4201e-06 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9795\n",
            "Epoch 743/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6978e-06 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9796\n",
            "Epoch 744/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0642e-06 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9795\n",
            "Epoch 745/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5111e-06 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9795\n",
            "Epoch 746/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0160e-06 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9796\n",
            "Epoch 747/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.5940e-06 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9797\n",
            "Epoch 748/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.2064e-06 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9796\n",
            "Epoch 749/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8716e-06 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9797\n",
            "Epoch 750/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5511e-06 - accuracy: 1.0000 - val_loss: 0.2119 - val_accuracy: 0.9796\n",
            "Epoch 751/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2719e-06 - accuracy: 1.0000 - val_loss: 0.2119 - val_accuracy: 0.9796\n",
            "Epoch 752/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0133e-06 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9797\n",
            "Epoch 753/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7811e-06 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9795\n",
            "Epoch 754/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5658e-06 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9795\n",
            "Epoch 755/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3664e-06 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9796\n",
            "Epoch 756/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1883e-06 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 0.9796\n",
            "Epoch 757/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0020e-06 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 0.9797\n",
            "Epoch 758/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8457e-06 - accuracy: 1.0000 - val_loss: 0.2128 - val_accuracy: 0.9798\n",
            "Epoch 759/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6967e-06 - accuracy: 1.0000 - val_loss: 0.2128 - val_accuracy: 0.9797\n",
            "Epoch 760/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5674e-06 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9797\n",
            "Epoch 761/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4430e-06 - accuracy: 1.0000 - val_loss: 0.2133 - val_accuracy: 0.9798\n",
            "Epoch 762/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3336e-06 - accuracy: 1.0000 - val_loss: 0.2136 - val_accuracy: 0.9799\n",
            "Epoch 763/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2346e-06 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9798\n",
            "Epoch 764/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1403e-06 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9797\n",
            "Epoch 765/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0575e-06 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9797\n",
            "Epoch 766/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.8515e-07 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9799\n",
            "Epoch 767/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1356e-07 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 0.9798\n",
            "Epoch 768/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4886e-07 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9799\n",
            "Epoch 769/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8788e-07 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9800\n",
            "Epoch 770/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3191e-07 - accuracy: 1.0000 - val_loss: 0.2165 - val_accuracy: 0.9800\n",
            "Epoch 771/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7936e-07 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9799\n",
            "Epoch 772/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2821e-07 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9801\n",
            "Epoch 773/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8338e-07 - accuracy: 1.0000 - val_loss: 0.2179 - val_accuracy: 0.9801\n",
            "Epoch 774/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3793e-07 - accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.9801\n",
            "Epoch 775/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9916e-07 - accuracy: 1.0000 - val_loss: 0.2189 - val_accuracy: 0.9801\n",
            "Epoch 776/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6185e-07 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9800\n",
            "Epoch 777/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2896e-07 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9799\n",
            "Epoch 778/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9699e-07 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9798\n",
            "Epoch 779/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6880e-07 - accuracy: 1.0000 - val_loss: 0.2214 - val_accuracy: 0.9799\n",
            "Epoch 780/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3978e-07 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9800\n",
            "Epoch 781/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1505e-07 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9800\n",
            "Epoch 782/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8995e-07 - accuracy: 1.0000 - val_loss: 0.2237 - val_accuracy: 0.9801\n",
            "Epoch 783/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6766e-07 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9801\n",
            "Epoch 784/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4644e-07 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9802\n",
            "Epoch 785/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2635e-07 - accuracy: 1.0000 - val_loss: 0.2265 - val_accuracy: 0.9803\n",
            "Epoch 786/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0743e-07 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9805\n",
            "Epoch 787/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8952e-07 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9805\n",
            "Epoch 788/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7240e-07 - accuracy: 1.0000 - val_loss: 0.2303 - val_accuracy: 0.9804\n",
            "Epoch 789/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5807e-07 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.9805\n",
            "Epoch 790/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4390e-07 - accuracy: 1.0000 - val_loss: 0.2327 - val_accuracy: 0.9805\n",
            "Epoch 791/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3091e-07 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9805\n",
            "Epoch 792/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1995e-07 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9806\n",
            "Epoch 793/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0878e-07 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9809\n",
            "Epoch 794/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.8930e-08 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.9809\n",
            "Epoch 795/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9931e-08 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9808\n",
            "Epoch 796/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1949e-08 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9809\n",
            "Epoch 797/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5351e-08 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 0.9809\n",
            "Epoch 798/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8757e-08 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9809\n",
            "Epoch 799/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3019e-08 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.9809\n",
            "Epoch 800/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8047e-08 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9807\n",
            "Epoch 801/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3480e-08 - accuracy: 1.0000 - val_loss: 0.2473 - val_accuracy: 0.9809\n",
            "Epoch 802/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9262e-08 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.9807\n",
            "Epoch 803/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5813e-08 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9807\n",
            "Epoch 804/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2189e-08 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9808\n",
            "Epoch 805/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9082e-08 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.9807\n",
            "Epoch 806/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6001e-08 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.9808\n",
            "Epoch 807/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3585e-08 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.9806\n",
            "Epoch 808/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1114e-08 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.9809\n",
            "Epoch 809/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8880e-08 - accuracy: 1.0000 - val_loss: 0.2558 - val_accuracy: 0.9808\n",
            "Epoch 810/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6838e-08 - accuracy: 1.0000 - val_loss: 0.2567 - val_accuracy: 0.9808\n",
            "Epoch 811/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5002e-08 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.9807\n",
            "Epoch 812/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3325e-08 - accuracy: 1.0000 - val_loss: 0.2587 - val_accuracy: 0.9807\n",
            "Epoch 813/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1823e-08 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.9807\n",
            "Epoch 814/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0385e-08 - accuracy: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.9806\n",
            "Epoch 815/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9018e-08 - accuracy: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.9807\n",
            "Epoch 816/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7815e-08 - accuracy: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.9807\n",
            "Epoch 817/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6610e-08 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9807\n",
            "Epoch 818/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5439e-08 - accuracy: 1.0000 - val_loss: 0.2639 - val_accuracy: 0.9807\n",
            "Epoch 819/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4419e-08 - accuracy: 1.0000 - val_loss: 0.2648 - val_accuracy: 0.9807\n",
            "Epoch 820/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3526e-08 - accuracy: 1.0000 - val_loss: 0.2655 - val_accuracy: 0.9805\n",
            "Epoch 821/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2644e-08 - accuracy: 1.0000 - val_loss: 0.2661 - val_accuracy: 0.9808\n",
            "Epoch 822/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1865e-08 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9808\n",
            "Epoch 823/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1081e-08 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.9805\n",
            "Epoch 824/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0400e-08 - accuracy: 1.0000 - val_loss: 0.2689 - val_accuracy: 0.9807\n",
            "Epoch 825/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7487e-09 - accuracy: 1.0000 - val_loss: 0.2697 - val_accuracy: 0.9805\n",
            "Epoch 826/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1208e-09 - accuracy: 1.0000 - val_loss: 0.2706 - val_accuracy: 0.9805\n",
            "Epoch 827/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.4903e-09 - accuracy: 1.0000 - val_loss: 0.2714 - val_accuracy: 0.9806\n",
            "Epoch 828/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9711e-09 - accuracy: 1.0000 - val_loss: 0.2724 - val_accuracy: 0.9806\n",
            "Epoch 829/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4731e-09 - accuracy: 1.0000 - val_loss: 0.2733 - val_accuracy: 0.9807\n",
            "Epoch 830/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0333e-09 - accuracy: 1.0000 - val_loss: 0.2744 - val_accuracy: 0.9806\n",
            "Epoch 831/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5804e-09 - accuracy: 1.0000 - val_loss: 0.2751 - val_accuracy: 0.9806\n",
            "Epoch 832/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1644e-09 - accuracy: 1.0000 - val_loss: 0.2759 - val_accuracy: 0.9806\n",
            "Epoch 833/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8095e-09 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.9806\n",
            "Epoch 834/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.4306e-09 - accuracy: 1.0000 - val_loss: 0.2778 - val_accuracy: 0.9806\n",
            "Epoch 835/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1286e-09 - accuracy: 1.0000 - val_loss: 0.2787 - val_accuracy: 0.9807\n",
            "Epoch 836/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.8319e-09 - accuracy: 1.0000 - val_loss: 0.2797 - val_accuracy: 0.9806\n",
            "Epoch 837/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5273e-09 - accuracy: 1.0000 - val_loss: 0.2806 - val_accuracy: 0.9807\n",
            "Epoch 838/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2147e-09 - accuracy: 1.0000 - val_loss: 0.2815 - val_accuracy: 0.9805\n",
            "Epoch 839/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0054e-09 - accuracy: 1.0000 - val_loss: 0.2826 - val_accuracy: 0.9804\n",
            "Epoch 840/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7909e-09 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 0.9805\n",
            "Epoch 841/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5657e-09 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 0.9805\n",
            "Epoch 842/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3167e-09 - accuracy: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.9805\n",
            "Epoch 843/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1206e-09 - accuracy: 1.0000 - val_loss: 0.2867 - val_accuracy: 0.9805\n",
            "Epoch 844/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9378e-09 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.9805\n",
            "Epoch 845/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7710e-09 - accuracy: 1.0000 - val_loss: 0.2891 - val_accuracy: 0.9804\n",
            "Epoch 846/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6438e-09 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9804\n",
            "Epoch 847/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4557e-09 - accuracy: 1.0000 - val_loss: 0.2914 - val_accuracy: 0.9802\n",
            "Epoch 848/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3497e-09 - accuracy: 1.0000 - val_loss: 0.2925 - val_accuracy: 0.9804\n",
            "Epoch 849/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2517e-09 - accuracy: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.9803\n",
            "Epoch 850/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0716e-09 - accuracy: 1.0000 - val_loss: 0.2949 - val_accuracy: 0.9804\n",
            "Epoch 851/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9921e-09 - accuracy: 1.0000 - val_loss: 0.2962 - val_accuracy: 0.9803\n",
            "Epoch 852/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9153e-09 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.9803\n",
            "Epoch 853/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8332e-09 - accuracy: 1.0000 - val_loss: 0.2987 - val_accuracy: 0.9802\n",
            "Epoch 854/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7352e-09 - accuracy: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.9802\n",
            "Epoch 855/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6875e-09 - accuracy: 1.0000 - val_loss: 0.3011 - val_accuracy: 0.9801\n",
            "Epoch 856/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5577e-09 - accuracy: 1.0000 - val_loss: 0.3028 - val_accuracy: 0.9802\n",
            "Epoch 857/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5365e-09 - accuracy: 1.0000 - val_loss: 0.3039 - val_accuracy: 0.9801\n",
            "Epoch 858/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4729e-09 - accuracy: 1.0000 - val_loss: 0.3050 - val_accuracy: 0.9800\n",
            "Epoch 859/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3881e-09 - accuracy: 1.0000 - val_loss: 0.3066 - val_accuracy: 0.9800\n",
            "Epoch 860/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3616e-09 - accuracy: 1.0000 - val_loss: 0.3077 - val_accuracy: 0.9801\n",
            "Epoch 861/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3590e-09 - accuracy: 1.0000 - val_loss: 0.3088 - val_accuracy: 0.9800\n",
            "Epoch 862/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2795e-09 - accuracy: 1.0000 - val_loss: 0.3099 - val_accuracy: 0.9801\n",
            "Epoch 863/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2265e-09 - accuracy: 1.0000 - val_loss: 0.3110 - val_accuracy: 0.9801\n",
            "Epoch 864/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1947e-09 - accuracy: 1.0000 - val_loss: 0.3124 - val_accuracy: 0.9799\n",
            "Epoch 865/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1709e-09 - accuracy: 1.0000 - val_loss: 0.3128 - val_accuracy: 0.9799\n",
            "Epoch 866/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1391e-09 - accuracy: 1.0000 - val_loss: 0.3144 - val_accuracy: 0.9799\n",
            "Epoch 867/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0808e-09 - accuracy: 1.0000 - val_loss: 0.3155 - val_accuracy: 0.9797\n",
            "Epoch 868/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0411e-09 - accuracy: 1.0000 - val_loss: 0.3166 - val_accuracy: 0.9797\n",
            "Epoch 869/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0040e-09 - accuracy: 1.0000 - val_loss: 0.3179 - val_accuracy: 0.9797\n",
            "Epoch 870/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9076e-10 - accuracy: 1.0000 - val_loss: 0.3193 - val_accuracy: 0.9797\n",
            "Epoch 871/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0146e-09 - accuracy: 1.0000 - val_loss: 0.3200 - val_accuracy: 0.9798\n",
            "Epoch 872/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3778e-10 - accuracy: 1.0000 - val_loss: 0.3212 - val_accuracy: 0.9799\n",
            "Epoch 873/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5103e-10 - accuracy: 1.0000 - val_loss: 0.3223 - val_accuracy: 0.9797\n",
            "Epoch 874/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1129e-10 - accuracy: 1.0000 - val_loss: 0.3239 - val_accuracy: 0.9797\n",
            "Epoch 875/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.7155e-10 - accuracy: 1.0000 - val_loss: 0.3244 - val_accuracy: 0.9797\n",
            "Epoch 876/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6361e-10 - accuracy: 1.0000 - val_loss: 0.3255 - val_accuracy: 0.9798\n",
            "Epoch 877/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3446e-10 - accuracy: 1.0000 - val_loss: 0.3271 - val_accuracy: 0.9797\n",
            "Epoch 878/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4771e-10 - accuracy: 1.0000 - val_loss: 0.3281 - val_accuracy: 0.9798\n",
            "Epoch 879/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.8148e-10 - accuracy: 1.0000 - val_loss: 0.3294 - val_accuracy: 0.9798\n",
            "Epoch 880/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1592e-10 - accuracy: 1.0000 - val_loss: 0.3299 - val_accuracy: 0.9799\n",
            "Epoch 881/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2917e-10 - accuracy: 1.0000 - val_loss: 0.3314 - val_accuracy: 0.9798\n",
            "Epoch 882/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7089e-10 - accuracy: 1.0000 - val_loss: 0.3326 - val_accuracy: 0.9798\n",
            "Epoch 883/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9208e-10 - accuracy: 1.0000 - val_loss: 0.3332 - val_accuracy: 0.9797\n",
            "Epoch 884/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3380e-10 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9797\n",
            "Epoch 885/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6029e-10 - accuracy: 1.0000 - val_loss: 0.3352 - val_accuracy: 0.9796\n",
            "Epoch 886/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.0201e-10 - accuracy: 1.0000 - val_loss: 0.3362 - val_accuracy: 0.9794\n",
            "Epoch 887/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1790e-10 - accuracy: 1.0000 - val_loss: 0.3370 - val_accuracy: 0.9795\n",
            "Epoch 888/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3380e-10 - accuracy: 1.0000 - val_loss: 0.3383 - val_accuracy: 0.9797\n",
            "Epoch 889/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1790e-10 - accuracy: 1.0000 - val_loss: 0.3390 - val_accuracy: 0.9796\n",
            "Epoch 890/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.9141e-10 - accuracy: 1.0000 - val_loss: 0.3400 - val_accuracy: 0.9795\n",
            "Epoch 891/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8347e-10 - accuracy: 1.0000 - val_loss: 0.3412 - val_accuracy: 0.9795\n",
            "Epoch 892/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.0996e-10 - accuracy: 1.0000 - val_loss: 0.3422 - val_accuracy: 0.9795\n",
            "Epoch 893/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8876e-10 - accuracy: 1.0000 - val_loss: 0.3424 - val_accuracy: 0.9795\n",
            "Epoch 894/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0996e-10 - accuracy: 1.0000 - val_loss: 0.3438 - val_accuracy: 0.9794\n",
            "Epoch 895/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3910e-10 - accuracy: 1.0000 - val_loss: 0.3441 - val_accuracy: 0.9793\n",
            "Epoch 896/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2585e-10 - accuracy: 1.0000 - val_loss: 0.3444 - val_accuracy: 0.9795\n",
            "Epoch 897/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8347e-10 - accuracy: 1.0000 - val_loss: 0.3454 - val_accuracy: 0.9795\n",
            "Epoch 898/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8347e-10 - accuracy: 1.0000 - val_loss: 0.3458 - val_accuracy: 0.9795\n",
            "Epoch 899/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3578e-10 - accuracy: 1.0000 - val_loss: 0.3466 - val_accuracy: 0.9794\n",
            "Epoch 900/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.3048e-10 - accuracy: 1.0000 - val_loss: 0.3476 - val_accuracy: 0.9795\n",
            "Epoch 901/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5433e-10 - accuracy: 1.0000 - val_loss: 0.3488 - val_accuracy: 0.9795\n",
            "Epoch 902/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8347e-10 - accuracy: 1.0000 - val_loss: 0.3490 - val_accuracy: 0.9795\n",
            "Epoch 903/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5698e-10 - accuracy: 1.0000 - val_loss: 0.3497 - val_accuracy: 0.9793\n",
            "Epoch 904/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.0201e-10 - accuracy: 1.0000 - val_loss: 0.3496 - val_accuracy: 0.9795\n",
            "Epoch 905/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3578e-10 - accuracy: 1.0000 - val_loss: 0.3498 - val_accuracy: 0.9795\n",
            "Epoch 906/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3843e-10 - accuracy: 1.0000 - val_loss: 0.3515 - val_accuracy: 0.9795\n",
            "Epoch 907/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2254e-10 - accuracy: 1.0000 - val_loss: 0.3528 - val_accuracy: 0.9795\n",
            "Epoch 908/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.4638e-10 - accuracy: 1.0000 - val_loss: 0.3522 - val_accuracy: 0.9793\n",
            "Epoch 909/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3843e-10 - accuracy: 1.0000 - val_loss: 0.3533 - val_accuracy: 0.9795\n",
            "Epoch 910/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.0466e-10 - accuracy: 1.0000 - val_loss: 0.3538 - val_accuracy: 0.9795\n",
            "Epoch 911/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.7287e-10 - accuracy: 1.0000 - val_loss: 0.3543 - val_accuracy: 0.9794\n",
            "Epoch 912/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 0.9795\n",
            "Epoch 913/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0134e-10 - accuracy: 1.0000 - val_loss: 0.3544 - val_accuracy: 0.9795\n",
            "Epoch 914/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6492e-10 - accuracy: 1.0000 - val_loss: 0.3555 - val_accuracy: 0.9794\n",
            "Epoch 915/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7287e-10 - accuracy: 1.0000 - val_loss: 0.3562 - val_accuracy: 0.9793\n",
            "Epoch 916/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1526e-10 - accuracy: 1.0000 - val_loss: 0.3568 - val_accuracy: 0.9797\n",
            "Epoch 917/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7817e-10 - accuracy: 1.0000 - val_loss: 0.3567 - val_accuracy: 0.9794\n",
            "Epoch 918/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5698e-10 - accuracy: 1.0000 - val_loss: 0.3576 - val_accuracy: 0.9793\n",
            "Epoch 919/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2784e-10 - accuracy: 1.0000 - val_loss: 0.3589 - val_accuracy: 0.9794\n",
            "Epoch 920/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.7022e-10 - accuracy: 1.0000 - val_loss: 0.3586 - val_accuracy: 0.9794\n",
            "Epoch 921/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3578e-10 - accuracy: 1.0000 - val_loss: 0.3580 - val_accuracy: 0.9793\n",
            "Epoch 922/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.6559e-10 - accuracy: 1.0000 - val_loss: 0.3594 - val_accuracy: 0.9793\n",
            "Epoch 923/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2320e-10 - accuracy: 1.0000 - val_loss: 0.3606 - val_accuracy: 0.9792\n",
            "Epoch 924/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7287e-10 - accuracy: 1.0000 - val_loss: 0.3607 - val_accuracy: 0.9793\n",
            "Epoch 925/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.9141e-10 - accuracy: 1.0000 - val_loss: 0.3603 - val_accuracy: 0.9794\n",
            "Epoch 926/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.9936e-10 - accuracy: 1.0000 - val_loss: 0.3596 - val_accuracy: 0.9794\n",
            "Epoch 927/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1526e-10 - accuracy: 1.0000 - val_loss: 0.3616 - val_accuracy: 0.9793\n",
            "Epoch 928/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7618e-10 - accuracy: 1.0000 - val_loss: 0.3615 - val_accuracy: 0.9792\n",
            "Epoch 929/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6227e-10 - accuracy: 1.0000 - val_loss: 0.3640 - val_accuracy: 0.9794\n",
            "Epoch 930/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1989e-10 - accuracy: 1.0000 - val_loss: 0.3629 - val_accuracy: 0.9793\n",
            "Epoch 931/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8876e-10 - accuracy: 1.0000 - val_loss: 0.3642 - val_accuracy: 0.9793\n",
            "Epoch 932/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.1304 - accuracy: 0.9875 - val_loss: 0.2665 - val_accuracy: 0.9758\n",
            "Epoch 933/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.2506 - val_accuracy: 0.9761\n",
            "Epoch 934/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.2237 - val_accuracy: 0.9791\n",
            "Epoch 935/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4985e-04 - accuracy: 0.9998 - val_loss: 0.2253 - val_accuracy: 0.9791\n",
            "Epoch 936/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9129e-04 - accuracy: 0.9999 - val_loss: 0.2249 - val_accuracy: 0.9789\n",
            "Epoch 937/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9030e-04 - accuracy: 0.9999 - val_loss: 0.2284 - val_accuracy: 0.9787\n",
            "Epoch 938/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2427e-04 - accuracy: 1.0000 - val_loss: 0.2260 - val_accuracy: 0.9785\n",
            "Epoch 939/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4654e-05 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9788\n",
            "Epoch 940/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8694e-06 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9789\n",
            "Epoch 941/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.6429e-06 - accuracy: 1.0000 - val_loss: 0.2255 - val_accuracy: 0.9790\n",
            "Epoch 942/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.8407e-06 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9790\n",
            "Epoch 943/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.2883e-06 - accuracy: 1.0000 - val_loss: 0.2252 - val_accuracy: 0.9790\n",
            "Epoch 944/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8245e-06 - accuracy: 1.0000 - val_loss: 0.2251 - val_accuracy: 0.9791\n",
            "Epoch 945/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4507e-06 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9791\n",
            "Epoch 946/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1312e-06 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9790\n",
            "Epoch 947/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8544e-06 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9790\n",
            "Epoch 948/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6048e-06 - accuracy: 1.0000 - val_loss: 0.2249 - val_accuracy: 0.9791\n",
            "Epoch 949/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3850e-06 - accuracy: 1.0000 - val_loss: 0.2249 - val_accuracy: 0.9790\n",
            "Epoch 950/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1950e-06 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9791\n",
            "Epoch 951/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0212e-06 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9791\n",
            "Epoch 952/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8665e-06 - accuracy: 1.0000 - val_loss: 0.2249 - val_accuracy: 0.9793\n",
            "Epoch 953/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7267e-06 - accuracy: 1.0000 - val_loss: 0.2249 - val_accuracy: 0.9793\n",
            "Epoch 954/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6007e-06 - accuracy: 1.0000 - val_loss: 0.2249 - val_accuracy: 0.9794\n",
            "Epoch 955/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4869e-06 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9795\n",
            "Epoch 956/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3835e-06 - accuracy: 1.0000 - val_loss: 0.2251 - val_accuracy: 0.9795\n",
            "Epoch 957/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2881e-06 - accuracy: 1.0000 - val_loss: 0.2252 - val_accuracy: 0.9794\n",
            "Epoch 958/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1994e-06 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9795\n",
            "Epoch 959/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1202e-06 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.9795\n",
            "Epoch 960/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0417e-06 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9796\n",
            "Epoch 961/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7180e-07 - accuracy: 1.0000 - val_loss: 0.2258 - val_accuracy: 0.9797\n",
            "Epoch 962/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.0674e-07 - accuracy: 1.0000 - val_loss: 0.2260 - val_accuracy: 0.9797\n",
            "Epoch 963/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4705e-07 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9796\n",
            "Epoch 964/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9086e-07 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9797\n",
            "Epoch 965/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4003e-07 - accuracy: 1.0000 - val_loss: 0.2265 - val_accuracy: 0.9797\n",
            "Epoch 966/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.9073e-07 - accuracy: 1.0000 - val_loss: 0.2268 - val_accuracy: 0.9797\n",
            "Epoch 967/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4745e-07 - accuracy: 1.0000 - val_loss: 0.2270 - val_accuracy: 0.9797\n",
            "Epoch 968/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0509e-07 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9798\n",
            "Epoch 969/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.6744e-07 - accuracy: 1.0000 - val_loss: 0.2274 - val_accuracy: 0.9798\n",
            "Epoch 970/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3011e-07 - accuracy: 1.0000 - val_loss: 0.2276 - val_accuracy: 0.9798\n",
            "Epoch 971/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9593e-07 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9797\n",
            "Epoch 972/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6355e-07 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9797\n",
            "Epoch 973/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3297e-07 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9798\n",
            "Epoch 974/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0448e-07 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9798\n",
            "Epoch 975/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7792e-07 - accuracy: 1.0000 - val_loss: 0.2290 - val_accuracy: 0.9798\n",
            "Epoch 976/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5222e-07 - accuracy: 1.0000 - val_loss: 0.2294 - val_accuracy: 0.9797\n",
            "Epoch 977/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2889e-07 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.9798\n",
            "Epoch 978/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0737e-07 - accuracy: 1.0000 - val_loss: 0.2300 - val_accuracy: 0.9797\n",
            "Epoch 979/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8693e-07 - accuracy: 1.0000 - val_loss: 0.2303 - val_accuracy: 0.9798\n",
            "Epoch 980/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6802e-07 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.9798\n",
            "Epoch 981/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5024e-07 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9798\n",
            "Epoch 982/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3330e-07 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.9797\n",
            "Epoch 983/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1819e-07 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.9797\n",
            "Epoch 984/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0340e-07 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9799\n",
            "Epoch 985/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8976e-07 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9798\n",
            "Epoch 986/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7715e-07 - accuracy: 1.0000 - val_loss: 0.2328 - val_accuracy: 0.9798\n",
            "Epoch 987/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6519e-07 - accuracy: 1.0000 - val_loss: 0.2333 - val_accuracy: 0.9799\n",
            "Epoch 988/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5404e-07 - accuracy: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.9798\n",
            "Epoch 989/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4371e-07 - accuracy: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9798\n",
            "Epoch 990/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3406e-07 - accuracy: 1.0000 - val_loss: 0.2343 - val_accuracy: 0.9798\n",
            "Epoch 991/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2444e-07 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9799\n",
            "Epoch 992/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1597e-07 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9799\n",
            "Epoch 993/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0781e-07 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9799\n",
            "Epoch 994/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0046e-07 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9799\n",
            "Epoch 995/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.3494e-08 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9798\n",
            "Epoch 996/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.7126e-08 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9800\n",
            "Epoch 997/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1073e-08 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9801\n",
            "Epoch 998/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5594e-08 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.9801\n",
            "Epoch 999/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.0309e-08 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 0.9801\n",
            "Epoch 1000/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5488e-08 - accuracy: 1.0000 - val_loss: 0.2388 - val_accuracy: 0.9801\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZgU1dX48e9hGBg2AQGVVVAJihsCElwScSGiUVxjFH1dXhNUXNBEI7ihKJJEY9yIUSNxRw0u4acQUYSoryiyiaAsgxsDCMO+DsxMn98ft3qmZ+gZmpmpvr2cz/P0091V1d2nurrr1F3qlqgqxhhjTGX1fAdgjDEmNVmCMMYYE5clCGOMMXFZgjDGGBOXJQhjjDFx1fcdQF1p3bq1du7c2XcYxhiTVmbNmrVGVdvEm5cxCaJz587MnDnTdxjGGJNWROT7quZZFZMxxpi4LEEYY4yJyxKEMcaYuDKmDSKe4uJiCgoKKCoq8h1K6PLy8ujQoQO5ubm+QzHGZIiMThAFBQU0a9aMzp07IyK+wwmNqrJ27VoKCgro0qWL73CMMRkio6uYioqKaNWqVUYnBwARoVWrVllRUjLGJE9GJwgg45NDVLaspzEmeTI+QRhjjKkZSxAh27BhA3/729/2+HWnn346GzZsCCEiY4xJjCWIkFWVIEpKSqp93cSJE2nRokVYYRljzG5ldC+mVDBs2DCWLl1Kjx49yM3NJS8vj5YtW7Jw4UIWL17M2WefzbJlyygqKmLo0KEMHjwYKB86ZMuWLZx22mkcf/zxfPLJJ7Rv355///vfNGrUyPOaGWMyXdYkiBtvhLlz6/Y9e/SAhx+ufpk//vGPzJ8/n7lz5zJt2jR++ctfMn/+/LLuqGPHjmXvvfdm+/btHH300Zx33nm0atWqwnssWbKEcePG8fTTT3PBBRfw+uuvc8kll9TtyhhjTCWhVTGJyFgRWS0i86uYLyLyqIjki8g8EekZM+8yEVkS3C4LK0Yf+vTpU+FchUcffZQjjzySvn37smzZMpYsWbLLa7p06UKPHj0A6NWrF999912ywjXGZLEwSxDPAo8Dz1cx/zSga3D7KfAE8FMR2RsYAfQGFJglIhNUdX1tgtndkX6yNGnSpOzxtGnTeP/995k+fTqNGzemX79+cc9laNiwYdnjnJwctm/fnpRYjTHZLbQEoaofikjnahY5C3heVRX4VERaiEhboB/wnqquAxCR94ABwLiwYq3OmjWwcWPNX79+fTPWr9/M0qWwfDls2wZLl7p5CxdupEGDlqxc2ZilSxcyffqnLF/u5peUwLffuuV37ix/zdq1sHVr+fNYhYUwYkTNY/UhJwdOOQU+/titV7bLzYWrr4bnnoNNm3xHE75+/WDePFi3znckyTNwoNuvfP45FBfXzXt27QqjRtXNe8Xy2QbRHlgW87wgmFbV9F2IyGBgMECnTp3qLLDiYli4EA480O3UIxH3x62JvLxWHHnkcQwYcBgNGzaiVat9iRYA+vQZwIsv/p3+/Q+hc+duHHFEX3buhO3bQRWKitxNlbLXFBe75BGvEFFcDPPjVuilroUL4ZVX3ONDDvEbi2+lpbB4MfzrX25bHnwwZPL5j8uWuXUF919r0MBvPMnw/ffl69y0KXTsWDfvWy+kxoK0bqRW1aeApwB69+6tdfW+GzfCjh3www/uj9qxI+y7b83fb+LEl6uY05CPP54Ud87y5d8Fj1qzZEn5Xv/BB2+u8nNycuCrr2oWoy/t28OKFXDFFTB2rO9o/Nq0CZo3d7+5I4+s+04VqeZXv4Lx46FZM/e7zYYE0b8/vP8+tGvnagHy8nxHVD2f50EsB2LzZ4dgWlXTk27nTndvA6SGp21bd7/33n7jSAWxO8hsGHMxetTbp092JAcoX+eTTkr95AB+E8QE4NKgN1NfYKOqrgTeBX4hIi1FpCXwi2Ba0kQTQ1ROTjI/Pbs0a+buW7b0G0cqiD0QyaYE0by53ziSKVpl2CbuFaBTT2hVTCIyDtfg3FpECnA9k3IBVPXvwETgdCAf2AZcEcxbJyL3Ap8HbzUy2mCdLNGGo+jJzvXTuiIutUUbYi1BVDwQyYYEEd1ZRg8SskH04LN1a79xJCrMXkwX7Wa+AtdWMW8skPQaaVWXHAoL3fNIxN1bgghP9A9jJ4ZXtN9+viMIX7QEkU0JYn3QWb/SubApy3Z9MdauhcrnoOXmZk/9qE+Z3FunJrLhoCSbSxAxp0OlNBusL0a8fucNG9rOK0zR7zasbnrpKhvavaJVuU2b+o3Dh3T5vadJmMkRLxHU9kiupsN9Azz88MNs27atdgGkiXT5wyRLNiSI6Lk8jRv7jcOHdPm9p0mYyRF7VmM0MdS2i6sliOppcPZKuvxhkiWbvo9sqE6LSrffexZtmt2LvURD/frueW1/vLHDfffv35999tmH1157jR07dnDOOedwzz33sHXrVi644AIKCgooLS3lzjvvZNWqVaxYsYITTzyR1q1bM3Xq1NoFkuLS5Q+TLNlQgki3nWVdSLd1zq4E0a/frtMuuACGDIFt2+h02enUqwe59WFnMURKIXLp5TD0cjd4yvnnV3zttGm7/cjY4b4nT57M+PHjmTFjBqrKwIED+fDDDyksLKRdu3a88847AGzcuJHmzZvz0EMPMXXqVFqnS5+4WrB2norSZQdSF7JpXaPS5QAgCzdNfKqgEfdjzc3FjSNL3W7IyZMnM3nyZI466ih69uzJwoULWbJkCYcffjjvvfcet956Kx999BHNs+nMoUA27iSqky47kLqQjds+XdY5u0oQ1RzxF+c2ZtGT0+jUCfL2gfwvXJtE167BAq1bJ1RiqI6qMnz4cK666qpd5s2ePZuJEydyxx13cPLJJ3PXXXfV6rPSTbr8YZIlG76PdKtuqUvpss5pEmb4ov2To5deqKuzqJs1a8bmzZsBOPXUUxk7dixbtmwBYPny5axevZoVK1bQuHFjLrnkEm655RZmz569y2szXbr8YZLFShCZKd2SYnaVIKpRWuruo3/M6Ias7UlyrVq14rjjjuOwww7jtNNOY9CgQRxzzDEANG3alBdffJH8/HxuueUW6tWrR25uLk888QQAgwcPZsCAAbRr1y7jG6mtDaIiSxCZLV3W2RJEIDqsRuUNVxdd8F5+ueJw30OHDq3w/MADD+TUU0/d5XXXX389119/fe0DSAPp8odJlmz4PtLtaLoupNs6p0mY4aucIPbbzyUHO7JNjnT5wySLlSAyW7qss5UgApUTRIcO7maSI13+MMmSTd9HNq1rVLocAGT8plFN7EJz0QSRriWGRNczVWXjTqI66bIDqY10q26pS+myzmkSZs3k5eWxdu3ahHaeVbVBpANVZe3ateSlwyWqqpCuiTks6fg7rKlsWtd0S4oZXcXUoUMHCgoKKIxe4KEaGza4a1EvWpSeO6u8vDw6pGGdWLr9YZLFShCZLV3WOaMTRG5uLl0SvDTXrbfCI49AUVHIQZm40uUPkyzZ8H1kY4JIt3VOkzDDt327XdXMp3T5wyRLNpQgorJpXaPS5feeJmGGzxKEH3bBoPiyaaeZjds+XbZvFm6a+CxB+BEtcqdju08Ysilhplt1S11It3VOkzDDt22bJQif0uUPE7ZogkiXI8y6kI3bPl3WOU3CDJ+VIPxKlz9M2LKpBBGVjaXHdNm+aRJm+CxB+JUuf5hkyYYSRJqf21kr6fJ7T5Mww7d9e3ZePD1VpMsfJmxWgshs1gYRQ0QGiMgiEckXkWFx5u8vIlNEZJ6ITBORDjHz/iQi84Pbr8OME6wE4Vs27SSqk41tENlEQ7hSZZhCSxAikgOMAU4DugMXiUj3Sos9CDyvqkcAI4HRwWt/CfQEegA/BW4Wkb3CihUsQfiWLkdUYcumBGFVTKkvzDD7APmq+o2q7gReAc6qtEx34IPg8dSY+d2BD1W1RFW3AvOAASHGys6dtb84kKm5dPnDhM2qmLJDumzfMMNsDyyLeV4QTIv1BXBu8PgcoJmItAqmDxCRxiLSGjgR6BhirJSU1M3FgcyeSbc62bBlUwkim6VLUvT9t7wZOEFE5gAnAMuBUlWdDEwEPgHGAdOB0sovFpHBIjJTRGYmMiBfdUpKIDe3Vm9hasEShBPdcaTLDqQ2srmKKV22b5h/y+VUPOrvEEwro6orVPVcVT0KuD2YtiG4H6WqPVS1PyDA4sofoKpPqWpvVe3dpk2bWgVrJQg/smmHmIhjj3X32VSCyKZtn24jB4SZID4HuopIFxFpAFwITIhdQERai0g0huHA2GB6TlDVhIgcARwBTA4xVksQJiW8+SbMnAkNG/qOxIQh3RJEaLtEVS0RkeuAd4EcYKyqLhCRkcBMVZ0A9ANGi4gCHwLXBi/PBT4S9y1uAi5R1ZKwYgUoLrYE4UM2VzPE06wZ9OrlO4rksG2f+kLdJarqRFxbQuy0u2IejwfGx3ldEa4nU9JYCcKvdDmiMnXPtn3qsqbBgDVSG2NMRZYgcNejVrUShA/Ro0erbsg+ts1TnyUIXOkBLEH4YDsJk01VTNHOB+myzrZLxDVQgyUIn9LlD2PqTjYeHLzzDjz/PHTq5DuSxNgukfIShLVBGJM86dblsy4cdBCMHOk7isRZFRNWxWSMT9mUINKNJQgsQRhjTDyWILAEYYwP55/v7g880G8cpmqWILBGap8OOMDd27U4ss+QIbB1a/o02GYj2yVijdQ+vfACfPBBeaIw2UPELvOb6qwEgVUx+dSiBZx77u6XM8YknyUILEEYY0w8liCwNghjjInHEgRWgjDGmHgsQWCN1MYYE48lCKwEYYwx8ViCwBKEMcbEYwkCa6Q2xph4LEFgbRDGGBOPJQhCqGLaudNdps4YY9KYJQjqMEGoQmmpu2zU739fPn3jRli/vpZvbowxyWUJgt0kiE8+gX794PTTYcYM2Gcf2G8/NwTlZ5/BxRe7AWVyc6FePXjkEfe6hx+G/v3dgDMtWsBPfwovvwzXX++m/frX8POfwxVXQI8e8OGHrtTx2GMwfjyceCJ8+y3MmQNnngkvvQTz58OFF8KgQbB8uWs8UYUXX4Rhw+Cee9znrljhYli/HrZvr3rFS0thx466/CqNMZlEVTPi1qtXL62pF19UBdVFi+LMbNvWzQTVfv3KH4PqySdXfP6zn6n26VNxWvR22mmqZ5wRfx6oXnSR6owZFae1alXx+YknqjZtWv789793MV5yScXlzjxTtahI9cgjVevXVz3sMNVjjlF9+GG3/PvvqzZoUL78jBk1/u7SXmmp7wiM8QqYqVXsV63fDrtppL7uOrj9dnfU/qc/uSP6GTPgl7+Evn1h0ya3m92+3ZUsAAoKYNw4GDAAliyBgQNd8eS119yH9O0Lkya5Uki3bnDwwdCzp3uP+++HV1+FI4+EESNcieMXv4Bbb3WxiJSPbjd/vit1PPGEW3bOHHjrLTc06pIl7nPy8mDBAtiyBebOdevRq5drJ4l64AH3mfPmweuvw+GHwzHHQIcOoX7vCSkuhvx8+PFHV5Lbk8uPLVjgru9YXAxXXum22ciRbvjYpk3ddz95MkyZ4kqGgwa57danD7Rr577X6DY1JhtVlTnS7VabEsQ//uEOpH/4ocZvkfqKi1VnznT3UaWlqvn5qldfrbpjh+orr1QsiUyZ4i9eVdW1a1V79CiP56WX3PTt26t+zbp1bh1//HHXUtpDD6kOGlRx2pFHqi5dqrpmza7Lf/KJ6scfqz7+uOr8+clZZ1MzY8eq/vOfqtu2qV5zjbsNHKj6wQdu/s6dqk8/7banqYBqShCh7rSBAcAiIB8YFmf+/sAUYB4wDegQM+/PwALga+BRQKr7rNokiL//3X0TK1ZUmlFa6nZG2VINEYmovvOO6rBh7gsZNEj122/dH2vlStV333VVV6qqH33klv3Xv1T/+9/y12/f7pbZscM9T/RzH320fMf85JNuJ5+XpyqieuutLondeKNqYaFqw4ZuuaeeUt2wQbVXL9XcXNX993fTTz/dvX7ECNW77lIdN071vffcziMSUf3uO/e5337rdhyxcaxZ46rc7rvPTXvnnYpJo1s31S1bVDdvVp00SXXBguz5faSihQtVH3us/LeycqXqPvuUb68GDdx2ffbZ8mlNmqguXuz+8Pvt56pkH3jA/ZaykJcEAeQAS4EDgAbAF0D3Ssv8C7gseHwS8ELw+Fjg/4L3yAGmA/2q+7zaJIjHHnPfxOrVlWZ8/72b8cwzNX7vtLRzp9shL16sev/9FXeQbdq4neipp1acXlCg+vbbFadNmODaPS67TPU//6k6Ybzwwq5H7sXFro3nL3+puGxBgeqBB5Yv+8EHqvfc49pwDj7YTdtvv7r7s0ciLr6zzy7/zHnzVDt2LH/eooVLYqruu7nyStVOndy89u3drV491datVY8+2pWMli+vm/iy2fz5LjGA6t57uxJyJOJKmldd5Q5wxo51y44ZU769zjpLddMml+ibN6/421u1yh1ATJ7sfkObNvldxyTwlSCOAd6NeT4cGF5pmQVAx+CxAJtiXjsLaAQ0BmYCh1T3ebVJEH/9q/sm1q2rNGPpUjfjuedq/N5pb/p01/g+dKjqkCGuoX3rVtU33ij/U117rfvy/vQn1d69y6c/9FDFP98f/lD++K23VD/91CWVG29002bPTjyuq692ryksDG/dKyspcQlA1e1AQPX8811yGjbMTf/yS5cMquqM8NvfulIHuA4H33yjOm2aS4Q//li38ZaWuu0XLfWpuh3ok0+69Sgu3jVpP/OM6g03uPudO90R+ldfudg2b67b+PbEpEmqRxzhvrfmzV0J9rXX3OMxY+L8eRP05ZeuBHz77aotW7r1HTKkfHs1aeJKzqruu1q/3i0f+52GqbDQlcrXr3e3aIl3+XLVUaNcjPXrV1/tuhu+EsT5wD9inv8P8HilZV4GhgaPzwUUaBU8fxDYAGwERlXxGYOD5DGzU6dONf6CHnjAfRNlv/9t29yRxBdfaIW6b1NRJBK/emXVKrcTikRcUoj2vFq4sPyPF/2zg+rgwapz5tTs81NNcbFLoJs3ux/WvHnu9zNunKvSiERcUomu+4gRqiNHlj/v109148bqPyMScTvI2bNdu1G8o9z581V/85vy9/397yu2y5x3Xnnvt7/8RbVDB9VXX1V94omKCe3kk8vrYEH10ENVlyxx77V9uzt4WrrUHY2rulL37NmuqieRqrd161z1n6rbEd94o2r//i6RTpjgpr/5ZvnnH3CAK6EVFbnvc+XKhDfNbpWUuPvXX3c9Bvfay31mu3bu80aMKI+jfXtX0lV122PlSve7nz/f7cSLi902+vnP41RN7CaG6IHCTTfteoDx2Wfu93XIIeXTzjijYlXpHkrlBNEOeAOYAzwCFAAtgIOAd4CmwW068LPqPq82JYjRo903sW1bMOHll92Eww5z96++WuP3Nup2FKtWuceffuq+02jf4tjqqGxx331unefOdTu/efNUf/KT8u9i3rzyZZcudd9daWn5Tvh3v6v43R12mNvZ33+/SxixJbXY23ffVdzx/+//Vpx/+eVu53TWWapHHeW6Rj/9tOrEiRWr9dq3r9h5IJpw/vzn8ud9+7qdXXTn+fjjriSi6orszz/v5g0e7JZfu1b1kUd2jXnCBFfaPO00t8NNtsJCl+xXrVK94gq3Mx461JUsGjRw2+W44yrGPG9exQ4fjRu7HfjUqa50OX78rp9TXFyx5LJ8uaseu/FG9/4DB6peeqnbPhs2uJ41M2a45FrLNrCUrWKqtHxToCB4fAtwZ8y8u4A/VPd5tUkQ0f9rWRJ+5hk3IVqP/PrrNX5vU4VIxO3YzjzTfce+e0wlUyQSv/Tzf//n2mpiRavSordvv3U7IFBt1MhV/w0YUHGZFi3KH3/+uevd889/us+cM8ftoFatcs8nTHBJYP368iPoqpSUuAS/bJkrIV5xheoFF7jP+fvfVW+5peL5Nfffv2t126RJ5Y9jzytSdSWTJ590O+R581K759isWa6n1Nat5ec39eqlZUf5Tz5Zvm6jR7vXdOlSPu2GG8p37J9/Xj69WzfVY4/dfSmyDvlKEPWBb4AuMY3Uh1ZapjVQL3g8ChgZPP418H7wHrm4nk5nVvd5tUkQ0RJ+WQ/QBx90E449VvW221ydsal7kUh5A9D06b6j8a+kxCWAjRvL2zpid6jg6p0r+/RTlyzatnU7rvHjXa+wSZOSGn6ZZ591vdumTlW9+GLXLlW/vovp9NPL1yU31903aeInzmT7/vuKCTQ3123ztWvd8+OP91Jt6iVBuM/ldGBx0Jvp9mDaSGBg8Ph8YEmwzD+AhsH0HOBJXBfXr4CHdvdZtUkQ99zjvomyktodd7gJgwbV+D1NAnbsKP+zfPGF72j8i56Lcfnlqs2auSNR1fI67S1bqj7Kr0UddFLt3OnaDk45pWLpIlvE9oaD8vYGj9uvugSx2zOpReRM4B1V3ePhSVV1IjCx0rS7Yh6PB8bHeV0pcNWefl5NRQdeLTtJNzqw3rZtUFjoxlKyscDD1bix7wj8i/4A//1v2LzZnd0N5b+96kaTTJffZ24utG0L770Hl14KL7zgRgTIFrfdBjfd5MZB++or2HdfNz1Ft18ig/X9GlgiIn8WkYPDDsiHSMT9N8sSxNlnQ6dO0KqV+5N+/LHX+DLerbdCly6+o/Av+gOMHqB06uQvlmSoXx86doRDD/UdSfIcfTR07+6Gsrn2Wt/R7NZuE4SqXgIchasmelZEpovIYBFpFnp0SRJNEGVOOQW+/96NzQN2qbmw7bUX5OT4jsK/ejF/x5NOqvg8E7VqBcuWwbvv+o4keb78Etq0gbvv9h1JQhL6BarqJlxV0CtAW+AcYLaIXB9ibEmjGvwXd+501Ur5+fDdd7Bhg1vAEkS4br/dDSaY7WKPUn71K39xJMs117j7Vav8xpFMTzzh7hs29BtHghJpgxgIXIE7N+F5oI+qrhaRxrgG5MfCDTF8kUiQIPr0gS++gEMOga+/Ll/AEkQ4cnLgiCPcKLJFRW6E1WyWl+euJ3L88W4030yXzdf6zcvzHUFCEtnznQf8VVU/jJ2oqttE5MpwwkquSARypcQlBygvOURZgghHTg789rduSHMDDRrADTf4jiJ5Ro5099n0/3K9NNMmQSRSxXQ3MCP6REQaiUhnAFWdEkpUSRaJwEvFF5RPqHx50HbtkhtQtlCFmTN9R5E6IhEYO9ZdR+SHH3xHE77Vq919NiaITKliwo24emzM89Jg2tGhRORBJAJnRd4sn1BUVHGBaFc0U7dKS+G553xHkTqKityFjSA7LgXbqJG7b9HCbxzJFF3Xnj39xpGgREoQ9VW17PJjweMG4YWUfKowu14v9+TKOLVmW7cmNyCTnWIbqffay18cyXLYYa6a8cQTfUeSPEOGwEcfue6uaSCRBFEYNFQDICJnAWvCCyn5IhEokuBErWeecfexpYZsOpHHh3vvhdatfUfhX2yCaJYxvcirVr++K0VGq12yQadOrhNCmnTrTiRBXA3cJiI/iMgy4FaSeJZzMkQisDAn5mSd+vXhN79xj7PtRB7jT+x5D9nQs2f7dnc/a5bfOEyVEjlRbqmq9gW64y7ac6yq5ocfWvJEIrA8J+asVVW44w7XUPjDD9b9Mmx33mnnQUDFEkSFMzcz1KmnuvtoojApJ6HuAyLyS+BQIE+CH66qjgwxrqRShR31YrqdibhuaB07+gsqG9SrB337wqefupMUs11OjuvF1LNndvTsiZ4HkQ3rmqZ2W4IQkb/jxmO6HndZ0F8B+4ccV1JFInDztph891jan/uXHurVg4su8h1F6qhXD664IjtOkgP429/c/bZtfuMwVUqkDeJYVb0UWK+q9+AuBPSTcMNKrkgEGuoO6BX0ZNq82W9A2UIVpk71HUXqUIXrrkubLpC1ZtWKKS+Rsl30pIBtItIOWIsbjyljREqVBuxwJyjt3OnGYjLhi0Tgrbd8R5FaxozxHUHyRHuu2VDvKSuRBPH/RKQF8AAwG1Dg6VCjSrJ6kRJyiLh2h+eec13vjEm2bGiYjnXSSfDaa9C5s+9ITBWqTRAiUg+YoqobgNdF5G0gT1U3JiW6JMkpDgpJeXlw1FF+g8lG99wDe+/tOwqTbNHG6WhjtUk51bZBBFeRGxPzfEemJQeAYnIZ1eIBOOEE36Fkl2w7YjYVRccjsl5MKSuRRuopInKeSOb+m3dIHs+0vDltTn/POCNGWINlNrr4YtchpG1GNWlmlEQSxFW4wfl2iMgmEdksIptCjiup6hXvoEvxYttJJZuIu3ofQHGx31hSxfjx7qpj2UDETkJNcYmcSd1MVeupagNV3St4nlEjie2zKZ8pBd1g4kTfoWQXETjjDN9RpJbzznOD2BmTAhK5otzP402vfAGhdJZTEgytnCYX8cgYqjBhgu8oUsv557sLVy1Z4jsSYxLq5npLzOM8oA8wCzgplIg8qF8S9GJKk4t4ZJQPPvAdQWp5/XXfERhTZrcJQlXPjH0uIh2Bh0OLyAMrQaSAzO0DYUzaSqSRurIC4JBEFhSRASKySETyRWRYnPn7i8gUEZknItNEpEMw/UQRmRtzKxKRs2sQa0JyS60E4dXdd2fXVcWMSROJtEE8hjt7GlxC6YE7o3p3r8vBnUPRH5dUPheRCar6VcxiDwLPq+pzInISMBr4H1WdGnwOIrI3kA9MTnit9tAPTbtzb7snuPOAA8L6CGOMSTuJlCBm4tocZgHTgVtV9ZIEXtcHyFfVb4LLlL4CnFVpme5AtBJ6apz5AOcDk1Q1tCEfV+Xtz+ttroZ99gnrI0x17r7bLutqTApKJEGMB15U1edU9SXgUxFJZHSt9sCymOcFwbRYXwDnBo/PAZqJSKtKy1wIjIv3ASIyWERmisjMwsLCBEKKr9n21RyyfbZdk8CHs4JjAhtuwXn/fVi40HcUxgAJnkkNNIp53gh4v44+/2bgBBGZA5wALAfKRsoTkbbA4cC78V6sqk+pam9V7d2mTZsaB9F35ZuMW9wL1mTUpbZTn4gNb1LZySdDt26+ozAGSKyba56qlp1irKpbEixBLF5Ub9UAABIQSURBVAdiL8nWIZhWRlVXEJQgRKQpcF4wMGDUBcCbqhrqabZl3VytF1PyvfSS7whSy7HHwjffwI8/+o7EmIRKEFtFpOwKJiLSC0jkIrKfA11FpIuINMBVFVU4K0pEWgcjxgIMB8ZWeo+LqKJ6qS7VLw26uVovpuSzC9ZXNH06rFrlOwpjgMRKEDcC/xKRFbhLju6HuwRptVS1RESuw1UP5QBjVXWBiIwEZqrqBKAfMFpEFPgQuDb6ehHpjCuB/HdPVqgmckuDfGclCH/q1aTHtTEmTImcKPe5iBwMRCtGFyVa5aOqE4GJlabdFfN4PK4RPN5rv2PXRu1QNCzZyg7Jo2FOTjI+zlR2113QrJnvKIwxlez2sE1ErgWaqOp8VZ0PNBWRIeGHljwf7DuIUV2f9R2GMcaklETK9b+NbThW1fXAb8MLKfmWNOnBtH13W2tmwjJypJ0HYUwKSiRB5MReLCg4Q7pBeCEl3wGb5tJt625PDjdhGDTI3UcifuNIFZ99Bvn5vqMwBkiskfo/wKsi8mTw/CpgUnghJd9vvrmNFiWFuI5XJql69oSXX/YdRero08d3BMaUSSRB3AoMBq4Ons/D9WTKGHmlWynKaeI7jOz01FO+I0gtnTtDYaFVuZmUkMgV5SLAZ8B3uPGVTgK+Djes5MqN7KCknp0D4cXixb4jSC3ffw/bQht2zJg9UmUJQkR+gjtR7SJgDfAqgKqemJzQkkc0gor1w/fKzoMwJuVUV8W0EPgIOENV8wFE5KakRJV0agnCl3r14LbboIlV8RmTaqpLEOfihseYKiL/wQ3XnZGX/Xqk00M03Ksh1jxojDHlqjxsVtW3VPVC4GDctRpuBPYRkSdE5BfJCjAZ5jb7GYtbWHrwIhKB++6zRlljUlAijdRbVfXl4NrUHYA5uJ5NGaPnpml02zjDdxjZafBgd69a/XLZ4uuv4YcffEdhDJBYN9cywVnUTwW3jPG774dSuO4A4E3foWSfgw7yHUFqOfhg3xEYU8ZaZgEhgkpGNq+kvr/8xd3b9+80aGDfhUkZliAAQVH7Kvywax9UVBzqtbGM2SO2VyR6HoQdtXll50EYk3L2qA0iU4mdB+FPTg4MGwaNGu1+WWNMUlmCAEZ0fp7GbZrwc9+BGGNMCrHDZuCrJkdTsFd332Fkp9JSGDUKtidymXNjTDJZggB+vv7fHLzuE99hZKcbb3T3dh6Es2yZNdyblGFVTMDvCm5iyY7jgGN9h5J92rb1HUFq6dDBdwTGlLESBK6ROmKN1H6MHOk7gtQiYudBmJRhe0WgnkbI0HEIU5+NwWRMyrIEAdhw3ykgJ8d3BMaYSqwNAqhHBLUShB+5uXDzzdDQruhnTKqxBAFcd8Akmnfci/6+AzHGmBQSar2KiAwQkUUiki8iw+LM319EpojIPBGZJiIdYuZ1EpHJIvK1iHwlIp3DinNJ3uEUNt4/rLc31SkuhtGjoajIdyTGmEpCSxAikgOMAU4DugMXiUjls9EeBJ5X1SOAkcDomHnPAw+o6iFAH2B1WLGeue45Dl33UVhvb6pz++2+I0gt69bBxo2+ozAGCLcE0QfIV9VvVHUn7pKlZ1VapjvwQfB4anR+kEjqq+p7AKq6RVW3hRXoTStv4WcF48J6e1Odpk19R5BaWraEvfbyHYUxQLgJoj2wLOZ5QTAt1he4a18DnAM0E5FWwE+ADSLyhojMEZEHghJJBSIyWERmisjMwsLCGgcqao3U3gwf7juC1GLnQZgU4rtv583ACSIyBzgBWA6U4hrPfxbMPxo4ALi88otV9SlV7a2qvdu0aVPjIAS1P6UxxlQSZoJYDnSMed4hmFZGVVeo6rmqehRwezBtA660MTeonioB3gJ6hhWonUmdAux6EMaknDC7uX4OdBWRLrjEcCEwKHYBEWkNrFPVCDAcGBvz2hYi0kZVC4GTgJlhBSoasRKELw0bugH7GjTwHUlq+NvfoHFj31EYA4SYIFS1RESuA94FcoCxqrpAREYCM1V1AtAPGC0iCnwIXBu8tlREbgamiIgAs4Cnw4r1woNmse9BzTgjrA8wJlHXXOM7AmPKiGbIMMu9e/fWmTNrVsg4/HDo2hXeeKOOgzK7Fy25FRXZ2dTGeCAis1S1d7x5VvELXLLmYQ5d81/fYWSnUaPcvVXxGZNyLEEAN6y6jV4/vuM7DGOMSSmWIHCD9dkRrCd2JrUxKcsSBNbN1Rhj4rG9ItFurvZVeGXnQRiTcmy4b+x6EF7l5cENN0B9+ykak2rsXwmc2HU5+3drwnm+AzHGmBRi5XpgTf392NGgme8wslNREfz5z7Bzp+9IjDGVWIJQ5brVd9F99TTfkWSn++5z99aLzJiUYwlClSFr76X7mg99R2KMMSnFEkQkAoBaLyY/7rjDdwTGmCrYXrEsQVgVhzHGxLIEEQxWqPZV+GXnQRiTcqybq5Ug/GrcGIYMgZxdrihrjPHMEkReHj0O2sJh3XIrXs3IJMeOHbB5syvJWZI2JqVYuV6EbdKE0hy7opkXpaXw5JNlJTljTOqwBLFjB8MLb7LzIHwZOdJ3BMaYKliC2LGDKzY8TJf1s31HYowxKcUSRFC1EbGvwo+77vIdgTGmCrZXjNZ9WwOpMcZUYAkieh6EnUntlyVoY1KOdXO1EoRfTZvC4MF2opwxKcgSRJs2HHiAckw3uMx3LNloyxZYscLOgzAmBdlhW8D2TR698orvCIwxcYSaIERkgIgsEpF8ERkWZ/7+IjJFROaJyDQR6RAzr1RE5ga3CWHGaTy6+27fERhjqhBaFZOI5ABjgP5AAfC5iExQ1a9iFnsQeF5VnxORk4DRwP8E87arao+w4osVtFMbY4yJEWYJog+Qr6rfqOpO4BXgrErLdAc+CB5PjTM/aayKyRMrQRiTssJMEO2BZTHPC4Jpsb4Azg0enwM0E5FWwfM8EZkpIp+KyNnxPkBEBgfLzCwsLKxxoFaCMMaYXflupL4ZOEFE5gAnAMuB0mDe/qraGxgEPCwiB1Z+sao+paq9VbV3mzZtahWIlSCMMaaiMLu5Lgc6xjzvEEwro6orCEoQItIUOE9VNwTzlgf334jINOAoYGmI8RofmjWDK6+0DG1MCgqzBPE50FVEuohIA+BCoEJvJBFpLVJ2CvNwYGwwvaWINIwuAxwHxDZu1ymrYvJo82ZYtMg2gjEpKLQEoaolwHXAu8DXwGuqukBERorIwGCxfsAiEVkM7AuMCqYfAswUkS9wjdd/rNT7qc7ZAaxHkybZBjAmBYV6JrWqTgQmVpp2V8zj8cD4OK/7BDg8zNgqfl6yPsnsYsQIuOce31EYY+Lw3UidMuwA1hPLzsakLEsQ2D7KK7uinDEpyxJEwEoQxhhTkSUI419enu8IjDFx2HDfWBWTV82bw+WX+47CGBOHlSACVsXkycaNMGuW7yiMMXFYgsBKEN59/LHvCIwxcViCCFgJwpM777Qv35gUZQkCK0EYY0w81kgdsINYT+6913cExpgqWAnCGGNMXJYgsCom71q39h2BMSYOSxABq2LypGVLuOgi31EYY+KwBIGVILxavx6mTfMdhTEmDksQAStBePTll74jMMbEYQnC+HX77ZCT4zsKY0wcliCwKiZjjInHzoMIWBWTJ6NG7X4ZY4wXVoLAShDGGBOPJYiAlSA82n9/3xEYY+KwBIGVILxq1QrOOMN3FMaYOCxBBKwE4cnatfD2276jMMbEYQnC+Pf9974jMMbEYQkCq2LyavhwyM31HYUxJg5LEAGrYjLGmIpCTRAiMkBEFolIvogMizN/fxGZIiLzRGSaiHSoNH8vESkQkcfDjNNKEB6NHg3Fxb6jMMbEEVqCEJEcYAxwGtAduEhEulda7EHgeVU9AhgJjK40/17gw7BijGUlCGOMqSjMEkQfIF9Vv1HVncArwFmVlukOfBA8nho7X0R6AfsCk0OM0aSCQw/1HYExJo4wh9poDyyLeV4A/LTSMl8A5wKPAOcAzUSkFbAe+AtwCXBKVR8gIoOBwcHTLSKyqKbBjhlD6zFjWFPT16ep1pAC67xgQTKLcKmxzsmTbesLts57qsozVX2PxXQz8LiIXI6rSloOlAJDgImqWiDV7DhU9SngqboIRERmqmrvunivdGHrnPmybX3B1rkuhZkglgMdY553CKaVUdUVuBIEItIUOE9VN4jIMcDPRGQI0BRoICJbVHWXhm5jjDHhCDNBfA50FZEuuMRwITAodgERaQ2sU9UIMBwYC6CqF8cscznQ25KDMcYkV2iN1KpaAlwHvAt8DbymqgtEZKSIDAwW6wcsEpHFuAZpn2M/10lVVZqxdc582ba+YOtcZ0TtJABjjDFx2JnUxhhj4rIEYYwxJq6sTxC7Gw4kXYlIRxGZKiJficgCERkaTN9bRN4TkSXBfctguojIo8H3ME9Eevpdg5oTkRwRmSMibwfPu4jIZ8G6vSoiDYLpDYPn+cH8zj7jrikRaSEi40VkoYh8LSLHZPp2FpGbgt/1fBEZJyJ5mbadRWSsiKwWkfkx0/Z4u4rIZcHyS0Tksj2JIasTRILDgaSrEuD3qtod6AtcG6zbMGCKqnYFpgTPwX0HXYPbYOCJ5IdcZ4biOkZE/Qn4q6oehDsJ88pg+pXA+mD6X4Pl0tEjwH9U9WDgSNy6Z+x2FpH2wA243o2HATm4XpKZtp2fBQZUmrZH21VE9gZG4E5S7gOMiCaVhKhq1t6AY4B3Y54PB4b7jiukdf030B9YBLQNprUFFgWPnwQuilm+bLl0uuHOt5kCnAS8DQjuDNP6lbc5rofdMcHj+sFy4nsd9nB9mwPfVo47k7cz5aM07B1st7eBUzNxOwOdgfk13a7ARcCTMdMrLLe7W1aXIIg/HEh7T7GEJihSHwV8BuyrqiuDWT/iuhdD5nwXDwN/ACLB81bABnXdrqHiepWtczB/Y7B8OukCFAL/DKrV/iEiTcjg7ayqy3EDff4ArMRtt1lk9naO2tPtWqvtne0JIuMFZ6i/Dtyoqpti56k7pMiYfs4icgawWlVn+Y4lieoDPYEnVPUoYCvl1Q5ARm7nlriBPbsA7YAm7FoVk/GSsV2zPUHsdjiQdCYiubjk8JKqvhFMXiUibYP5bYHVwfRM+C6OAwaKyHe40YNPwtXPtxCR6KgBsetVts7B/ObA2mQGXAcKgAJV/Sx4Ph6XMDJ5O58CfKuqhapaDLyB2/aZvJ2j9nS71mp7Z3uCKBsOJOjxcCEwwXNMdUJEBHgG+FpVH4qZNQGI9mS4DNc2EZ1+adAboi+wMaYomxZUdbiqdlDVzrht+YG6YVumAucHi1Ve5+h3cX6wfFodaavqj8AyEekWTDoZ+IoM3s64qqW+ItI4+J1H1zljt3OMPd2u7wK/EJGWQcnrF8G0xPhuhPF9A04HFgNLgdt9x1OH63U8rvg5D5gb3E7H1b1OAZYA7wN7B8sLrkfXUuBLXA8R7+tRi/XvB7wdPD4AmAHkA/8CGgbT84Ln+cH8A3zHXcN17QHMDLb1W0DLTN/OwD3AQmA+8ALQMNO2MzAO18ZSjCspXlmT7Qr8b7Du+cAVexKDDbVhjDEmrmyvYjLGGFMFSxDGGGPisgRhjDEmLksQxhhj4rIEYYwxJi5LEMbsAREpFZG5Mbc6GwFYRDrHjtxpjG9hXpPamEy0XVV7+A7CmGSwEoQxdUBEvhORP4vIlyIyQ0QOCqZ3FpEPgjH6p4hIp2D6viLypoh8EdyODd4qR0SeDq51MFlEGnlbKZP1LEEYs2caVapi+nXMvI2qejjwOG5UWYDHgOdU9QjgJeDRYPqjwH9V9Ujc2EkLguldgTGqeiiwATgv5PUxpkp2JrUxe0BEtqhq0zjTvwNOUtVvgkESf1TVViKyBjd+f3EwfaWqthaRQqCDqu6IeY/OwHvqLgaDiNwK5KrqfeGvmTG7shKEMXVHq3i8J3bEPC7F2gmNR5YgjKk7v465nx48/gQ3sizAxcBHweMpwDVQdg3t5skK0phE2dGJMXumkYjMjXn+H1WNdnVtKSLzcKWAi4Jp1+Ou9nYL7spvVwTThwJPiciVuJLCNbiRO41JGdYGYUwdCNogeqvqGt+xGFNXrIrJGGNMXFaCMMYYE5eVIIwxxsRlCcIYY0xcliCMMcbEZQnCGGNMXJYgjDHGxPX/AXlZd5yxDwzQAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0597 - accuracy: 0.9950\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2010 - accuracy: 0.9818\n",
            "train accuracy :  0.9950166940689087 train loss :  0.05969356372952461\n",
            "test accuracy :  0.9818000197410583  test loss :  0.20098258554935455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFDjWj30V1HW",
        "outputId": "41c99c1f-8d48-4329-835b-6daef66830f2"
      },
      "source": [
        "#정리\n",
        "print(\"=========== [은닉층 1개] ===========\")\n",
        "print(\"=========== epochs = 12 ===========\")\n",
        "print(\"train accuracy : \", sc_train1_1[1], \"train loss : \", sc_train1_1[0])\n",
        "print(\"test accuracy : \", sc_test1_1[1], \" test loss : \", sc_test1_1[0])\n",
        "print(\"/n\")\n",
        "\n",
        "print(\"=========== epochs = 120 ===========\")\n",
        "print(\"train accuracy : \", sc_train1_2[1], \"train loss : \", sc_train1_2[0])\n",
        "print(\"test accuracy : \", sc_test1_2[1], \" test loss : \", sc_test1_2[0])\n",
        "print(\"/n\")\n",
        "\n",
        "print(\"=========== epochs = 500 ===========\")\n",
        "print(\"train accuracy : \", sc_train1_3[1], \"train loss : \", sc_train1_3[0])\n",
        "print(\"test accuracy : \", sc_test1_3[1], \" test loss : \", sc_test1_3[0])\n",
        "print(\"/n\")\n",
        "\n",
        "print(\"=========== epochs = 1000 ===========\")\n",
        "print(\"train accuracy : \", sc_train1_4[1], \"train loss : \", sc_train1_4[0])\n",
        "print(\"test accuracy : \", sc_test1_4[1], \" test loss : \", sc_test1_4[0])\n",
        "print(\"/n\")\n",
        "\n",
        "print(\"=========== [은닉층 2개 & 뉴런의 수 512/512] ===========\")\n",
        "print(\"=========== epochs = 12 ===========\")\n",
        "print(\"train accuracy : \", sc_train2_1[1], \"train loss : \", sc_train2_1[0])\n",
        "print(\"test accuracy : \", sc_test2_1[1], \" test loss : \", sc_test2_1[0])\n",
        "print(\"/n\")\n",
        "\n",
        "print(\"=========== epochs = 120 ===========\")\n",
        "print(\"train accuracy : \", sc_train2_1_2[1], \"train loss : \", sc_train2_1_2[0])\n",
        "print(\"test accuracy : \", sc_test2_1_2[1], \" test loss : \", sc_test2_1_2[0])\n",
        "print(\"/n\")\n",
        "\n",
        "print(\"=========== epochs = 500 ===========\")\n",
        "print(\"train accuracy : \", sc_train2_1_3[1], \"train loss : \", sc_train2_1_3[0])\n",
        "print(\"test accuracy : \", sc_test2_1_3[1], \" test loss : \", sc_test2_1_3[0])\n",
        "print(\"/n\")\n",
        "\n",
        "print(\"=========== epochs = 1000 ===========\")\n",
        "print(\"train accuracy : \", sc_train2_1_4[1], \"train loss : \", sc_train2_1_4[0])\n",
        "print(\"test accuracy : \", sc_test2_1_4[1], \" test loss : \", sc_test2_1_4[0])\n",
        "\n",
        "print(\"=========== [은닉층 2개 & 뉴런의 수 512/256] ===========\")\n",
        "print(\"=========== epochs = 12 ===========\")\n",
        "print(\"train accuracy : \", sc_train2_2[1], \"train loss : \", sc_train2_2[0])\n",
        "print(\"test accuracy : \", sc_test2_2[1], \" test loss : \", sc_test2_2[0])\n",
        "print(\"/n\")\n",
        "\n",
        "print(\"=========== epochs = 120 ===========\")\n",
        "print(\"train accuracy : \", sc_train2_2_2[1], \"train loss : \", sc_train2_2_2[0])\n",
        "print(\"test accuracy : \", sc_test2_2_2[1], \" test loss : \", sc_test2_2_2[0])\n",
        "print(\"/n\")\n",
        "\n",
        "print(\"=========== epochs = 500 ===========\")\n",
        "print(\"train accuracy : \", sc_train2_2_3[1], \"train loss : \", sc_train2_2_3[0])\n",
        "print(\"test accuracy : \", sc_test2_2_3[1], \" test loss : \", sc_test2_2_3[0])\n",
        "print(\"/n\")\n",
        "\n",
        "print(\"=========== epochs = 1000 ===========\")\n",
        "print(\"train accuracy : \", sc_train2_2_4[1], \"train loss : \", sc_train2_2_4[0])\n",
        "print(\"test accuracy : \", sc_test2_2_4[1], \" test loss : \", sc_test2_2_4[0])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========== [은닉층 1개] ===========\n",
            "=========== epochs = 12 ===========\n",
            "train accuracy :  0.9937999844551086 train loss :  0.02729642763733864\n",
            "test accuracy :  0.9811999797821045  test loss :  0.06480918824672699\n",
            "/n\n",
            "=========== epochs = 120 ===========\n",
            "train accuracy :  0.9949333071708679 train loss :  0.0372379831969738\n",
            "test accuracy :  0.9807000160217285  test loss :  0.11860010027885437\n",
            "/n\n",
            "=========== epochs = 500 ===========\n",
            "train accuracy :  0.994866669178009 train loss :  0.05115368217229843\n",
            "test accuracy :  0.9815999865531921  test loss :  0.15946437418460846\n",
            "/n\n",
            "=========== epochs = 1000 ===========\n",
            "train accuracy :  0.9947333335876465 train loss :  0.06144125014543533\n",
            "test accuracy :  0.9814000129699707  test loss :  0.19138523936271667\n",
            "/n\n",
            "=========== [은닉층 2개 & 뉴런의 수 512/512] ===========\n",
            "=========== epochs = 12 ===========\n",
            "train accuracy :  0.9912999868392944 train loss :  0.034651078283786774\n",
            "test accuracy :  0.9800999760627747  test loss :  0.08432424813508987\n",
            "/n\n",
            "=========== epochs = 120 ===========\n",
            "train accuracy :  0.9954833388328552 train loss :  0.04640447348356247\n",
            "test accuracy :  0.9842000007629395  test loss :  0.14507167041301727\n",
            "/n\n",
            "=========== epochs = 500 ===========\n",
            "train accuracy :  0.995199978351593 train loss :  0.057611025869846344\n",
            "test accuracy :  0.9835000038146973  test loss :  0.187482550740242\n",
            "/n\n",
            "=========== epochs = 1000 ===========\n",
            "train accuracy :  0.9952499866485596 train loss :  0.08460886776447296\n",
            "test accuracy :  0.982200026512146  test loss :  0.2703184485435486\n",
            "=========== [은닉층 2개 & 뉴런의 수 512/256] ===========\n",
            "=========== epochs = 12 ===========\n",
            "train accuracy :  0.9915000200271606 train loss :  0.03434007987380028\n",
            "test accuracy :  0.9753999710083008  test loss :  0.09303631633520126\n",
            "/n\n",
            "=========== epochs = 120 ===========\n",
            "train accuracy :  0.9956333041191101 train loss :  0.047478754073381424\n",
            "test accuracy :  0.9840999841690063  test loss :  0.13929954171180725\n",
            "/n\n",
            "=========== epochs = 500 ===========\n",
            "train accuracy :  0.9949166774749756 train loss :  0.06766366213560104\n",
            "test accuracy :  0.9825000166893005  test loss :  0.19414091110229492\n",
            "/n\n",
            "=========== epochs = 1000 ===========\n",
            "train accuracy :  0.9950166940689087 train loss :  0.05969356372952461\n",
            "test accuracy :  0.9818000197410583  test loss :  0.20098258554935455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjBbLF6UY65m"
      },
      "source": [
        "epochs를 늘렸을 때 시험 데이저의 정확도는 늘어나지만 98.3% 이상을 넘기지 못하는 결과를 보여주고 있다.\n",
        "\n",
        "가장 좋은 정확도를 보여주고 있는 모델은 은닉층이 2개(512/512) 이고 epochs = 120일때 test accuracy는  98.42%이고, train accuracy는 99.55%으로 나타났다,\n",
        "\n",
        "은닉층2개인 모델에서 정확도를 빠르게 올리기 위해 \n",
        "초기값을 히 초깃값으로 하여 epochs를 12, 120, 500, 1000으로 학습해 보았다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf3q8f4Eb2IN"
      },
      "source": [
        "# 은닉층 2개(512/512) &  히 초깃값 (epochs = 12 / 120 / 500 / 1000)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AporfAd2OvOB"
      },
      "source": [
        "# Usage in a Keras layer:\n",
        "initializer = tf.keras.initializers.HeNormal()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        },
        "id": "QuoQu8ccXphD",
        "outputId": "11fd7a7a-4a75-43b5-e0fb-183459c9cb1f"
      },
      "source": [
        "#신경망 학습3\n",
        "model3_1 = models.Sequential([\n",
        "                            Flatten(input_shape = (28, 28)),\n",
        "                            Dense(512, activation= 'relu', kernel_initializer=initializer),\n",
        "                            Dense(512, activation= 'relu', kernel_initializer=initializer),\n",
        "                            Dense(10, activation= 'softmax', kernel_initializer=initializer)\n",
        "                            ])\n",
        "\n",
        "model3_1.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "hist3_1 = model3_1.fit(train_x, train_y, epochs = 12, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "#학습 그래프3\n",
        "plt.plot(hist3_1.history['accuracy'], 'b-')\n",
        "plt.plot(hist3_1.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train3_1 = model3_1.evaluate(train_x, train_y)\n",
        "sc_test3_1 = model3_1.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train3_1[1], \"train loss : \", sc_train3_1[0])\n",
        "print(\"test accuracy : \", sc_test3_1[1], \" test loss : \", sc_test3_1[0])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "176/176 [==============================] - 2s 7ms/step - loss: 0.2900 - accuracy: 0.9167 - val_loss: 0.1483 - val_accuracy: 0.9556\n",
            "Epoch 2/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0977 - accuracy: 0.9714 - val_loss: 0.1199 - val_accuracy: 0.9632\n",
            "Epoch 3/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0598 - accuracy: 0.9822 - val_loss: 0.0940 - val_accuracy: 0.9721\n",
            "Epoch 4/12\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0401 - accuracy: 0.9880 - val_loss: 0.0918 - val_accuracy: 0.9716\n",
            "Epoch 5/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0262 - accuracy: 0.9916 - val_loss: 0.0846 - val_accuracy: 0.9755\n",
            "Epoch 6/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 0.0975 - val_accuracy: 0.9737\n",
            "Epoch 7/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.0992 - val_accuracy: 0.9745\n",
            "Epoch 8/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0979 - val_accuracy: 0.9752\n",
            "Epoch 9/12\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.1009 - val_accuracy: 0.9756\n",
            "Epoch 10/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.0951 - val_accuracy: 0.9778\n",
            "Epoch 11/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0976 - val_accuracy: 0.9779\n",
            "Epoch 12/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.1314 - val_accuracy: 0.9714\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0469 - accuracy: 0.9880\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1022 - accuracy: 0.9730\n",
            "train accuracy :  0.9879666566848755 train loss :  0.04692676663398743\n",
            "test accuracy :  0.9729999899864197  test loss :  0.10215163230895996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dWliyvAcAAS3",
        "outputId": "173dc905-5bce-4170-bc09-151079c0065c"
      },
      "source": [
        "#은닉층 1개 & epochs = 120\n",
        "model3_2 = models.Sequential([\n",
        "                            Flatten(input_shape = (28, 28)),\n",
        "                            Dense(512, activation= 'relu', kernel_initializer=initializer),\n",
        "                            Dense(512, activation= 'relu', kernel_initializer=initializer),\n",
        "                            Dense(10, activation= 'softmax', kernel_initializer=initializer)\n",
        "                            ])\n",
        "\n",
        "model3_2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "#신경망 학습2\n",
        "hist3_2 = model3_2.fit(train_x, train_y, epochs = 120, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "plt.plot(hist3_2.history['accuracy'], 'b-')\n",
        "plt.plot(hist3_2.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train3_2 = model3_2.evaluate(train_x, train_y)\n",
        "sc_test3_2 = model3_2.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train3_2[1], \"train loss : \", sc_train3_2[0])\n",
        "print(\"test accuracy : \", sc_test3_2[1], \" test loss : \", sc_test3_2[0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "176/176 [==============================] - 2s 7ms/step - loss: 0.2897 - accuracy: 0.9154 - val_loss: 0.1414 - val_accuracy: 0.9599\n",
            "Epoch 2/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.1012 - accuracy: 0.9706 - val_loss: 0.1025 - val_accuracy: 0.9696\n",
            "Epoch 3/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0624 - accuracy: 0.9817 - val_loss: 0.0888 - val_accuracy: 0.9743\n",
            "Epoch 4/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0414 - accuracy: 0.9878 - val_loss: 0.0902 - val_accuracy: 0.9741\n",
            "Epoch 5/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0286 - accuracy: 0.9912 - val_loss: 0.0890 - val_accuracy: 0.9753\n",
            "Epoch 6/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0194 - accuracy: 0.9945 - val_loss: 0.0893 - val_accuracy: 0.9762\n",
            "Epoch 7/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.0891 - val_accuracy: 0.9769\n",
            "Epoch 8/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.0997 - val_accuracy: 0.9761\n",
            "Epoch 9/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.0940 - val_accuracy: 0.9767\n",
            "Epoch 10/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.0918 - val_accuracy: 0.9784\n",
            "Epoch 11/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.1082 - val_accuracy: 0.9762\n",
            "Epoch 12/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.1269 - val_accuracy: 0.9713\n",
            "Epoch 13/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.1141 - val_accuracy: 0.9743\n",
            "Epoch 14/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0118 - accuracy: 0.9956 - val_loss: 0.0989 - val_accuracy: 0.9776\n",
            "Epoch 15/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 0.1095 - val_accuracy: 0.9778\n",
            "Epoch 16/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.1063 - val_accuracy: 0.9774\n",
            "Epoch 17/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.1041 - val_accuracy: 0.9785\n",
            "Epoch 18/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.1155 - val_accuracy: 0.9783\n",
            "Epoch 19/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.7326e-04 - accuracy: 0.9998 - val_loss: 0.1021 - val_accuracy: 0.9799\n",
            "Epoch 20/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5668e-04 - accuracy: 1.0000 - val_loss: 0.1000 - val_accuracy: 0.9811\n",
            "Epoch 21/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9537e-05 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 0.9817\n",
            "Epoch 22/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1912e-05 - accuracy: 1.0000 - val_loss: 0.1010 - val_accuracy: 0.9818\n",
            "Epoch 23/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1262e-05 - accuracy: 1.0000 - val_loss: 0.1020 - val_accuracy: 0.9817\n",
            "Epoch 24/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.3874e-05 - accuracy: 1.0000 - val_loss: 0.1028 - val_accuracy: 0.9818\n",
            "Epoch 25/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8150e-05 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9819\n",
            "Epoch 26/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3520e-05 - accuracy: 1.0000 - val_loss: 0.1045 - val_accuracy: 0.9819\n",
            "Epoch 27/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9666e-05 - accuracy: 1.0000 - val_loss: 0.1053 - val_accuracy: 0.9819\n",
            "Epoch 28/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6396e-05 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9817\n",
            "Epoch 29/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3714e-05 - accuracy: 1.0000 - val_loss: 0.1068 - val_accuracy: 0.9817\n",
            "Epoch 30/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1274e-05 - accuracy: 1.0000 - val_loss: 0.1074 - val_accuracy: 0.9819\n",
            "Epoch 31/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9149e-05 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9819\n",
            "Epoch 32/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7345e-05 - accuracy: 1.0000 - val_loss: 0.1092 - val_accuracy: 0.9816\n",
            "Epoch 33/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5697e-05 - accuracy: 1.0000 - val_loss: 0.1098 - val_accuracy: 0.9816\n",
            "Epoch 34/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4210e-05 - accuracy: 1.0000 - val_loss: 0.1105 - val_accuracy: 0.9819\n",
            "Epoch 35/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2880e-05 - accuracy: 1.0000 - val_loss: 0.1116 - val_accuracy: 0.9817\n",
            "Epoch 36/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1687e-05 - accuracy: 1.0000 - val_loss: 0.1121 - val_accuracy: 0.9817\n",
            "Epoch 37/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0650e-05 - accuracy: 1.0000 - val_loss: 0.1128 - val_accuracy: 0.9817\n",
            "Epoch 38/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6713e-06 - accuracy: 1.0000 - val_loss: 0.1138 - val_accuracy: 0.9818\n",
            "Epoch 39/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.8275e-06 - accuracy: 1.0000 - val_loss: 0.1145 - val_accuracy: 0.9818\n",
            "Epoch 40/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0321e-06 - accuracy: 1.0000 - val_loss: 0.1152 - val_accuracy: 0.9817\n",
            "Epoch 41/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.3392e-06 - accuracy: 1.0000 - val_loss: 0.1159 - val_accuracy: 0.9818\n",
            "Epoch 42/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6710e-06 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 0.9818\n",
            "Epoch 43/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0665e-06 - accuracy: 1.0000 - val_loss: 0.1175 - val_accuracy: 0.9817\n",
            "Epoch 44/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5747e-06 - accuracy: 1.0000 - val_loss: 0.1178 - val_accuracy: 0.9819\n",
            "Epoch 45/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0690e-06 - accuracy: 1.0000 - val_loss: 0.1189 - val_accuracy: 0.9817\n",
            "Epoch 46/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.6565e-06 - accuracy: 1.0000 - val_loss: 0.1195 - val_accuracy: 0.9820\n",
            "Epoch 47/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2296e-06 - accuracy: 1.0000 - val_loss: 0.1202 - val_accuracy: 0.9819\n",
            "Epoch 48/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8789e-06 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 0.9819\n",
            "Epoch 49/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.5645e-06 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9821\n",
            "Epoch 50/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.2454e-06 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9823\n",
            "Epoch 51/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9761e-06 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9823\n",
            "Epoch 52/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7386e-06 - accuracy: 1.0000 - val_loss: 0.1238 - val_accuracy: 0.9823\n",
            "Epoch 53/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4985e-06 - accuracy: 1.0000 - val_loss: 0.1246 - val_accuracy: 0.9823\n",
            "Epoch 54/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2965e-06 - accuracy: 1.0000 - val_loss: 0.1255 - val_accuracy: 0.9825\n",
            "Epoch 55/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1104e-06 - accuracy: 1.0000 - val_loss: 0.1261 - val_accuracy: 0.9823\n",
            "Epoch 56/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9177e-06 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 0.9822\n",
            "Epoch 57/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7823e-06 - accuracy: 1.0000 - val_loss: 0.1275 - val_accuracy: 0.9824\n",
            "Epoch 58/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6255e-06 - accuracy: 1.0000 - val_loss: 0.1282 - val_accuracy: 0.9824\n",
            "Epoch 59/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4902e-06 - accuracy: 1.0000 - val_loss: 0.1293 - val_accuracy: 0.9823\n",
            "Epoch 60/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3621e-06 - accuracy: 1.0000 - val_loss: 0.1299 - val_accuracy: 0.9825\n",
            "Epoch 61/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2557e-06 - accuracy: 1.0000 - val_loss: 0.1305 - val_accuracy: 0.9823\n",
            "Epoch 62/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1473e-06 - accuracy: 1.0000 - val_loss: 0.1310 - val_accuracy: 0.9823\n",
            "Epoch 63/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0582e-06 - accuracy: 1.0000 - val_loss: 0.1324 - val_accuracy: 0.9823\n",
            "Epoch 64/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.7088e-07 - accuracy: 1.0000 - val_loss: 0.1331 - val_accuracy: 0.9822\n",
            "Epoch 65/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.9003e-07 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.9825\n",
            "Epoch 66/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1689e-07 - accuracy: 1.0000 - val_loss: 0.1347 - val_accuracy: 0.9825\n",
            "Epoch 67/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.5375e-07 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.9824\n",
            "Epoch 68/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8977e-07 - accuracy: 1.0000 - val_loss: 0.1363 - val_accuracy: 0.9822\n",
            "Epoch 69/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3214e-07 - accuracy: 1.0000 - val_loss: 0.1365 - val_accuracy: 0.9823\n",
            "Epoch 70/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8003e-07 - accuracy: 1.0000 - val_loss: 0.1372 - val_accuracy: 0.9825\n",
            "Epoch 71/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3209e-07 - accuracy: 1.0000 - val_loss: 0.1381 - val_accuracy: 0.9823\n",
            "Epoch 72/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9066e-07 - accuracy: 1.0000 - val_loss: 0.1390 - val_accuracy: 0.9825\n",
            "Epoch 73/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.5099e-07 - accuracy: 1.0000 - val_loss: 0.1397 - val_accuracy: 0.9825\n",
            "Epoch 74/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1332e-07 - accuracy: 1.0000 - val_loss: 0.1403 - val_accuracy: 0.9826\n",
            "Epoch 75/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.7883e-07 - accuracy: 1.0000 - val_loss: 0.1413 - val_accuracy: 0.9827\n",
            "Epoch 76/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5095e-07 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9823\n",
            "Epoch 77/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1834e-07 - accuracy: 1.0000 - val_loss: 0.1431 - val_accuracy: 0.9825\n",
            "Epoch 78/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9384e-07 - accuracy: 1.0000 - val_loss: 0.1438 - val_accuracy: 0.9824\n",
            "Epoch 79/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6981e-07 - accuracy: 1.0000 - val_loss: 0.1446 - val_accuracy: 0.9825\n",
            "Epoch 80/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4906e-07 - accuracy: 1.0000 - val_loss: 0.1451 - val_accuracy: 0.9825\n",
            "Epoch 81/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2974e-07 - accuracy: 1.0000 - val_loss: 0.1460 - val_accuracy: 0.9824\n",
            "Epoch 82/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1148e-07 - accuracy: 1.0000 - val_loss: 0.1464 - val_accuracy: 0.9825\n",
            "Epoch 83/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9273e-07 - accuracy: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9827\n",
            "Epoch 84/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7846e-07 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 0.9825\n",
            "Epoch 85/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6378e-07 - accuracy: 1.0000 - val_loss: 0.1485 - val_accuracy: 0.9826\n",
            "Epoch 86/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5145e-07 - accuracy: 1.0000 - val_loss: 0.1497 - val_accuracy: 0.9824\n",
            "Epoch 87/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3879e-07 - accuracy: 1.0000 - val_loss: 0.1503 - val_accuracy: 0.9826\n",
            "Epoch 88/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2773e-07 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9827\n",
            "Epoch 89/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1772e-07 - accuracy: 1.0000 - val_loss: 0.1517 - val_accuracy: 0.9825\n",
            "Epoch 90/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0900e-07 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9825\n",
            "Epoch 91/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0065e-07 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 0.9826\n",
            "Epoch 92/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2467e-08 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9826\n",
            "Epoch 93/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5039e-08 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 0.9826\n",
            "Epoch 94/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8837e-08 - accuracy: 1.0000 - val_loss: 0.1548 - val_accuracy: 0.9825\n",
            "Epoch 95/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2670e-08 - accuracy: 1.0000 - val_loss: 0.1565 - val_accuracy: 0.9826\n",
            "Epoch 96/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7213e-08 - accuracy: 1.0000 - val_loss: 0.1561 - val_accuracy: 0.9827\n",
            "Epoch 97/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2060e-08 - accuracy: 1.0000 - val_loss: 0.1573 - val_accuracy: 0.9825\n",
            "Epoch 98/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7223e-08 - accuracy: 1.0000 - val_loss: 0.1579 - val_accuracy: 0.9825\n",
            "Epoch 99/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2977e-08 - accuracy: 1.0000 - val_loss: 0.1586 - val_accuracy: 0.9825\n",
            "Epoch 100/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.9093e-08 - accuracy: 1.0000 - val_loss: 0.1591 - val_accuracy: 0.9827\n",
            "Epoch 101/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5723e-08 - accuracy: 1.0000 - val_loss: 0.1598 - val_accuracy: 0.9824\n",
            "Epoch 102/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.2224e-08 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9827\n",
            "Epoch 103/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9215e-08 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9825\n",
            "Epoch 104/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6261e-08 - accuracy: 1.0000 - val_loss: 0.1617 - val_accuracy: 0.9823\n",
            "Epoch 105/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3903e-08 - accuracy: 1.0000 - val_loss: 0.1621 - val_accuracy: 0.9826\n",
            "Epoch 106/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1551e-08 - accuracy: 1.0000 - val_loss: 0.1627 - val_accuracy: 0.9825\n",
            "Epoch 107/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9230e-08 - accuracy: 1.0000 - val_loss: 0.1634 - val_accuracy: 0.9824\n",
            "Epoch 108/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7196e-08 - accuracy: 1.0000 - val_loss: 0.1641 - val_accuracy: 0.9823\n",
            "Epoch 109/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5275e-08 - accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 0.9825\n",
            "Epoch 110/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3656e-08 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9823\n",
            "Epoch 111/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2048e-08 - accuracy: 1.0000 - val_loss: 0.1657 - val_accuracy: 0.9823\n",
            "Epoch 112/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0660e-08 - accuracy: 1.0000 - val_loss: 0.1660 - val_accuracy: 0.9825\n",
            "Epoch 113/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9185e-08 - accuracy: 1.0000 - val_loss: 0.1664 - val_accuracy: 0.9825\n",
            "Epoch 114/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7913e-08 - accuracy: 1.0000 - val_loss: 0.1675 - val_accuracy: 0.9824\n",
            "Epoch 115/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6793e-08 - accuracy: 1.0000 - val_loss: 0.1675 - val_accuracy: 0.9824\n",
            "Epoch 116/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5728e-08 - accuracy: 1.0000 - val_loss: 0.1682 - val_accuracy: 0.9823\n",
            "Epoch 117/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4761e-08 - accuracy: 1.0000 - val_loss: 0.1687 - val_accuracy: 0.9824\n",
            "Epoch 118/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3871e-08 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9823\n",
            "Epoch 119/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2999e-08 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.9823\n",
            "Epoch 120/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2239e-08 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 0.9823\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0425 - accuracy: 0.9956\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1443 - accuracy: 0.9831\n",
            "train accuracy :  0.9955666661262512 train loss :  0.04253648966550827\n",
            "test accuracy :  0.9830999970436096  test loss :  0.14426426589488983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hbGowW28_2h_",
        "outputId": "8af7fae8-0216-4cac-f14d-fd37b6a2e8d4"
      },
      "source": [
        "#은닉층 1개 & epochs = 500\n",
        "model3_3 = models.Sequential([\n",
        "                            Flatten(input_shape = (28, 28)),\n",
        "                            Dense(512, activation= 'relu', kernel_initializer=initializer),\n",
        "                            Dense(512, activation= 'relu', kernel_initializer=initializer),\n",
        "                            Dense(10, activation= 'softmax', kernel_initializer=initializer)\n",
        "                            ])\n",
        "\n",
        "model3_3.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "#신경망 학습 3_3\n",
        "hist3_3 = model3_3.fit(train_x, train_y, epochs = 500, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "plt.plot(hist3_3.history['accuracy'], 'b-')\n",
        "plt.plot(hist3_3.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train3_3 = model3_3.evaluate(train_x, train_y)\n",
        "sc_test3_3 = model3_3.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train3_3[1], \"train loss : \", sc_train3_3[0])\n",
        "print(\"test accuracy : \", sc_test3_3[1], \" test loss : \", sc_test3_3[0])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "176/176 [==============================] - 2s 7ms/step - loss: 0.2978 - accuracy: 0.9126 - val_loss: 0.1522 - val_accuracy: 0.9542\n",
            "Epoch 2/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.1009 - accuracy: 0.9700 - val_loss: 0.1039 - val_accuracy: 0.9691\n",
            "Epoch 3/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0617 - accuracy: 0.9814 - val_loss: 0.0926 - val_accuracy: 0.9717\n",
            "Epoch 4/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0404 - accuracy: 0.9880 - val_loss: 0.0917 - val_accuracy: 0.9727\n",
            "Epoch 5/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.0883 - val_accuracy: 0.9761\n",
            "Epoch 6/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0183 - accuracy: 0.9946 - val_loss: 0.0896 - val_accuracy: 0.9766\n",
            "Epoch 7/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0134 - accuracy: 0.9961 - val_loss: 0.0888 - val_accuracy: 0.9769\n",
            "Epoch 8/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.0953 - val_accuracy: 0.9764\n",
            "Epoch 9/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 0.0913 - val_accuracy: 0.9781\n",
            "Epoch 10/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.1009 - val_accuracy: 0.9771\n",
            "Epoch 11/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.1054 - val_accuracy: 0.9772\n",
            "Epoch 12/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.1060 - val_accuracy: 0.9772\n",
            "Epoch 13/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.1060 - val_accuracy: 0.9783\n",
            "Epoch 14/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0181 - accuracy: 0.9939 - val_loss: 0.1473 - val_accuracy: 0.9661\n",
            "Epoch 15/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0215 - accuracy: 0.9925 - val_loss: 0.1072 - val_accuracy: 0.9753\n",
            "Epoch 16/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.1222 - val_accuracy: 0.9738\n",
            "Epoch 17/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.1146 - val_accuracy: 0.9771\n",
            "Epoch 18/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.1352 - val_accuracy: 0.9749\n",
            "Epoch 19/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.1195 - val_accuracy: 0.9792\n",
            "Epoch 20/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0058 - accuracy: 0.9977 - val_loss: 0.1321 - val_accuracy: 0.9760\n",
            "Epoch 21/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.1219 - val_accuracy: 0.9783\n",
            "Epoch 22/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.1259 - val_accuracy: 0.9754\n",
            "Epoch 23/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.1394 - val_accuracy: 0.9769\n",
            "Epoch 24/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.1218 - val_accuracy: 0.9801\n",
            "Epoch 25/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.1210 - val_accuracy: 0.9789\n",
            "Epoch 26/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.1117 - val_accuracy: 0.9803\n",
            "Epoch 27/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.3328e-04 - accuracy: 0.9998 - val_loss: 0.1146 - val_accuracy: 0.9806\n",
            "Epoch 28/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1727e-04 - accuracy: 0.9999 - val_loss: 0.1173 - val_accuracy: 0.9809\n",
            "Epoch 29/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4256e-05 - accuracy: 1.0000 - val_loss: 0.1121 - val_accuracy: 0.9823\n",
            "Epoch 30/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3783e-05 - accuracy: 1.0000 - val_loss: 0.1131 - val_accuracy: 0.9821\n",
            "Epoch 31/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6950e-05 - accuracy: 1.0000 - val_loss: 0.1140 - val_accuracy: 0.9821\n",
            "Epoch 32/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2870e-05 - accuracy: 1.0000 - val_loss: 0.1150 - val_accuracy: 0.9820\n",
            "Epoch 33/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9798e-05 - accuracy: 1.0000 - val_loss: 0.1158 - val_accuracy: 0.9820\n",
            "Epoch 34/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7372e-05 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 0.9821\n",
            "Epoch 35/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5394e-05 - accuracy: 1.0000 - val_loss: 0.1174 - val_accuracy: 0.9820\n",
            "Epoch 36/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3697e-05 - accuracy: 1.0000 - val_loss: 0.1183 - val_accuracy: 0.9821\n",
            "Epoch 37/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2260e-05 - accuracy: 1.0000 - val_loss: 0.1190 - val_accuracy: 0.9820\n",
            "Epoch 38/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1023e-05 - accuracy: 1.0000 - val_loss: 0.1199 - val_accuracy: 0.9821\n",
            "Epoch 39/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9720e-06 - accuracy: 1.0000 - val_loss: 0.1206 - val_accuracy: 0.9821\n",
            "Epoch 40/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0233e-06 - accuracy: 1.0000 - val_loss: 0.1214 - val_accuracy: 0.9822\n",
            "Epoch 41/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.1831e-06 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9821\n",
            "Epoch 42/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4423e-06 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9822\n",
            "Epoch 43/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7696e-06 - accuracy: 1.0000 - val_loss: 0.1238 - val_accuracy: 0.9822\n",
            "Epoch 44/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1807e-06 - accuracy: 1.0000 - val_loss: 0.1245 - val_accuracy: 0.9821\n",
            "Epoch 45/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.6200e-06 - accuracy: 1.0000 - val_loss: 0.1253 - val_accuracy: 0.9822\n",
            "Epoch 46/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1594e-06 - accuracy: 1.0000 - val_loss: 0.1261 - val_accuracy: 0.9821\n",
            "Epoch 47/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.7051e-06 - accuracy: 1.0000 - val_loss: 0.1269 - val_accuracy: 0.9821\n",
            "Epoch 48/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.3145e-06 - accuracy: 1.0000 - val_loss: 0.1277 - val_accuracy: 0.9823\n",
            "Epoch 49/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9515e-06 - accuracy: 1.0000 - val_loss: 0.1284 - val_accuracy: 0.9822\n",
            "Epoch 50/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6301e-06 - accuracy: 1.0000 - val_loss: 0.1292 - val_accuracy: 0.9823\n",
            "Epoch 51/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3274e-06 - accuracy: 1.0000 - val_loss: 0.1299 - val_accuracy: 0.9821\n",
            "Epoch 52/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0428e-06 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 0.9822\n",
            "Epoch 53/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8071e-06 - accuracy: 1.0000 - val_loss: 0.1314 - val_accuracy: 0.9822\n",
            "Epoch 54/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5699e-06 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.9821\n",
            "Epoch 55/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3701e-06 - accuracy: 1.0000 - val_loss: 0.1329 - val_accuracy: 0.9823\n",
            "Epoch 56/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1667e-06 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.9822\n",
            "Epoch 57/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9965e-06 - accuracy: 1.0000 - val_loss: 0.1345 - val_accuracy: 0.9821\n",
            "Epoch 58/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8311e-06 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.9822\n",
            "Epoch 59/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6900e-06 - accuracy: 1.0000 - val_loss: 0.1361 - val_accuracy: 0.9821\n",
            "Epoch 60/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5545e-06 - accuracy: 1.0000 - val_loss: 0.1367 - val_accuracy: 0.9823\n",
            "Epoch 61/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4276e-06 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9822\n",
            "Epoch 62/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3098e-06 - accuracy: 1.0000 - val_loss: 0.1384 - val_accuracy: 0.9823\n",
            "Epoch 63/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2059e-06 - accuracy: 1.0000 - val_loss: 0.1393 - val_accuracy: 0.9823\n",
            "Epoch 64/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1131e-06 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.9823\n",
            "Epoch 65/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0212e-06 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9822\n",
            "Epoch 66/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4067e-07 - accuracy: 1.0000 - val_loss: 0.1416 - val_accuracy: 0.9822\n",
            "Epoch 67/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.6012e-07 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 0.9823\n",
            "Epoch 68/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9185e-07 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9823\n",
            "Epoch 69/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.2388e-07 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9822\n",
            "Epoch 70/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8110e-07 - accuracy: 1.0000 - val_loss: 0.1450 - val_accuracy: 0.9821\n",
            "Epoch 71/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1728e-07 - accuracy: 1.0000 - val_loss: 0.1458 - val_accuracy: 0.9821\n",
            "Epoch 72/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6945e-07 - accuracy: 1.0000 - val_loss: 0.1466 - val_accuracy: 0.9821\n",
            "Epoch 73/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2578e-07 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.9822\n",
            "Epoch 74/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.8197e-07 - accuracy: 1.0000 - val_loss: 0.1480 - val_accuracy: 0.9824\n",
            "Epoch 75/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4202e-07 - accuracy: 1.0000 - val_loss: 0.1488 - val_accuracy: 0.9822\n",
            "Epoch 76/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.0822e-07 - accuracy: 1.0000 - val_loss: 0.1496 - val_accuracy: 0.9822\n",
            "Epoch 77/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.7737e-07 - accuracy: 1.0000 - val_loss: 0.1506 - val_accuracy: 0.9821\n",
            "Epoch 78/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4652e-07 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9822\n",
            "Epoch 79/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1765e-07 - accuracy: 1.0000 - val_loss: 0.1522 - val_accuracy: 0.9822\n",
            "Epoch 80/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9295e-07 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.9823\n",
            "Epoch 81/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7213e-07 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9822\n",
            "Epoch 82/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4755e-07 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 0.9822\n",
            "Epoch 83/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2887e-07 - accuracy: 1.0000 - val_loss: 0.1553 - val_accuracy: 0.9823\n",
            "Epoch 84/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1115e-07 - accuracy: 1.0000 - val_loss: 0.1563 - val_accuracy: 0.9823\n",
            "Epoch 85/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9397e-07 - accuracy: 1.0000 - val_loss: 0.1569 - val_accuracy: 0.9823\n",
            "Epoch 86/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7781e-07 - accuracy: 1.0000 - val_loss: 0.1577 - val_accuracy: 0.9821\n",
            "Epoch 87/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6415e-07 - accuracy: 1.0000 - val_loss: 0.1584 - val_accuracy: 0.9823\n",
            "Epoch 88/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5077e-07 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 0.9821\n",
            "Epoch 89/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3970e-07 - accuracy: 1.0000 - val_loss: 0.1602 - val_accuracy: 0.9821\n",
            "Epoch 90/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2806e-07 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9822\n",
            "Epoch 91/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1866e-07 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.9823\n",
            "Epoch 92/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0907e-07 - accuracy: 1.0000 - val_loss: 0.1621 - val_accuracy: 0.9823\n",
            "Epoch 93/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0104e-07 - accuracy: 1.0000 - val_loss: 0.1632 - val_accuracy: 0.9823\n",
            "Epoch 94/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.2917e-08 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9822\n",
            "Epoch 95/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.6387e-08 - accuracy: 1.0000 - val_loss: 0.1647 - val_accuracy: 0.9823\n",
            "Epoch 96/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9396e-08 - accuracy: 1.0000 - val_loss: 0.1653 - val_accuracy: 0.9823\n",
            "Epoch 97/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.2927e-08 - accuracy: 1.0000 - val_loss: 0.1663 - val_accuracy: 0.9823\n",
            "Epoch 98/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8010e-08 - accuracy: 1.0000 - val_loss: 0.1670 - val_accuracy: 0.9821\n",
            "Epoch 99/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2487e-08 - accuracy: 1.0000 - val_loss: 0.1679 - val_accuracy: 0.9824\n",
            "Epoch 100/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8420e-08 - accuracy: 1.0000 - val_loss: 0.1683 - val_accuracy: 0.9823\n",
            "Epoch 101/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3316e-08 - accuracy: 1.0000 - val_loss: 0.1692 - val_accuracy: 0.9823\n",
            "Epoch 102/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.9673e-08 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 0.9823\n",
            "Epoch 103/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5917e-08 - accuracy: 1.0000 - val_loss: 0.1703 - val_accuracy: 0.9824\n",
            "Epoch 104/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2934e-08 - accuracy: 1.0000 - val_loss: 0.1712 - val_accuracy: 0.9823\n",
            "Epoch 105/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9901e-08 - accuracy: 1.0000 - val_loss: 0.1719 - val_accuracy: 0.9825\n",
            "Epoch 106/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6520e-08 - accuracy: 1.0000 - val_loss: 0.1726 - val_accuracy: 0.9825\n",
            "Epoch 107/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3869e-08 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.9824\n",
            "Epoch 108/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1622e-08 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 0.9823\n",
            "Epoch 109/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9447e-08 - accuracy: 1.0000 - val_loss: 0.1744 - val_accuracy: 0.9826\n",
            "Epoch 110/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7288e-08 - accuracy: 1.0000 - val_loss: 0.1754 - val_accuracy: 0.9823\n",
            "Epoch 111/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5368e-08 - accuracy: 1.0000 - val_loss: 0.1761 - val_accuracy: 0.9824\n",
            "Epoch 112/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3701e-08 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 0.9823\n",
            "Epoch 113/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2059e-08 - accuracy: 1.0000 - val_loss: 0.1773 - val_accuracy: 0.9823\n",
            "Epoch 114/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0438e-08 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 0.9823\n",
            "Epoch 115/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9132e-08 - accuracy: 1.0000 - val_loss: 0.1786 - val_accuracy: 0.9824\n",
            "Epoch 116/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7889e-08 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 0.9823\n",
            "Epoch 117/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6665e-08 - accuracy: 1.0000 - val_loss: 0.1795 - val_accuracy: 0.9824\n",
            "Epoch 118/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5706e-08 - accuracy: 1.0000 - val_loss: 0.1801 - val_accuracy: 0.9822\n",
            "Epoch 119/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4575e-08 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9824\n",
            "Epoch 120/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3661e-08 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 0.9822\n",
            "Epoch 121/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2803e-08 - accuracy: 1.0000 - val_loss: 0.1817 - val_accuracy: 0.9824\n",
            "Epoch 122/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2003e-08 - accuracy: 1.0000 - val_loss: 0.1825 - val_accuracy: 0.9823\n",
            "Epoch 123/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1312e-08 - accuracy: 1.0000 - val_loss: 0.1827 - val_accuracy: 0.9825\n",
            "Epoch 124/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0573e-08 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9824\n",
            "Epoch 125/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.9368e-09 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.9823\n",
            "Epoch 126/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.3275e-09 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 0.9823\n",
            "Epoch 127/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8321e-09 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9824\n",
            "Epoch 128/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3579e-09 - accuracy: 1.0000 - val_loss: 0.1853 - val_accuracy: 0.9823\n",
            "Epoch 129/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8281e-09 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9823\n",
            "Epoch 130/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3989e-09 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9823\n",
            "Epoch 131/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.9883e-09 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 0.9823\n",
            "Epoch 132/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6651e-09 - accuracy: 1.0000 - val_loss: 0.1873 - val_accuracy: 0.9823\n",
            "Epoch 133/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2995e-09 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9823\n",
            "Epoch 134/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9446e-09 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9823\n",
            "Epoch 135/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6267e-09 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9823\n",
            "Epoch 136/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3936e-09 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 0.9824\n",
            "Epoch 137/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0651e-09 - accuracy: 1.0000 - val_loss: 0.1892 - val_accuracy: 0.9823\n",
            "Epoch 138/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.8028e-09 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9823\n",
            "Epoch 139/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.5379e-09 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9823\n",
            "Epoch 140/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3710e-09 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 0.9823\n",
            "Epoch 141/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.0849e-09 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9823\n",
            "Epoch 142/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9922e-09 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 0.9823\n",
            "Epoch 143/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8412e-09 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9824\n",
            "Epoch 144/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6266e-09 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9823\n",
            "Epoch 145/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.4783e-09 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9823\n",
            "Epoch 146/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3061e-09 - accuracy: 1.0000 - val_loss: 0.1919 - val_accuracy: 0.9824\n",
            "Epoch 147/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1551e-09 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 0.9824\n",
            "Epoch 148/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0173e-09 - accuracy: 1.0000 - val_loss: 0.1922 - val_accuracy: 0.9824\n",
            "Epoch 149/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9140e-09 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9823\n",
            "Epoch 150/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7604e-09 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9824\n",
            "Epoch 151/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6835e-09 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 0.9824\n",
            "Epoch 152/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5590e-09 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9824\n",
            "Epoch 153/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4610e-09 - accuracy: 1.0000 - val_loss: 0.1932 - val_accuracy: 0.9825\n",
            "Epoch 154/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3948e-09 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9824\n",
            "Epoch 155/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3392e-09 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9824\n",
            "Epoch 156/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2385e-09 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9823\n",
            "Epoch 157/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1378e-09 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 0.9824\n",
            "Epoch 158/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1140e-09 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 0.9823\n",
            "Epoch 159/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0504e-09 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9823\n",
            "Epoch 160/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9895e-09 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9823\n",
            "Epoch 161/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9153e-09 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9823\n",
            "Epoch 162/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8782e-09 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9823\n",
            "Epoch 163/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8332e-09 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9823\n",
            "Epoch 164/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7802e-09 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.9822\n",
            "Epoch 165/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7166e-09 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.9823\n",
            "Epoch 166/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6822e-09 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.9823\n",
            "Epoch 167/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6504e-09 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9823\n",
            "Epoch 168/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5683e-09 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 0.9823\n",
            "Epoch 169/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5312e-09 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9823\n",
            "Epoch 170/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5259e-09 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9823\n",
            "Epoch 171/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4914e-09 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9823\n",
            "Epoch 172/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4597e-09 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9823\n",
            "Epoch 173/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4199e-09 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9823\n",
            "Epoch 174/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3881e-09 - accuracy: 1.0000 - val_loss: 0.1958 - val_accuracy: 0.9821\n",
            "Epoch 175/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3775e-09 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9822\n",
            "Epoch 176/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3404e-09 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 0.9823\n",
            "Epoch 177/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2769e-09 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 0.9822\n",
            "Epoch 178/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2848e-09 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.9821\n",
            "Epoch 179/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2769e-09 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9821\n",
            "Epoch 180/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2689e-09 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.9820\n",
            "Epoch 181/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2318e-09 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.9821\n",
            "Epoch 182/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2133e-09 - accuracy: 1.0000 - val_loss: 0.1969 - val_accuracy: 0.9821\n",
            "Epoch 183/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2027e-09 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9820\n",
            "Epoch 184/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2000e-09 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 0.9820\n",
            "Epoch 185/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1841e-09 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9820\n",
            "Epoch 186/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1762e-09 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9819\n",
            "Epoch 187/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1841e-09 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 0.9821\n",
            "Epoch 188/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1338e-09 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9819\n",
            "Epoch 189/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1391e-09 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9821\n",
            "Epoch 190/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1073e-09 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9821\n",
            "Epoch 191/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0967e-09 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9821\n",
            "Epoch 192/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1179e-09 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 0.9820\n",
            "Epoch 193/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1206e-09 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 0.9819\n",
            "Epoch 194/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1020e-09 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 0.9821\n",
            "Epoch 195/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0967e-09 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.9821\n",
            "Epoch 196/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0596e-09 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.9819\n",
            "Epoch 197/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0861e-09 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9819\n",
            "Epoch 198/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0464e-09 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9821\n",
            "Epoch 199/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0570e-09 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9819\n",
            "Epoch 200/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0252e-09 - accuracy: 1.0000 - val_loss: 0.1994 - val_accuracy: 0.9820\n",
            "Epoch 201/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0517e-09 - accuracy: 1.0000 - val_loss: 0.1996 - val_accuracy: 0.9820\n",
            "Epoch 202/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0490e-09 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9819\n",
            "Epoch 203/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0278e-09 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9819\n",
            "Epoch 204/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0490e-09 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9819\n",
            "Epoch 205/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0199e-09 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9819\n",
            "Epoch 206/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0437e-09 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9821\n",
            "Epoch 207/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0199e-09 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9819\n",
            "Epoch 208/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0226e-09 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9820\n",
            "Epoch 209/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0464e-09 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9821\n",
            "Epoch 210/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0199e-09 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9820\n",
            "Epoch 211/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9606e-10 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9820\n",
            "Epoch 212/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0278e-09 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9821\n",
            "Epoch 213/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0464e-09 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9819\n",
            "Epoch 214/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0067e-09 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9820\n",
            "Epoch 215/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0278e-09 - accuracy: 1.0000 - val_loss: 0.2025 - val_accuracy: 0.9820\n",
            "Epoch 216/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0252e-09 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9819\n",
            "Epoch 217/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0358e-09 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9821\n",
            "Epoch 218/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0120e-09 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9821\n",
            "Epoch 219/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0173e-09 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.9819\n",
            "Epoch 220/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0278e-09 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 0.9819\n",
            "Epoch 221/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0278e-09 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9819\n",
            "Epoch 222/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0835e-09 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.9819\n",
            "Epoch 223/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0146e-09 - accuracy: 1.0000 - val_loss: 0.2046 - val_accuracy: 0.9819\n",
            "Epoch 224/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0464e-09 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9820\n",
            "Epoch 225/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0173e-09 - accuracy: 1.0000 - val_loss: 0.2051 - val_accuracy: 0.9820\n",
            "Epoch 226/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0702e-09 - accuracy: 1.0000 - val_loss: 0.2053 - val_accuracy: 0.9820\n",
            "Epoch 227/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0782e-09 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9820\n",
            "Epoch 228/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0649e-09 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9819\n",
            "Epoch 229/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0517e-09 - accuracy: 1.0000 - val_loss: 0.2061 - val_accuracy: 0.9820\n",
            "Epoch 230/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0596e-09 - accuracy: 1.0000 - val_loss: 0.2065 - val_accuracy: 0.9820\n",
            "Epoch 231/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0543e-09 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9821\n",
            "Epoch 232/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0861e-09 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 0.9820\n",
            "Epoch 233/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0676e-09 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9820\n",
            "Epoch 234/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0835e-09 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9820\n",
            "Epoch 235/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0808e-09 - accuracy: 1.0000 - val_loss: 0.2077 - val_accuracy: 0.9821\n",
            "Epoch 236/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0676e-09 - accuracy: 1.0000 - val_loss: 0.2082 - val_accuracy: 0.9820\n",
            "Epoch 237/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1047e-09 - accuracy: 1.0000 - val_loss: 0.2082 - val_accuracy: 0.9821\n",
            "Epoch 238/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1126e-09 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9820\n",
            "Epoch 239/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1020e-09 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9820\n",
            "Epoch 240/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1073e-09 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 0.9820\n",
            "Epoch 241/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1259e-09 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9820\n",
            "Epoch 242/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1047e-09 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9820\n",
            "Epoch 243/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1762e-09 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9819\n",
            "Epoch 244/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1285e-09 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 0.9820\n",
            "Epoch 245/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1338e-09 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9819\n",
            "Epoch 246/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1471e-09 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9819\n",
            "Epoch 247/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1418e-09 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9819\n",
            "Epoch 248/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1312e-09 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9819\n",
            "Epoch 249/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1762e-09 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9819\n",
            "Epoch 250/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1735e-09 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9819\n",
            "Epoch 251/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2265e-09 - accuracy: 1.0000 - val_loss: 0.2125 - val_accuracy: 0.9819\n",
            "Epoch 252/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2000e-09 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 0.9819\n",
            "Epoch 253/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1815e-09 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.9819\n",
            "Epoch 254/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1974e-09 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9819\n",
            "Epoch 255/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1788e-09 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9819\n",
            "Epoch 256/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2106e-09 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9817\n",
            "Epoch 257/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2239e-09 - accuracy: 1.0000 - val_loss: 0.2146 - val_accuracy: 0.9817\n",
            "Epoch 258/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2292e-09 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9818\n",
            "Epoch 259/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2371e-09 - accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 0.9817\n",
            "Epoch 260/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2292e-09 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9817\n",
            "Epoch 261/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2530e-09 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9817\n",
            "Epoch 262/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2530e-09 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9818\n",
            "Epoch 263/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2477e-09 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 0.9817\n",
            "Epoch 264/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2610e-09 - accuracy: 1.0000 - val_loss: 0.2170 - val_accuracy: 0.9816\n",
            "Epoch 265/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2557e-09 - accuracy: 1.0000 - val_loss: 0.2170 - val_accuracy: 0.9815\n",
            "Epoch 266/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3087e-09 - accuracy: 1.0000 - val_loss: 0.2175 - val_accuracy: 0.9817\n",
            "Epoch 267/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2901e-09 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9815\n",
            "Epoch 268/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3166e-09 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9816\n",
            "Epoch 269/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3034e-09 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9816\n",
            "Epoch 270/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2848e-09 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9816\n",
            "Epoch 271/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3140e-09 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9815\n",
            "Epoch 272/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3140e-09 - accuracy: 1.0000 - val_loss: 0.2194 - val_accuracy: 0.9817\n",
            "Epoch 273/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3510e-09 - accuracy: 1.0000 - val_loss: 0.2194 - val_accuracy: 0.9815\n",
            "Epoch 274/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3007e-09 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 0.9816\n",
            "Epoch 275/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3378e-09 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9815\n",
            "Epoch 276/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3643e-09 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9816\n",
            "Epoch 277/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3351e-09 - accuracy: 1.0000 - val_loss: 0.2209 - val_accuracy: 0.9815\n",
            "Epoch 278/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3749e-09 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9814\n",
            "Epoch 279/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3775e-09 - accuracy: 1.0000 - val_loss: 0.2215 - val_accuracy: 0.9815\n",
            "Epoch 280/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3616e-09 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 0.9814\n",
            "Epoch 281/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3643e-09 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 0.9814\n",
            "Epoch 282/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3802e-09 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.9813\n",
            "Epoch 283/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3775e-09 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9813\n",
            "Epoch 284/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3696e-09 - accuracy: 1.0000 - val_loss: 0.2233 - val_accuracy: 0.9813\n",
            "Epoch 285/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3961e-09 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9813\n",
            "Epoch 286/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4040e-09 - accuracy: 1.0000 - val_loss: 0.2237 - val_accuracy: 0.9813\n",
            "Epoch 287/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4040e-09 - accuracy: 1.0000 - val_loss: 0.2239 - val_accuracy: 0.9813\n",
            "Epoch 288/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4411e-09 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9814\n",
            "Epoch 289/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4199e-09 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9813\n",
            "Epoch 290/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3908e-09 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9813\n",
            "Epoch 291/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3802e-09 - accuracy: 1.0000 - val_loss: 0.2255 - val_accuracy: 0.9813\n",
            "Epoch 292/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4702e-09 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9811\n",
            "Epoch 293/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4808e-09 - accuracy: 1.0000 - val_loss: 0.2264 - val_accuracy: 0.9813\n",
            "Epoch 294/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4491e-09 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 0.9812\n",
            "Epoch 295/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4570e-09 - accuracy: 1.0000 - val_loss: 0.2273 - val_accuracy: 0.9813\n",
            "Epoch 296/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4914e-09 - accuracy: 1.0000 - val_loss: 0.2274 - val_accuracy: 0.9812\n",
            "Epoch 297/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4782e-09 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9813\n",
            "Epoch 298/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4623e-09 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9811\n",
            "Epoch 299/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5338e-09 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9811\n",
            "Epoch 300/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5232e-09 - accuracy: 1.0000 - val_loss: 0.2293 - val_accuracy: 0.9811\n",
            "Epoch 301/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5047e-09 - accuracy: 1.0000 - val_loss: 0.2296 - val_accuracy: 0.9811\n",
            "Epoch 302/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5603e-09 - accuracy: 1.0000 - val_loss: 0.2300 - val_accuracy: 0.9810\n",
            "Epoch 303/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5100e-09 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 0.9811\n",
            "Epoch 304/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5285e-09 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.9811\n",
            "Epoch 305/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5868e-09 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 0.9811\n",
            "Epoch 306/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5285e-09 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9809\n",
            "Epoch 307/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5815e-09 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9809\n",
            "Epoch 308/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5577e-09 - accuracy: 1.0000 - val_loss: 0.2327 - val_accuracy: 0.9810\n",
            "Epoch 309/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6398e-09 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.9808\n",
            "Epoch 310/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6477e-09 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.9809\n",
            "Epoch 311/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6265e-09 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.9810\n",
            "Epoch 312/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6875e-09 - accuracy: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9809\n",
            "Epoch 313/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6795e-09 - accuracy: 1.0000 - val_loss: 0.2341 - val_accuracy: 0.9810\n",
            "Epoch 314/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7272e-09 - accuracy: 1.0000 - val_loss: 0.2344 - val_accuracy: 0.9809\n",
            "Epoch 315/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7140e-09 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9809\n",
            "Epoch 316/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7537e-09 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9809\n",
            "Epoch 317/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6769e-09 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 0.9809\n",
            "Epoch 318/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7325e-09 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9808\n",
            "Epoch 319/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7299e-09 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9811\n",
            "Epoch 320/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7219e-09 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9809\n",
            "Epoch 321/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8199e-09 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9808\n",
            "Epoch 322/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7802e-09 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.9809\n",
            "Epoch 323/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8014e-09 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.9810\n",
            "Epoch 324/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7537e-09 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9807\n",
            "Epoch 325/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7828e-09 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9808\n",
            "Epoch 326/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8120e-09 - accuracy: 1.0000 - val_loss: 0.2396 - val_accuracy: 0.9807\n",
            "Epoch 327/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7749e-09 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9809\n",
            "Epoch 328/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8199e-09 - accuracy: 1.0000 - val_loss: 0.2398 - val_accuracy: 0.9809\n",
            "Epoch 329/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8173e-09 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 0.9807\n",
            "Epoch 330/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7828e-09 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9806\n",
            "Epoch 331/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8570e-09 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 0.9805\n",
            "Epoch 332/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8650e-09 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9807\n",
            "Epoch 333/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8411e-09 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 0.9805\n",
            "Epoch 334/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8782e-09 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.9803\n",
            "Epoch 335/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9312e-09 - accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 0.9805\n",
            "Epoch 336/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9100e-09 - accuracy: 1.0000 - val_loss: 0.2432 - val_accuracy: 0.9805\n",
            "Epoch 337/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9550e-09 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9805\n",
            "Epoch 338/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9815e-09 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 0.9803\n",
            "Epoch 339/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9974e-09 - accuracy: 1.0000 - val_loss: 0.2442 - val_accuracy: 0.9805\n",
            "Epoch 340/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0372e-09 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9804\n",
            "Epoch 341/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0054e-09 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 0.9804\n",
            "Epoch 342/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0186e-09 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9803\n",
            "Epoch 343/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0372e-09 - accuracy: 1.0000 - val_loss: 0.2470 - val_accuracy: 0.9805\n",
            "Epoch 344/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0636e-09 - accuracy: 1.0000 - val_loss: 0.2472 - val_accuracy: 0.9802\n",
            "Epoch 345/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0292e-09 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9804\n",
            "Epoch 346/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1140e-09 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 0.9801\n",
            "Epoch 347/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1617e-09 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9803\n",
            "Epoch 348/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1246e-09 - accuracy: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.9803\n",
            "Epoch 349/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1087e-09 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9803\n",
            "Epoch 350/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1802e-09 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9809\n",
            "Epoch 351/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1670e-09 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 0.9803\n",
            "Epoch 352/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2173e-09 - accuracy: 1.0000 - val_loss: 0.2510 - val_accuracy: 0.9801\n",
            "Epoch 353/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2305e-09 - accuracy: 1.0000 - val_loss: 0.2501 - val_accuracy: 0.9801\n",
            "Epoch 354/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2279e-09 - accuracy: 1.0000 - val_loss: 0.2511 - val_accuracy: 0.9805\n",
            "Epoch 355/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4266e-09 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.9800\n",
            "Epoch 356/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3392e-09 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9801\n",
            "Epoch 357/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4981e-09 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.9801\n",
            "Epoch 358/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4160e-09 - accuracy: 1.0000 - val_loss: 0.2514 - val_accuracy: 0.9801\n",
            "Epoch 359/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6358e-09 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9802\n",
            "Epoch 360/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7286e-09 - accuracy: 1.0000 - val_loss: 0.2548 - val_accuracy: 0.9802\n",
            "Epoch 361/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5087e-09 - accuracy: 1.0000 - val_loss: 0.2557 - val_accuracy: 0.9799\n",
            "Epoch 362/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4054e-09 - accuracy: 1.0000 - val_loss: 0.2557 - val_accuracy: 0.9800\n",
            "Epoch 363/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5405e-09 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.9800\n",
            "Epoch 364/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3409 - accuracy: 0.9878 - val_loss: 0.2638 - val_accuracy: 0.9658\n",
            "Epoch 365/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0193 - accuracy: 0.9943 - val_loss: 0.1478 - val_accuracy: 0.9773\n",
            "Epoch 366/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.1442 - val_accuracy: 0.9786\n",
            "Epoch 367/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0979e-04 - accuracy: 0.9999 - val_loss: 0.1429 - val_accuracy: 0.9798\n",
            "Epoch 368/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5585e-04 - accuracy: 1.0000 - val_loss: 0.1432 - val_accuracy: 0.9797\n",
            "Epoch 369/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1984e-04 - accuracy: 1.0000 - val_loss: 0.1436 - val_accuracy: 0.9800\n",
            "Epoch 370/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9089e-05 - accuracy: 1.0000 - val_loss: 0.1440 - val_accuracy: 0.9800\n",
            "Epoch 371/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4240e-05 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9803\n",
            "Epoch 372/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2490e-05 - accuracy: 1.0000 - val_loss: 0.1446 - val_accuracy: 0.9803\n",
            "Epoch 373/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3173e-05 - accuracy: 1.0000 - val_loss: 0.1452 - val_accuracy: 0.9803\n",
            "Epoch 374/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5655e-05 - accuracy: 1.0000 - val_loss: 0.1456 - val_accuracy: 0.9805\n",
            "Epoch 375/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9333e-05 - accuracy: 1.0000 - val_loss: 0.1459 - val_accuracy: 0.9804\n",
            "Epoch 376/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3951e-05 - accuracy: 1.0000 - val_loss: 0.1464 - val_accuracy: 0.9805\n",
            "Epoch 377/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9301e-05 - accuracy: 1.0000 - val_loss: 0.1469 - val_accuracy: 0.9805\n",
            "Epoch 378/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5231e-05 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.9805\n",
            "Epoch 379/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1590e-05 - accuracy: 1.0000 - val_loss: 0.1478 - val_accuracy: 0.9804\n",
            "Epoch 380/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8464e-05 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 0.9806\n",
            "Epoch 381/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5716e-05 - accuracy: 1.0000 - val_loss: 0.1486 - val_accuracy: 0.9807\n",
            "Epoch 382/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3156e-05 - accuracy: 1.0000 - val_loss: 0.1493 - val_accuracy: 0.9807\n",
            "Epoch 383/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0890e-05 - accuracy: 1.0000 - val_loss: 0.1495 - val_accuracy: 0.9809\n",
            "Epoch 384/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8377e-05 - accuracy: 1.0000 - val_loss: 0.1501 - val_accuracy: 0.9809\n",
            "Epoch 385/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6166e-05 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 0.9811\n",
            "Epoch 386/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4238e-05 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 0.9812\n",
            "Epoch 387/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2567e-05 - accuracy: 1.0000 - val_loss: 0.1515 - val_accuracy: 0.9813\n",
            "Epoch 388/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1194e-05 - accuracy: 1.0000 - val_loss: 0.1519 - val_accuracy: 0.9813\n",
            "Epoch 389/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0015e-05 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9813\n",
            "Epoch 390/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9865e-06 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9815\n",
            "Epoch 391/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0781e-06 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9813\n",
            "Epoch 392/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2536e-06 - accuracy: 1.0000 - val_loss: 0.1543 - val_accuracy: 0.9815\n",
            "Epoch 393/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5524e-06 - accuracy: 1.0000 - val_loss: 0.1550 - val_accuracy: 0.9813\n",
            "Epoch 394/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.9198e-06 - accuracy: 1.0000 - val_loss: 0.1557 - val_accuracy: 0.9814\n",
            "Epoch 395/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3742e-06 - accuracy: 1.0000 - val_loss: 0.1565 - val_accuracy: 0.9813\n",
            "Epoch 396/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.8856e-06 - accuracy: 1.0000 - val_loss: 0.1570 - val_accuracy: 0.9815\n",
            "Epoch 397/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.4450e-06 - accuracy: 1.0000 - val_loss: 0.1576 - val_accuracy: 0.9814\n",
            "Epoch 398/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0433e-06 - accuracy: 1.0000 - val_loss: 0.1584 - val_accuracy: 0.9814\n",
            "Epoch 399/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6858e-06 - accuracy: 1.0000 - val_loss: 0.1590 - val_accuracy: 0.9813\n",
            "Epoch 400/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3733e-06 - accuracy: 1.0000 - val_loss: 0.1596 - val_accuracy: 0.9813\n",
            "Epoch 401/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0808e-06 - accuracy: 1.0000 - val_loss: 0.1606 - val_accuracy: 0.9813\n",
            "Epoch 402/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8164e-06 - accuracy: 1.0000 - val_loss: 0.1610 - val_accuracy: 0.9813\n",
            "Epoch 403/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5680e-06 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.9813\n",
            "Epoch 404/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3502e-06 - accuracy: 1.0000 - val_loss: 0.1624 - val_accuracy: 0.9811\n",
            "Epoch 405/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1575e-06 - accuracy: 1.0000 - val_loss: 0.1632 - val_accuracy: 0.9811\n",
            "Epoch 406/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9735e-06 - accuracy: 1.0000 - val_loss: 0.1641 - val_accuracy: 0.9811\n",
            "Epoch 407/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8086e-06 - accuracy: 1.0000 - val_loss: 0.1646 - val_accuracy: 0.9811\n",
            "Epoch 408/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6640e-06 - accuracy: 1.0000 - val_loss: 0.1654 - val_accuracy: 0.9813\n",
            "Epoch 409/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5208e-06 - accuracy: 1.0000 - val_loss: 0.1660 - val_accuracy: 0.9813\n",
            "Epoch 410/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3972e-06 - accuracy: 1.0000 - val_loss: 0.1669 - val_accuracy: 0.9812\n",
            "Epoch 411/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2809e-06 - accuracy: 1.0000 - val_loss: 0.1676 - val_accuracy: 0.9813\n",
            "Epoch 412/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1766e-06 - accuracy: 1.0000 - val_loss: 0.1684 - val_accuracy: 0.9814\n",
            "Epoch 413/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0811e-06 - accuracy: 1.0000 - val_loss: 0.1689 - val_accuracy: 0.9814\n",
            "Epoch 414/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.9220e-07 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 0.9814\n",
            "Epoch 415/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0999e-07 - accuracy: 1.0000 - val_loss: 0.1704 - val_accuracy: 0.9813\n",
            "Epoch 416/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.3635e-07 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 0.9813\n",
            "Epoch 417/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6760e-07 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 0.9814\n",
            "Epoch 418/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.0753e-07 - accuracy: 1.0000 - val_loss: 0.1728 - val_accuracy: 0.9813\n",
            "Epoch 419/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4683e-07 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 0.9815\n",
            "Epoch 420/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.9767e-07 - accuracy: 1.0000 - val_loss: 0.1743 - val_accuracy: 0.9814\n",
            "Epoch 421/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.4915e-07 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 0.9816\n",
            "Epoch 422/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.0653e-07 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 0.9816\n",
            "Epoch 423/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6545e-07 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 0.9815\n",
            "Epoch 424/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.2855e-07 - accuracy: 1.0000 - val_loss: 0.1771 - val_accuracy: 0.9815\n",
            "Epoch 425/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.9437e-07 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 0.9816\n",
            "Epoch 426/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6471e-07 - accuracy: 1.0000 - val_loss: 0.1788 - val_accuracy: 0.9814\n",
            "Epoch 427/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3517e-07 - accuracy: 1.0000 - val_loss: 0.1796 - val_accuracy: 0.9816\n",
            "Epoch 428/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0805e-07 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 0.9817\n",
            "Epoch 429/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8345e-07 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9819\n",
            "Epoch 430/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6162e-07 - accuracy: 1.0000 - val_loss: 0.1817 - val_accuracy: 0.9817\n",
            "Epoch 431/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4122e-07 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 0.9815\n",
            "Epoch 432/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2151e-07 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 0.9818\n",
            "Epoch 433/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0396e-07 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.9819\n",
            "Epoch 434/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8916e-07 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 0.9819\n",
            "Epoch 435/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7369e-07 - accuracy: 1.0000 - val_loss: 0.1853 - val_accuracy: 0.9819\n",
            "Epoch 436/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6006e-07 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9820\n",
            "Epoch 437/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4772e-07 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9819\n",
            "Epoch 438/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3638e-07 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 0.9821\n",
            "Epoch 439/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2600e-07 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9820\n",
            "Epoch 440/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1627e-07 - accuracy: 1.0000 - val_loss: 0.1892 - val_accuracy: 0.9821\n",
            "Epoch 441/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0703e-07 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.9820\n",
            "Epoch 442/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.9134e-08 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9821\n",
            "Epoch 443/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1489e-08 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9819\n",
            "Epoch 444/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.4649e-08 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9821\n",
            "Epoch 445/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8069e-08 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 0.9821\n",
            "Epoch 446/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.2384e-08 - accuracy: 1.0000 - val_loss: 0.1932 - val_accuracy: 0.9819\n",
            "Epoch 447/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6996e-08 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9820\n",
            "Epoch 448/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.1938e-08 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9821\n",
            "Epoch 449/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7411e-08 - accuracy: 1.0000 - val_loss: 0.1954 - val_accuracy: 0.9821\n",
            "Epoch 450/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2932e-08 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9821\n",
            "Epoch 451/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9252e-08 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.9821\n",
            "Epoch 452/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5498e-08 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 0.9820\n",
            "Epoch 453/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2338e-08 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9821\n",
            "Epoch 454/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.9193e-08 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9820\n",
            "Epoch 455/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6303e-08 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9819\n",
            "Epoch 456/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3736e-08 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9821\n",
            "Epoch 457/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1238e-08 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9819\n",
            "Epoch 458/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9061e-08 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9821\n",
            "Epoch 459/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6962e-08 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9819\n",
            "Epoch 460/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5010e-08 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9820\n",
            "Epoch 461/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3288e-08 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.9819\n",
            "Epoch 462/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1659e-08 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.9820\n",
            "Epoch 463/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0093e-08 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 0.9820\n",
            "Epoch 464/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8758e-08 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.9819\n",
            "Epoch 465/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7537e-08 - accuracy: 1.0000 - val_loss: 0.2061 - val_accuracy: 0.9821\n",
            "Epoch 466/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6377e-08 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9821\n",
            "Epoch 467/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5283e-08 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9819\n",
            "Epoch 468/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4297e-08 - accuracy: 1.0000 - val_loss: 0.2083 - val_accuracy: 0.9821\n",
            "Epoch 469/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3338e-08 - accuracy: 1.0000 - val_loss: 0.2087 - val_accuracy: 0.9819\n",
            "Epoch 470/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2488e-08 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9819\n",
            "Epoch 471/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1664e-08 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.9819\n",
            "Epoch 472/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0954e-08 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9821\n",
            "Epoch 473/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0239e-08 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9820\n",
            "Epoch 474/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5765e-09 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9820\n",
            "Epoch 475/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.0096e-09 - accuracy: 1.0000 - val_loss: 0.2126 - val_accuracy: 0.9819\n",
            "Epoch 476/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4771e-09 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9820\n",
            "Epoch 477/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.9499e-09 - accuracy: 1.0000 - val_loss: 0.2138 - val_accuracy: 0.9819\n",
            "Epoch 478/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4413e-09 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.9818\n",
            "Epoch 479/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.0042e-09 - accuracy: 1.0000 - val_loss: 0.2151 - val_accuracy: 0.9820\n",
            "Epoch 480/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5353e-09 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9820\n",
            "Epoch 481/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1883e-09 - accuracy: 1.0000 - val_loss: 0.2166 - val_accuracy: 0.9820\n",
            "Epoch 482/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7697e-09 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9821\n",
            "Epoch 483/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.4359e-09 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9819\n",
            "Epoch 484/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.1181e-09 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9820\n",
            "Epoch 485/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.8161e-09 - accuracy: 1.0000 - val_loss: 0.2191 - val_accuracy: 0.9820\n",
            "Epoch 486/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5458e-09 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9819\n",
            "Epoch 487/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.2862e-09 - accuracy: 1.0000 - val_loss: 0.2205 - val_accuracy: 0.9819\n",
            "Epoch 488/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0346e-09 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9819\n",
            "Epoch 489/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8094e-09 - accuracy: 1.0000 - val_loss: 0.2221 - val_accuracy: 0.9819\n",
            "Epoch 490/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5895e-09 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9819\n",
            "Epoch 491/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3776e-09 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.9819\n",
            "Epoch 492/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1551e-09 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9819\n",
            "Epoch 493/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0332e-09 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9819\n",
            "Epoch 494/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8981e-09 - accuracy: 1.0000 - val_loss: 0.2257 - val_accuracy: 0.9819\n",
            "Epoch 495/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7206e-09 - accuracy: 1.0000 - val_loss: 0.2264 - val_accuracy: 0.9818\n",
            "Epoch 496/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5643e-09 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9821\n",
            "Epoch 497/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4425e-09 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9819\n",
            "Epoch 498/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3233e-09 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9821\n",
            "Epoch 499/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1882e-09 - accuracy: 1.0000 - val_loss: 0.2295 - val_accuracy: 0.9821\n",
            "Epoch 500/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0795e-09 - accuracy: 1.0000 - val_loss: 0.2303 - val_accuracy: 0.9820\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0576 - accuracy: 0.9955\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1665 - accuracy: 0.9835\n",
            "train accuracy :  0.9955000281333923 train loss :  0.05757958069443703\n",
            "test accuracy :  0.9835000038146973  test loss :  0.16651412844657898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgTm-dXEPjVg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0cb2762f-6a15-48d4-8476-d49d0e0d990e"
      },
      "source": [
        "#은닉층 1개 & epochs = 1000\n",
        "model3_4 = models.Sequential([\n",
        "                            Flatten(input_shape = (28, 28)),\n",
        "                            Dense(512, activation= 'relu', kernel_initializer=initializer),\n",
        "                            Dense(512, activation= 'relu', kernel_initializer=initializer),\n",
        "                            Dense(10, activation= 'softmax', kernel_initializer=initializer)\n",
        "                            ])\n",
        "\n",
        "model3_4.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "#신경망 학습 3_4\n",
        "hist3_4 = model3_4.fit(train_x, train_y, epochs = 1000, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "plt.plot(hist3_4.history['accuracy'], 'b-')\n",
        "plt.plot(hist3_4.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train3_4 = model3_4.evaluate(train_x, train_y)\n",
        "sc_test3_4 = model3_4.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train3_4[1], \"train loss : \", sc_train3_4[0])\n",
        "print(\"test accuracy : \", sc_test3_4[1], \" test loss : \", sc_test3_4[0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "176/176 [==============================] - 2s 7ms/step - loss: 0.2948 - accuracy: 0.9136 - val_loss: 0.1487 - val_accuracy: 0.9570\n",
            "Epoch 2/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.1024 - accuracy: 0.9701 - val_loss: 0.1148 - val_accuracy: 0.9650\n",
            "Epoch 3/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0631 - accuracy: 0.9811 - val_loss: 0.1012 - val_accuracy: 0.9686\n",
            "Epoch 4/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0409 - accuracy: 0.9871 - val_loss: 0.0899 - val_accuracy: 0.9741\n",
            "Epoch 5/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0261 - accuracy: 0.9922 - val_loss: 0.0951 - val_accuracy: 0.9734\n",
            "Epoch 6/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0168 - accuracy: 0.9954 - val_loss: 0.0963 - val_accuracy: 0.9743\n",
            "Epoch 7/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.0988 - val_accuracy: 0.9753\n",
            "Epoch 8/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0097 - accuracy: 0.9973 - val_loss: 0.1075 - val_accuracy: 0.9741\n",
            "Epoch 9/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.1085 - val_accuracy: 0.9742\n",
            "Epoch 10/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.1110 - val_accuracy: 0.9739\n",
            "Epoch 11/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.1101 - val_accuracy: 0.9738\n",
            "Epoch 12/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.1135 - val_accuracy: 0.9755\n",
            "Epoch 13/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.1068 - val_accuracy: 0.9774\n",
            "Epoch 14/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0986 - val_accuracy: 0.9801\n",
            "Epoch 15/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.1265 - val_accuracy: 0.9758\n",
            "Epoch 16/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.1526 - val_accuracy: 0.9695\n",
            "Epoch 17/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.1156 - val_accuracy: 0.9769\n",
            "Epoch 18/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.1168 - val_accuracy: 0.9777\n",
            "Epoch 19/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.1347 - val_accuracy: 0.9761\n",
            "Epoch 20/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.1334 - val_accuracy: 0.9760\n",
            "Epoch 21/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.1611 - val_accuracy: 0.9689\n",
            "Epoch 22/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.1335 - val_accuracy: 0.9765\n",
            "Epoch 23/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.1504 - val_accuracy: 0.9724\n",
            "Epoch 24/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.1342 - val_accuracy: 0.9749\n",
            "Epoch 25/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.1306 - val_accuracy: 0.9743\n",
            "Epoch 26/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.1270 - val_accuracy: 0.9787\n",
            "Epoch 27/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.1330 - val_accuracy: 0.9787\n",
            "Epoch 28/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.1545 - val_accuracy: 0.9739\n",
            "Epoch 29/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.1451 - val_accuracy: 0.9769\n",
            "Epoch 30/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.1305 - val_accuracy: 0.9771\n",
            "Epoch 31/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.1368 - val_accuracy: 0.9783\n",
            "Epoch 32/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.1418 - val_accuracy: 0.9770\n",
            "Epoch 33/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.1742 - val_accuracy: 0.9755\n",
            "Epoch 34/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.1273 - val_accuracy: 0.9792\n",
            "Epoch 35/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.1387 - val_accuracy: 0.9783\n",
            "Epoch 36/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9819e-04 - accuracy: 0.9998 - val_loss: 0.1346 - val_accuracy: 0.9795\n",
            "Epoch 37/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3804e-04 - accuracy: 1.0000 - val_loss: 0.1334 - val_accuracy: 0.9792\n",
            "Epoch 38/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6062e-05 - accuracy: 1.0000 - val_loss: 0.1311 - val_accuracy: 0.9803\n",
            "Epoch 39/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7570e-05 - accuracy: 1.0000 - val_loss: 0.1315 - val_accuracy: 0.9802\n",
            "Epoch 40/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4382e-05 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 0.9806\n",
            "Epoch 41/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2365e-05 - accuracy: 1.0000 - val_loss: 0.1325 - val_accuracy: 0.9805\n",
            "Epoch 42/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0852e-05 - accuracy: 1.0000 - val_loss: 0.1331 - val_accuracy: 0.9806\n",
            "Epoch 43/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.6570e-06 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.9807\n",
            "Epoch 44/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.6640e-06 - accuracy: 1.0000 - val_loss: 0.1342 - val_accuracy: 0.9809\n",
            "Epoch 45/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8160e-06 - accuracy: 1.0000 - val_loss: 0.1347 - val_accuracy: 0.9808\n",
            "Epoch 46/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.0849e-06 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.9809\n",
            "Epoch 47/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4357e-06 - accuracy: 1.0000 - val_loss: 0.1358 - val_accuracy: 0.9811\n",
            "Epoch 48/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8733e-06 - accuracy: 1.0000 - val_loss: 0.1363 - val_accuracy: 0.9811\n",
            "Epoch 49/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3625e-06 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.9812\n",
            "Epoch 50/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.9086e-06 - accuracy: 1.0000 - val_loss: 0.1374 - val_accuracy: 0.9813\n",
            "Epoch 51/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.5012e-06 - accuracy: 1.0000 - val_loss: 0.1381 - val_accuracy: 0.9813\n",
            "Epoch 52/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.1216e-06 - accuracy: 1.0000 - val_loss: 0.1386 - val_accuracy: 0.9813\n",
            "Epoch 53/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.7937e-06 - accuracy: 1.0000 - val_loss: 0.1392 - val_accuracy: 0.9813\n",
            "Epoch 54/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4742e-06 - accuracy: 1.0000 - val_loss: 0.1399 - val_accuracy: 0.9815\n",
            "Epoch 55/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1953e-06 - accuracy: 1.0000 - val_loss: 0.1404 - val_accuracy: 0.9814\n",
            "Epoch 56/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9429e-06 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9815\n",
            "Epoch 57/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7091e-06 - accuracy: 1.0000 - val_loss: 0.1416 - val_accuracy: 0.9816\n",
            "Epoch 58/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4947e-06 - accuracy: 1.0000 - val_loss: 0.1423 - val_accuracy: 0.9817\n",
            "Epoch 59/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2945e-06 - accuracy: 1.0000 - val_loss: 0.1429 - val_accuracy: 0.9817\n",
            "Epoch 60/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1141e-06 - accuracy: 1.0000 - val_loss: 0.1434 - val_accuracy: 0.9817\n",
            "Epoch 61/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9447e-06 - accuracy: 1.0000 - val_loss: 0.1441 - val_accuracy: 0.9818\n",
            "Epoch 62/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7935e-06 - accuracy: 1.0000 - val_loss: 0.1448 - val_accuracy: 0.9817\n",
            "Epoch 63/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6436e-06 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.9819\n",
            "Epoch 64/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5214e-06 - accuracy: 1.0000 - val_loss: 0.1460 - val_accuracy: 0.9819\n",
            "Epoch 65/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3983e-06 - accuracy: 1.0000 - val_loss: 0.1466 - val_accuracy: 0.9820\n",
            "Epoch 66/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2844e-06 - accuracy: 1.0000 - val_loss: 0.1473 - val_accuracy: 0.9821\n",
            "Epoch 67/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1814e-06 - accuracy: 1.0000 - val_loss: 0.1480 - val_accuracy: 0.9821\n",
            "Epoch 68/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0908e-06 - accuracy: 1.0000 - val_loss: 0.1487 - val_accuracy: 0.9821\n",
            "Epoch 69/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0023e-06 - accuracy: 1.0000 - val_loss: 0.1494 - val_accuracy: 0.9821\n",
            "Epoch 70/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.2144e-07 - accuracy: 1.0000 - val_loss: 0.1500 - val_accuracy: 0.9821\n",
            "Epoch 71/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4718e-07 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 0.9820\n",
            "Epoch 72/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7907e-07 - accuracy: 1.0000 - val_loss: 0.1515 - val_accuracy: 0.9821\n",
            "Epoch 73/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1874e-07 - accuracy: 1.0000 - val_loss: 0.1522 - val_accuracy: 0.9821\n",
            "Epoch 74/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5907e-07 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.9821\n",
            "Epoch 75/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0633e-07 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9820\n",
            "Epoch 76/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5957e-07 - accuracy: 1.0000 - val_loss: 0.1542 - val_accuracy: 0.9821\n",
            "Epoch 77/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1120e-07 - accuracy: 1.0000 - val_loss: 0.1549 - val_accuracy: 0.9821\n",
            "Epoch 78/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.7071e-07 - accuracy: 1.0000 - val_loss: 0.1556 - val_accuracy: 0.9821\n",
            "Epoch 79/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.3360e-07 - accuracy: 1.0000 - val_loss: 0.1564 - val_accuracy: 0.9820\n",
            "Epoch 80/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9930e-07 - accuracy: 1.0000 - val_loss: 0.1571 - val_accuracy: 0.9820\n",
            "Epoch 81/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6579e-07 - accuracy: 1.0000 - val_loss: 0.1577 - val_accuracy: 0.9822\n",
            "Epoch 82/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3649e-07 - accuracy: 1.0000 - val_loss: 0.1584 - val_accuracy: 0.9821\n",
            "Epoch 83/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0972e-07 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 0.9821\n",
            "Epoch 84/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8432e-07 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9821\n",
            "Epoch 85/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6139e-07 - accuracy: 1.0000 - val_loss: 0.1607 - val_accuracy: 0.9820\n",
            "Epoch 86/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4031e-07 - accuracy: 1.0000 - val_loss: 0.1615 - val_accuracy: 0.9821\n",
            "Epoch 87/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2016e-07 - accuracy: 1.0000 - val_loss: 0.1622 - val_accuracy: 0.9820\n",
            "Epoch 88/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0242e-07 - accuracy: 1.0000 - val_loss: 0.1629 - val_accuracy: 0.9821\n",
            "Epoch 89/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8575e-07 - accuracy: 1.0000 - val_loss: 0.1637 - val_accuracy: 0.9820\n",
            "Epoch 90/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7130e-07 - accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 0.9820\n",
            "Epoch 91/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5742e-07 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9819\n",
            "Epoch 92/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4481e-07 - accuracy: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9819\n",
            "Epoch 93/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3361e-07 - accuracy: 1.0000 - val_loss: 0.1666 - val_accuracy: 0.9819\n",
            "Epoch 94/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2258e-07 - accuracy: 1.0000 - val_loss: 0.1676 - val_accuracy: 0.9819\n",
            "Epoch 95/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1246e-07 - accuracy: 1.0000 - val_loss: 0.1685 - val_accuracy: 0.9819\n",
            "Epoch 96/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0378e-07 - accuracy: 1.0000 - val_loss: 0.1690 - val_accuracy: 0.9819\n",
            "Epoch 97/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.5346e-08 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.9821\n",
            "Epoch 98/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.8371e-08 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 0.9821\n",
            "Epoch 99/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1113e-08 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 0.9821\n",
            "Epoch 100/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4813e-08 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 0.9822\n",
            "Epoch 101/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8800e-08 - accuracy: 1.0000 - val_loss: 0.1726 - val_accuracy: 0.9820\n",
            "Epoch 102/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3562e-08 - accuracy: 1.0000 - val_loss: 0.1735 - val_accuracy: 0.9821\n",
            "Epoch 103/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8460e-08 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9822\n",
            "Epoch 104/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.4044e-08 - accuracy: 1.0000 - val_loss: 0.1748 - val_accuracy: 0.9823\n",
            "Epoch 105/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.9853e-08 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 0.9821\n",
            "Epoch 106/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6121e-08 - accuracy: 1.0000 - val_loss: 0.1761 - val_accuracy: 0.9823\n",
            "Epoch 107/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.2672e-08 - accuracy: 1.0000 - val_loss: 0.1767 - val_accuracy: 0.9823\n",
            "Epoch 108/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9615e-08 - accuracy: 1.0000 - val_loss: 0.1778 - val_accuracy: 0.9824\n",
            "Epoch 109/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6486e-08 - accuracy: 1.0000 - val_loss: 0.1783 - val_accuracy: 0.9823\n",
            "Epoch 110/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3853e-08 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9823\n",
            "Epoch 111/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1381e-08 - accuracy: 1.0000 - val_loss: 0.1798 - val_accuracy: 0.9823\n",
            "Epoch 112/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9137e-08 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 0.9825\n",
            "Epoch 113/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6962e-08 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 0.9825\n",
            "Epoch 114/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5098e-08 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 0.9825\n",
            "Epoch 115/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3307e-08 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 0.9826\n",
            "Epoch 116/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1736e-08 - accuracy: 1.0000 - val_loss: 0.1830 - val_accuracy: 0.9825\n",
            "Epoch 117/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0136e-08 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9826\n",
            "Epoch 118/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8944e-08 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 0.9827\n",
            "Epoch 119/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7489e-08 - accuracy: 1.0000 - val_loss: 0.1846 - val_accuracy: 0.9826\n",
            "Epoch 120/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6273e-08 - accuracy: 1.0000 - val_loss: 0.1853 - val_accuracy: 0.9825\n",
            "Epoch 121/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5177e-08 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9825\n",
            "Epoch 122/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4236e-08 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9824\n",
            "Epoch 123/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3256e-08 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9825\n",
            "Epoch 124/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2422e-08 - accuracy: 1.0000 - val_loss: 0.1874 - val_accuracy: 0.9825\n",
            "Epoch 125/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1672e-08 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.9825\n",
            "Epoch 126/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0922e-08 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9825\n",
            "Epoch 127/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0180e-08 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9826\n",
            "Epoch 128/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5553e-09 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.9824\n",
            "Epoch 129/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.9831e-09 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9823\n",
            "Epoch 130/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.4745e-09 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9824\n",
            "Epoch 131/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.9287e-09 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.9824\n",
            "Epoch 132/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.5075e-09 - accuracy: 1.0000 - val_loss: 0.1916 - val_accuracy: 0.9824\n",
            "Epoch 133/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0784e-09 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9824\n",
            "Epoch 134/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.6280e-09 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9823\n",
            "Epoch 135/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2916e-09 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 0.9824\n",
            "Epoch 136/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9154e-09 - accuracy: 1.0000 - val_loss: 0.1932 - val_accuracy: 0.9824\n",
            "Epoch 137/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6055e-09 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9823\n",
            "Epoch 138/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2796e-09 - accuracy: 1.0000 - val_loss: 0.1940 - val_accuracy: 0.9825\n",
            "Epoch 139/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.9909e-09 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9824\n",
            "Epoch 140/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.6889e-09 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 0.9825\n",
            "Epoch 141/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.4372e-09 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 0.9825\n",
            "Epoch 142/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.2465e-09 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9825\n",
            "Epoch 143/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.0505e-09 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9824\n",
            "Epoch 144/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.8306e-09 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.9825\n",
            "Epoch 145/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6478e-09 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9824\n",
            "Epoch 146/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.4809e-09 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9825\n",
            "Epoch 147/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3485e-09 - accuracy: 1.0000 - val_loss: 0.1969 - val_accuracy: 0.9825\n",
            "Epoch 148/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1789e-09 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9825\n",
            "Epoch 149/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0306e-09 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9825\n",
            "Epoch 150/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8875e-09 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9825\n",
            "Epoch 151/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7630e-09 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9825\n",
            "Epoch 152/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6411e-09 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9825\n",
            "Epoch 153/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5431e-09 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 0.9825\n",
            "Epoch 154/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4372e-09 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 0.9825\n",
            "Epoch 155/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3339e-09 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.9825\n",
            "Epoch 156/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2332e-09 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.9826\n",
            "Epoch 157/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1776e-09 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.9825\n",
            "Epoch 158/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0928e-09 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 0.9825\n",
            "Epoch 159/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0001e-09 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9825\n",
            "Epoch 160/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9603e-09 - accuracy: 1.0000 - val_loss: 0.1994 - val_accuracy: 0.9825\n",
            "Epoch 161/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8703e-09 - accuracy: 1.0000 - val_loss: 0.1996 - val_accuracy: 0.9825\n",
            "Epoch 162/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8252e-09 - accuracy: 1.0000 - val_loss: 0.1996 - val_accuracy: 0.9825\n",
            "Epoch 163/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7511e-09 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9825\n",
            "Epoch 164/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6663e-09 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9825\n",
            "Epoch 165/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6106e-09 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9825\n",
            "Epoch 166/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5921e-09 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9824\n",
            "Epoch 167/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5100e-09 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.9823\n",
            "Epoch 168/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4782e-09 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9823\n",
            "Epoch 169/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4252e-09 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.9824\n",
            "Epoch 170/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4067e-09 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9823\n",
            "Epoch 171/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3351e-09 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9824\n",
            "Epoch 172/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3219e-09 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9825\n",
            "Epoch 173/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2424e-09 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9825\n",
            "Epoch 174/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2875e-09 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9823\n",
            "Epoch 175/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2292e-09 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9824\n",
            "Epoch 176/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1894e-09 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9823\n",
            "Epoch 177/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1735e-09 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9825\n",
            "Epoch 178/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1285e-09 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9824\n",
            "Epoch 179/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1312e-09 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9825\n",
            "Epoch 180/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1153e-09 - accuracy: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.9825\n",
            "Epoch 181/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1047e-09 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9824\n",
            "Epoch 182/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0729e-09 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9825\n",
            "Epoch 183/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0199e-09 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9825\n",
            "Epoch 184/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0226e-09 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9825\n",
            "Epoch 185/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.9871e-10 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9826\n",
            "Epoch 186/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0014e-09 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9825\n",
            "Epoch 187/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.7487e-10 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9825\n",
            "Epoch 188/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.5367e-10 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9825\n",
            "Epoch 189/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.4838e-10 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9825\n",
            "Epoch 190/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.1659e-10 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9825\n",
            "Epoch 191/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.8480e-10 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9825\n",
            "Epoch 192/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.9010e-10 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9825\n",
            "Epoch 193/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.6625e-10 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9825\n",
            "Epoch 194/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.6625e-10 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9825\n",
            "Epoch 195/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.3976e-10 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9825\n",
            "Epoch 196/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3711e-10 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9825\n",
            "Epoch 197/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.2652e-10 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9824\n",
            "Epoch 198/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.9208e-10 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9824\n",
            "Epoch 199/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8413e-10 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9825\n",
            "Epoch 200/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8678e-10 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9825\n",
            "Epoch 201/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6294e-10 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9825\n",
            "Epoch 202/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9208e-10 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9825\n",
            "Epoch 203/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.6029e-10 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9825\n",
            "Epoch 204/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7618e-10 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9825\n",
            "Epoch 205/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4440e-10 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9825\n",
            "Epoch 206/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1790e-10 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9825\n",
            "Epoch 207/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.3645e-10 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9825\n",
            "Epoch 208/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.5499e-10 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9825\n",
            "Epoch 209/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.9671e-10 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9824\n",
            "Epoch 210/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.9671e-10 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9824\n",
            "Epoch 211/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2320e-10 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9825\n",
            "Epoch 212/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.4373e-10 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9825\n",
            "Epoch 213/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.9406e-10 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9825\n",
            "Epoch 214/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7287e-10 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9825\n",
            "Epoch 215/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.4373e-10 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9825\n",
            "Epoch 216/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.4638e-10 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9825\n",
            "Epoch 217/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3048e-10 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9825\n",
            "Epoch 218/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.4108e-10 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9825\n",
            "Epoch 219/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8082e-10 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9825\n",
            "Epoch 220/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0399e-10 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9825\n",
            "Epoch 221/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4373e-10 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9825\n",
            "Epoch 222/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2519e-10 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9825\n",
            "Epoch 223/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1724e-10 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9825\n",
            "Epoch 224/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9870e-10 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9825\n",
            "Epoch 225/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1459e-10 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9825\n",
            "Epoch 226/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0664e-10 - accuracy: 1.0000 - val_loss: 0.2025 - val_accuracy: 0.9825\n",
            "Epoch 227/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0399e-10 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9825\n",
            "Epoch 228/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0399e-10 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9826\n",
            "Epoch 229/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0664e-10 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9826\n",
            "Epoch 230/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9825\n",
            "Epoch 231/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0399e-10 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 0.9825\n",
            "Epoch 232/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8015e-10 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9826\n",
            "Epoch 233/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8280e-10 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9826\n",
            "Epoch 234/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8810e-10 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 0.9827\n",
            "Epoch 235/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 0.9825\n",
            "Epoch 236/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8545e-10 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9827\n",
            "Epoch 237/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6956e-10 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.9825\n",
            "Epoch 238/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9340e-10 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9827\n",
            "Epoch 239/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8015e-10 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 0.9826\n",
            "Epoch 240/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6956e-10 - accuracy: 1.0000 - val_loss: 0.2038 - val_accuracy: 0.9827\n",
            "Epoch 241/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7750e-10 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9827\n",
            "Epoch 242/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.6426e-10 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9827\n",
            "Epoch 243/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9075e-10 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9827\n",
            "Epoch 244/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8015e-10 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 0.9826\n",
            "Epoch 245/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6691e-10 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9826\n",
            "Epoch 246/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0134e-10 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9827\n",
            "Epoch 247/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4836e-10 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.9826\n",
            "Epoch 248/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5366e-10 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9826\n",
            "Epoch 249/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5366e-10 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 0.9826\n",
            "Epoch 250/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7750e-10 - accuracy: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.9827\n",
            "Epoch 251/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8280e-10 - accuracy: 1.0000 - val_loss: 0.2053 - val_accuracy: 0.9827\n",
            "Epoch 252/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6956e-10 - accuracy: 1.0000 - val_loss: 0.2054 - val_accuracy: 0.9827\n",
            "Epoch 253/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6691e-10 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 0.9827\n",
            "Epoch 254/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8545e-10 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9826\n",
            "Epoch 255/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8280e-10 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9827\n",
            "Epoch 256/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8015e-10 - accuracy: 1.0000 - val_loss: 0.2060 - val_accuracy: 0.9827\n",
            "Epoch 257/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5101e-10 - accuracy: 1.0000 - val_loss: 0.2061 - val_accuracy: 0.9825\n",
            "Epoch 258/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9340e-10 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9825\n",
            "Epoch 259/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4571e-10 - accuracy: 1.0000 - val_loss: 0.2065 - val_accuracy: 0.9825\n",
            "Epoch 260/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9870e-10 - accuracy: 1.0000 - val_loss: 0.2066 - val_accuracy: 0.9824\n",
            "Epoch 261/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0664e-10 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9825\n",
            "Epoch 262/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2452e-10 - accuracy: 1.0000 - val_loss: 0.2071 - val_accuracy: 0.9823\n",
            "Epoch 263/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8810e-10 - accuracy: 1.0000 - val_loss: 0.2073 - val_accuracy: 0.9824\n",
            "Epoch 264/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6691e-10 - accuracy: 1.0000 - val_loss: 0.2073 - val_accuracy: 0.9825\n",
            "Epoch 265/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7485e-10 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 0.9823\n",
            "Epoch 266/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.4571e-10 - accuracy: 1.0000 - val_loss: 0.2078 - val_accuracy: 0.9823\n",
            "Epoch 267/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 0.2078 - val_accuracy: 0.9823\n",
            "Epoch 268/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.6956e-10 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9823\n",
            "Epoch 269/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.6956e-10 - accuracy: 1.0000 - val_loss: 0.2083 - val_accuracy: 0.9823\n",
            "Epoch 270/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5631e-10 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.9823\n",
            "Epoch 271/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8280e-10 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9824\n",
            "Epoch 272/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8810e-10 - accuracy: 1.0000 - val_loss: 0.2087 - val_accuracy: 0.9824\n",
            "Epoch 273/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.9075e-10 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9824\n",
            "Epoch 274/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7485e-10 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 0.9823\n",
            "Epoch 275/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.9340e-10 - accuracy: 1.0000 - val_loss: 0.2093 - val_accuracy: 0.9823\n",
            "Epoch 276/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7750e-10 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9823\n",
            "Epoch 277/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8810e-10 - accuracy: 1.0000 - val_loss: 0.2097 - val_accuracy: 0.9823\n",
            "Epoch 278/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0664e-10 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9821\n",
            "Epoch 279/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9340e-10 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.9821\n",
            "Epoch 280/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1459e-10 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 0.9821\n",
            "Epoch 281/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8810e-10 - accuracy: 1.0000 - val_loss: 0.2106 - val_accuracy: 0.9821\n",
            "Epoch 282/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9821\n",
            "Epoch 283/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1989e-10 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9821\n",
            "Epoch 284/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3048e-10 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9821\n",
            "Epoch 285/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2254e-10 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9821\n",
            "Epoch 286/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8810e-10 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9821\n",
            "Epoch 287/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1989e-10 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9821\n",
            "Epoch 288/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8810e-10 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9821\n",
            "Epoch 289/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2784e-10 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 0.9822\n",
            "Epoch 290/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3843e-10 - accuracy: 1.0000 - val_loss: 0.2125 - val_accuracy: 0.9821\n",
            "Epoch 291/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 0.2128 - val_accuracy: 0.9821\n",
            "Epoch 292/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8082e-10 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.9823\n",
            "Epoch 293/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1724e-10 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.9821\n",
            "Epoch 294/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.4108e-10 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9822\n",
            "Epoch 295/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3313e-10 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9823\n",
            "Epoch 296/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.4373e-10 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9823\n",
            "Epoch 297/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8082e-10 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.9824\n",
            "Epoch 298/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6492e-10 - accuracy: 1.0000 - val_loss: 0.2146 - val_accuracy: 0.9823\n",
            "Epoch 299/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2519e-10 - accuracy: 1.0000 - val_loss: 0.2149 - val_accuracy: 0.9823\n",
            "Epoch 300/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0201e-10 - accuracy: 1.0000 - val_loss: 0.2149 - val_accuracy: 0.9823\n",
            "Epoch 301/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4373e-10 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9822\n",
            "Epoch 302/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4638e-10 - accuracy: 1.0000 - val_loss: 0.2155 - val_accuracy: 0.9823\n",
            "Epoch 303/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8876e-10 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9823\n",
            "Epoch 304/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.4638e-10 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9823\n",
            "Epoch 305/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7287e-10 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9822\n",
            "Epoch 306/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.0201e-10 - accuracy: 1.0000 - val_loss: 0.2166 - val_accuracy: 0.9823\n",
            "Epoch 307/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8612e-10 - accuracy: 1.0000 - val_loss: 0.2170 - val_accuracy: 0.9823\n",
            "Epoch 308/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.9141e-10 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9823\n",
            "Epoch 309/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.9141e-10 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9822\n",
            "Epoch 310/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.9141e-10 - accuracy: 1.0000 - val_loss: 0.2175 - val_accuracy: 0.9822\n",
            "Epoch 311/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2585e-10 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9823\n",
            "Epoch 312/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8876e-10 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9821\n",
            "Epoch 313/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.9671e-10 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9823\n",
            "Epoch 314/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.0201e-10 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9822\n",
            "Epoch 315/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.3910e-10 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9822\n",
            "Epoch 316/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1261e-10 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 0.9821\n",
            "Epoch 317/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.0466e-10 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9822\n",
            "Epoch 318/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7354e-10 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9822\n",
            "Epoch 319/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3645e-10 - accuracy: 1.0000 - val_loss: 0.2200 - val_accuracy: 0.9822\n",
            "Epoch 320/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6029e-10 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9823\n",
            "Epoch 321/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.2320e-10 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 0.9823\n",
            "Epoch 322/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4969e-10 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9823\n",
            "Epoch 323/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2055e-10 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9822\n",
            "Epoch 324/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8413e-10 - accuracy: 1.0000 - val_loss: 0.2217 - val_accuracy: 0.9822\n",
            "Epoch 325/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.5499e-10 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9822\n",
            "Epoch 326/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6029e-10 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9822\n",
            "Epoch 327/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7089e-10 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9824\n",
            "Epoch 328/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6029e-10 - accuracy: 1.0000 - val_loss: 0.2226 - val_accuracy: 0.9822\n",
            "Epoch 329/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1062e-10 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 0.9823\n",
            "Epoch 330/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7089e-10 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9823\n",
            "Epoch 331/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8943e-10 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9824\n",
            "Epoch 332/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8413e-10 - accuracy: 1.0000 - val_loss: 0.2240 - val_accuracy: 0.9823\n",
            "Epoch 333/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.8413e-10 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 0.9823\n",
            "Epoch 334/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.2387e-10 - accuracy: 1.0000 - val_loss: 0.2245 - val_accuracy: 0.9822\n",
            "Epoch 335/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2917e-10 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9823\n",
            "Epoch 336/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1857e-10 - accuracy: 1.0000 - val_loss: 0.2251 - val_accuracy: 0.9823\n",
            "Epoch 337/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.9208e-10 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9823\n",
            "Epoch 338/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3182e-10 - accuracy: 1.0000 - val_loss: 0.2257 - val_accuracy: 0.9823\n",
            "Epoch 339/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.5036e-10 - accuracy: 1.0000 - val_loss: 0.2260 - val_accuracy: 0.9822\n",
            "Epoch 340/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9473e-10 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9822\n",
            "Epoch 341/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3182e-10 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9822\n",
            "Epoch 342/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2122e-10 - accuracy: 1.0000 - val_loss: 0.2270 - val_accuracy: 0.9822\n",
            "Epoch 343/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.3711e-10 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9823\n",
            "Epoch 344/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.5566e-10 - accuracy: 1.0000 - val_loss: 0.2273 - val_accuracy: 0.9823\n",
            "Epoch 345/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5301e-10 - accuracy: 1.0000 - val_loss: 0.2280 - val_accuracy: 0.9823\n",
            "Epoch 346/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.2122e-10 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 0.9821\n",
            "Epoch 347/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.2387e-10 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9821\n",
            "Epoch 348/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8745e-10 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9821\n",
            "Epoch 349/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.8745e-10 - accuracy: 1.0000 - val_loss: 0.2289 - val_accuracy: 0.9823\n",
            "Epoch 350/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1592e-10 - accuracy: 1.0000 - val_loss: 0.2295 - val_accuracy: 0.9821\n",
            "Epoch 351/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5301e-10 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.9821\n",
            "Epoch 352/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9804e-10 - accuracy: 1.0000 - val_loss: 0.2300 - val_accuracy: 0.9823\n",
            "Epoch 353/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8215e-10 - accuracy: 1.0000 - val_loss: 0.2302 - val_accuracy: 0.9822\n",
            "Epoch 354/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8480e-10 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.9821\n",
            "Epoch 355/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1394e-10 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.9821\n",
            "Epoch 356/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3248e-10 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.9822\n",
            "Epoch 357/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.9275e-10 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.9822\n",
            "Epoch 358/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9010e-10 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9823\n",
            "Epoch 359/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8215e-10 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9822\n",
            "Epoch 360/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5367e-10 - accuracy: 1.0000 - val_loss: 0.2326 - val_accuracy: 0.9822\n",
            "Epoch 361/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1394e-10 - accuracy: 1.0000 - val_loss: 0.2327 - val_accuracy: 0.9821\n",
            "Epoch 362/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2718e-10 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.9821\n",
            "Epoch 363/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2453e-10 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.9821\n",
            "Epoch 364/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7222e-10 - accuracy: 1.0000 - val_loss: 0.2337 - val_accuracy: 0.9822\n",
            "Epoch 365/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.6692e-10 - accuracy: 1.0000 - val_loss: 0.2341 - val_accuracy: 0.9821\n",
            "Epoch 366/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.6427e-10 - accuracy: 1.0000 - val_loss: 0.2344 - val_accuracy: 0.9821\n",
            "Epoch 367/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.4308e-10 - accuracy: 1.0000 - val_loss: 0.2348 - val_accuracy: 0.9821\n",
            "Epoch 368/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.6162e-10 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9820\n",
            "Epoch 369/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0040e-09 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9821\n",
            "Epoch 370/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5367e-10 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9821\n",
            "Epoch 371/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7222e-10 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9821\n",
            "Epoch 372/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0067e-09 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.9821\n",
            "Epoch 373/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0093e-09 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9820\n",
            "Epoch 374/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0173e-09 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9817\n",
            "Epoch 375/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0331e-09 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9819\n",
            "Epoch 376/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0146e-09 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.9821\n",
            "Epoch 377/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0358e-09 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9823\n",
            "Epoch 378/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0331e-09 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9822\n",
            "Epoch 379/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0358e-09 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9822\n",
            "Epoch 380/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0649e-09 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9821\n",
            "Epoch 381/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0384e-09 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9819\n",
            "Epoch 382/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0517e-09 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9819\n",
            "Epoch 383/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0676e-09 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9820\n",
            "Epoch 384/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0543e-09 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9821\n",
            "Epoch 385/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0861e-09 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9821\n",
            "Epoch 386/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1047e-09 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9819\n",
            "Epoch 387/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0702e-09 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9819\n",
            "Epoch 388/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0782e-09 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9822\n",
            "Epoch 389/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1285e-09 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9822\n",
            "Epoch 390/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0888e-09 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 0.9820\n",
            "Epoch 391/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0490e-09 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9821\n",
            "Epoch 392/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0808e-09 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9821\n",
            "Epoch 393/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1100e-09 - accuracy: 1.0000 - val_loss: 0.2441 - val_accuracy: 0.9820\n",
            "Epoch 394/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1100e-09 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9821\n",
            "Epoch 395/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1312e-09 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9821\n",
            "Epoch 396/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0888e-09 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9819\n",
            "Epoch 397/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1047e-09 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.9820\n",
            "Epoch 398/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1338e-09 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9821\n",
            "Epoch 399/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1232e-09 - accuracy: 1.0000 - val_loss: 0.2465 - val_accuracy: 0.9822\n",
            "Epoch 400/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1206e-09 - accuracy: 1.0000 - val_loss: 0.2471 - val_accuracy: 0.9819\n",
            "Epoch 401/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1073e-09 - accuracy: 1.0000 - val_loss: 0.2470 - val_accuracy: 0.9821\n",
            "Epoch 402/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2027e-09 - accuracy: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.9820\n",
            "Epoch 403/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1550e-09 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.9820\n",
            "Epoch 404/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1603e-09 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.9819\n",
            "Epoch 405/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2106e-09 - accuracy: 1.0000 - val_loss: 0.2486 - val_accuracy: 0.9821\n",
            "Epoch 406/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1020e-09 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9820\n",
            "Epoch 407/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1788e-09 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 0.9821\n",
            "Epoch 408/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1841e-09 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 0.9820\n",
            "Epoch 409/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2371e-09 - accuracy: 1.0000 - val_loss: 0.2508 - val_accuracy: 0.9818\n",
            "Epoch 410/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2133e-09 - accuracy: 1.0000 - val_loss: 0.2507 - val_accuracy: 0.9820\n",
            "Epoch 411/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2212e-09 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.9816\n",
            "Epoch 412/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2318e-09 - accuracy: 1.0000 - val_loss: 0.2511 - val_accuracy: 0.9819\n",
            "Epoch 413/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2053e-09 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.9819\n",
            "Epoch 414/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2159e-09 - accuracy: 1.0000 - val_loss: 0.2519 - val_accuracy: 0.9818\n",
            "Epoch 415/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2610e-09 - accuracy: 1.0000 - val_loss: 0.2523 - val_accuracy: 0.9820\n",
            "Epoch 416/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2398e-09 - accuracy: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.9817\n",
            "Epoch 417/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2265e-09 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.9817\n",
            "Epoch 418/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2265e-09 - accuracy: 1.0000 - val_loss: 0.2535 - val_accuracy: 0.9816\n",
            "Epoch 419/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2477e-09 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.9817\n",
            "Epoch 420/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2954e-09 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.9817\n",
            "Epoch 421/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2822e-09 - accuracy: 1.0000 - val_loss: 0.2551 - val_accuracy: 0.9814\n",
            "Epoch 422/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2239e-09 - accuracy: 1.0000 - val_loss: 0.2561 - val_accuracy: 0.9815\n",
            "Epoch 423/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3060e-09 - accuracy: 1.0000 - val_loss: 0.2560 - val_accuracy: 0.9814\n",
            "Epoch 424/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3034e-09 - accuracy: 1.0000 - val_loss: 0.2561 - val_accuracy: 0.9815\n",
            "Epoch 425/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2769e-09 - accuracy: 1.0000 - val_loss: 0.2570 - val_accuracy: 0.9814\n",
            "Epoch 426/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3510e-09 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.9813\n",
            "Epoch 427/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3431e-09 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.9815\n",
            "Epoch 428/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3669e-09 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.9815\n",
            "Epoch 429/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3007e-09 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9815\n",
            "Epoch 430/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3881e-09 - accuracy: 1.0000 - val_loss: 0.2582 - val_accuracy: 0.9814\n",
            "Epoch 431/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3775e-09 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.9812\n",
            "Epoch 432/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3537e-09 - accuracy: 1.0000 - val_loss: 0.2596 - val_accuracy: 0.9809\n",
            "Epoch 433/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4517e-09 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.9815\n",
            "Epoch 434/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3404e-09 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9814\n",
            "Epoch 435/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3749e-09 - accuracy: 1.0000 - val_loss: 0.2603 - val_accuracy: 0.9813\n",
            "Epoch 436/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3961e-09 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.9813\n",
            "Epoch 437/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3563e-09 - accuracy: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.9811\n",
            "Epoch 438/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4067e-09 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.9812\n",
            "Epoch 439/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4305e-09 - accuracy: 1.0000 - val_loss: 0.2627 - val_accuracy: 0.9809\n",
            "Epoch 440/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4120e-09 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.9813\n",
            "Epoch 441/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4358e-09 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9809\n",
            "Epoch 442/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5312e-09 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9813\n",
            "Epoch 443/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4252e-09 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9808\n",
            "Epoch 444/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4332e-09 - accuracy: 1.0000 - val_loss: 0.2639 - val_accuracy: 0.9808\n",
            "Epoch 445/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4676e-09 - accuracy: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.9813\n",
            "Epoch 446/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4967e-09 - accuracy: 1.0000 - val_loss: 0.2658 - val_accuracy: 0.9808\n",
            "Epoch 447/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5550e-09 - accuracy: 1.0000 - val_loss: 0.2663 - val_accuracy: 0.9807\n",
            "Epoch 448/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6186e-09 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.9811\n",
            "Epoch 449/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5471e-09 - accuracy: 1.0000 - val_loss: 0.2676 - val_accuracy: 0.9810\n",
            "Epoch 450/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6663e-09 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.9809\n",
            "Epoch 451/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5524e-09 - accuracy: 1.0000 - val_loss: 0.2676 - val_accuracy: 0.9811\n",
            "Epoch 452/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5815e-09 - accuracy: 1.0000 - val_loss: 0.2673 - val_accuracy: 0.9806\n",
            "Epoch 453/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7140e-09 - accuracy: 1.0000 - val_loss: 0.2683 - val_accuracy: 0.9807\n",
            "Epoch 454/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6610e-09 - accuracy: 1.0000 - val_loss: 0.2698 - val_accuracy: 0.9808\n",
            "Epoch 455/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6186e-09 - accuracy: 1.0000 - val_loss: 0.2689 - val_accuracy: 0.9805\n",
            "Epoch 456/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5868e-09 - accuracy: 1.0000 - val_loss: 0.2700 - val_accuracy: 0.9808\n",
            "Epoch 457/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6822e-09 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.9809\n",
            "Epoch 458/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7140e-09 - accuracy: 1.0000 - val_loss: 0.2706 - val_accuracy: 0.9807\n",
            "Epoch 459/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6583e-09 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9805\n",
            "Epoch 460/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8358e-09 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9808\n",
            "Epoch 461/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7325e-09 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.9806\n",
            "Epoch 462/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7537e-09 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9805\n",
            "Epoch 463/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8756e-09 - accuracy: 1.0000 - val_loss: 0.2752 - val_accuracy: 0.9802\n",
            "Epoch 464/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7828e-09 - accuracy: 1.0000 - val_loss: 0.2746 - val_accuracy: 0.9805\n",
            "Epoch 465/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8040e-09 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.9807\n",
            "Epoch 466/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.2080 - accuracy: 0.9895 - val_loss: 0.3494 - val_accuracy: 0.9649\n",
            "Epoch 467/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0215 - accuracy: 0.9952 - val_loss: 0.1771 - val_accuracy: 0.9767\n",
            "Epoch 468/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.1627 - val_accuracy: 0.9784\n",
            "Epoch 469/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2937e-04 - accuracy: 1.0000 - val_loss: 0.1649 - val_accuracy: 0.9787\n",
            "Epoch 470/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7450e-05 - accuracy: 1.0000 - val_loss: 0.1652 - val_accuracy: 0.9785\n",
            "Epoch 471/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6142e-05 - accuracy: 1.0000 - val_loss: 0.1656 - val_accuracy: 0.9787\n",
            "Epoch 472/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0832e-05 - accuracy: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9786\n",
            "Epoch 473/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6945e-05 - accuracy: 1.0000 - val_loss: 0.1662 - val_accuracy: 0.9787\n",
            "Epoch 474/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3938e-05 - accuracy: 1.0000 - val_loss: 0.1665 - val_accuracy: 0.9787\n",
            "Epoch 475/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1388e-05 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9788\n",
            "Epoch 476/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9333e-05 - accuracy: 1.0000 - val_loss: 0.1671 - val_accuracy: 0.9789\n",
            "Epoch 477/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7521e-05 - accuracy: 1.0000 - val_loss: 0.1674 - val_accuracy: 0.9789\n",
            "Epoch 478/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5954e-05 - accuracy: 1.0000 - val_loss: 0.1677 - val_accuracy: 0.9788\n",
            "Epoch 479/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4548e-05 - accuracy: 1.0000 - val_loss: 0.1681 - val_accuracy: 0.9789\n",
            "Epoch 480/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3338e-05 - accuracy: 1.0000 - val_loss: 0.1684 - val_accuracy: 0.9790\n",
            "Epoch 481/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2231e-05 - accuracy: 1.0000 - val_loss: 0.1688 - val_accuracy: 0.9790\n",
            "Epoch 482/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1217e-05 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9790\n",
            "Epoch 483/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0320e-05 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 0.9791\n",
            "Epoch 484/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4880e-06 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 0.9793\n",
            "Epoch 485/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7291e-06 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 0.9793\n",
            "Epoch 486/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0425e-06 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 0.9793\n",
            "Epoch 487/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4136e-06 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 0.9794\n",
            "Epoch 488/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8391e-06 - accuracy: 1.0000 - val_loss: 0.1714 - val_accuracy: 0.9795\n",
            "Epoch 489/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3100e-06 - accuracy: 1.0000 - val_loss: 0.1719 - val_accuracy: 0.9794\n",
            "Epoch 490/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8157e-06 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 0.9794\n",
            "Epoch 491/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.3724e-06 - accuracy: 1.0000 - val_loss: 0.1727 - val_accuracy: 0.9795\n",
            "Epoch 492/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9602e-06 - accuracy: 1.0000 - val_loss: 0.1732 - val_accuracy: 0.9794\n",
            "Epoch 493/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5790e-06 - accuracy: 1.0000 - val_loss: 0.1736 - val_accuracy: 0.9793\n",
            "Epoch 494/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2256e-06 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 0.9793\n",
            "Epoch 495/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9043e-06 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9792\n",
            "Epoch 496/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6094e-06 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 0.9792\n",
            "Epoch 497/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3277e-06 - accuracy: 1.0000 - val_loss: 0.1756 - val_accuracy: 0.9792\n",
            "Epoch 498/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0731e-06 - accuracy: 1.0000 - val_loss: 0.1761 - val_accuracy: 0.9793\n",
            "Epoch 499/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8374e-06 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 0.9794\n",
            "Epoch 500/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6183e-06 - accuracy: 1.0000 - val_loss: 0.1771 - val_accuracy: 0.9794\n",
            "Epoch 501/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4178e-06 - accuracy: 1.0000 - val_loss: 0.1775 - val_accuracy: 0.9794\n",
            "Epoch 502/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2317e-06 - accuracy: 1.0000 - val_loss: 0.1781 - val_accuracy: 0.9793\n",
            "Epoch 503/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0552e-06 - accuracy: 1.0000 - val_loss: 0.1786 - val_accuracy: 0.9794\n",
            "Epoch 504/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8964e-06 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9794\n",
            "Epoch 505/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7539e-06 - accuracy: 1.0000 - val_loss: 0.1797 - val_accuracy: 0.9794\n",
            "Epoch 506/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6200e-06 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 0.9796\n",
            "Epoch 507/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4938e-06 - accuracy: 1.0000 - val_loss: 0.1807 - val_accuracy: 0.9796\n",
            "Epoch 508/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3747e-06 - accuracy: 1.0000 - val_loss: 0.1813 - val_accuracy: 0.9796\n",
            "Epoch 509/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2725e-06 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9797\n",
            "Epoch 510/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1703e-06 - accuracy: 1.0000 - val_loss: 0.1824 - val_accuracy: 0.9797\n",
            "Epoch 511/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0832e-06 - accuracy: 1.0000 - val_loss: 0.1830 - val_accuracy: 0.9798\n",
            "Epoch 512/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.9463e-07 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9799\n",
            "Epoch 513/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1671e-07 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.9798\n",
            "Epoch 514/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4691e-07 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 0.9798\n",
            "Epoch 515/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7878e-07 - accuracy: 1.0000 - val_loss: 0.1853 - val_accuracy: 0.9798\n",
            "Epoch 516/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.1963e-07 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9799\n",
            "Epoch 517/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6036e-07 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 0.9799\n",
            "Epoch 518/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1007e-07 - accuracy: 1.0000 - val_loss: 0.1870 - val_accuracy: 0.9799\n",
            "Epoch 519/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.6143e-07 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9799\n",
            "Epoch 520/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1717e-07 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9798\n",
            "Epoch 521/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.7832e-07 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9799\n",
            "Epoch 522/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4006e-07 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9799\n",
            "Epoch 523/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.0539e-07 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9799\n",
            "Epoch 524/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.7342e-07 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.9798\n",
            "Epoch 525/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.4411e-07 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9800\n",
            "Epoch 526/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1719e-07 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9799\n",
            "Epoch 527/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9205e-07 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9799\n",
            "Epoch 528/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6844e-07 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9799\n",
            "Epoch 529/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4729e-07 - accuracy: 1.0000 - val_loss: 0.1940 - val_accuracy: 0.9799\n",
            "Epoch 530/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2800e-07 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9799\n",
            "Epoch 531/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1013e-07 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9799\n",
            "Epoch 532/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9335e-07 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 0.9799\n",
            "Epoch 533/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7847e-07 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9799\n",
            "Epoch 534/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6429e-07 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9799\n",
            "Epoch 535/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5143e-07 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9800\n",
            "Epoch 536/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3976e-07 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9801\n",
            "Epoch 537/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2939e-07 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.9801\n",
            "Epoch 538/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1929e-07 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9801\n",
            "Epoch 539/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0964e-07 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9799\n",
            "Epoch 540/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0136e-07 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9799\n",
            "Epoch 541/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3407e-08 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9800\n",
            "Epoch 542/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5989e-08 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9799\n",
            "Epoch 543/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9698e-08 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.9800\n",
            "Epoch 544/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3181e-08 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 0.9799\n",
            "Epoch 545/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7684e-08 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 0.9800\n",
            "Epoch 546/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2413e-08 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9800\n",
            "Epoch 547/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7809e-08 - accuracy: 1.0000 - val_loss: 0.2062 - val_accuracy: 0.9801\n",
            "Epoch 548/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.3345e-08 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9800\n",
            "Epoch 549/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9517e-08 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9800\n",
            "Epoch 550/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5713e-08 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.9801\n",
            "Epoch 551/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2431e-08 - accuracy: 1.0000 - val_loss: 0.2089 - val_accuracy: 0.9802\n",
            "Epoch 552/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9193e-08 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9801\n",
            "Epoch 553/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6168e-08 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 0.9803\n",
            "Epoch 554/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3450e-08 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9802\n",
            "Epoch 555/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1103e-08 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9801\n",
            "Epoch 556/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8780e-08 - accuracy: 1.0000 - val_loss: 0.2125 - val_accuracy: 0.9802\n",
            "Epoch 557/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6642e-08 - accuracy: 1.0000 - val_loss: 0.2131 - val_accuracy: 0.9803\n",
            "Epoch 558/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4690e-08 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9803\n",
            "Epoch 559/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2965e-08 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9803\n",
            "Epoch 560/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1285e-08 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 0.9803\n",
            "Epoch 561/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9773e-08 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9803\n",
            "Epoch 562/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8411e-08 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9804\n",
            "Epoch 563/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7079e-08 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9803\n",
            "Epoch 564/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5818e-08 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9803\n",
            "Epoch 565/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4771e-08 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9803\n",
            "Epoch 566/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3691e-08 - accuracy: 1.0000 - val_loss: 0.2195 - val_accuracy: 0.9803\n",
            "Epoch 567/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2853e-08 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9803\n",
            "Epoch 568/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1916e-08 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 0.9803\n",
            "Epoch 569/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1097e-08 - accuracy: 1.0000 - val_loss: 0.2216 - val_accuracy: 0.9803\n",
            "Epoch 570/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0337e-08 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.9803\n",
            "Epoch 571/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6639e-09 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9803\n",
            "Epoch 572/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0096e-09 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9803\n",
            "Epoch 573/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3764e-09 - accuracy: 1.0000 - val_loss: 0.2245 - val_accuracy: 0.9803\n",
            "Epoch 574/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8387e-09 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9803\n",
            "Epoch 575/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3300e-09 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9803\n",
            "Epoch 576/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.8929e-09 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9803\n",
            "Epoch 577/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.4135e-09 - accuracy: 1.0000 - val_loss: 0.2277 - val_accuracy: 0.9803\n",
            "Epoch 578/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.0081e-09 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9803\n",
            "Epoch 579/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.6320e-09 - accuracy: 1.0000 - val_loss: 0.2294 - val_accuracy: 0.9803\n",
            "Epoch 580/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.2320e-09 - accuracy: 1.0000 - val_loss: 0.2302 - val_accuracy: 0.9803\n",
            "Epoch 581/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9432e-09 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.9803\n",
            "Epoch 582/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6730e-09 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.9803\n",
            "Epoch 583/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3684e-09 - accuracy: 1.0000 - val_loss: 0.2326 - val_accuracy: 0.9802\n",
            "Epoch 584/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0664e-09 - accuracy: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.9802\n",
            "Epoch 585/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8677e-09 - accuracy: 1.0000 - val_loss: 0.2343 - val_accuracy: 0.9802\n",
            "Epoch 586/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6478e-09 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9803\n",
            "Epoch 587/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4889e-09 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9802\n",
            "Epoch 588/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2743e-09 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9802\n",
            "Epoch 589/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0544e-09 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 0.9801\n",
            "Epoch 590/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9458e-09 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9800\n",
            "Epoch 591/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7339e-09 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9799\n",
            "Epoch 592/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6385e-09 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9800\n",
            "Epoch 593/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4769e-09 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9799\n",
            "Epoch 594/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3524e-09 - accuracy: 1.0000 - val_loss: 0.2428 - val_accuracy: 0.9801\n",
            "Epoch 595/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2279e-09 - accuracy: 1.0000 - val_loss: 0.2439 - val_accuracy: 0.9801\n",
            "Epoch 596/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1537e-09 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9803\n",
            "Epoch 597/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0292e-09 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9802\n",
            "Epoch 598/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9948e-09 - accuracy: 1.0000 - val_loss: 0.2465 - val_accuracy: 0.9800\n",
            "Epoch 599/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8517e-09 - accuracy: 1.0000 - val_loss: 0.2478 - val_accuracy: 0.9801\n",
            "Epoch 600/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8146e-09 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.9801\n",
            "Epoch 601/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7484e-09 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9799\n",
            "Epoch 602/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6822e-09 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9800\n",
            "Epoch 603/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6716e-09 - accuracy: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.9799\n",
            "Epoch 604/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5762e-09 - accuracy: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.9799\n",
            "Epoch 605/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5153e-09 - accuracy: 1.0000 - val_loss: 0.2533 - val_accuracy: 0.9800\n",
            "Epoch 606/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4649e-09 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.9800\n",
            "Epoch 607/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4252e-09 - accuracy: 1.0000 - val_loss: 0.2552 - val_accuracy: 0.9800\n",
            "Epoch 608/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3537e-09 - accuracy: 1.0000 - val_loss: 0.2561 - val_accuracy: 0.9802\n",
            "Epoch 609/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3484e-09 - accuracy: 1.0000 - val_loss: 0.2571 - val_accuracy: 0.9801\n",
            "Epoch 610/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2848e-09 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.9801\n",
            "Epoch 611/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3113e-09 - accuracy: 1.0000 - val_loss: 0.2592 - val_accuracy: 0.9801\n",
            "Epoch 612/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2398e-09 - accuracy: 1.0000 - val_loss: 0.2598 - val_accuracy: 0.9803\n",
            "Epoch 613/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2212e-09 - accuracy: 1.0000 - val_loss: 0.2608 - val_accuracy: 0.9803\n",
            "Epoch 614/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1894e-09 - accuracy: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.9802\n",
            "Epoch 615/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1735e-09 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9803\n",
            "Epoch 616/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1630e-09 - accuracy: 1.0000 - val_loss: 0.2636 - val_accuracy: 0.9803\n",
            "Epoch 617/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1391e-09 - accuracy: 1.0000 - val_loss: 0.2643 - val_accuracy: 0.9803\n",
            "Epoch 618/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1285e-09 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9802\n",
            "Epoch 619/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1073e-09 - accuracy: 1.0000 - val_loss: 0.2661 - val_accuracy: 0.9802\n",
            "Epoch 620/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0729e-09 - accuracy: 1.0000 - val_loss: 0.2672 - val_accuracy: 0.9801\n",
            "Epoch 621/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0729e-09 - accuracy: 1.0000 - val_loss: 0.2682 - val_accuracy: 0.9801\n",
            "Epoch 622/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0649e-09 - accuracy: 1.0000 - val_loss: 0.2692 - val_accuracy: 0.9800\n",
            "Epoch 623/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0596e-09 - accuracy: 1.0000 - val_loss: 0.2700 - val_accuracy: 0.9800\n",
            "Epoch 624/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0384e-09 - accuracy: 1.0000 - val_loss: 0.2707 - val_accuracy: 0.9801\n",
            "Epoch 625/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0411e-09 - accuracy: 1.0000 - val_loss: 0.2714 - val_accuracy: 0.9801\n",
            "Epoch 626/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0358e-09 - accuracy: 1.0000 - val_loss: 0.2728 - val_accuracy: 0.9801\n",
            "Epoch 627/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9341e-10 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.9801\n",
            "Epoch 628/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0199e-09 - accuracy: 1.0000 - val_loss: 0.2748 - val_accuracy: 0.9801\n",
            "Epoch 629/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0331e-09 - accuracy: 1.0000 - val_loss: 0.2750 - val_accuracy: 0.9801\n",
            "Epoch 630/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0596e-09 - accuracy: 1.0000 - val_loss: 0.2757 - val_accuracy: 0.9799\n",
            "Epoch 631/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9871e-10 - accuracy: 1.0000 - val_loss: 0.2769 - val_accuracy: 0.9801\n",
            "Epoch 632/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0252e-09 - accuracy: 1.0000 - val_loss: 0.2771 - val_accuracy: 0.9799\n",
            "Epoch 633/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0384e-09 - accuracy: 1.0000 - val_loss: 0.2780 - val_accuracy: 0.9799\n",
            "Epoch 634/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0040e-09 - accuracy: 1.0000 - val_loss: 0.2794 - val_accuracy: 0.9800\n",
            "Epoch 635/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9871e-10 - accuracy: 1.0000 - val_loss: 0.2796 - val_accuracy: 0.9800\n",
            "Epoch 636/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0146e-09 - accuracy: 1.0000 - val_loss: 0.2806 - val_accuracy: 0.9798\n",
            "Epoch 637/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9606e-10 - accuracy: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.9797\n",
            "Epoch 638/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.7752e-10 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.9797\n",
            "Epoch 639/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0226e-09 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9798\n",
            "Epoch 640/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0014e-09 - accuracy: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.9798\n",
            "Epoch 641/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0199e-09 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 0.9798\n",
            "Epoch 642/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0226e-09 - accuracy: 1.0000 - val_loss: 0.2852 - val_accuracy: 0.9798\n",
            "Epoch 643/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0040e-09 - accuracy: 1.0000 - val_loss: 0.2860 - val_accuracy: 0.9799\n",
            "Epoch 644/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0146e-09 - accuracy: 1.0000 - val_loss: 0.2868 - val_accuracy: 0.9799\n",
            "Epoch 645/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0331e-09 - accuracy: 1.0000 - val_loss: 0.2875 - val_accuracy: 0.9799\n",
            "Epoch 646/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0305e-09 - accuracy: 1.0000 - val_loss: 0.2881 - val_accuracy: 0.9798\n",
            "Epoch 647/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0358e-09 - accuracy: 1.0000 - val_loss: 0.2891 - val_accuracy: 0.9796\n",
            "Epoch 648/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0437e-09 - accuracy: 1.0000 - val_loss: 0.2894 - val_accuracy: 0.9796\n",
            "Epoch 649/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0676e-09 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.9799\n",
            "Epoch 650/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0649e-09 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9798\n",
            "Epoch 651/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0226e-09 - accuracy: 1.0000 - val_loss: 0.2921 - val_accuracy: 0.9799\n",
            "Epoch 652/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0649e-09 - accuracy: 1.0000 - val_loss: 0.2922 - val_accuracy: 0.9798\n",
            "Epoch 653/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0623e-09 - accuracy: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.9799\n",
            "Epoch 654/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1073e-09 - accuracy: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.9799\n",
            "Epoch 655/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0782e-09 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.9797\n",
            "Epoch 656/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0623e-09 - accuracy: 1.0000 - val_loss: 0.2948 - val_accuracy: 0.9797\n",
            "Epoch 657/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1232e-09 - accuracy: 1.0000 - val_loss: 0.2968 - val_accuracy: 0.9797\n",
            "Epoch 658/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1047e-09 - accuracy: 1.0000 - val_loss: 0.2957 - val_accuracy: 0.9796\n",
            "Epoch 659/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0782e-09 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.9799\n",
            "Epoch 660/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0914e-09 - accuracy: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.9798\n",
            "Epoch 661/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1577e-09 - accuracy: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.9797\n",
            "Epoch 662/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1259e-09 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.9798\n",
            "Epoch 663/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1100e-09 - accuracy: 1.0000 - val_loss: 0.2991 - val_accuracy: 0.9797\n",
            "Epoch 664/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1020e-09 - accuracy: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.9797\n",
            "Epoch 665/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0543e-09 - accuracy: 1.0000 - val_loss: 0.3004 - val_accuracy: 0.9797\n",
            "Epoch 666/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0941e-09 - accuracy: 1.0000 - val_loss: 0.3006 - val_accuracy: 0.9798\n",
            "Epoch 667/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1788e-09 - accuracy: 1.0000 - val_loss: 0.3013 - val_accuracy: 0.9799\n",
            "Epoch 668/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1841e-09 - accuracy: 1.0000 - val_loss: 0.3026 - val_accuracy: 0.9797\n",
            "Epoch 669/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0861e-09 - accuracy: 1.0000 - val_loss: 0.3033 - val_accuracy: 0.9797\n",
            "Epoch 670/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1073e-09 - accuracy: 1.0000 - val_loss: 0.3029 - val_accuracy: 0.9798\n",
            "Epoch 671/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0702e-09 - accuracy: 1.0000 - val_loss: 0.3029 - val_accuracy: 0.9797\n",
            "Epoch 672/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1047e-09 - accuracy: 1.0000 - val_loss: 0.3037 - val_accuracy: 0.9798\n",
            "Epoch 673/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0967e-09 - accuracy: 1.0000 - val_loss: 0.3036 - val_accuracy: 0.9797\n",
            "Epoch 674/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0755e-09 - accuracy: 1.0000 - val_loss: 0.3049 - val_accuracy: 0.9798\n",
            "Epoch 675/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1471e-09 - accuracy: 1.0000 - val_loss: 0.3046 - val_accuracy: 0.9795\n",
            "Epoch 676/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1735e-09 - accuracy: 1.0000 - val_loss: 0.3065 - val_accuracy: 0.9797\n",
            "Epoch 677/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1603e-09 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.9797\n",
            "Epoch 678/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1497e-09 - accuracy: 1.0000 - val_loss: 0.3073 - val_accuracy: 0.9799\n",
            "Epoch 679/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3113e-09 - accuracy: 1.0000 - val_loss: 0.3072 - val_accuracy: 0.9797\n",
            "Epoch 680/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1841e-09 - accuracy: 1.0000 - val_loss: 0.3085 - val_accuracy: 0.9799\n",
            "Epoch 681/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0727 - accuracy: 0.9945 - val_loss: 0.4922 - val_accuracy: 0.9618\n",
            "Epoch 682/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0392 - accuracy: 0.9926 - val_loss: 0.2015 - val_accuracy: 0.9759\n",
            "Epoch 683/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.1912 - val_accuracy: 0.9775\n",
            "Epoch 684/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0347e-04 - accuracy: 0.9998 - val_loss: 0.1860 - val_accuracy: 0.9776\n",
            "Epoch 685/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6028e-05 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9780\n",
            "Epoch 686/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1919e-05 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9780\n",
            "Epoch 687/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7677e-05 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9781\n",
            "Epoch 688/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5008e-05 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9783\n",
            "Epoch 689/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3080e-05 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 0.9783\n",
            "Epoch 690/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1553e-05 - accuracy: 1.0000 - val_loss: 0.1864 - val_accuracy: 0.9783\n",
            "Epoch 691/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0320e-05 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9784\n",
            "Epoch 692/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2384e-06 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9785\n",
            "Epoch 693/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.3519e-06 - accuracy: 1.0000 - val_loss: 0.1874 - val_accuracy: 0.9785\n",
            "Epoch 694/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.5351e-06 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 0.9786\n",
            "Epoch 695/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8320e-06 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9785\n",
            "Epoch 696/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2182e-06 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 0.9784\n",
            "Epoch 697/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.6576e-06 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9785\n",
            "Epoch 698/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1525e-06 - accuracy: 1.0000 - val_loss: 0.1892 - val_accuracy: 0.9786\n",
            "Epoch 699/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7452e-06 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9784\n",
            "Epoch 700/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.3411e-06 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9785\n",
            "Epoch 701/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.9756e-06 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9785\n",
            "Epoch 702/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6337e-06 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9784\n",
            "Epoch 703/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2329e-06 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9786\n",
            "Epoch 704/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9226e-06 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9786\n",
            "Epoch 705/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5772e-06 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9786\n",
            "Epoch 706/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2361e-06 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9787\n",
            "Epoch 707/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9389e-06 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9787\n",
            "Epoch 708/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5332e-06 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9787\n",
            "Epoch 709/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2484e-06 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9789\n",
            "Epoch 710/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0383e-06 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.9790\n",
            "Epoch 711/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2258e-07 - accuracy: 1.0000 - val_loss: 0.2204 - val_accuracy: 0.9789\n",
            "Epoch 712/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.0434e-07 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 0.9789\n",
            "Epoch 713/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.9083e-07 - accuracy: 1.0000 - val_loss: 0.2265 - val_accuracy: 0.9793\n",
            "Epoch 714/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2080e-07 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.9789\n",
            "Epoch 715/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4948e-07 - accuracy: 1.0000 - val_loss: 0.2326 - val_accuracy: 0.9792\n",
            "Epoch 716/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0208e-07 - accuracy: 1.0000 - val_loss: 0.2345 - val_accuracy: 0.9788\n",
            "Epoch 717/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6241e-07 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9790\n",
            "Epoch 718/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2324e-07 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 0.9791\n",
            "Epoch 719/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8896e-07 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.9792\n",
            "Epoch 720/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6365e-07 - accuracy: 1.0000 - val_loss: 0.2415 - val_accuracy: 0.9790\n",
            "Epoch 721/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3532e-07 - accuracy: 1.0000 - val_loss: 0.2429 - val_accuracy: 0.9792\n",
            "Epoch 722/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3280e-07 - accuracy: 1.0000 - val_loss: 0.2432 - val_accuracy: 0.9793\n",
            "Epoch 723/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0041e-07 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9793\n",
            "Epoch 724/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8467e-07 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9789\n",
            "Epoch 725/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7176e-07 - accuracy: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.9790\n",
            "Epoch 726/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5756e-07 - accuracy: 1.0000 - val_loss: 0.2482 - val_accuracy: 0.9791\n",
            "Epoch 727/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4995e-07 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9789\n",
            "Epoch 728/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4308e-07 - accuracy: 1.0000 - val_loss: 0.2503 - val_accuracy: 0.9793\n",
            "Epoch 729/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3240e-07 - accuracy: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.9789\n",
            "Epoch 730/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2087e-07 - accuracy: 1.0000 - val_loss: 0.2519 - val_accuracy: 0.9791\n",
            "Epoch 731/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1458e-07 - accuracy: 1.0000 - val_loss: 0.2537 - val_accuracy: 0.9789\n",
            "Epoch 732/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0949e-07 - accuracy: 1.0000 - val_loss: 0.2537 - val_accuracy: 0.9789\n",
            "Epoch 733/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9937e-08 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.9791\n",
            "Epoch 734/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.4095e-08 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.9792\n",
            "Epoch 735/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1722e-08 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.9790\n",
            "Epoch 736/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1581e-08 - accuracy: 1.0000 - val_loss: 0.2571 - val_accuracy: 0.9791\n",
            "Epoch 737/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8826e-08 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.9789\n",
            "Epoch 738/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.2328e-08 - accuracy: 1.0000 - val_loss: 0.2587 - val_accuracy: 0.9791\n",
            "Epoch 739/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.9901e-08 - accuracy: 1.0000 - val_loss: 0.2593 - val_accuracy: 0.9789\n",
            "Epoch 740/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2860e-08 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.9789\n",
            "Epoch 741/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0717e-08 - accuracy: 1.0000 - val_loss: 0.2608 - val_accuracy: 0.9792\n",
            "Epoch 742/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.6216e-08 - accuracy: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.9793\n",
            "Epoch 743/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.3130e-08 - accuracy: 1.0000 - val_loss: 0.2625 - val_accuracy: 0.9791\n",
            "Epoch 744/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.9747e-08 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9791\n",
            "Epoch 745/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.6563e-08 - accuracy: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.9789\n",
            "Epoch 746/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4134e-08 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9793\n",
            "Epoch 747/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0717e-08 - accuracy: 1.0000 - val_loss: 0.2655 - val_accuracy: 0.9791\n",
            "Epoch 748/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8565e-08 - accuracy: 1.0000 - val_loss: 0.2656 - val_accuracy: 0.9792\n",
            "Epoch 749/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6393e-08 - accuracy: 1.0000 - val_loss: 0.2664 - val_accuracy: 0.9792\n",
            "Epoch 750/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4160e-08 - accuracy: 1.0000 - val_loss: 0.2674 - val_accuracy: 0.9791\n",
            "Epoch 751/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1567e-08 - accuracy: 1.0000 - val_loss: 0.2677 - val_accuracy: 0.9791\n",
            "Epoch 752/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9813e-08 - accuracy: 1.0000 - val_loss: 0.2688 - val_accuracy: 0.9791\n",
            "Epoch 753/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7903e-08 - accuracy: 1.0000 - val_loss: 0.2693 - val_accuracy: 0.9791\n",
            "Epoch 754/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6316e-08 - accuracy: 1.0000 - val_loss: 0.2697 - val_accuracy: 0.9791\n",
            "Epoch 755/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4565e-08 - accuracy: 1.0000 - val_loss: 0.2706 - val_accuracy: 0.9793\n",
            "Epoch 756/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3108e-08 - accuracy: 1.0000 - val_loss: 0.2714 - val_accuracy: 0.9791\n",
            "Epoch 757/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1606e-08 - accuracy: 1.0000 - val_loss: 0.2717 - val_accuracy: 0.9792\n",
            "Epoch 758/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0077e-08 - accuracy: 1.0000 - val_loss: 0.2725 - val_accuracy: 0.9791\n",
            "Epoch 759/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8936e-08 - accuracy: 1.0000 - val_loss: 0.2731 - val_accuracy: 0.9793\n",
            "Epoch 760/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7579e-08 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9791\n",
            "Epoch 761/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6697e-08 - accuracy: 1.0000 - val_loss: 0.2746 - val_accuracy: 0.9791\n",
            "Epoch 762/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5571e-08 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9793\n",
            "Epoch 763/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4626e-08 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9791\n",
            "Epoch 764/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3706e-08 - accuracy: 1.0000 - val_loss: 0.2767 - val_accuracy: 0.9791\n",
            "Epoch 765/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2806e-08 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.9795\n",
            "Epoch 766/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2027e-08 - accuracy: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.9795\n",
            "Epoch 767/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1269e-08 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9794\n",
            "Epoch 768/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0501e-08 - accuracy: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.9795\n",
            "Epoch 769/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.8917e-09 - accuracy: 1.0000 - val_loss: 0.2805 - val_accuracy: 0.9795\n",
            "Epoch 770/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.2798e-09 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9796\n",
            "Epoch 771/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.6811e-09 - accuracy: 1.0000 - val_loss: 0.2818 - val_accuracy: 0.9797\n",
            "Epoch 772/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.1460e-09 - accuracy: 1.0000 - val_loss: 0.2823 - val_accuracy: 0.9796\n",
            "Epoch 773/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6294e-09 - accuracy: 1.0000 - val_loss: 0.2834 - val_accuracy: 0.9796\n",
            "Epoch 774/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2002e-09 - accuracy: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.9797\n",
            "Epoch 775/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7472e-09 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.9797\n",
            "Epoch 776/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.3260e-09 - accuracy: 1.0000 - val_loss: 0.2854 - val_accuracy: 0.9799\n",
            "Epoch 777/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.9154e-09 - accuracy: 1.0000 - val_loss: 0.2860 - val_accuracy: 0.9798\n",
            "Epoch 778/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5843e-09 - accuracy: 1.0000 - val_loss: 0.2868 - val_accuracy: 0.9798\n",
            "Epoch 779/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2293e-09 - accuracy: 1.0000 - val_loss: 0.2878 - val_accuracy: 0.9799\n",
            "Epoch 780/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.9459e-09 - accuracy: 1.0000 - val_loss: 0.2887 - val_accuracy: 0.9798\n",
            "Epoch 781/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6359e-09 - accuracy: 1.0000 - val_loss: 0.2893 - val_accuracy: 0.9799\n",
            "Epoch 782/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3445e-09 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9799\n",
            "Epoch 783/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1220e-09 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.9799\n",
            "Epoch 784/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8703e-09 - accuracy: 1.0000 - val_loss: 0.2916 - val_accuracy: 0.9798\n",
            "Epoch 785/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6160e-09 - accuracy: 1.0000 - val_loss: 0.2924 - val_accuracy: 0.9799\n",
            "Epoch 786/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.4279e-09 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.9799\n",
            "Epoch 787/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2690e-09 - accuracy: 1.0000 - val_loss: 0.2938 - val_accuracy: 0.9800\n",
            "Epoch 788/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0677e-09 - accuracy: 1.0000 - val_loss: 0.2949 - val_accuracy: 0.9797\n",
            "Epoch 789/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9034e-09 - accuracy: 1.0000 - val_loss: 0.2957 - val_accuracy: 0.9799\n",
            "Epoch 790/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7418e-09 - accuracy: 1.0000 - val_loss: 0.2962 - val_accuracy: 0.9799\n",
            "Epoch 791/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5564e-09 - accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.9798\n",
            "Epoch 792/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4531e-09 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.9798\n",
            "Epoch 793/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3153e-09 - accuracy: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.9797\n",
            "Epoch 794/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1405e-09 - accuracy: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.9798\n",
            "Epoch 795/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0478e-09 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.9799\n",
            "Epoch 796/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9577e-09 - accuracy: 1.0000 - val_loss: 0.3019 - val_accuracy: 0.9799\n",
            "Epoch 797/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8756e-09 - accuracy: 1.0000 - val_loss: 0.3026 - val_accuracy: 0.9798\n",
            "Epoch 798/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7802e-09 - accuracy: 1.0000 - val_loss: 0.3036 - val_accuracy: 0.9799\n",
            "Epoch 799/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6716e-09 - accuracy: 1.0000 - val_loss: 0.3046 - val_accuracy: 0.9797\n",
            "Epoch 800/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6239e-09 - accuracy: 1.0000 - val_loss: 0.3058 - val_accuracy: 0.9799\n",
            "Epoch 801/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5365e-09 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.9798\n",
            "Epoch 802/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5179e-09 - accuracy: 1.0000 - val_loss: 0.3076 - val_accuracy: 0.9799\n",
            "Epoch 803/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4093e-09 - accuracy: 1.0000 - val_loss: 0.3084 - val_accuracy: 0.9798\n",
            "Epoch 804/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3775e-09 - accuracy: 1.0000 - val_loss: 0.3095 - val_accuracy: 0.9799\n",
            "Epoch 805/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3404e-09 - accuracy: 1.0000 - val_loss: 0.3104 - val_accuracy: 0.9797\n",
            "Epoch 806/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2742e-09 - accuracy: 1.0000 - val_loss: 0.3113 - val_accuracy: 0.9798\n",
            "Epoch 807/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2106e-09 - accuracy: 1.0000 - val_loss: 0.3125 - val_accuracy: 0.9797\n",
            "Epoch 808/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1683e-09 - accuracy: 1.0000 - val_loss: 0.3135 - val_accuracy: 0.9796\n",
            "Epoch 809/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1497e-09 - accuracy: 1.0000 - val_loss: 0.3146 - val_accuracy: 0.9796\n",
            "Epoch 810/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0861e-09 - accuracy: 1.0000 - val_loss: 0.3158 - val_accuracy: 0.9795\n",
            "Epoch 811/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1020e-09 - accuracy: 1.0000 - val_loss: 0.3165 - val_accuracy: 0.9797\n",
            "Epoch 812/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0490e-09 - accuracy: 1.0000 - val_loss: 0.3177 - val_accuracy: 0.9796\n",
            "Epoch 813/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0067e-09 - accuracy: 1.0000 - val_loss: 0.3189 - val_accuracy: 0.9795\n",
            "Epoch 814/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0384e-09 - accuracy: 1.0000 - val_loss: 0.3198 - val_accuracy: 0.9795\n",
            "Epoch 815/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0146e-09 - accuracy: 1.0000 - val_loss: 0.3209 - val_accuracy: 0.9795\n",
            "Epoch 816/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9341e-10 - accuracy: 1.0000 - val_loss: 0.3219 - val_accuracy: 0.9796\n",
            "Epoch 817/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7487e-10 - accuracy: 1.0000 - val_loss: 0.3227 - val_accuracy: 0.9795\n",
            "Epoch 818/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5897e-10 - accuracy: 1.0000 - val_loss: 0.3239 - val_accuracy: 0.9793\n",
            "Epoch 819/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4838e-10 - accuracy: 1.0000 - val_loss: 0.3247 - val_accuracy: 0.9793\n",
            "Epoch 820/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.1129e-10 - accuracy: 1.0000 - val_loss: 0.3258 - val_accuracy: 0.9794\n",
            "Epoch 821/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0599e-10 - accuracy: 1.0000 - val_loss: 0.3269 - val_accuracy: 0.9793\n",
            "Epoch 822/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0599e-10 - accuracy: 1.0000 - val_loss: 0.3273 - val_accuracy: 0.9795\n",
            "Epoch 823/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.9010e-10 - accuracy: 1.0000 - val_loss: 0.3285 - val_accuracy: 0.9793\n",
            "Epoch 824/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.5301e-10 - accuracy: 1.0000 - val_loss: 0.3293 - val_accuracy: 0.9792\n",
            "Epoch 825/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7155e-10 - accuracy: 1.0000 - val_loss: 0.3299 - val_accuracy: 0.9795\n",
            "Epoch 826/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3446e-10 - accuracy: 1.0000 - val_loss: 0.3311 - val_accuracy: 0.9792\n",
            "Epoch 827/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2122e-10 - accuracy: 1.0000 - val_loss: 0.3321 - val_accuracy: 0.9792\n",
            "Epoch 828/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6361e-10 - accuracy: 1.0000 - val_loss: 0.3329 - val_accuracy: 0.9793\n",
            "Epoch 829/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5831e-10 - accuracy: 1.0000 - val_loss: 0.3333 - val_accuracy: 0.9794\n",
            "Epoch 830/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.3976e-10 - accuracy: 1.0000 - val_loss: 0.3345 - val_accuracy: 0.9794\n",
            "Epoch 831/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.1857e-10 - accuracy: 1.0000 - val_loss: 0.3353 - val_accuracy: 0.9793\n",
            "Epoch 832/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2917e-10 - accuracy: 1.0000 - val_loss: 0.3359 - val_accuracy: 0.9793\n",
            "Epoch 833/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9738e-10 - accuracy: 1.0000 - val_loss: 0.3369 - val_accuracy: 0.9793\n",
            "Epoch 834/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1327e-10 - accuracy: 1.0000 - val_loss: 0.3373 - val_accuracy: 0.9793\n",
            "Epoch 835/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5499e-10 - accuracy: 1.0000 - val_loss: 0.3381 - val_accuracy: 0.9793\n",
            "Epoch 836/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.0532e-10 - accuracy: 1.0000 - val_loss: 0.3386 - val_accuracy: 0.9793\n",
            "Epoch 837/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.6824e-10 - accuracy: 1.0000 - val_loss: 0.3396 - val_accuracy: 0.9793\n",
            "Epoch 838/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8148e-10 - accuracy: 1.0000 - val_loss: 0.3408 - val_accuracy: 0.9794\n",
            "Epoch 839/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8148e-10 - accuracy: 1.0000 - val_loss: 0.3411 - val_accuracy: 0.9793\n",
            "Epoch 840/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.8413e-10 - accuracy: 1.0000 - val_loss: 0.3419 - val_accuracy: 0.9793\n",
            "Epoch 841/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8148e-10 - accuracy: 1.0000 - val_loss: 0.3426 - val_accuracy: 0.9793\n",
            "Epoch 842/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7354e-10 - accuracy: 1.0000 - val_loss: 0.3427 - val_accuracy: 0.9795\n",
            "Epoch 843/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.6559e-10 - accuracy: 1.0000 - val_loss: 0.3441 - val_accuracy: 0.9793\n",
            "Epoch 844/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6294e-10 - accuracy: 1.0000 - val_loss: 0.3441 - val_accuracy: 0.9793\n",
            "Epoch 845/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6824e-10 - accuracy: 1.0000 - val_loss: 0.3456 - val_accuracy: 0.9789\n",
            "Epoch 846/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5234e-10 - accuracy: 1.0000 - val_loss: 0.3461 - val_accuracy: 0.9792\n",
            "Epoch 847/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8678e-10 - accuracy: 1.0000 - val_loss: 0.3469 - val_accuracy: 0.9793\n",
            "Epoch 848/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5499e-10 - accuracy: 1.0000 - val_loss: 0.3474 - val_accuracy: 0.9790\n",
            "Epoch 849/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.6096e-10 - accuracy: 1.0000 - val_loss: 0.3477 - val_accuracy: 0.9792\n",
            "Epoch 850/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9208e-10 - accuracy: 1.0000 - val_loss: 0.3488 - val_accuracy: 0.9791\n",
            "Epoch 851/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3380e-10 - accuracy: 1.0000 - val_loss: 0.3489 - val_accuracy: 0.9791\n",
            "Epoch 852/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1857e-10 - accuracy: 1.0000 - val_loss: 0.3500 - val_accuracy: 0.9790\n",
            "Epoch 853/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8148e-10 - accuracy: 1.0000 - val_loss: 0.3507 - val_accuracy: 0.9792\n",
            "Epoch 854/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4969e-10 - accuracy: 1.0000 - val_loss: 0.3509 - val_accuracy: 0.9791\n",
            "Epoch 855/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0532e-10 - accuracy: 1.0000 - val_loss: 0.3515 - val_accuracy: 0.9790\n",
            "Epoch 856/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0532e-10 - accuracy: 1.0000 - val_loss: 0.3529 - val_accuracy: 0.9791\n",
            "Epoch 857/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0797e-10 - accuracy: 1.0000 - val_loss: 0.3533 - val_accuracy: 0.9788\n",
            "Epoch 858/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8943e-10 - accuracy: 1.0000 - val_loss: 0.3533 - val_accuracy: 0.9790\n",
            "Epoch 859/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.9738e-10 - accuracy: 1.0000 - val_loss: 0.3545 - val_accuracy: 0.9789\n",
            "Epoch 860/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8678e-10 - accuracy: 1.0000 - val_loss: 0.3549 - val_accuracy: 0.9790\n",
            "Epoch 861/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.6294e-10 - accuracy: 1.0000 - val_loss: 0.3555 - val_accuracy: 0.9790\n",
            "Epoch 862/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.1062e-10 - accuracy: 1.0000 - val_loss: 0.3568 - val_accuracy: 0.9790\n",
            "Epoch 863/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.0532e-10 - accuracy: 1.0000 - val_loss: 0.3571 - val_accuracy: 0.9790\n",
            "Epoch 864/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1062e-10 - accuracy: 1.0000 - val_loss: 0.3576 - val_accuracy: 0.9789\n",
            "Epoch 865/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.1857e-10 - accuracy: 1.0000 - val_loss: 0.3586 - val_accuracy: 0.9789\n",
            "Epoch 866/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.8148e-10 - accuracy: 1.0000 - val_loss: 0.3588 - val_accuracy: 0.9790\n",
            "Epoch 867/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3446e-10 - accuracy: 1.0000 - val_loss: 0.3598 - val_accuracy: 0.9790\n",
            "Epoch 868/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1857e-10 - accuracy: 1.0000 - val_loss: 0.3603 - val_accuracy: 0.9789\n",
            "Epoch 869/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0596e-09 - accuracy: 1.0000 - val_loss: 0.3605 - val_accuracy: 0.9785\n",
            "Epoch 870/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1482 - accuracy: 0.9870 - val_loss: 0.2424 - val_accuracy: 0.9765\n",
            "Epoch 871/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.2306 - val_accuracy: 0.9770\n",
            "Epoch 872/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.2226 - val_accuracy: 0.9784\n",
            "Epoch 873/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.1581e-04 - accuracy: 0.9999 - val_loss: 0.2128 - val_accuracy: 0.9793\n",
            "Epoch 874/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9199e-05 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9795\n",
            "Epoch 875/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0875e-05 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9795\n",
            "Epoch 876/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8094e-06 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9796\n",
            "Epoch 877/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3284e-06 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9797\n",
            "Epoch 878/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.1241e-06 - accuracy: 1.0000 - val_loss: 0.2170 - val_accuracy: 0.9797\n",
            "Epoch 879/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3947e-06 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.9795\n",
            "Epoch 880/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3249e-06 - accuracy: 1.0000 - val_loss: 0.2282 - val_accuracy: 0.9794\n",
            "Epoch 881/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3474e-06 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9795\n",
            "Epoch 882/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9741e-06 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9793\n",
            "Epoch 883/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4924e-06 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.9793\n",
            "Epoch 884/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2745e-06 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9793\n",
            "Epoch 885/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0391e-06 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.9793\n",
            "Epoch 886/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9921e-07 - accuracy: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.9792\n",
            "Epoch 887/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7294e-07 - accuracy: 1.0000 - val_loss: 0.2546 - val_accuracy: 0.9791\n",
            "Epoch 888/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4097e-07 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9792\n",
            "Epoch 889/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3773e-07 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.9792\n",
            "Epoch 890/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.6061e-07 - accuracy: 1.0000 - val_loss: 0.2609 - val_accuracy: 0.9791\n",
            "Epoch 891/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0355e-07 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9791\n",
            "Epoch 892/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6972e-07 - accuracy: 1.0000 - val_loss: 0.2639 - val_accuracy: 0.9795\n",
            "Epoch 893/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2608e-07 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.9794\n",
            "Epoch 894/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8989e-07 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9793\n",
            "Epoch 895/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5345e-07 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.9793\n",
            "Epoch 896/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2562e-07 - accuracy: 1.0000 - val_loss: 0.2709 - val_accuracy: 0.9793\n",
            "Epoch 897/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9918e-07 - accuracy: 1.0000 - val_loss: 0.2717 - val_accuracy: 0.9792\n",
            "Epoch 898/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9478e-07 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9793\n",
            "Epoch 899/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6620e-07 - accuracy: 1.0000 - val_loss: 0.2737 - val_accuracy: 0.9795\n",
            "Epoch 900/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4453e-07 - accuracy: 1.0000 - val_loss: 0.2763 - val_accuracy: 0.9793\n",
            "Epoch 901/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2635e-07 - accuracy: 1.0000 - val_loss: 0.2761 - val_accuracy: 0.9796\n",
            "Epoch 902/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1155e-07 - accuracy: 1.0000 - val_loss: 0.2779 - val_accuracy: 0.9794\n",
            "Epoch 903/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9633e-07 - accuracy: 1.0000 - val_loss: 0.2797 - val_accuracy: 0.9794\n",
            "Epoch 904/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8004e-07 - accuracy: 1.0000 - val_loss: 0.2818 - val_accuracy: 0.9795\n",
            "Epoch 905/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7381e-07 - accuracy: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.9794\n",
            "Epoch 906/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5808e-07 - accuracy: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.9792\n",
            "Epoch 907/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5518e-07 - accuracy: 1.0000 - val_loss: 0.2836 - val_accuracy: 0.9795\n",
            "Epoch 908/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5155e-07 - accuracy: 1.0000 - val_loss: 0.2833 - val_accuracy: 0.9797\n",
            "Epoch 909/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3350e-07 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.9795\n",
            "Epoch 910/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2529e-07 - accuracy: 1.0000 - val_loss: 0.2854 - val_accuracy: 0.9795\n",
            "Epoch 911/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2005e-07 - accuracy: 1.0000 - val_loss: 0.2856 - val_accuracy: 0.9795\n",
            "Epoch 912/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0958e-07 - accuracy: 1.0000 - val_loss: 0.2876 - val_accuracy: 0.9793\n",
            "Epoch 913/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0549e-07 - accuracy: 1.0000 - val_loss: 0.2876 - val_accuracy: 0.9795\n",
            "Epoch 914/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0087e-07 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.9795\n",
            "Epoch 915/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4596e-08 - accuracy: 1.0000 - val_loss: 0.2888 - val_accuracy: 0.9796\n",
            "Epoch 916/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7758e-08 - accuracy: 1.0000 - val_loss: 0.2892 - val_accuracy: 0.9794\n",
            "Epoch 917/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.3803e-08 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.9798\n",
            "Epoch 918/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0087e-08 - accuracy: 1.0000 - val_loss: 0.2914 - val_accuracy: 0.9796\n",
            "Epoch 919/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4164e-08 - accuracy: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.9795\n",
            "Epoch 920/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.9766e-08 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9795\n",
            "Epoch 921/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7053e-08 - accuracy: 1.0000 - val_loss: 0.2924 - val_accuracy: 0.9796\n",
            "Epoch 922/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.2301e-08 - accuracy: 1.0000 - val_loss: 0.2935 - val_accuracy: 0.9795\n",
            "Epoch 923/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.8781e-08 - accuracy: 1.0000 - val_loss: 0.2945 - val_accuracy: 0.9796\n",
            "Epoch 924/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5427e-08 - accuracy: 1.0000 - val_loss: 0.2946 - val_accuracy: 0.9796\n",
            "Epoch 925/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3141e-08 - accuracy: 1.0000 - val_loss: 0.2954 - val_accuracy: 0.9797\n",
            "Epoch 926/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.9657e-08 - accuracy: 1.0000 - val_loss: 0.2957 - val_accuracy: 0.9795\n",
            "Epoch 927/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6958e-08 - accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.9797\n",
            "Epoch 928/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3683e-08 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.9797\n",
            "Epoch 929/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.2171e-08 - accuracy: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.9797\n",
            "Epoch 930/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9154e-08 - accuracy: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.9797\n",
            "Epoch 931/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6851e-08 - accuracy: 1.0000 - val_loss: 0.2992 - val_accuracy: 0.9798\n",
            "Epoch 932/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5156e-08 - accuracy: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.9797\n",
            "Epoch 933/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3299e-08 - accuracy: 1.0000 - val_loss: 0.2995 - val_accuracy: 0.9797\n",
            "Epoch 934/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1635e-08 - accuracy: 1.0000 - val_loss: 0.3001 - val_accuracy: 0.9797\n",
            "Epoch 935/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9283e-08 - accuracy: 1.0000 - val_loss: 0.3005 - val_accuracy: 0.9797\n",
            "Epoch 936/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7556e-08 - accuracy: 1.0000 - val_loss: 0.3012 - val_accuracy: 0.9797\n",
            "Epoch 937/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6226e-08 - accuracy: 1.0000 - val_loss: 0.3021 - val_accuracy: 0.9798\n",
            "Epoch 938/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4819e-08 - accuracy: 1.0000 - val_loss: 0.3025 - val_accuracy: 0.9797\n",
            "Epoch 939/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3161e-08 - accuracy: 1.0000 - val_loss: 0.3033 - val_accuracy: 0.9797\n",
            "Epoch 940/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2303e-08 - accuracy: 1.0000 - val_loss: 0.3037 - val_accuracy: 0.9797\n",
            "Epoch 941/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0713e-08 - accuracy: 1.0000 - val_loss: 0.3040 - val_accuracy: 0.9797\n",
            "Epoch 942/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9558e-08 - accuracy: 1.0000 - val_loss: 0.3045 - val_accuracy: 0.9797\n",
            "Epoch 943/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8411e-08 - accuracy: 1.0000 - val_loss: 0.3051 - val_accuracy: 0.9795\n",
            "Epoch 944/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7301e-08 - accuracy: 1.0000 - val_loss: 0.3055 - val_accuracy: 0.9796\n",
            "Epoch 945/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6345e-08 - accuracy: 1.0000 - val_loss: 0.3063 - val_accuracy: 0.9798\n",
            "Epoch 946/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5357e-08 - accuracy: 1.0000 - val_loss: 0.3069 - val_accuracy: 0.9797\n",
            "Epoch 947/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4581e-08 - accuracy: 1.0000 - val_loss: 0.3071 - val_accuracy: 0.9795\n",
            "Epoch 948/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3606e-08 - accuracy: 1.0000 - val_loss: 0.3076 - val_accuracy: 0.9796\n",
            "Epoch 949/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2692e-08 - accuracy: 1.0000 - val_loss: 0.3086 - val_accuracy: 0.9795\n",
            "Epoch 950/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2016e-08 - accuracy: 1.0000 - val_loss: 0.3089 - val_accuracy: 0.9795\n",
            "Epoch 951/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1280e-08 - accuracy: 1.0000 - val_loss: 0.3094 - val_accuracy: 0.9795\n",
            "Epoch 952/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0673e-08 - accuracy: 1.0000 - val_loss: 0.3099 - val_accuracy: 0.9794\n",
            "Epoch 953/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0011e-08 - accuracy: 1.0000 - val_loss: 0.3104 - val_accuracy: 0.9795\n",
            "Epoch 954/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3460e-09 - accuracy: 1.0000 - val_loss: 0.3111 - val_accuracy: 0.9795\n",
            "Epoch 955/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9222e-09 - accuracy: 1.0000 - val_loss: 0.3119 - val_accuracy: 0.9795\n",
            "Epoch 956/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.3394e-09 - accuracy: 1.0000 - val_loss: 0.3124 - val_accuracy: 0.9795\n",
            "Epoch 957/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8572e-09 - accuracy: 1.0000 - val_loss: 0.3129 - val_accuracy: 0.9794\n",
            "Epoch 958/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4148e-09 - accuracy: 1.0000 - val_loss: 0.3137 - val_accuracy: 0.9795\n",
            "Epoch 959/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.9141e-09 - accuracy: 1.0000 - val_loss: 0.3142 - val_accuracy: 0.9797\n",
            "Epoch 960/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5486e-09 - accuracy: 1.0000 - val_loss: 0.3148 - val_accuracy: 0.9795\n",
            "Epoch 961/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1618e-09 - accuracy: 1.0000 - val_loss: 0.3155 - val_accuracy: 0.9795\n",
            "Epoch 962/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8042e-09 - accuracy: 1.0000 - val_loss: 0.3161 - val_accuracy: 0.9795\n",
            "Epoch 963/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.4174e-09 - accuracy: 1.0000 - val_loss: 0.3167 - val_accuracy: 0.9795\n",
            "Epoch 964/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0836e-09 - accuracy: 1.0000 - val_loss: 0.3174 - val_accuracy: 0.9796\n",
            "Epoch 965/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.8293e-09 - accuracy: 1.0000 - val_loss: 0.3182 - val_accuracy: 0.9795\n",
            "Epoch 966/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5194e-09 - accuracy: 1.0000 - val_loss: 0.3184 - val_accuracy: 0.9797\n",
            "Epoch 967/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.2836e-09 - accuracy: 1.0000 - val_loss: 0.3190 - val_accuracy: 0.9797\n",
            "Epoch 968/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9948e-09 - accuracy: 1.0000 - val_loss: 0.3197 - val_accuracy: 0.9797\n",
            "Epoch 969/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7193e-09 - accuracy: 1.0000 - val_loss: 0.3205 - val_accuracy: 0.9797\n",
            "Epoch 970/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.5551e-09 - accuracy: 1.0000 - val_loss: 0.3214 - val_accuracy: 0.9797\n",
            "Epoch 971/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3776e-09 - accuracy: 1.0000 - val_loss: 0.3221 - val_accuracy: 0.9797\n",
            "Epoch 972/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1180e-09 - accuracy: 1.0000 - val_loss: 0.3227 - val_accuracy: 0.9797\n",
            "Epoch 973/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9193e-09 - accuracy: 1.0000 - val_loss: 0.3236 - val_accuracy: 0.9798\n",
            "Epoch 974/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7815e-09 - accuracy: 1.0000 - val_loss: 0.3244 - val_accuracy: 0.9797\n",
            "Epoch 975/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6332e-09 - accuracy: 1.0000 - val_loss: 0.3252 - val_accuracy: 0.9797\n",
            "Epoch 976/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4690e-09 - accuracy: 1.0000 - val_loss: 0.3260 - val_accuracy: 0.9797\n",
            "Epoch 977/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3444e-09 - accuracy: 1.0000 - val_loss: 0.3268 - val_accuracy: 0.9798\n",
            "Epoch 978/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2173e-09 - accuracy: 1.0000 - val_loss: 0.3277 - val_accuracy: 0.9797\n",
            "Epoch 979/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0981e-09 - accuracy: 1.0000 - val_loss: 0.3285 - val_accuracy: 0.9797\n",
            "Epoch 980/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9789e-09 - accuracy: 1.0000 - val_loss: 0.3293 - val_accuracy: 0.9797\n",
            "Epoch 981/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9047e-09 - accuracy: 1.0000 - val_loss: 0.3303 - val_accuracy: 0.9797\n",
            "Epoch 982/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7722e-09 - accuracy: 1.0000 - val_loss: 0.3311 - val_accuracy: 0.9797\n",
            "Epoch 983/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6795e-09 - accuracy: 1.0000 - val_loss: 0.3320 - val_accuracy: 0.9797\n",
            "Epoch 984/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5974e-09 - accuracy: 1.0000 - val_loss: 0.3329 - val_accuracy: 0.9797\n",
            "Epoch 985/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5338e-09 - accuracy: 1.0000 - val_loss: 0.3338 - val_accuracy: 0.9797\n",
            "Epoch 986/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4411e-09 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.9797\n",
            "Epoch 987/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3987e-09 - accuracy: 1.0000 - val_loss: 0.3356 - val_accuracy: 0.9797\n",
            "Epoch 988/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3087e-09 - accuracy: 1.0000 - val_loss: 0.3365 - val_accuracy: 0.9797\n",
            "Epoch 989/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2345e-09 - accuracy: 1.0000 - val_loss: 0.3375 - val_accuracy: 0.9796\n",
            "Epoch 990/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1735e-09 - accuracy: 1.0000 - val_loss: 0.3384 - val_accuracy: 0.9797\n",
            "Epoch 991/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1312e-09 - accuracy: 1.0000 - val_loss: 0.3393 - val_accuracy: 0.9797\n",
            "Epoch 992/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0570e-09 - accuracy: 1.0000 - val_loss: 0.3408 - val_accuracy: 0.9796\n",
            "Epoch 993/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0517e-09 - accuracy: 1.0000 - val_loss: 0.3418 - val_accuracy: 0.9795\n",
            "Epoch 994/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0093e-09 - accuracy: 1.0000 - val_loss: 0.3429 - val_accuracy: 0.9796\n",
            "Epoch 995/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.3778e-10 - accuracy: 1.0000 - val_loss: 0.3439 - val_accuracy: 0.9795\n",
            "Epoch 996/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.9275e-10 - accuracy: 1.0000 - val_loss: 0.3451 - val_accuracy: 0.9795\n",
            "Epoch 997/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7950e-10 - accuracy: 1.0000 - val_loss: 0.3463 - val_accuracy: 0.9795\n",
            "Epoch 998/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3976e-10 - accuracy: 1.0000 - val_loss: 0.3475 - val_accuracy: 0.9795\n",
            "Epoch 999/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7354e-10 - accuracy: 1.0000 - val_loss: 0.3486 - val_accuracy: 0.9794\n",
            "Epoch 1000/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.8943e-10 - accuracy: 1.0000 - val_loss: 0.3500 - val_accuracy: 0.9794\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0875 - accuracy: 0.9948\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2349 - accuracy: 0.9826\n",
            "train accuracy :  0.9948499798774719 train loss :  0.08750451356172562\n",
            "test accuracy :  0.9825999736785889  test loss :  0.23493239283561707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYJ-cKxxPx_r"
      },
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCAlKST3P3zu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bca774c-f4b8-4382-a51b-4899865ee6c7"
      },
      "source": [
        "#정리\n",
        "print(\"=========== total evaluatation ===========\")\n",
        "print(\"\")\n",
        "\n",
        "print(\"########### initializer option = default ###########\")\n",
        "print(\"\")\n",
        "\n",
        "print(\"=========== [은닉층 2개] ===========\")\n",
        "print(\"=========== epochs = 12 ===========\")\n",
        "print(\"train accuracy : \", sc_train2_1[1], \"train loss : \", sc_train2_1[0])\n",
        "print(\"test accuracy : \", sc_test2_1[1], \" test loss : \", sc_test2_1[0])\n",
        "print(\"\")\n",
        "\n",
        "print(\"=========== epochs = 120 ===========\")\n",
        "print(\"train accuracy : \", sc_train2_1_2[1], \"train loss : \", sc_train2_1_2[0])\n",
        "print(\"test accuracy : \", sc_test2_1_2[1], \" test loss : \", sc_test2_1_2[0])\n",
        "print(\"\")\n",
        "\n",
        "print(\"=========== epochs = 500 ===========\")\n",
        "print(\"train accuracy : \", sc_train2_1_3[1], \"train loss : \", sc_train2_1_3[0])\n",
        "print(\"test accuracy : \", sc_test2_1_3[1], \" test loss : \", sc_test2_1_3[0])\n",
        "print(\"\")\n",
        "\n",
        "print(\"=========== epochs = 1000 ===========\")\n",
        "print(\"train accuracy : \", sc_train2_1_4[1], \"train loss : \", sc_train2_1_4[0])\n",
        "print(\"test accuracy : \", sc_test2_1_4[1], \" test loss : \", sc_test2_1_4[0])\n",
        "print(\"\")\n",
        "\n",
        "print(\"########### initializer option = HeNormal() ###########\")\n",
        "print(\"\")\n",
        "\n",
        "print(\"=========== [은닉층 2개 & 512/512]==+=========\")\n",
        "print(\"=========== epochs = 12 ===========\")\n",
        "print(\"train accuracy : \", sc_train3_1[1], \"train loss : \", sc_train3_1[0])\n",
        "print(\"test accuracy : \", sc_test3_1[1], \" test loss : \", sc_test3_1[0])\n",
        "print(\"\")\n",
        "\n",
        "print(\"=========== epochs = 120 ===========\")\n",
        "print(\"train accuracy : \", sc_train3_2[1], \"train loss : \", sc_train3_2[0])\n",
        "print(\"test accuracy : \", sc_test3_2[1], \" test loss : \", sc_test3_2[0])\n",
        "print(\"\")\n",
        "\n",
        "print(\"=========== epochs = 500 ===========\")\n",
        "print(\"train accuracy : \", sc_train3_3[1], \"train loss : \", sc_train3_3[0])\n",
        "print(\"test accuracy : \", sc_test3_3[1], \" test loss : \", sc_test3_3[0])\n",
        "print(\"\")\n",
        "\n",
        "print(\"=========== epochs = 1000 ===========\")\n",
        "print(\"train accuracy : \", sc_train3_4[1], \"train loss : \", sc_train3_4[0])\n",
        "print(\"test accuracy : \", sc_test3_4[1], \" test loss : \", sc_test3_4[0])\n",
        "print(\"\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========== total evaluatation ===========\n",
            "\n",
            "########### initializer option = default ###########\n",
            "\n",
            "=========== [은닉층 2개] ===========\n",
            "=========== epochs = 12 ===========\n",
            "train accuracy :  0.9912999868392944 train loss :  0.034651078283786774\n",
            "test accuracy :  0.9800999760627747  test loss :  0.08432424813508987\n",
            "\n",
            "=========== epochs = 120 ===========\n",
            "train accuracy :  0.9954833388328552 train loss :  0.04640447348356247\n",
            "test accuracy :  0.9842000007629395  test loss :  0.14507167041301727\n",
            "\n",
            "=========== epochs = 500 ===========\n",
            "train accuracy :  0.995199978351593 train loss :  0.057611025869846344\n",
            "test accuracy :  0.9835000038146973  test loss :  0.187482550740242\n",
            "\n",
            "=========== epochs = 1000 ===========\n",
            "train accuracy :  0.9952499866485596 train loss :  0.08460886776447296\n",
            "test accuracy :  0.982200026512146  test loss :  0.2703184485435486\n",
            "\n",
            "########### initializer option = HeNormal() ###########\n",
            "\n",
            "=========== [은닉층 2개 & 512/512]==+=========\n",
            "=========== epochs = 12 ===========\n",
            "train accuracy :  0.9879666566848755 train loss :  0.04692676663398743\n",
            "test accuracy :  0.9729999899864197  test loss :  0.10215163230895996\n",
            "\n",
            "=========== epochs = 120 ===========\n",
            "train accuracy :  0.9955666661262512 train loss :  0.04253648966550827\n",
            "test accuracy :  0.9830999970436096  test loss :  0.14426426589488983\n",
            "\n",
            "=========== epochs = 500 ===========\n",
            "train accuracy :  0.9955000281333923 train loss :  0.05757958069443703\n",
            "test accuracy :  0.9835000038146973  test loss :  0.16651412844657898\n",
            "\n",
            "=========== epochs = 1000 ===========\n",
            "train accuracy :  0.9948499798774719 train loss :  0.08750451356172562\n",
            "test accuracy :  0.9825999736785889  test loss :  0.23493239283561707\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rt456pdDFty"
      },
      "source": [
        "test 정확도로 봤을 때 은닉층2개(512/512)이고, epochs = 120일때 98.30으로 결과가 가장 좋고, train 정확도도 98.8%로 높은 것을 알 수 있다."
      ]
    }
  ]
}