{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FCN(Fully Connected Network)_MNIST_딥러닝의통계적이해_중간과제물.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "gCcTdkEHVitf"
      ],
      "authorship_tag": "ABX9TyOsE8BaeKAfm+dsZJZ+EITt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seunghee0518/AI_python/blob/main/FCN(Fully_Connected_Network)_MNIST_%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%98%ED%86%B5%EA%B3%84%EC%A0%81%EC%9D%B4%ED%95%B4_%EC%A4%91%EA%B0%84%EA%B3%BC%EC%A0%9C%EB%AC%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihHv6LNT__Cp"
      },
      "source": [
        "# MNIST 데이터를 이용해 손글씨를 식별하는 은닉층 1개의 완전연결신경망"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cGCeTqjAMud",
        "outputId": "c32caeff-bb40-424a-f09a-5706e982d739"
      },
      "source": [
        "#import library\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, models\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, Conv2D, MaxPool2D\n",
        "from tensorflow.keras.utils import plot_model\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "PjODhd-SAin7",
        "outputId": "c5783ab9-df86-4b93-c386-97af3cc9b0ef"
      },
      "source": [
        "# MNIST데이터셋 불러오기 & 데이터셋 확인\n",
        "mnist = datasets.mnist\n",
        "(train_x, train_y), (test_x, test_y) = mnist.load_data()\n",
        "train_x, test_x = train_x / 255.0, test_x / 255.0\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "for col1 in range(16) : \n",
        "  plt.subplot(4, 4, col1+1)\n",
        "  plt.imshow(train_x[col1].reshape(28, 28), cmap = plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 16 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dJ3btZCBDZz",
        "outputId": "6788a905-84e5-4d74-e0bc-6848a6dfd4b8"
      },
      "source": [
        "#MNIST 이미지 데이터 구조 확인\n",
        "digit = train_x[0]\n",
        "print(\"digit : \", digit.shape)\n",
        "print(\"train images : \", train_x.shape)\n",
        "print(\"test images : \", test_x.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "digit :  (28, 28)\n",
            "train images :  (60000, 28, 28)\n",
            "test images :  (10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TBKY5AcHBZt"
      },
      "source": [
        "# 은닉층1개"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "s8jQeyFPDBt3",
        "outputId": "237c22ef-948c-49b5-c54b-c8c4cf09bad1"
      },
      "source": [
        "#MNIST 이미지 식별하는 완전신경망(은닉층 1개)\n",
        "#신경망 작성\n",
        "model1_1 = models.Sequential([\n",
        "                              Flatten(input_shape = (28, 28)),\n",
        "                              Dense(512, activation= 'relu'),\n",
        "                              Dense(10, activation= 'softmax') # 분류할 개수 10개(0~9까지 숫자)\n",
        "                              ])\n",
        "\n",
        "#신경망 요약\n",
        "model1_1.summary()\n",
        "plot_model(model1_1, to_file= \" model1_1_mnist.png\", show_shapes= True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKsiyQDOEu--",
        "outputId": "6ed5682c-1865-4181-f5b8-aa242216bd94"
      },
      "source": [
        "#신경망 학습\n",
        "model1_1.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "hist1_1 = model1_1.fit(train_x, train_y, epochs = 12, batch_size = 256, validation_split = 0.25)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "176/176 [==============================] - 4s 7ms/step - loss: 0.3770 - accuracy: 0.8962 - val_loss: 0.2026 - val_accuracy: 0.9439\n",
            "Epoch 2/12\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.1597 - accuracy: 0.9552 - val_loss: 0.1436 - val_accuracy: 0.9583\n",
            "Epoch 3/12\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.1095 - accuracy: 0.9694 - val_loss: 0.1196 - val_accuracy: 0.9646\n",
            "Epoch 4/12\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0811 - accuracy: 0.9770 - val_loss: 0.1097 - val_accuracy: 0.9680\n",
            "Epoch 5/12\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0622 - accuracy: 0.9827 - val_loss: 0.0929 - val_accuracy: 0.9719\n",
            "Epoch 6/12\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0482 - accuracy: 0.9868 - val_loss: 0.0932 - val_accuracy: 0.9730\n",
            "Epoch 7/12\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0372 - accuracy: 0.9903 - val_loss: 0.0878 - val_accuracy: 0.9733\n",
            "Epoch 8/12\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0299 - accuracy: 0.9929 - val_loss: 0.0821 - val_accuracy: 0.9757\n",
            "Epoch 9/12\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0229 - accuracy: 0.9950 - val_loss: 0.0860 - val_accuracy: 0.9743\n",
            "Epoch 10/12\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0179 - accuracy: 0.9966 - val_loss: 0.0830 - val_accuracy: 0.9759\n",
            "Epoch 11/12\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0145 - accuracy: 0.9974 - val_loss: 0.0819 - val_accuracy: 0.9761\n",
            "Epoch 12/12\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0117 - accuracy: 0.9983 - val_loss: 0.0816 - val_accuracy: 0.9778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "UWhx3jfuDuRe",
        "outputId": "e56a9a75-18be-4eb4-8b10-2096e820bd9b"
      },
      "source": [
        "#학습 그래프 \n",
        "plt.plot(hist1_1.history['accuracy'], 'b-')\n",
        "plt.plot(hist1_1.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train1_1 = model1_1.evaluate(train_x, train_y)\n",
        "sc_test1_1 = model1_1.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train1_1[1], \"train loss : \", sc_train1_1[0])\n",
        "print(\"test accuracy : \", sc_test1_1[1], \" test loss : \", sc_test1_1[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0273 - accuracy: 0.9938\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0648 - accuracy: 0.9812\n",
            "train accuracy :  0.9937999844551086 train loss :  0.02729642763733864\n",
            "test accuracy :  0.9811999797821045  test loss :  0.06480918824672699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h57AbRi6KAJ5"
      },
      "source": [
        "위 결과를 보면 은닉층이 1개 일 때 훈련데이터의 정확도는 99.3%, 시험 데이터의 정확도는 98% 정도로 시험데이터의 정확도가 더 낮다는 것을 알 수 있다.\n",
        "은닉층을 2개로 설정해 모델을 작성하고 학습해 보았다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyaVNmknJPW-"
      },
      "source": [
        "# 은닉층2개\n",
        "* model2_1 뉴런 수 : 512 / 512\n",
        "* model2_2 뉴런 수 : 512 / 256"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "id": "nloX73QdGPFI",
        "outputId": "465608fc-d944-4fa6-d0e5-1590eb71754c"
      },
      "source": [
        "#MNIST 이미지 식별하는 완전신경망(은닉층 2개(은닉층 뉴런512개))\n",
        "#신경망 작성\n",
        "model2_1 = models.Sequential([\n",
        "                            Flatten(input_shape = (28, 28)),\n",
        "                            Dense(512, activation = 'relu'),\n",
        "                            Dense(512, activation = 'relu'),\n",
        "                            Dense(10, activation= 'softmax')\n",
        "                            ])\n",
        "\n",
        "#신경망 요약\n",
        "model2_1.summary()\n",
        "plot_model(model2_1, to_file= \" model2_1_mnist.png\", show_shapes= True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        },
        "id": "EPMC_peRJJCB",
        "outputId": "fc9512d1-a912-43ed-fa79-e9a876f82e7d"
      },
      "source": [
        "#은닉층2개 신경망 학습\n",
        "model2_1.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "hist2_1 = model2_1.fit(train_x, train_y, epochs = 12, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "#학습 그래프 \n",
        "plt.plot(hist2_1.history['accuracy'], 'b-')\n",
        "plt.plot(hist2_1.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train2_1 = model2_1.evaluate(train_x, train_y)\n",
        "sc_test2_1 = model2_1.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train2_1[1], \" train loss : \", sc_train2_1[0])\n",
        "print(\"test accuracy : \", sc_test2_1[1], \" test loss : \", sc_test2_1[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "176/176 [==============================] - 2s 7ms/step - loss: 0.3064 - accuracy: 0.9124 - val_loss: 0.1435 - val_accuracy: 0.9595\n",
            "Epoch 2/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.1066 - accuracy: 0.9688 - val_loss: 0.1159 - val_accuracy: 0.9657\n",
            "Epoch 3/12\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0655 - accuracy: 0.9809 - val_loss: 0.1005 - val_accuracy: 0.9695\n",
            "Epoch 4/12\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0402 - accuracy: 0.9880 - val_loss: 0.0994 - val_accuracy: 0.9719\n",
            "Epoch 5/12\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0298 - accuracy: 0.9912 - val_loss: 0.0897 - val_accuracy: 0.9736\n",
            "Epoch 6/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 0.0907 - val_accuracy: 0.9754\n",
            "Epoch 7/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 0.0909 - val_accuracy: 0.9771\n",
            "Epoch 8/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.0971 - val_accuracy: 0.9757\n",
            "Epoch 9/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.1095 - val_accuracy: 0.9721\n",
            "Epoch 10/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.1049 - val_accuracy: 0.9761\n",
            "Epoch 11/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0105 - accuracy: 0.9972 - val_loss: 0.1162 - val_accuracy: 0.9718\n",
            "Epoch 12/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.1104 - val_accuracy: 0.9743\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0347 - accuracy: 0.9913\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0843 - accuracy: 0.9801\n",
            "train accuracy :  0.9912999868392944  train loss :  0.034651078283786774\n",
            "test accuracy :  0.9800999760627747  test loss :  0.08432424813508987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "id": "kJMHN8ntMEkj",
        "outputId": "3c5a349a-2366-4c53-e917-99590e48d557"
      },
      "source": [
        "#MNIST 이미지 식별하는 완전신경망(은닉층 2개(은닉층 뉴런512개, 256개))\n",
        "#신경망 작성\n",
        "model2_2 = models.Sequential([\n",
        "                            Flatten(input_shape = (28, 28)),\n",
        "                            Dense(512, activation = 'relu'),\n",
        "                            Dense(256, activation = 'relu'),\n",
        "                            Dense(10, activation= 'softmax')\n",
        "                            ])\n",
        "\n",
        "#신경망 요약\n",
        "model2_2.summary()\n",
        "plot_model(model2_2, to_file= \" model2_2_mnist.png\", show_shapes= True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_2 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 535,818\n",
            "Trainable params: 535,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        },
        "id": "dfRIXXqzMMx4",
        "outputId": "f6f3977b-35dd-440b-e703-5aeed74bd1c9"
      },
      "source": [
        "#은닉층2개 신경망 학습\n",
        "model2_2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "hist2_2 = model2_2.fit(train_x, train_y, epochs = 12, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "#학습 그래프 \n",
        "plt.plot(hist2_2.history['accuracy'], 'b-')\n",
        "plt.plot(hist2_2.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train2_2 = model2_2.evaluate(train_x, train_y)\n",
        "sc_test2_2 = model2_2.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train2_2[1], \" train loss : \", sc_train2_2[0])\n",
        "print(\"test accuracy : \", sc_test2_2[1], \" test loss : \", sc_test2_2[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3192 - accuracy: 0.9081 - val_loss: 0.1505 - val_accuracy: 0.9551\n",
            "Epoch 2/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.1108 - accuracy: 0.9668 - val_loss: 0.1125 - val_accuracy: 0.9667\n",
            "Epoch 3/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0719 - accuracy: 0.9787 - val_loss: 0.0969 - val_accuracy: 0.9717\n",
            "Epoch 4/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0469 - accuracy: 0.9857 - val_loss: 0.0948 - val_accuracy: 0.9715\n",
            "Epoch 5/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0339 - accuracy: 0.9899 - val_loss: 0.0849 - val_accuracy: 0.9755\n",
            "Epoch 6/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0240 - accuracy: 0.9933 - val_loss: 0.0889 - val_accuracy: 0.9747\n",
            "Epoch 7/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0148 - accuracy: 0.9962 - val_loss: 0.0855 - val_accuracy: 0.9771\n",
            "Epoch 8/12\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0109 - accuracy: 0.9971 - val_loss: 0.0911 - val_accuracy: 0.9766\n",
            "Epoch 9/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.0989 - val_accuracy: 0.9749\n",
            "Epoch 10/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.0926 - val_accuracy: 0.9767\n",
            "Epoch 11/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.1088 - val_accuracy: 0.9750\n",
            "Epoch 12/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.1085 - val_accuracy: 0.9750\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0343 - accuracy: 0.9915\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0930 - accuracy: 0.9754\n",
            "train accuracy :  0.9915000200271606  train loss :  0.03434007987380028\n",
            "test accuracy :  0.9753999710083008  test loss :  0.09303631633520126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtXubJC8CGmU",
        "outputId": "19a0932c-824f-4b94-d704-fdf7e18122fc"
      },
      "source": [
        "print(\"=========== [은닉층 1개] ===========\")\n",
        "print(\"train accuracy : \", sc_train1_1[1], \"train loss : \", sc_train1_1[0])\n",
        "print(\"test accuracy : \", sc_test1_1[1], \" test loss : \", sc_test1_1[0])\n",
        "print(\"/n\")\n",
        "\n",
        "print(\"=========== [은닉층 2개] ===========\")\n",
        "print(\"=========== hidden = 512 / 512 ===========\")\n",
        "print(\"train accuracy : \", sc_train2_1[1], \"train loss : \", sc_train2_1[0])\n",
        "print(\"test accuracy : \", sc_test2_1[1], \" test loss : \", sc_test2_1[0])\n",
        "print(\"/n\")\n",
        "\n",
        "print(\"=========== hidden = 512 / 256 ===========\")\n",
        "print(\"train accuracy : \", sc_train2_2[1], \"train loss : \", sc_train2_2[0])\n",
        "print(\"test accuracy : \", sc_test2_2[1], \" test loss : \", sc_test2_2[0])\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========== [은닉층 1개] ===========\n",
            "train accuracy :  0.9937999844551086 train loss :  0.02729642763733864\n",
            "test accuracy :  0.9811999797821045  test loss :  0.06480918824672699\n",
            "/n\n",
            "=========== [은닉층 2개] ===========\n",
            "=========== hidden = 512 / 512 ===========\n",
            "train accuracy :  0.9912999868392944 train loss :  0.034651078283786774\n",
            "test accuracy :  0.9800999760627747  test loss :  0.08432424813508987\n",
            "/n\n",
            "=========== hidden = 512 / 256 ===========\n",
            "train accuracy :  0.9915000200271606 train loss :  0.03434007987380028\n",
            "test accuracy :  0.9753999710083008  test loss :  0.09303631633520126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO-St7a5VJzO"
      },
      "source": [
        "3개의 모델을 비교해 보았을 때 가장 결과가 좋은 모델은 은닉층이 1개인 모델이고, 은닉층을 2개 & 은닉층별 뉴런의 수가 512/512인 모델도 은닉층이 2개인 모델 중 가장 결과가 좋았다.\n",
        "\n",
        "따라서 은닉층이 1개인 모델, 은닉층이 2개이고 뉴런의 수가 512, 512인 모델에 epochs를 증가시켜 학습해 보았다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCcTdkEHVitf"
      },
      "source": [
        "# 은닉층 1개 & epochs = 120 / 500 / 1000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d5cFsW2YOoaX",
        "outputId": "01df00db-cf5e-440a-bde7-dbe52026b018"
      },
      "source": [
        "#은닉층 1개 & epochs = 120\n",
        "model1_2 = models.Sequential([\n",
        "                            Flatten(input_shape = (28, 28)),\n",
        "                            Dense(512, activation= 'relu'),\n",
        "                            Dense(10, activation= 'softmax')\n",
        "                            ])\n",
        "\n",
        "model1_2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "#신경망 학습2\n",
        "hist1_2 = model1_2.fit(train_x, train_y, epochs = 120, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "plt.plot(hist1_2.history['accuracy'], 'b-')\n",
        "plt.plot(hist1_2.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train1_2 = model1_2.evaluate(train_x, train_y)\n",
        "sc_test1_2 = model1_2.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train1_2[1], \"train loss : \", sc_train1_2[0])\n",
        "print(\"test accuracy : \", sc_test1_2[1], \" test loss : \", sc_test1_2[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3639 - accuracy: 0.9002 - val_loss: 0.1997 - val_accuracy: 0.9431\n",
            "Epoch 2/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.1561 - accuracy: 0.9561 - val_loss: 0.1398 - val_accuracy: 0.9593\n",
            "Epoch 3/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.1071 - accuracy: 0.9692 - val_loss: 0.1220 - val_accuracy: 0.9634\n",
            "Epoch 4/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0790 - accuracy: 0.9780 - val_loss: 0.1032 - val_accuracy: 0.9692\n",
            "Epoch 5/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0602 - accuracy: 0.9827 - val_loss: 0.1000 - val_accuracy: 0.9699\n",
            "Epoch 6/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0460 - accuracy: 0.9880 - val_loss: 0.0912 - val_accuracy: 0.9715\n",
            "Epoch 7/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0368 - accuracy: 0.9905 - val_loss: 0.0879 - val_accuracy: 0.9726\n",
            "Epoch 8/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0292 - accuracy: 0.9929 - val_loss: 0.0902 - val_accuracy: 0.9730\n",
            "Epoch 9/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0222 - accuracy: 0.9955 - val_loss: 0.0858 - val_accuracy: 0.9742\n",
            "Epoch 10/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0180 - accuracy: 0.9966 - val_loss: 0.0846 - val_accuracy: 0.9744\n",
            "Epoch 11/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0142 - accuracy: 0.9977 - val_loss: 0.0807 - val_accuracy: 0.9772\n",
            "Epoch 12/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0113 - accuracy: 0.9983 - val_loss: 0.0798 - val_accuracy: 0.9775\n",
            "Epoch 13/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.9988 - val_loss: 0.0834 - val_accuracy: 0.9766\n",
            "Epoch 14/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0072 - accuracy: 0.9994 - val_loss: 0.0820 - val_accuracy: 0.9774\n",
            "Epoch 15/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 0.9997 - val_loss: 0.0898 - val_accuracy: 0.9756\n",
            "Epoch 16/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.0871 - val_accuracy: 0.9763\n",
            "Epoch 17/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0037 - accuracy: 0.9999 - val_loss: 0.0856 - val_accuracy: 0.9767\n",
            "Epoch 18/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.0832 - val_accuracy: 0.9781\n",
            "Epoch 19/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.0857 - val_accuracy: 0.9781\n",
            "Epoch 20/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9785\n",
            "Epoch 21/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 0.9783\n",
            "Epoch 22/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0875 - val_accuracy: 0.9782\n",
            "Epoch 23/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0896 - val_accuracy: 0.9783\n",
            "Epoch 24/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9785\n",
            "Epoch 25/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.5424e-04 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 0.9783\n",
            "Epoch 26/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.3130e-04 - accuracy: 1.0000 - val_loss: 0.0914 - val_accuracy: 0.9785\n",
            "Epoch 27/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.2766e-04 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9791\n",
            "Epoch 28/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.5271e-04 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9783\n",
            "Epoch 29/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.7792e-04 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9783\n",
            "Epoch 30/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.1642e-04 - accuracy: 1.0000 - val_loss: 0.0952 - val_accuracy: 0.9785\n",
            "Epoch 31/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.4790e-04 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9781\n",
            "Epoch 32/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.9617e-04 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 0.9783\n",
            "Epoch 33/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.5951e-04 - accuracy: 1.0000 - val_loss: 0.0985 - val_accuracy: 0.9788\n",
            "Epoch 34/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.2535e-04 - accuracy: 1.0000 - val_loss: 0.0985 - val_accuracy: 0.9782\n",
            "Epoch 35/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.8468e-04 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9791\n",
            "Epoch 36/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.5862e-04 - accuracy: 1.0000 - val_loss: 0.0996 - val_accuracy: 0.9785\n",
            "Epoch 37/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.3126e-04 - accuracy: 1.0000 - val_loss: 0.1008 - val_accuracy: 0.9789\n",
            "Epoch 38/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.1664e-04 - accuracy: 1.0000 - val_loss: 0.1017 - val_accuracy: 0.9786\n",
            "Epoch 39/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8806e-04 - accuracy: 1.0000 - val_loss: 0.1032 - val_accuracy: 0.9789\n",
            "Epoch 40/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.6505e-04 - accuracy: 1.0000 - val_loss: 0.1033 - val_accuracy: 0.9787\n",
            "Epoch 41/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4752e-04 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 0.9787\n",
            "Epoch 42/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3496e-04 - accuracy: 1.0000 - val_loss: 0.1045 - val_accuracy: 0.9789\n",
            "Epoch 43/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2084e-04 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 0.9786\n",
            "Epoch 44/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.6321e-04 - accuracy: 0.9999 - val_loss: 0.2405 - val_accuracy: 0.9561\n",
            "Epoch 45/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0357 - accuracy: 0.9889 - val_loss: 0.1078 - val_accuracy: 0.9761\n",
            "Epoch 46/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.1121 - val_accuracy: 0.9767\n",
            "Epoch 47/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.1058 - val_accuracy: 0.9777\n",
            "Epoch 48/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.1297e-04 - accuracy: 1.0000 - val_loss: 0.1070 - val_accuracy: 0.9784\n",
            "Epoch 49/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.2469e-04 - accuracy: 1.0000 - val_loss: 0.1050 - val_accuracy: 0.9787\n",
            "Epoch 50/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.4512e-04 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9786\n",
            "Epoch 51/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.1163e-04 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 0.9785\n",
            "Epoch 52/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8927e-04 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9787\n",
            "Epoch 53/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7160e-04 - accuracy: 1.0000 - val_loss: 0.1079 - val_accuracy: 0.9784\n",
            "Epoch 54/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5581e-04 - accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 0.9784\n",
            "Epoch 55/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4244e-04 - accuracy: 1.0000 - val_loss: 0.1092 - val_accuracy: 0.9787\n",
            "Epoch 56/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3192e-04 - accuracy: 1.0000 - val_loss: 0.1100 - val_accuracy: 0.9787\n",
            "Epoch 57/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2212e-04 - accuracy: 1.0000 - val_loss: 0.1101 - val_accuracy: 0.9788\n",
            "Epoch 58/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1322e-04 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 0.9785\n",
            "Epoch 59/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0500e-04 - accuracy: 1.0000 - val_loss: 0.1112 - val_accuracy: 0.9787\n",
            "Epoch 60/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.7337e-05 - accuracy: 1.0000 - val_loss: 0.1115 - val_accuracy: 0.9786\n",
            "Epoch 61/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.0432e-05 - accuracy: 1.0000 - val_loss: 0.1116 - val_accuracy: 0.9787\n",
            "Epoch 62/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.4073e-05 - accuracy: 1.0000 - val_loss: 0.1123 - val_accuracy: 0.9784\n",
            "Epoch 63/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.8640e-05 - accuracy: 1.0000 - val_loss: 0.1134 - val_accuracy: 0.9782\n",
            "Epoch 64/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.3026e-05 - accuracy: 1.0000 - val_loss: 0.1138 - val_accuracy: 0.9787\n",
            "Epoch 65/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.8054e-05 - accuracy: 1.0000 - val_loss: 0.1145 - val_accuracy: 0.9783\n",
            "Epoch 66/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.3627e-05 - accuracy: 1.0000 - val_loss: 0.1144 - val_accuracy: 0.9783\n",
            "Epoch 67/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.9352e-05 - accuracy: 1.0000 - val_loss: 0.1155 - val_accuracy: 0.9787\n",
            "Epoch 68/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.5144e-05 - accuracy: 1.0000 - val_loss: 0.1157 - val_accuracy: 0.9783\n",
            "Epoch 69/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.1568e-05 - accuracy: 1.0000 - val_loss: 0.1158 - val_accuracy: 0.9785\n",
            "Epoch 70/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.8020e-05 - accuracy: 1.0000 - val_loss: 0.1168 - val_accuracy: 0.9783\n",
            "Epoch 71/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.4762e-05 - accuracy: 1.0000 - val_loss: 0.1169 - val_accuracy: 0.9781\n",
            "Epoch 72/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.2032e-05 - accuracy: 1.0000 - val_loss: 0.1175 - val_accuracy: 0.9789\n",
            "Epoch 73/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.9218e-05 - accuracy: 1.0000 - val_loss: 0.1183 - val_accuracy: 0.9785\n",
            "Epoch 74/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.6671e-05 - accuracy: 1.0000 - val_loss: 0.1186 - val_accuracy: 0.9785\n",
            "Epoch 75/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.3754e-05 - accuracy: 1.0000 - val_loss: 0.1194 - val_accuracy: 0.9787\n",
            "Epoch 76/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.1621e-05 - accuracy: 1.0000 - val_loss: 0.1193 - val_accuracy: 0.9790\n",
            "Epoch 77/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.9363e-05 - accuracy: 1.0000 - val_loss: 0.1201 - val_accuracy: 0.9791\n",
            "Epoch 78/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.7200e-05 - accuracy: 1.0000 - val_loss: 0.1205 - val_accuracy: 0.9791\n",
            "Epoch 79/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.5415e-05 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9789\n",
            "Epoch 80/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.3531e-05 - accuracy: 1.0000 - val_loss: 0.1219 - val_accuracy: 0.9792\n",
            "Epoch 81/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.1843e-05 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 0.9789\n",
            "Epoch 82/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.0247e-05 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9793\n",
            "Epoch 83/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8542e-05 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9789\n",
            "Epoch 84/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7435e-05 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9791\n",
            "Epoch 85/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.6049e-05 - accuracy: 1.0000 - val_loss: 0.1243 - val_accuracy: 0.9791\n",
            "Epoch 86/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4863e-05 - accuracy: 1.0000 - val_loss: 0.1246 - val_accuracy: 0.9789\n",
            "Epoch 87/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3731e-05 - accuracy: 1.0000 - val_loss: 0.1253 - val_accuracy: 0.9789\n",
            "Epoch 88/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2599e-05 - accuracy: 1.0000 - val_loss: 0.1255 - val_accuracy: 0.9791\n",
            "Epoch 89/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1637e-05 - accuracy: 1.0000 - val_loss: 0.1270 - val_accuracy: 0.9787\n",
            "Epoch 90/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0893e-05 - accuracy: 1.0000 - val_loss: 0.1262 - val_accuracy: 0.9789\n",
            "Epoch 91/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0175e-05 - accuracy: 1.0000 - val_loss: 0.1277 - val_accuracy: 0.9793\n",
            "Epoch 92/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.2548e-06 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 0.9788\n",
            "Epoch 93/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.4926e-06 - accuracy: 1.0000 - val_loss: 0.1277 - val_accuracy: 0.9793\n",
            "Epoch 94/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.7817e-06 - accuracy: 1.0000 - val_loss: 0.1294 - val_accuracy: 0.9793\n",
            "Epoch 95/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.2200e-06 - accuracy: 1.0000 - val_loss: 0.1305 - val_accuracy: 0.9791\n",
            "Epoch 96/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.5772e-06 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9793\n",
            "Epoch 97/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.0434e-06 - accuracy: 1.0000 - val_loss: 0.1309 - val_accuracy: 0.9790\n",
            "Epoch 98/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.5835e-06 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.9794\n",
            "Epoch 99/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1852e-06 - accuracy: 1.0000 - val_loss: 0.1323 - val_accuracy: 0.9793\n",
            "Epoch 100/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.7641e-06 - accuracy: 1.0000 - val_loss: 0.1339 - val_accuracy: 0.9795\n",
            "Epoch 101/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.3564e-06 - accuracy: 1.0000 - val_loss: 0.1345 - val_accuracy: 0.9797\n",
            "Epoch 102/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.0034e-06 - accuracy: 1.0000 - val_loss: 0.1347 - val_accuracy: 0.9795\n",
            "Epoch 103/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.6851e-06 - accuracy: 1.0000 - val_loss: 0.1362 - val_accuracy: 0.9794\n",
            "Epoch 104/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.3879e-06 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9793\n",
            "Epoch 105/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0523e-06 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9793\n",
            "Epoch 106/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.8255e-06 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9795\n",
            "Epoch 107/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.5958e-06 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9795\n",
            "Epoch 108/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.3704e-06 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9793\n",
            "Epoch 109/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.1982e-06 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 0.9795\n",
            "Epoch 110/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.9930e-06 - accuracy: 1.0000 - val_loss: 0.1407 - val_accuracy: 0.9795\n",
            "Epoch 111/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8163e-06 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9793\n",
            "Epoch 112/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6846e-06 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 0.9795\n",
            "Epoch 113/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5518e-06 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9795\n",
            "Epoch 114/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4198e-06 - accuracy: 1.0000 - val_loss: 0.1440 - val_accuracy: 0.9797\n",
            "Epoch 115/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3004e-06 - accuracy: 1.0000 - val_loss: 0.1450 - val_accuracy: 0.9795\n",
            "Epoch 116/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1972e-06 - accuracy: 1.0000 - val_loss: 0.1447 - val_accuracy: 0.9794\n",
            "Epoch 117/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0966e-06 - accuracy: 1.0000 - val_loss: 0.1469 - val_accuracy: 0.9797\n",
            "Epoch 118/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0153e-06 - accuracy: 1.0000 - val_loss: 0.1473 - val_accuracy: 0.9794\n",
            "Epoch 119/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.3023e-07 - accuracy: 1.0000 - val_loss: 0.1473 - val_accuracy: 0.9795\n",
            "Epoch 120/120\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.6548e-07 - accuracy: 1.0000 - val_loss: 0.1489 - val_accuracy: 0.9797\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0372 - accuracy: 0.9949\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1186 - accuracy: 0.9807\n",
            "train accuracy :  0.9949333071708679 train loss :  0.0372379831969738\n",
            "test accuracy :  0.9807000160217285  test loss :  0.11860010027885437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o6p7_433O4U5",
        "outputId": "72767a95-0e4c-410c-c3c7-95d97568ca81"
      },
      "source": [
        "#신경망 학습3\n",
        "model1_3 = models.Sequential([\n",
        "                            Flatten(input_shape = (28, 28)),\n",
        "                            Dense(512, activation= 'relu'),\n",
        "                            Dense(10, activation= 'softmax')\n",
        "                            ])\n",
        "\n",
        "model1_3.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "hist1_3 = model1_3.fit(train_x, train_y, epochs = 500, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "#학습 그래프3\n",
        "plt.plot(hist1_3.history['accuracy'], 'b-')\n",
        "plt.plot(hist1_3.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train1_3 = model1_3.evaluate(train_x, train_y)\n",
        "sc_test1_3 = model1_3.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train1_3[1], \"train loss : \", sc_train1_3[0])\n",
        "print(\"test accuracy : \", sc_test1_3[1], \" test loss : \", sc_test1_3[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3765 - accuracy: 0.8977 - val_loss: 0.1984 - val_accuracy: 0.9441\n",
            "Epoch 2/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.1608 - accuracy: 0.9550 - val_loss: 0.1472 - val_accuracy: 0.9566\n",
            "Epoch 3/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.1086 - accuracy: 0.9698 - val_loss: 0.1146 - val_accuracy: 0.9660\n",
            "Epoch 4/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0793 - accuracy: 0.9777 - val_loss: 0.1051 - val_accuracy: 0.9686\n",
            "Epoch 5/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0617 - accuracy: 0.9836 - val_loss: 0.0976 - val_accuracy: 0.9709\n",
            "Epoch 6/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0472 - accuracy: 0.9871 - val_loss: 0.0872 - val_accuracy: 0.9743\n",
            "Epoch 7/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0382 - accuracy: 0.9900 - val_loss: 0.0870 - val_accuracy: 0.9735\n",
            "Epoch 8/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0293 - accuracy: 0.9930 - val_loss: 0.0830 - val_accuracy: 0.9756\n",
            "Epoch 9/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0235 - accuracy: 0.9950 - val_loss: 0.0840 - val_accuracy: 0.9747\n",
            "Epoch 10/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0179 - accuracy: 0.9967 - val_loss: 0.0876 - val_accuracy: 0.9730\n",
            "Epoch 11/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0151 - accuracy: 0.9974 - val_loss: 0.0801 - val_accuracy: 0.9765\n",
            "Epoch 12/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0119 - accuracy: 0.9982 - val_loss: 0.0823 - val_accuracy: 0.9763\n",
            "Epoch 13/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.9989 - val_loss: 0.0784 - val_accuracy: 0.9778\n",
            "Epoch 14/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0071 - accuracy: 0.9994 - val_loss: 0.0797 - val_accuracy: 0.9774\n",
            "Epoch 15/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0056 - accuracy: 0.9996 - val_loss: 0.0839 - val_accuracy: 0.9771\n",
            "Epoch 16/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 0.9998 - val_loss: 0.0811 - val_accuracy: 0.9773\n",
            "Epoch 17/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0036 - accuracy: 0.9999 - val_loss: 0.0816 - val_accuracy: 0.9775\n",
            "Epoch 18/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 0.9999 - val_loss: 0.0854 - val_accuracy: 0.9770\n",
            "Epoch 19/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 0.0825 - val_accuracy: 0.9775\n",
            "Epoch 20/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 0.9775\n",
            "Epoch 21/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9783\n",
            "Epoch 22/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0865 - val_accuracy: 0.9779\n",
            "Epoch 23/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9782\n",
            "Epoch 24/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9784\n",
            "Epoch 25/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.5028e-04 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9785\n",
            "Epoch 26/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.4759e-04 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9785\n",
            "Epoch 27/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.4627e-04 - accuracy: 1.0000 - val_loss: 0.0910 - val_accuracy: 0.9782\n",
            "Epoch 28/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.5687e-04 - accuracy: 1.0000 - val_loss: 0.0909 - val_accuracy: 0.9787\n",
            "Epoch 29/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8099e-04 - accuracy: 1.0000 - val_loss: 0.0913 - val_accuracy: 0.9783\n",
            "Epoch 30/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.2012e-04 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9793\n",
            "Epoch 31/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.0471e-04 - accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 0.9791\n",
            "Epoch 32/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.1873e-04 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 0.9785\n",
            "Epoch 33/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.9758e-04 - accuracy: 1.0000 - val_loss: 0.0957 - val_accuracy: 0.9785\n",
            "Epoch 34/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.2890e-04 - accuracy: 1.0000 - val_loss: 0.0974 - val_accuracy: 0.9781\n",
            "Epoch 35/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.9160e-04 - accuracy: 1.0000 - val_loss: 0.0957 - val_accuracy: 0.9789\n",
            "Epoch 36/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.6956e-04 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9786\n",
            "Epoch 37/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.2983e-04 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9791\n",
            "Epoch 38/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.0989e-04 - accuracy: 1.0000 - val_loss: 0.1000 - val_accuracy: 0.9787\n",
            "Epoch 39/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8677e-04 - accuracy: 1.0000 - val_loss: 0.0998 - val_accuracy: 0.9793\n",
            "Epoch 40/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.6720e-04 - accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 0.9787\n",
            "Epoch 41/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4918e-04 - accuracy: 1.0000 - val_loss: 0.1002 - val_accuracy: 0.9797\n",
            "Epoch 42/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3548e-04 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 0.9791\n",
            "Epoch 43/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2385e-04 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9797\n",
            "Epoch 44/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1139e-04 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9789\n",
            "Epoch 45/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.9815e-05 - accuracy: 1.0000 - val_loss: 0.1040 - val_accuracy: 0.9791\n",
            "Epoch 46/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.2242e-05 - accuracy: 1.0000 - val_loss: 0.1064 - val_accuracy: 0.9792\n",
            "Epoch 47/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.2604e-05 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9794\n",
            "Epoch 48/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.4001e-05 - accuracy: 1.0000 - val_loss: 0.1086 - val_accuracy: 0.9793\n",
            "Epoch 49/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.8079e-05 - accuracy: 1.0000 - val_loss: 0.1088 - val_accuracy: 0.9793\n",
            "Epoch 50/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.0890e-05 - accuracy: 1.0000 - val_loss: 0.1087 - val_accuracy: 0.9795\n",
            "Epoch 51/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.3701e-05 - accuracy: 1.0000 - val_loss: 0.1112 - val_accuracy: 0.9793\n",
            "Epoch 52/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.8579e-05 - accuracy: 1.0000 - val_loss: 0.1114 - val_accuracy: 0.9797\n",
            "Epoch 53/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.4018e-05 - accuracy: 1.0000 - val_loss: 0.1121 - val_accuracy: 0.9793\n",
            "Epoch 54/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.9330e-05 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9791\n",
            "Epoch 55/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.6596e-05 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9795\n",
            "Epoch 56/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.3391e-05 - accuracy: 1.0000 - val_loss: 0.1149 - val_accuracy: 0.9794\n",
            "Epoch 57/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.9888e-05 - accuracy: 1.0000 - val_loss: 0.1164 - val_accuracy: 0.9789\n",
            "Epoch 58/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.6913e-05 - accuracy: 1.0000 - val_loss: 0.1162 - val_accuracy: 0.9795\n",
            "Epoch 59/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.3956e-05 - accuracy: 1.0000 - val_loss: 0.1174 - val_accuracy: 0.9795\n",
            "Epoch 60/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.2089e-05 - accuracy: 1.0000 - val_loss: 0.1186 - val_accuracy: 0.9793\n",
            "Epoch 61/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.0168e-05 - accuracy: 1.0000 - val_loss: 0.1199 - val_accuracy: 0.9794\n",
            "Epoch 62/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8369e-05 - accuracy: 1.0000 - val_loss: 0.1202 - val_accuracy: 0.9793\n",
            "Epoch 63/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.6305e-05 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9795\n",
            "Epoch 64/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5034e-05 - accuracy: 1.0000 - val_loss: 0.1210 - val_accuracy: 0.9795\n",
            "Epoch 65/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3724e-05 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9796\n",
            "Epoch 66/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2332e-05 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9793\n",
            "Epoch 67/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0972e-05 - accuracy: 1.0000 - val_loss: 0.1241 - val_accuracy: 0.9794\n",
            "Epoch 68/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0035e-05 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9795\n",
            "Epoch 69/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.1304e-06 - accuracy: 1.0000 - val_loss: 0.1256 - val_accuracy: 0.9793\n",
            "Epoch 70/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.4217e-06 - accuracy: 1.0000 - val_loss: 0.1275 - val_accuracy: 0.9791\n",
            "Epoch 71/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.5668e-06 - accuracy: 1.0000 - val_loss: 0.1287 - val_accuracy: 0.9793\n",
            "Epoch 72/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.7499e-06 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9797\n",
            "Epoch 73/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.1825e-06 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9798\n",
            "Epoch 74/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.6579e-06 - accuracy: 1.0000 - val_loss: 0.1305 - val_accuracy: 0.9796\n",
            "Epoch 75/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.1132e-06 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.9796\n",
            "Epoch 76/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.7900e-06 - accuracy: 1.0000 - val_loss: 0.1328 - val_accuracy: 0.9797\n",
            "Epoch 77/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.3199e-06 - accuracy: 1.0000 - val_loss: 0.1323 - val_accuracy: 0.9793\n",
            "Epoch 78/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.9739e-06 - accuracy: 1.0000 - val_loss: 0.1343 - val_accuracy: 0.9793\n",
            "Epoch 79/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.4853e-06 - accuracy: 1.0000 - val_loss: 0.1353 - val_accuracy: 0.9795\n",
            "Epoch 80/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.2880e-06 - accuracy: 1.0000 - val_loss: 0.1354 - val_accuracy: 0.9799\n",
            "Epoch 81/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.9154e-06 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.9794\n",
            "Epoch 82/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.6502e-06 - accuracy: 1.0000 - val_loss: 0.1375 - val_accuracy: 0.9795\n",
            "Epoch 83/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.4049e-06 - accuracy: 1.0000 - val_loss: 0.1381 - val_accuracy: 0.9795\n",
            "Epoch 84/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.2451e-06 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9793\n",
            "Epoch 85/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.0872e-06 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.9794\n",
            "Epoch 86/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8262e-06 - accuracy: 1.0000 - val_loss: 0.1405 - val_accuracy: 0.9794\n",
            "Epoch 87/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.6727e-06 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9800\n",
            "Epoch 88/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5090e-06 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9797\n",
            "Epoch 89/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3888e-06 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9798\n",
            "Epoch 90/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2698e-06 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9796\n",
            "Epoch 91/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1579e-06 - accuracy: 1.0000 - val_loss: 0.1445 - val_accuracy: 0.9797\n",
            "Epoch 92/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0647e-06 - accuracy: 1.0000 - val_loss: 0.1465 - val_accuracy: 0.9795\n",
            "Epoch 93/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.8450e-07 - accuracy: 1.0000 - val_loss: 0.1465 - val_accuracy: 0.9795\n",
            "Epoch 94/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.9173e-07 - accuracy: 1.0000 - val_loss: 0.1464 - val_accuracy: 0.9797\n",
            "Epoch 95/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.3169e-07 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9799\n",
            "Epoch 96/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.5500e-07 - accuracy: 1.0000 - val_loss: 0.1483 - val_accuracy: 0.9798\n",
            "Epoch 97/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.0247e-07 - accuracy: 1.0000 - val_loss: 0.1501 - val_accuracy: 0.9799\n",
            "Epoch 98/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.3371e-07 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9797\n",
            "Epoch 99/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.8317e-07 - accuracy: 1.0000 - val_loss: 0.1519 - val_accuracy: 0.9801\n",
            "Epoch 100/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.3128e-07 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 0.9797\n",
            "Epoch 101/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.9340e-07 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9801\n",
            "Epoch 102/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.6019e-07 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9795\n",
            "Epoch 103/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.1670e-07 - accuracy: 1.0000 - val_loss: 0.1553 - val_accuracy: 0.9797\n",
            "Epoch 104/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.9084e-07 - accuracy: 1.0000 - val_loss: 0.1551 - val_accuracy: 0.9798\n",
            "Epoch 105/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.6294e-07 - accuracy: 1.0000 - val_loss: 0.1557 - val_accuracy: 0.9797\n",
            "Epoch 106/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3051e-07 - accuracy: 1.0000 - val_loss: 0.1563 - val_accuracy: 0.9799\n",
            "Epoch 107/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.0913e-07 - accuracy: 1.0000 - val_loss: 0.1577 - val_accuracy: 0.9797\n",
            "Epoch 108/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.8542e-07 - accuracy: 1.0000 - val_loss: 0.1575 - val_accuracy: 0.9799\n",
            "Epoch 109/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.6459e-07 - accuracy: 1.0000 - val_loss: 0.1584 - val_accuracy: 0.9795\n",
            "Epoch 110/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.4478e-07 - accuracy: 1.0000 - val_loss: 0.1597 - val_accuracy: 0.9797\n",
            "Epoch 111/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.2962e-07 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 0.9798\n",
            "Epoch 112/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.1289e-07 - accuracy: 1.0000 - val_loss: 0.1605 - val_accuracy: 0.9796\n",
            "Epoch 113/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.9582e-07 - accuracy: 1.0000 - val_loss: 0.1613 - val_accuracy: 0.9799\n",
            "Epoch 114/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8317e-07 - accuracy: 1.0000 - val_loss: 0.1624 - val_accuracy: 0.9799\n",
            "Epoch 115/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.7251e-07 - accuracy: 1.0000 - val_loss: 0.1618 - val_accuracy: 0.9798\n",
            "Epoch 116/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5999e-07 - accuracy: 1.0000 - val_loss: 0.1638 - val_accuracy: 0.9798\n",
            "Epoch 117/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4976e-07 - accuracy: 1.0000 - val_loss: 0.1638 - val_accuracy: 0.9799\n",
            "Epoch 118/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3998e-07 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9801\n",
            "Epoch 119/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3141e-07 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9799\n",
            "Epoch 120/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2369e-07 - accuracy: 1.0000 - val_loss: 0.1662 - val_accuracy: 0.9799\n",
            "Epoch 121/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1606e-07 - accuracy: 1.0000 - val_loss: 0.1660 - val_accuracy: 0.9799\n",
            "Epoch 122/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0850e-07 - accuracy: 1.0000 - val_loss: 0.1661 - val_accuracy: 0.9799\n",
            "Epoch 123/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0263e-07 - accuracy: 1.0000 - val_loss: 0.1674 - val_accuracy: 0.9798\n",
            "Epoch 124/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.6861e-08 - accuracy: 1.0000 - val_loss: 0.1680 - val_accuracy: 0.9799\n",
            "Epoch 125/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.1637e-08 - accuracy: 1.0000 - val_loss: 0.1688 - val_accuracy: 0.9799\n",
            "Epoch 126/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.5995e-08 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 0.9799\n",
            "Epoch 127/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.1656e-08 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 0.9798\n",
            "Epoch 128/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.7279e-08 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 0.9801\n",
            "Epoch 129/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.3314e-08 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 0.9799\n",
            "Epoch 130/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.0246e-08 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 0.9800\n",
            "Epoch 131/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.6339e-08 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 0.9799\n",
            "Epoch 132/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.3072e-08 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 0.9799\n",
            "Epoch 133/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.0328e-08 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 0.9799\n",
            "Epoch 134/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.7705e-08 - accuracy: 1.0000 - val_loss: 0.1727 - val_accuracy: 0.9801\n",
            "Epoch 135/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.4720e-08 - accuracy: 1.0000 - val_loss: 0.1735 - val_accuracy: 0.9797\n",
            "Epoch 136/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.2595e-08 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.9799\n",
            "Epoch 137/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.0304e-08 - accuracy: 1.0000 - val_loss: 0.1738 - val_accuracy: 0.9801\n",
            "Epoch 138/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.8063e-08 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9799\n",
            "Epoch 139/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.6155e-08 - accuracy: 1.0000 - val_loss: 0.1745 - val_accuracy: 0.9800\n",
            "Epoch 140/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.4235e-08 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 0.9802\n",
            "Epoch 141/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.2780e-08 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 0.9799\n",
            "Epoch 142/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.1024e-08 - accuracy: 1.0000 - val_loss: 0.1761 - val_accuracy: 0.9799\n",
            "Epoch 143/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9379e-08 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 0.9799\n",
            "Epoch 144/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.8120e-08 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 0.9799\n",
            "Epoch 145/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.6634e-08 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.9799\n",
            "Epoch 146/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.5527e-08 - accuracy: 1.0000 - val_loss: 0.1770 - val_accuracy: 0.9799\n",
            "Epoch 147/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.4367e-08 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9800\n",
            "Epoch 148/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.3225e-08 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 0.9800\n",
            "Epoch 149/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.2128e-08 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9799\n",
            "Epoch 150/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.1182e-08 - accuracy: 1.0000 - val_loss: 0.1786 - val_accuracy: 0.9799\n",
            "Epoch 151/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.0247e-08 - accuracy: 1.0000 - val_loss: 0.1785 - val_accuracy: 0.9801\n",
            "Epoch 152/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.9331e-08 - accuracy: 1.0000 - val_loss: 0.1794 - val_accuracy: 0.9799\n",
            "Epoch 153/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.8425e-08 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9801\n",
            "Epoch 154/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7569e-08 - accuracy: 1.0000 - val_loss: 0.1796 - val_accuracy: 0.9800\n",
            "Epoch 155/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6830e-08 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 0.9799\n",
            "Epoch 156/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.6226e-08 - accuracy: 1.0000 - val_loss: 0.1799 - val_accuracy: 0.9800\n",
            "Epoch 157/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.5304e-08 - accuracy: 1.0000 - val_loss: 0.1804 - val_accuracy: 0.9799\n",
            "Epoch 158/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4663e-08 - accuracy: 1.0000 - val_loss: 0.1804 - val_accuracy: 0.9801\n",
            "Epoch 159/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3972e-08 - accuracy: 1.0000 - val_loss: 0.1807 - val_accuracy: 0.9800\n",
            "Epoch 160/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.3503e-08 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 0.9800\n",
            "Epoch 161/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.2970e-08 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9800\n",
            "Epoch 162/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.2385e-08 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9800\n",
            "Epoch 163/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.1768e-08 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9800\n",
            "Epoch 164/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.1386e-08 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9799\n",
            "Epoch 165/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0846e-08 - accuracy: 1.0000 - val_loss: 0.1821 - val_accuracy: 0.9801\n",
            "Epoch 166/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.0356e-08 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9800\n",
            "Epoch 167/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9937e-08 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 0.9800\n",
            "Epoch 168/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.9587e-08 - accuracy: 1.0000 - val_loss: 0.1823 - val_accuracy: 0.9801\n",
            "Epoch 169/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9052e-08 - accuracy: 1.0000 - val_loss: 0.1825 - val_accuracy: 0.9801\n",
            "Epoch 170/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8764e-08 - accuracy: 1.0000 - val_loss: 0.1827 - val_accuracy: 0.9801\n",
            "Epoch 171/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8454e-08 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 0.9801\n",
            "Epoch 172/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8009e-08 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 0.9800\n",
            "Epoch 173/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.7699e-08 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 0.9801\n",
            "Epoch 174/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.7381e-08 - accuracy: 1.0000 - val_loss: 0.1837 - val_accuracy: 0.9800\n",
            "Epoch 175/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.7063e-08 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9801\n",
            "Epoch 176/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.6668e-08 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9799\n",
            "Epoch 177/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.6374e-08 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.9801\n",
            "Epoch 178/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.6178e-08 - accuracy: 1.0000 - val_loss: 0.1839 - val_accuracy: 0.9800\n",
            "Epoch 179/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5839e-08 - accuracy: 1.0000 - val_loss: 0.1850 - val_accuracy: 0.9799\n",
            "Epoch 180/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5646e-08 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9800\n",
            "Epoch 181/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5304e-08 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 0.9800\n",
            "Epoch 182/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5057e-08 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9801\n",
            "Epoch 183/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4684e-08 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 0.9801\n",
            "Epoch 184/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4620e-08 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9801\n",
            "Epoch 185/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4337e-08 - accuracy: 1.0000 - val_loss: 0.1850 - val_accuracy: 0.9799\n",
            "Epoch 186/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4265e-08 - accuracy: 1.0000 - val_loss: 0.1853 - val_accuracy: 0.9801\n",
            "Epoch 187/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3892e-08 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9801\n",
            "Epoch 188/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3810e-08 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9801\n",
            "Epoch 189/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3595e-08 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9801\n",
            "Epoch 190/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3309e-08 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9801\n",
            "Epoch 191/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3200e-08 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9801\n",
            "Epoch 192/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3002e-08 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 0.9801\n",
            "Epoch 193/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2747e-08 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9801\n",
            "Epoch 194/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2618e-08 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9801\n",
            "Epoch 195/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2445e-08 - accuracy: 1.0000 - val_loss: 0.1864 - val_accuracy: 0.9801\n",
            "Epoch 196/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2284e-08 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9800\n",
            "Epoch 197/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2053e-08 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 0.9801\n",
            "Epoch 198/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1982e-08 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9801\n",
            "Epoch 199/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1881e-08 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9801\n",
            "Epoch 200/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1590e-08 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9801\n",
            "Epoch 201/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1518e-08 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9801\n",
            "Epoch 202/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1370e-08 - accuracy: 1.0000 - val_loss: 0.1870 - val_accuracy: 0.9801\n",
            "Epoch 203/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1216e-08 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9801\n",
            "Epoch 204/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1137e-08 - accuracy: 1.0000 - val_loss: 0.1873 - val_accuracy: 0.9801\n",
            "Epoch 205/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0949e-08 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9801\n",
            "Epoch 206/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0830e-08 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 0.9801\n",
            "Epoch 207/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0742e-08 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9802\n",
            "Epoch 208/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0578e-08 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9801\n",
            "Epoch 209/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0475e-08 - accuracy: 1.0000 - val_loss: 0.1879 - val_accuracy: 0.9801\n",
            "Epoch 210/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0294e-08 - accuracy: 1.0000 - val_loss: 0.1879 - val_accuracy: 0.9801\n",
            "Epoch 211/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0204e-08 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9802\n",
            "Epoch 212/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0093e-08 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9801\n",
            "Epoch 213/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.9871e-09 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 0.9801\n",
            "Epoch 214/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.9315e-09 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9801\n",
            "Epoch 215/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.8255e-09 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9801\n",
            "Epoch 216/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.6824e-09 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 0.9801\n",
            "Epoch 217/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.5473e-09 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9801\n",
            "Epoch 218/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.4705e-09 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9800\n",
            "Epoch 219/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.3884e-09 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.9801\n",
            "Epoch 220/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.3036e-09 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 0.9801\n",
            "Epoch 221/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.1844e-09 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9802\n",
            "Epoch 222/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.1341e-09 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9801\n",
            "Epoch 223/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.9857e-09 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9801\n",
            "Epoch 224/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.9778e-09 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9801\n",
            "Epoch 225/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.7870e-09 - accuracy: 1.0000 - val_loss: 0.1892 - val_accuracy: 0.9801\n",
            "Epoch 226/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.7632e-09 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9801\n",
            "Epoch 227/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.6334e-09 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9801\n",
            "Epoch 228/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.5751e-09 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9801\n",
            "Epoch 229/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.4718e-09 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9801\n",
            "Epoch 230/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.4400e-09 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9801\n",
            "Epoch 231/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.3288e-09 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9801\n",
            "Epoch 232/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.2917e-09 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.9801\n",
            "Epoch 233/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.1857e-09 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9801\n",
            "Epoch 234/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.0850e-09 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 0.9801\n",
            "Epoch 235/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.0506e-09 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9801\n",
            "Epoch 236/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.9658e-09 - accuracy: 1.0000 - val_loss: 0.1900 - val_accuracy: 0.9801\n",
            "Epoch 237/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.9102e-09 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9801\n",
            "Epoch 238/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7989e-09 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9801\n",
            "Epoch 239/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.7777e-09 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9801\n",
            "Epoch 240/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7168e-09 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9801\n",
            "Epoch 241/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.6718e-09 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 0.9801\n",
            "Epoch 242/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.5897e-09 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 0.9800\n",
            "Epoch 243/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.5022e-09 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9801\n",
            "Epoch 244/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.4969e-09 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9801\n",
            "Epoch 245/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.4042e-09 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9801\n",
            "Epoch 246/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.3433e-09 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9801\n",
            "Epoch 247/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.2797e-09 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.9801\n",
            "Epoch 248/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.2320e-09 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9801\n",
            "Epoch 249/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.1976e-09 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9800\n",
            "Epoch 250/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.0784e-09 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9800\n",
            "Epoch 251/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0916e-09 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9799\n",
            "Epoch 252/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0254e-09 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9801\n",
            "Epoch 253/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.9751e-09 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9800\n",
            "Epoch 254/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.9115e-09 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9800\n",
            "Epoch 255/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8797e-09 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9799\n",
            "Epoch 256/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8241e-09 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9800\n",
            "Epoch 257/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.7472e-09 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9801\n",
            "Epoch 258/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.7790e-09 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9801\n",
            "Epoch 259/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7208e-09 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9801\n",
            "Epoch 260/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.6386e-09 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9800\n",
            "Epoch 261/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.6095e-09 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 0.9800\n",
            "Epoch 262/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.5671e-09 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9799\n",
            "Epoch 263/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5141e-09 - accuracy: 1.0000 - val_loss: 0.1919 - val_accuracy: 0.9800\n",
            "Epoch 264/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.4426e-09 - accuracy: 1.0000 - val_loss: 0.1920 - val_accuracy: 0.9800\n",
            "Epoch 265/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.4585e-09 - accuracy: 1.0000 - val_loss: 0.1920 - val_accuracy: 0.9799\n",
            "Epoch 266/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3843e-09 - accuracy: 1.0000 - val_loss: 0.1920 - val_accuracy: 0.9800\n",
            "Epoch 267/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3737e-09 - accuracy: 1.0000 - val_loss: 0.1920 - val_accuracy: 0.9799\n",
            "Epoch 268/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3499e-09 - accuracy: 1.0000 - val_loss: 0.1922 - val_accuracy: 0.9798\n",
            "Epoch 269/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2731e-09 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9799\n",
            "Epoch 270/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.2784e-09 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 0.9799\n",
            "Epoch 271/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3048e-09 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9799\n",
            "Epoch 272/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1274e-09 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 0.9799\n",
            "Epoch 273/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1618e-09 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 0.9799\n",
            "Epoch 274/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2068e-09 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 0.9799\n",
            "Epoch 275/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1247e-09 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9799\n",
            "Epoch 276/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.1062e-09 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9799\n",
            "Epoch 277/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0187e-09 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9799\n",
            "Epoch 278/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0002e-09 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9799\n",
            "Epoch 279/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.0293e-09 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 0.9798\n",
            "Epoch 280/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0134e-09 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 0.9799\n",
            "Epoch 281/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9446e-09 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9799\n",
            "Epoch 282/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9287e-09 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9798\n",
            "Epoch 283/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9128e-09 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9799\n",
            "Epoch 284/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8651e-09 - accuracy: 1.0000 - val_loss: 0.1931 - val_accuracy: 0.9799\n",
            "Epoch 285/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8942e-09 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9799\n",
            "Epoch 286/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8015e-09 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9798\n",
            "Epoch 287/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8095e-09 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9797\n",
            "Epoch 288/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7909e-09 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9798\n",
            "Epoch 289/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8624e-09 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9797\n",
            "Epoch 290/500\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.6956e-09 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9798\n",
            "Epoch 291/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7777e-09 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 0.9799\n",
            "Epoch 292/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7247e-09 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9799\n",
            "Epoch 293/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7062e-09 - accuracy: 1.0000 - val_loss: 0.1935 - val_accuracy: 0.9799\n",
            "Epoch 294/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6081e-09 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9799\n",
            "Epoch 295/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6505e-09 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9799\n",
            "Epoch 296/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6214e-09 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 0.9797\n",
            "Epoch 297/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6267e-09 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 0.9799\n",
            "Epoch 298/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6161e-09 - accuracy: 1.0000 - val_loss: 0.1940 - val_accuracy: 0.9799\n",
            "Epoch 299/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6399e-09 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9799\n",
            "Epoch 300/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5869e-09 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 0.9798\n",
            "Epoch 301/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5710e-09 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9798\n",
            "Epoch 302/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6055e-09 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 0.9798\n",
            "Epoch 303/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6055e-09 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9798\n",
            "Epoch 304/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5340e-09 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9799\n",
            "Epoch 305/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5101e-09 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 0.9799\n",
            "Epoch 306/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5340e-09 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 0.9798\n",
            "Epoch 307/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4412e-09 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9798\n",
            "Epoch 308/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4042e-09 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9798\n",
            "Epoch 309/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4704e-09 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 0.9798\n",
            "Epoch 310/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4280e-09 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.9798\n",
            "Epoch 311/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4704e-09 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.9797\n",
            "Epoch 312/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4598e-09 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.9797\n",
            "Epoch 313/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3909e-09 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9797\n",
            "Epoch 314/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3750e-09 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9797\n",
            "Epoch 315/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3856e-09 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9798\n",
            "Epoch 316/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4518e-09 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9798\n",
            "Epoch 317/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3803e-09 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 0.9797\n",
            "Epoch 318/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4121e-09 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9798\n",
            "Epoch 319/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3591e-09 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9797\n",
            "Epoch 320/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3618e-09 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9797\n",
            "Epoch 321/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2849e-09 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9798\n",
            "Epoch 322/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3035e-09 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9797\n",
            "Epoch 323/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3379e-09 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9797\n",
            "Epoch 324/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3697e-09 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9797\n",
            "Epoch 325/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2876e-09 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9797\n",
            "Epoch 326/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3035e-09 - accuracy: 1.0000 - val_loss: 0.1958 - val_accuracy: 0.9797\n",
            "Epoch 327/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3353e-09 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9798\n",
            "Epoch 328/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2955e-09 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9797\n",
            "Epoch 329/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3008e-09 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 0.9797\n",
            "Epoch 330/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2214e-09 - accuracy: 1.0000 - val_loss: 0.1958 - val_accuracy: 0.9797\n",
            "Epoch 331/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3565e-09 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9797\n",
            "Epoch 332/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2638e-09 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 0.9797\n",
            "Epoch 333/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3247e-09 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.9797\n",
            "Epoch 334/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2876e-09 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 0.9797\n",
            "Epoch 335/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2055e-09 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9797\n",
            "Epoch 336/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2955e-09 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.9797\n",
            "Epoch 337/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2240e-09 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.9797\n",
            "Epoch 338/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2028e-09 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.9797\n",
            "Epoch 339/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2638e-09 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.9797\n",
            "Epoch 340/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2982e-09 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.9797\n",
            "Epoch 341/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2267e-09 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.9797\n",
            "Epoch 342/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1737e-09 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9797\n",
            "Epoch 343/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2028e-09 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9797\n",
            "Epoch 344/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1498e-09 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9797\n",
            "Epoch 345/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1525e-09 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9797\n",
            "Epoch 346/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2187e-09 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9797\n",
            "Epoch 347/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2187e-09 - accuracy: 1.0000 - val_loss: 0.1969 - val_accuracy: 0.9797\n",
            "Epoch 348/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1843e-09 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 0.9798\n",
            "Epoch 349/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1525e-09 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 0.9797\n",
            "Epoch 350/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2161e-09 - accuracy: 1.0000 - val_loss: 0.1969 - val_accuracy: 0.9798\n",
            "Epoch 351/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1816e-09 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9797\n",
            "Epoch 352/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2108e-09 - accuracy: 1.0000 - val_loss: 0.1971 - val_accuracy: 0.9798\n",
            "Epoch 353/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1737e-09 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9798\n",
            "Epoch 354/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2426e-09 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 0.9797\n",
            "Epoch 355/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1578e-09 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9798\n",
            "Epoch 356/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1657e-09 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9798\n",
            "Epoch 357/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1472e-09 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9798\n",
            "Epoch 358/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1922e-09 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 0.9798\n",
            "Epoch 359/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1339e-09 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9797\n",
            "Epoch 360/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1181e-09 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 0.9798\n",
            "Epoch 361/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1869e-09 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9798\n",
            "Epoch 362/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1869e-09 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9798\n",
            "Epoch 363/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1551e-09 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9797\n",
            "Epoch 364/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1790e-09 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9797\n",
            "Epoch 365/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1710e-09 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9797\n",
            "Epoch 366/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1498e-09 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9798\n",
            "Epoch 367/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1207e-09 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9798\n",
            "Epoch 368/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1710e-09 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9798\n",
            "Epoch 369/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1419e-09 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9798\n",
            "Epoch 370/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1631e-09 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9797\n",
            "Epoch 371/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1313e-09 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9798\n",
            "Epoch 372/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1048e-09 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9798\n",
            "Epoch 373/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1684e-09 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 0.9797\n",
            "Epoch 374/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1392e-09 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9797\n",
            "Epoch 375/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1207e-09 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9798\n",
            "Epoch 376/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1445e-09 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9798\n",
            "Epoch 377/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1551e-09 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.9798\n",
            "Epoch 378/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1234e-09 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.9797\n",
            "Epoch 379/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1472e-09 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.9797\n",
            "Epoch 380/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1498e-09 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.9797\n",
            "Epoch 381/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1445e-09 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9798\n",
            "Epoch 382/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1207e-09 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9798\n",
            "Epoch 383/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0810e-09 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.9798\n",
            "Epoch 384/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0783e-09 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9797\n",
            "Epoch 385/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1790e-09 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.9797\n",
            "Epoch 386/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1286e-09 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.9797\n",
            "Epoch 387/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1313e-09 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9797\n",
            "Epoch 388/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1048e-09 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9799\n",
            "Epoch 389/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1339e-09 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9799\n",
            "Epoch 390/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1207e-09 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.9799\n",
            "Epoch 391/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1075e-09 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.9799\n",
            "Epoch 392/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0757e-09 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 0.9798\n",
            "Epoch 393/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0598e-09 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 0.9799\n",
            "Epoch 394/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1181e-09 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9799\n",
            "Epoch 395/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0757e-09 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9799\n",
            "Epoch 396/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1260e-09 - accuracy: 1.0000 - val_loss: 0.1994 - val_accuracy: 0.9798\n",
            "Epoch 397/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0995e-09 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9799\n",
            "Epoch 398/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1816e-09 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9797\n",
            "Epoch 399/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1313e-09 - accuracy: 1.0000 - val_loss: 0.1994 - val_accuracy: 0.9798\n",
            "Epoch 400/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0889e-09 - accuracy: 1.0000 - val_loss: 0.1994 - val_accuracy: 0.9799\n",
            "Epoch 401/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1075e-09 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9799\n",
            "Epoch 402/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0995e-09 - accuracy: 1.0000 - val_loss: 0.1996 - val_accuracy: 0.9799\n",
            "Epoch 403/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0704e-09 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9797\n",
            "Epoch 404/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0969e-09 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.9797\n",
            "Epoch 405/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1260e-09 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9797\n",
            "Epoch 406/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0783e-09 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.9797\n",
            "Epoch 407/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0518e-09 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9797\n",
            "Epoch 408/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1048e-09 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9798\n",
            "Epoch 409/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0836e-09 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9799\n",
            "Epoch 410/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1128e-09 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9797\n",
            "Epoch 411/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1392e-09 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.9797\n",
            "Epoch 412/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1154e-09 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9797\n",
            "Epoch 413/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1578e-09 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9796\n",
            "Epoch 414/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0704e-09 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9797\n",
            "Epoch 415/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1234e-09 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9797\n",
            "Epoch 416/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0200e-09 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9797\n",
            "Epoch 417/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1710e-09 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9797\n",
            "Epoch 418/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0942e-09 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9797\n",
            "Epoch 419/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1075e-09 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9796\n",
            "Epoch 420/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0571e-09 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9797\n",
            "Epoch 421/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0916e-09 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9797\n",
            "Epoch 422/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0942e-09 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9796\n",
            "Epoch 423/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0916e-09 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9796\n",
            "Epoch 424/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1286e-09 - accuracy: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.9796\n",
            "Epoch 425/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0995e-09 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9795\n",
            "Epoch 426/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1392e-09 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9797\n",
            "Epoch 427/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0757e-09 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9796\n",
            "Epoch 428/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0651e-09 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9797\n",
            "Epoch 429/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1445e-09 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9796\n",
            "Epoch 430/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0704e-09 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9795\n",
            "Epoch 431/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1234e-09 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9796\n",
            "Epoch 432/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0598e-09 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9797\n",
            "Epoch 433/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0174e-09 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9795\n",
            "Epoch 434/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1286e-09 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9795\n",
            "Epoch 435/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0942e-09 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9796\n",
            "Epoch 436/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0810e-09 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9795\n",
            "Epoch 437/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0783e-09 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9796\n",
            "Epoch 438/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1048e-09 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9795\n",
            "Epoch 439/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0704e-09 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9795\n",
            "Epoch 440/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0783e-09 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9795\n",
            "Epoch 441/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0995e-09 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9797\n",
            "Epoch 442/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0783e-09 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9795\n",
            "Epoch 443/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1445e-09 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9795\n",
            "Epoch 444/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1022e-09 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9795\n",
            "Epoch 445/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1286e-09 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9795\n",
            "Epoch 446/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1419e-09 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9794\n",
            "Epoch 447/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0651e-09 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9795\n",
            "Epoch 448/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1392e-09 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9795\n",
            "Epoch 449/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1286e-09 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9794\n",
            "Epoch 450/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1286e-09 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9795\n",
            "Epoch 451/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0280e-09 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9794\n",
            "Epoch 452/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1525e-09 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9796\n",
            "Epoch 453/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0916e-09 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9795\n",
            "Epoch 454/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0704e-09 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9794\n",
            "Epoch 455/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1922e-09 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9795\n",
            "Epoch 456/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0677e-09 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9794\n",
            "Epoch 457/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1313e-09 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9795\n",
            "Epoch 458/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1339e-09 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9794\n",
            "Epoch 459/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0810e-09 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9794\n",
            "Epoch 460/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1472e-09 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9794\n",
            "Epoch 461/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1075e-09 - accuracy: 1.0000 - val_loss: 0.2025 - val_accuracy: 0.9794\n",
            "Epoch 462/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0969e-09 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9795\n",
            "Epoch 463/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1445e-09 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9794\n",
            "Epoch 464/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0995e-09 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9794\n",
            "Epoch 465/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1975e-09 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9795\n",
            "Epoch 466/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1339e-09 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 0.9795\n",
            "Epoch 467/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1392e-09 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 0.9795\n",
            "Epoch 468/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1763e-09 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9795\n",
            "Epoch 469/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1551e-09 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9795\n",
            "Epoch 470/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1578e-09 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9795\n",
            "Epoch 471/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1339e-09 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9795\n",
            "Epoch 472/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1339e-09 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 0.9795\n",
            "Epoch 473/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1498e-09 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9795\n",
            "Epoch 474/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1604e-09 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9794\n",
            "Epoch 475/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1684e-09 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9795\n",
            "Epoch 476/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1737e-09 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.9794\n",
            "Epoch 477/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1843e-09 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9795\n",
            "Epoch 478/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1498e-09 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 0.9795\n",
            "Epoch 479/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2055e-09 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9794\n",
            "Epoch 480/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1101e-09 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9795\n",
            "Epoch 481/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1816e-09 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.9795\n",
            "Epoch 482/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1843e-09 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9794\n",
            "Epoch 483/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1234e-09 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.9795\n",
            "Epoch 484/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1816e-09 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9793\n",
            "Epoch 485/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1790e-09 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9794\n",
            "Epoch 486/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1022e-09 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 0.9794\n",
            "Epoch 487/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1922e-09 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9794\n",
            "Epoch 488/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0995e-09 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 0.9793\n",
            "Epoch 489/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2240e-09 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 0.9795\n",
            "Epoch 490/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1737e-09 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9795\n",
            "Epoch 491/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1525e-09 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9794\n",
            "Epoch 492/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1737e-09 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9795\n",
            "Epoch 493/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1896e-09 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9795\n",
            "Epoch 494/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1075e-09 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9794\n",
            "Epoch 495/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1551e-09 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9795\n",
            "Epoch 496/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1525e-09 - accuracy: 1.0000 - val_loss: 0.2046 - val_accuracy: 0.9795\n",
            "Epoch 497/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2108e-09 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.9795\n",
            "Epoch 498/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1710e-09 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 0.9794\n",
            "Epoch 499/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1710e-09 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.9794\n",
            "Epoch 500/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1869e-09 - accuracy: 1.0000 - val_loss: 0.2046 - val_accuracy: 0.9795\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0512 - accuracy: 0.9949\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1595 - accuracy: 0.9816\n",
            "train accuracy :  0.994866669178009 train loss :  0.05115368217229843\n",
            "test accuracy :  0.9815999865531921  test loss :  0.15946437418460846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S1-tzs7pQ-kL",
        "outputId": "a2b6d9d0-a534-4f07-b84c-f04293848910"
      },
      "source": [
        "#신경망 학습4\n",
        "model1_4 = models.Sequential([\n",
        "                            Flatten(input_shape = (28, 28)),\n",
        "                            Dense(512, activation= 'relu'),\n",
        "                            Dense(10, activation= 'softmax')\n",
        "                            ])\n",
        "\n",
        "model1_4.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "hist1_4 = model1_4.fit(train_x, train_y, epochs = 1000, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "#학습 그래프4\n",
        "plt.plot(hist1_4.history['accuracy'], 'b-')\n",
        "plt.plot(hist1_4.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train1_4 = model1_4.evaluate(train_x, train_y)\n",
        "sc_test1_4 = model1_4.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train1_4[1], \"train loss : \", sc_train1_4[0])\n",
        "print(\"test accuracy : \", sc_test1_4[1], \" test loss : \", sc_test1_4[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3709 - accuracy: 0.8987 - val_loss: 0.1955 - val_accuracy: 0.9449\n",
            "Epoch 2/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.1603 - accuracy: 0.9545 - val_loss: 0.1509 - val_accuracy: 0.9559\n",
            "Epoch 3/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.1092 - accuracy: 0.9695 - val_loss: 0.1194 - val_accuracy: 0.9661\n",
            "Epoch 4/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0821 - accuracy: 0.9766 - val_loss: 0.1110 - val_accuracy: 0.9681\n",
            "Epoch 5/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0624 - accuracy: 0.9831 - val_loss: 0.1008 - val_accuracy: 0.9691\n",
            "Epoch 6/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0481 - accuracy: 0.9870 - val_loss: 0.0936 - val_accuracy: 0.9727\n",
            "Epoch 7/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0385 - accuracy: 0.9899 - val_loss: 0.0921 - val_accuracy: 0.9721\n",
            "Epoch 8/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0304 - accuracy: 0.9924 - val_loss: 0.0871 - val_accuracy: 0.9742\n",
            "Epoch 9/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0231 - accuracy: 0.9950 - val_loss: 0.0854 - val_accuracy: 0.9740\n",
            "Epoch 10/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0184 - accuracy: 0.9967 - val_loss: 0.0820 - val_accuracy: 0.9765\n",
            "Epoch 11/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0151 - accuracy: 0.9972 - val_loss: 0.0892 - val_accuracy: 0.9741\n",
            "Epoch 12/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0123 - accuracy: 0.9981 - val_loss: 0.0832 - val_accuracy: 0.9758\n",
            "Epoch 13/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0101 - accuracy: 0.9985 - val_loss: 0.0865 - val_accuracy: 0.9755\n",
            "Epoch 14/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0074 - accuracy: 0.9995 - val_loss: 0.0837 - val_accuracy: 0.9777\n",
            "Epoch 15/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0064 - accuracy: 0.9995 - val_loss: 0.0849 - val_accuracy: 0.9759\n",
            "Epoch 16/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0046 - accuracy: 0.9998 - val_loss: 0.0873 - val_accuracy: 0.9763\n",
            "Epoch 17/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 0.9997 - val_loss: 0.0907 - val_accuracy: 0.9769\n",
            "Epoch 18/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0038 - accuracy: 0.9998 - val_loss: 0.0844 - val_accuracy: 0.9781\n",
            "Epoch 19/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.0865 - val_accuracy: 0.9774\n",
            "Epoch 20/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0873 - val_accuracy: 0.9780\n",
            "Epoch 21/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9779\n",
            "Epoch 22/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 0.9788\n",
            "Epoch 23/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9788\n",
            "Epoch 24/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0896 - val_accuracy: 0.9777\n",
            "Epoch 25/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.5765e-04 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9787\n",
            "Epoch 26/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.7274e-04 - accuracy: 1.0000 - val_loss: 0.0925 - val_accuracy: 0.9789\n",
            "Epoch 27/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.4831e-04 - accuracy: 1.0000 - val_loss: 0.0926 - val_accuracy: 0.9784\n",
            "Epoch 28/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.6419e-04 - accuracy: 1.0000 - val_loss: 0.0936 - val_accuracy: 0.9785\n",
            "Epoch 29/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.8098e-04 - accuracy: 1.0000 - val_loss: 0.0950 - val_accuracy: 0.9782\n",
            "Epoch 30/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.2973e-04 - accuracy: 1.0000 - val_loss: 0.0960 - val_accuracy: 0.9785\n",
            "Epoch 31/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.7654e-04 - accuracy: 1.0000 - val_loss: 0.0960 - val_accuracy: 0.9791\n",
            "Epoch 32/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.0640e-04 - accuracy: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9786\n",
            "Epoch 33/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.8435e-04 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9789\n",
            "Epoch 34/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.3623e-04 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 0.9783\n",
            "Epoch 35/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.9471e-04 - accuracy: 1.0000 - val_loss: 0.0998 - val_accuracy: 0.9790\n",
            "Epoch 36/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.6458e-04 - accuracy: 1.0000 - val_loss: 0.1003 - val_accuracy: 0.9783\n",
            "Epoch 37/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.3626e-04 - accuracy: 1.0000 - val_loss: 0.1011 - val_accuracy: 0.9787\n",
            "Epoch 38/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.1431e-04 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9787\n",
            "Epoch 39/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.9494e-04 - accuracy: 1.0000 - val_loss: 0.1026 - val_accuracy: 0.9787\n",
            "Epoch 40/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.7192e-04 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 0.9793\n",
            "Epoch 41/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.6014e-04 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9795\n",
            "Epoch 42/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4396e-04 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9793\n",
            "Epoch 43/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2886e-04 - accuracy: 1.0000 - val_loss: 0.1069 - val_accuracy: 0.9793\n",
            "Epoch 44/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1202e-04 - accuracy: 1.0000 - val_loss: 0.1076 - val_accuracy: 0.9797\n",
            "Epoch 45/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0301e-04 - accuracy: 1.0000 - val_loss: 0.1084 - val_accuracy: 0.9788\n",
            "Epoch 46/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.5737e-05 - accuracy: 1.0000 - val_loss: 0.1087 - val_accuracy: 0.9793\n",
            "Epoch 47/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.3498e-05 - accuracy: 1.0000 - val_loss: 0.1100 - val_accuracy: 0.9793\n",
            "Epoch 48/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.3963e-05 - accuracy: 1.0000 - val_loss: 0.1104 - val_accuracy: 0.9799\n",
            "Epoch 49/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.7417e-05 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9791\n",
            "Epoch 50/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.1664e-05 - accuracy: 1.0000 - val_loss: 0.1131 - val_accuracy: 0.9793\n",
            "Epoch 51/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.5559e-05 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.9794\n",
            "Epoch 52/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.1306e-05 - accuracy: 1.0000 - val_loss: 0.1141 - val_accuracy: 0.9794\n",
            "Epoch 53/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.5814e-05 - accuracy: 1.0000 - val_loss: 0.1142 - val_accuracy: 0.9792\n",
            "Epoch 54/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.0965e-05 - accuracy: 1.0000 - val_loss: 0.1151 - val_accuracy: 0.9799\n",
            "Epoch 55/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.7155e-05 - accuracy: 1.0000 - val_loss: 0.1168 - val_accuracy: 0.9795\n",
            "Epoch 56/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.3978e-05 - accuracy: 1.0000 - val_loss: 0.1175 - val_accuracy: 0.9793\n",
            "Epoch 57/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.0294e-05 - accuracy: 1.0000 - val_loss: 0.1183 - val_accuracy: 0.9795\n",
            "Epoch 58/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.7706e-05 - accuracy: 1.0000 - val_loss: 0.1198 - val_accuracy: 0.9794\n",
            "Epoch 59/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.4742e-05 - accuracy: 1.0000 - val_loss: 0.1200 - val_accuracy: 0.9798\n",
            "Epoch 60/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.2748e-05 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 0.9798\n",
            "Epoch 61/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.0481e-05 - accuracy: 1.0000 - val_loss: 0.1211 - val_accuracy: 0.9795\n",
            "Epoch 62/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8935e-05 - accuracy: 1.0000 - val_loss: 0.1222 - val_accuracy: 0.9794\n",
            "Epoch 63/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.7343e-05 - accuracy: 1.0000 - val_loss: 0.1237 - val_accuracy: 0.9799\n",
            "Epoch 64/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5246e-05 - accuracy: 1.0000 - val_loss: 0.1253 - val_accuracy: 0.9795\n",
            "Epoch 65/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3815e-05 - accuracy: 1.0000 - val_loss: 0.1255 - val_accuracy: 0.9797\n",
            "Epoch 66/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2859e-05 - accuracy: 1.0000 - val_loss: 0.1261 - val_accuracy: 0.9799\n",
            "Epoch 67/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1356e-05 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9799\n",
            "Epoch 68/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0287e-05 - accuracy: 1.0000 - val_loss: 0.1278 - val_accuracy: 0.9797\n",
            "Epoch 69/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.4582e-06 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.9799\n",
            "Epoch 70/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.4206e-06 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 0.9797\n",
            "Epoch 71/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.8077e-06 - accuracy: 1.0000 - val_loss: 0.1299 - val_accuracy: 0.9798\n",
            "Epoch 72/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.0011e-06 - accuracy: 1.0000 - val_loss: 0.1315 - val_accuracy: 0.9799\n",
            "Epoch 73/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.3743e-06 - accuracy: 1.0000 - val_loss: 0.1329 - val_accuracy: 0.9795\n",
            "Epoch 74/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.8091e-06 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.9795\n",
            "Epoch 75/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.2422e-06 - accuracy: 1.0000 - val_loss: 0.1341 - val_accuracy: 0.9796\n",
            "Epoch 76/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.7642e-06 - accuracy: 1.0000 - val_loss: 0.1346 - val_accuracy: 0.9798\n",
            "Epoch 77/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.3422e-06 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.9794\n",
            "Epoch 78/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.9699e-06 - accuracy: 1.0000 - val_loss: 0.1364 - val_accuracy: 0.9801\n",
            "Epoch 79/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.6075e-06 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9795\n",
            "Epoch 80/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.3554e-06 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9798\n",
            "Epoch 81/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.9817e-06 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9801\n",
            "Epoch 82/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.7247e-06 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.9800\n",
            "Epoch 83/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.4911e-06 - accuracy: 1.0000 - val_loss: 0.1407 - val_accuracy: 0.9801\n",
            "Epoch 84/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.2511e-06 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9801\n",
            "Epoch 85/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.0772e-06 - accuracy: 1.0000 - val_loss: 0.1419 - val_accuracy: 0.9801\n",
            "Epoch 86/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8950e-06 - accuracy: 1.0000 - val_loss: 0.1437 - val_accuracy: 0.9798\n",
            "Epoch 87/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.7155e-06 - accuracy: 1.0000 - val_loss: 0.1445 - val_accuracy: 0.9796\n",
            "Epoch 88/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5543e-06 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.9800\n",
            "Epoch 89/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4225e-06 - accuracy: 1.0000 - val_loss: 0.1452 - val_accuracy: 0.9799\n",
            "Epoch 90/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3437e-06 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.9797\n",
            "Epoch 91/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2027e-06 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9803\n",
            "Epoch 92/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0984e-06 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 0.9801\n",
            "Epoch 93/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.9963e-07 - accuracy: 1.0000 - val_loss: 0.1487 - val_accuracy: 0.9803\n",
            "Epoch 94/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.2098e-07 - accuracy: 1.0000 - val_loss: 0.1496 - val_accuracy: 0.9799\n",
            "Epoch 95/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.3745e-07 - accuracy: 1.0000 - val_loss: 0.1506 - val_accuracy: 0.9801\n",
            "Epoch 96/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.7724e-07 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 0.9800\n",
            "Epoch 97/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.1156e-07 - accuracy: 1.0000 - val_loss: 0.1518 - val_accuracy: 0.9800\n",
            "Epoch 98/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.4039e-07 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9800\n",
            "Epoch 99/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.0009e-07 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9804\n",
            "Epoch 100/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.5281e-07 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 0.9801\n",
            "Epoch 101/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.1850e-07 - accuracy: 1.0000 - val_loss: 0.1557 - val_accuracy: 0.9801\n",
            "Epoch 102/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.6326e-07 - accuracy: 1.0000 - val_loss: 0.1550 - val_accuracy: 0.9805\n",
            "Epoch 103/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.3043e-07 - accuracy: 1.0000 - val_loss: 0.1558 - val_accuracy: 0.9802\n",
            "Epoch 104/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.0178e-07 - accuracy: 1.0000 - val_loss: 0.1575 - val_accuracy: 0.9803\n",
            "Epoch 105/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.6860e-07 - accuracy: 1.0000 - val_loss: 0.1580 - val_accuracy: 0.9803\n",
            "Epoch 106/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.3895e-07 - accuracy: 1.0000 - val_loss: 0.1581 - val_accuracy: 0.9808\n",
            "Epoch 107/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.1388e-07 - accuracy: 1.0000 - val_loss: 0.1586 - val_accuracy: 0.9805\n",
            "Epoch 108/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.8816e-07 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 0.9802\n",
            "Epoch 109/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.6790e-07 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9801\n",
            "Epoch 110/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.4979e-07 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.9805\n",
            "Epoch 111/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.3226e-07 - accuracy: 1.0000 - val_loss: 0.1617 - val_accuracy: 0.9806\n",
            "Epoch 112/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.1434e-07 - accuracy: 1.0000 - val_loss: 0.1626 - val_accuracy: 0.9801\n",
            "Epoch 113/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.9952e-07 - accuracy: 1.0000 - val_loss: 0.1632 - val_accuracy: 0.9804\n",
            "Epoch 114/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8720e-07 - accuracy: 1.0000 - val_loss: 0.1637 - val_accuracy: 0.9802\n",
            "Epoch 115/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.7394e-07 - accuracy: 1.0000 - val_loss: 0.1642 - val_accuracy: 0.9804\n",
            "Epoch 116/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.6432e-07 - accuracy: 1.0000 - val_loss: 0.1648 - val_accuracy: 0.9805\n",
            "Epoch 117/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5093e-07 - accuracy: 1.0000 - val_loss: 0.1654 - val_accuracy: 0.9807\n",
            "Epoch 118/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4198e-07 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9805\n",
            "Epoch 119/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3202e-07 - accuracy: 1.0000 - val_loss: 0.1673 - val_accuracy: 0.9805\n",
            "Epoch 120/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2388e-07 - accuracy: 1.0000 - val_loss: 0.1670 - val_accuracy: 0.9804\n",
            "Epoch 121/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1802e-07 - accuracy: 1.0000 - val_loss: 0.1687 - val_accuracy: 0.9806\n",
            "Epoch 122/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1117e-07 - accuracy: 1.0000 - val_loss: 0.1682 - val_accuracy: 0.9805\n",
            "Epoch 123/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0343e-07 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 0.9807\n",
            "Epoch 124/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.7672e-08 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 0.9807\n",
            "Epoch 125/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.2930e-08 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 0.9807\n",
            "Epoch 126/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.6964e-08 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9806\n",
            "Epoch 127/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.2983e-08 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 0.9805\n",
            "Epoch 128/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.8056e-08 - accuracy: 1.0000 - val_loss: 0.1712 - val_accuracy: 0.9805\n",
            "Epoch 129/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.4426e-08 - accuracy: 1.0000 - val_loss: 0.1723 - val_accuracy: 0.9807\n",
            "Epoch 130/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.9859e-08 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 0.9805\n",
            "Epoch 131/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.7046e-08 - accuracy: 1.0000 - val_loss: 0.1731 - val_accuracy: 0.9805\n",
            "Epoch 132/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.3290e-08 - accuracy: 1.0000 - val_loss: 0.1738 - val_accuracy: 0.9806\n",
            "Epoch 133/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.0773e-08 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 0.9805\n",
            "Epoch 134/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7578e-08 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9807\n",
            "Epoch 135/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.5411e-08 - accuracy: 1.0000 - val_loss: 0.1750 - val_accuracy: 0.9805\n",
            "Epoch 136/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3030e-08 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 0.9805\n",
            "Epoch 137/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 5.0682e-08 - accuracy: 1.0000 - val_loss: 0.1758 - val_accuracy: 0.9806\n",
            "Epoch 138/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.8526e-08 - accuracy: 1.0000 - val_loss: 0.1762 - val_accuracy: 0.9807\n",
            "Epoch 139/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.6370e-08 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 0.9804\n",
            "Epoch 140/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.4696e-08 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9807\n",
            "Epoch 141/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.2968e-08 - accuracy: 1.0000 - val_loss: 0.1773 - val_accuracy: 0.9805\n",
            "Epoch 142/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4.1673e-08 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9805\n",
            "Epoch 143/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.9662e-08 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9807\n",
            "Epoch 144/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.8242e-08 - accuracy: 1.0000 - val_loss: 0.1783 - val_accuracy: 0.9806\n",
            "Epoch 145/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.7026e-08 - accuracy: 1.0000 - val_loss: 0.1787 - val_accuracy: 0.9807\n",
            "Epoch 146/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.5606e-08 - accuracy: 1.0000 - val_loss: 0.1788 - val_accuracy: 0.9805\n",
            "Epoch 147/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.4414e-08 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 0.9803\n",
            "Epoch 148/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.3307e-08 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 0.9805\n",
            "Epoch 149/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.2266e-08 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 0.9805\n",
            "Epoch 150/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1209e-08 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 0.9804\n",
            "Epoch 151/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3.0229e-08 - accuracy: 1.0000 - val_loss: 0.1807 - val_accuracy: 0.9807\n",
            "Epoch 152/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.9373e-08 - accuracy: 1.0000 - val_loss: 0.1808 - val_accuracy: 0.9807\n",
            "Epoch 153/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.8655e-08 - accuracy: 1.0000 - val_loss: 0.1813 - val_accuracy: 0.9806\n",
            "Epoch 154/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.7691e-08 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9807\n",
            "Epoch 155/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.6851e-08 - accuracy: 1.0000 - val_loss: 0.1818 - val_accuracy: 0.9805\n",
            "Epoch 156/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.6189e-08 - accuracy: 1.0000 - val_loss: 0.1818 - val_accuracy: 0.9804\n",
            "Epoch 157/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.5471e-08 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9805\n",
            "Epoch 158/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.4878e-08 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 0.9805\n",
            "Epoch 159/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.4067e-08 - accuracy: 1.0000 - val_loss: 0.1827 - val_accuracy: 0.9805\n",
            "Epoch 160/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.3580e-08 - accuracy: 1.0000 - val_loss: 0.1827 - val_accuracy: 0.9807\n",
            "Epoch 161/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.2954e-08 - accuracy: 1.0000 - val_loss: 0.1831 - val_accuracy: 0.9806\n",
            "Epoch 162/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.2332e-08 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 0.9804\n",
            "Epoch 163/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.2030e-08 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9807\n",
            "Epoch 164/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.1383e-08 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9805\n",
            "Epoch 165/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.1002e-08 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9806\n",
            "Epoch 166/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2.0523e-08 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9805\n",
            "Epoch 167/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.9998e-08 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.9805\n",
            "Epoch 168/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.9529e-08 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.9805\n",
            "Epoch 169/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.9134e-08 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 0.9806\n",
            "Epoch 170/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8803e-08 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9805\n",
            "Epoch 171/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.8464e-08 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 0.9805\n",
            "Epoch 172/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8043e-08 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9807\n",
            "Epoch 173/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.7714e-08 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9806\n",
            "Epoch 174/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.7360e-08 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9807\n",
            "Epoch 175/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.7153e-08 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9805\n",
            "Epoch 176/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6750e-08 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9805\n",
            "Epoch 177/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.6406e-08 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 0.9806\n",
            "Epoch 178/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.6120e-08 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9804\n",
            "Epoch 179/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5937e-08 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9805\n",
            "Epoch 180/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5555e-08 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9805\n",
            "Epoch 181/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5365e-08 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 0.9806\n",
            "Epoch 182/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.5126e-08 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 0.9805\n",
            "Epoch 183/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4819e-08 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9805\n",
            "Epoch 184/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4541e-08 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9805\n",
            "Epoch 185/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4326e-08 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9805\n",
            "Epoch 186/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.4141e-08 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9805\n",
            "Epoch 187/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3918e-08 - accuracy: 1.0000 - val_loss: 0.1873 - val_accuracy: 0.9803\n",
            "Epoch 188/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3706e-08 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9805\n",
            "Epoch 189/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3606e-08 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9805\n",
            "Epoch 190/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3338e-08 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9805\n",
            "Epoch 191/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.3049e-08 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.9805\n",
            "Epoch 192/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2943e-08 - accuracy: 1.0000 - val_loss: 0.1879 - val_accuracy: 0.9805\n",
            "Epoch 193/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2739e-08 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9805\n",
            "Epoch 194/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2549e-08 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9805\n",
            "Epoch 195/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2422e-08 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9805\n",
            "Epoch 196/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.2300e-08 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 0.9804\n",
            "Epoch 197/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1998e-08 - accuracy: 1.0000 - val_loss: 0.1885 - val_accuracy: 0.9804\n",
            "Epoch 198/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1953e-08 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9804\n",
            "Epoch 199/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1757e-08 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 0.9805\n",
            "Epoch 200/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1619e-08 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9805\n",
            "Epoch 201/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1508e-08 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 0.9804\n",
            "Epoch 202/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1306e-08 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.9804\n",
            "Epoch 203/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1129e-08 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9803\n",
            "Epoch 204/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.1049e-08 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9802\n",
            "Epoch 205/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0930e-08 - accuracy: 1.0000 - val_loss: 0.1892 - val_accuracy: 0.9805\n",
            "Epoch 206/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0798e-08 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9805\n",
            "Epoch 207/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0673e-08 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9805\n",
            "Epoch 208/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0525e-08 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9803\n",
            "Epoch 209/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0414e-08 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9805\n",
            "Epoch 210/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0305e-08 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9803\n",
            "Epoch 211/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1.0122e-08 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.9803\n",
            "Epoch 212/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0077e-08 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9803\n",
            "Epoch 213/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.9791e-09 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9803\n",
            "Epoch 214/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.8387e-09 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 0.9805\n",
            "Epoch 215/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.7381e-09 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 0.9803\n",
            "Epoch 216/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.6056e-09 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9803\n",
            "Epoch 217/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.5208e-09 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9803\n",
            "Epoch 218/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.4440e-09 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9804\n",
            "Epoch 219/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.3063e-09 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9803\n",
            "Epoch 220/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9.2665e-09 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9803\n",
            "Epoch 221/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.0811e-09 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9803\n",
            "Epoch 222/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.0626e-09 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9803\n",
            "Epoch 223/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.9222e-09 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9803\n",
            "Epoch 224/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.8824e-09 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.9803\n",
            "Epoch 225/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.7182e-09 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9803\n",
            "Epoch 226/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.7288e-09 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9803\n",
            "Epoch 227/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.5831e-09 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9804\n",
            "Epoch 228/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.4480e-09 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9804\n",
            "Epoch 229/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.4665e-09 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9804\n",
            "Epoch 230/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.3817e-09 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9803\n",
            "Epoch 231/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.2546e-09 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9804\n",
            "Epoch 232/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.2069e-09 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9803\n",
            "Epoch 233/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8.1248e-09 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9804\n",
            "Epoch 234/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.0797e-09 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9804\n",
            "Epoch 235/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.9817e-09 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9803\n",
            "Epoch 236/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.9711e-09 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9803\n",
            "Epoch 237/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.8281e-09 - accuracy: 1.0000 - val_loss: 0.1916 - val_accuracy: 0.9803\n",
            "Epoch 238/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.8201e-09 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9803\n",
            "Epoch 239/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7115e-09 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9803\n",
            "Epoch 240/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7142e-09 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 0.9803\n",
            "Epoch 241/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.6135e-09 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9803\n",
            "Epoch 242/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.5950e-09 - accuracy: 1.0000 - val_loss: 0.1919 - val_accuracy: 0.9802\n",
            "Epoch 243/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.4996e-09 - accuracy: 1.0000 - val_loss: 0.1920 - val_accuracy: 0.9804\n",
            "Epoch 244/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4916e-09 - accuracy: 1.0000 - val_loss: 0.1920 - val_accuracy: 0.9803\n",
            "Epoch 245/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.3565e-09 - accuracy: 1.0000 - val_loss: 0.1920 - val_accuracy: 0.9803\n",
            "Epoch 246/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.3512e-09 - accuracy: 1.0000 - val_loss: 0.1919 - val_accuracy: 0.9803\n",
            "Epoch 247/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.2612e-09 - accuracy: 1.0000 - val_loss: 0.1922 - val_accuracy: 0.9803\n",
            "Epoch 248/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 7.1790e-09 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9803\n",
            "Epoch 249/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.2691e-09 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9803\n",
            "Epoch 250/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0784e-09 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9803\n",
            "Epoch 251/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0466e-09 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 0.9803\n",
            "Epoch 252/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0492e-09 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9803\n",
            "Epoch 253/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.9804e-09 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 0.9803\n",
            "Epoch 254/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8718e-09 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 0.9803\n",
            "Epoch 255/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8956e-09 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9803\n",
            "Epoch 256/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8929e-09 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 0.9803\n",
            "Epoch 257/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.7737e-09 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 0.9802\n",
            "Epoch 258/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7499e-09 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9803\n",
            "Epoch 259/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.6969e-09 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9803\n",
            "Epoch 260/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7711e-09 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9803\n",
            "Epoch 261/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5512e-09 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9803\n",
            "Epoch 262/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5724e-09 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9802\n",
            "Epoch 263/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5168e-09 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9803\n",
            "Epoch 264/1000\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 6.4717e-09 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9803\n",
            "Epoch 265/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5009e-09 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9803\n",
            "Epoch 266/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.4452e-09 - accuracy: 1.0000 - val_loss: 0.1932 - val_accuracy: 0.9803\n",
            "Epoch 267/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.4611e-09 - accuracy: 1.0000 - val_loss: 0.1932 - val_accuracy: 0.9803\n",
            "Epoch 268/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3976e-09 - accuracy: 1.0000 - val_loss: 0.1932 - val_accuracy: 0.9803\n",
            "Epoch 269/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2890e-09 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9803\n",
            "Epoch 270/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3207e-09 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9803\n",
            "Epoch 271/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2625e-09 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9803\n",
            "Epoch 272/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2174e-09 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9803\n",
            "Epoch 273/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2757e-09 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9801\n",
            "Epoch 274/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1724e-09 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9803\n",
            "Epoch 275/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1724e-09 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 0.9802\n",
            "Epoch 276/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1565e-09 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9801\n",
            "Epoch 277/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1538e-09 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9802\n",
            "Epoch 278/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1062e-09 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9801\n",
            "Epoch 279/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0532e-09 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 0.9802\n",
            "Epoch 280/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0293e-09 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 0.9802\n",
            "Epoch 281/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0717e-09 - accuracy: 1.0000 - val_loss: 0.1940 - val_accuracy: 0.9802\n",
            "Epoch 282/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9949e-09 - accuracy: 1.0000 - val_loss: 0.1939 - val_accuracy: 0.9802\n",
            "Epoch 283/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9684e-09 - accuracy: 1.0000 - val_loss: 0.1940 - val_accuracy: 0.9802\n",
            "Epoch 284/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9658e-09 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9803\n",
            "Epoch 285/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8969e-09 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9801\n",
            "Epoch 286/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9313e-09 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9802\n",
            "Epoch 287/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8386e-09 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9801\n",
            "Epoch 288/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8969e-09 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 0.9802\n",
            "Epoch 289/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8571e-09 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 0.9801\n",
            "Epoch 290/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8439e-09 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9801\n",
            "Epoch 291/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8519e-09 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9801\n",
            "Epoch 292/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7538e-09 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9801\n",
            "Epoch 293/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7724e-09 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9801\n",
            "Epoch 294/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7538e-09 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9801\n",
            "Epoch 295/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7485e-09 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9801\n",
            "Epoch 296/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7512e-09 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9801\n",
            "Epoch 297/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7220e-09 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9801\n",
            "Epoch 298/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6399e-09 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9801\n",
            "Epoch 299/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6108e-09 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 0.9800\n",
            "Epoch 300/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6320e-09 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9801\n",
            "Epoch 301/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6426e-09 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.9801\n",
            "Epoch 302/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6505e-09 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9801\n",
            "Epoch 303/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6293e-09 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9801\n",
            "Epoch 304/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6028e-09 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9801\n",
            "Epoch 305/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5816e-09 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 0.9801\n",
            "Epoch 306/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5631e-09 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9801\n",
            "Epoch 307/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5472e-09 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9801\n",
            "Epoch 308/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5048e-09 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9801\n",
            "Epoch 309/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5419e-09 - accuracy: 1.0000 - val_loss: 0.1954 - val_accuracy: 0.9801\n",
            "Epoch 310/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4995e-09 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9801\n",
            "Epoch 311/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4651e-09 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.9801\n",
            "Epoch 312/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5313e-09 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9801\n",
            "Epoch 313/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4677e-09 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.9801\n",
            "Epoch 314/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4942e-09 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9801\n",
            "Epoch 315/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4174e-09 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9801\n",
            "Epoch 316/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4942e-09 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9801\n",
            "Epoch 317/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3962e-09 - accuracy: 1.0000 - val_loss: 0.1958 - val_accuracy: 0.9801\n",
            "Epoch 318/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3538e-09 - accuracy: 1.0000 - val_loss: 0.1958 - val_accuracy: 0.9802\n",
            "Epoch 319/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3856e-09 - accuracy: 1.0000 - val_loss: 0.1958 - val_accuracy: 0.9802\n",
            "Epoch 320/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4095e-09 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9802\n",
            "Epoch 321/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3591e-09 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9802\n",
            "Epoch 322/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3671e-09 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 0.9802\n",
            "Epoch 323/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3644e-09 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.9802\n",
            "Epoch 324/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3167e-09 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.9801\n",
            "Epoch 325/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3061e-09 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9801\n",
            "Epoch 326/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3803e-09 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9802\n",
            "Epoch 327/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3300e-09 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9801\n",
            "Epoch 328/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2823e-09 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9801\n",
            "Epoch 329/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3353e-09 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.9801\n",
            "Epoch 330/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3300e-09 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.9802\n",
            "Epoch 331/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3061e-09 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.9801\n",
            "Epoch 332/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2664e-09 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9802\n",
            "Epoch 333/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3141e-09 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9801\n",
            "Epoch 334/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2664e-09 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.9801\n",
            "Epoch 335/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2558e-09 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9802\n",
            "Epoch 336/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2293e-09 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9801\n",
            "Epoch 337/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2532e-09 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9802\n",
            "Epoch 338/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2373e-09 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9801\n",
            "Epoch 339/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2849e-09 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 0.9800\n",
            "Epoch 340/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2055e-09 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9801\n",
            "Epoch 341/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2426e-09 - accuracy: 1.0000 - val_loss: 0.1971 - val_accuracy: 0.9800\n",
            "Epoch 342/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2611e-09 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9801\n",
            "Epoch 343/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2240e-09 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9800\n",
            "Epoch 344/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2320e-09 - accuracy: 1.0000 - val_loss: 0.1971 - val_accuracy: 0.9801\n",
            "Epoch 345/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1684e-09 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9801\n",
            "Epoch 346/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1922e-09 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9801\n",
            "Epoch 347/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1578e-09 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9801\n",
            "Epoch 348/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2028e-09 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9803\n",
            "Epoch 349/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2267e-09 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9801\n",
            "Epoch 350/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1366e-09 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9800\n",
            "Epoch 351/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2028e-09 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 0.9801\n",
            "Epoch 352/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1366e-09 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 0.9801\n",
            "Epoch 353/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2134e-09 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 0.9801\n",
            "Epoch 354/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1604e-09 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 0.9801\n",
            "Epoch 355/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2240e-09 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 0.9801\n",
            "Epoch 356/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1657e-09 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9800\n",
            "Epoch 357/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1445e-09 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 0.9801\n",
            "Epoch 358/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1048e-09 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9801\n",
            "Epoch 359/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1207e-09 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9801\n",
            "Epoch 360/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1366e-09 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9801\n",
            "Epoch 361/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0942e-09 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9801\n",
            "Epoch 362/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1286e-09 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 0.9801\n",
            "Epoch 363/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1286e-09 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 0.9801\n",
            "Epoch 364/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1048e-09 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9801\n",
            "Epoch 365/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1684e-09 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9800\n",
            "Epoch 366/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1763e-09 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.9801\n",
            "Epoch 367/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1366e-09 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.9801\n",
            "Epoch 368/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2028e-09 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9800\n",
            "Epoch 369/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1313e-09 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 0.9801\n",
            "Epoch 370/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1313e-09 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.9801\n",
            "Epoch 371/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0651e-09 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9801\n",
            "Epoch 372/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1816e-09 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9801\n",
            "Epoch 373/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1419e-09 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9801\n",
            "Epoch 374/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1313e-09 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9801\n",
            "Epoch 375/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1128e-09 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.9801\n",
            "Epoch 376/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0704e-09 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.9801\n",
            "Epoch 377/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0995e-09 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9800\n",
            "Epoch 378/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1631e-09 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.9801\n",
            "Epoch 379/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0969e-09 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 0.9801\n",
            "Epoch 380/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1128e-09 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9801\n",
            "Epoch 381/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0995e-09 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9801\n",
            "Epoch 382/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0942e-09 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9801\n",
            "Epoch 383/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0704e-09 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9801\n",
            "Epoch 384/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0810e-09 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9801\n",
            "Epoch 385/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0757e-09 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9801\n",
            "Epoch 386/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1631e-09 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.9801\n",
            "Epoch 387/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1710e-09 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9801\n",
            "Epoch 388/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1260e-09 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9801\n",
            "Epoch 389/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1154e-09 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.9800\n",
            "Epoch 390/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0704e-09 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9801\n",
            "Epoch 391/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1419e-09 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9800\n",
            "Epoch 392/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0995e-09 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9800\n",
            "Epoch 393/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1472e-09 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9800\n",
            "Epoch 394/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1048e-09 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9801\n",
            "Epoch 395/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1525e-09 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9800\n",
            "Epoch 396/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1525e-09 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.9799\n",
            "Epoch 397/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1260e-09 - accuracy: 1.0000 - val_loss: 0.1996 - val_accuracy: 0.9801\n",
            "Epoch 398/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0969e-09 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9799\n",
            "Epoch 399/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1604e-09 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9800\n",
            "Epoch 400/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1154e-09 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9799\n",
            "Epoch 401/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0810e-09 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9800\n",
            "Epoch 402/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1022e-09 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9800\n",
            "Epoch 403/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1763e-09 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9799\n",
            "Epoch 404/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1631e-09 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9799\n",
            "Epoch 405/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1260e-09 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9799\n",
            "Epoch 406/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1551e-09 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9801\n",
            "Epoch 407/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1551e-09 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9800\n",
            "Epoch 408/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0545e-09 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9799\n",
            "Epoch 409/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0995e-09 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9799\n",
            "Epoch 410/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1313e-09 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9799\n",
            "Epoch 411/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1604e-09 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9799\n",
            "Epoch 412/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1869e-09 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9799\n",
            "Epoch 413/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1525e-09 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9799\n",
            "Epoch 414/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1578e-09 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9799\n",
            "Epoch 415/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1604e-09 - accuracy: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.9798\n",
            "Epoch 416/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1498e-09 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9799\n",
            "Epoch 417/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1207e-09 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9798\n",
            "Epoch 418/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1472e-09 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9798\n",
            "Epoch 419/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0889e-09 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9798\n",
            "Epoch 420/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1234e-09 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9799\n",
            "Epoch 421/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1154e-09 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9798\n",
            "Epoch 422/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1286e-09 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9799\n",
            "Epoch 423/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1339e-09 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9798\n",
            "Epoch 424/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1790e-09 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9799\n",
            "Epoch 425/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1022e-09 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9797\n",
            "Epoch 426/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1525e-09 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9799\n",
            "Epoch 427/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1286e-09 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9797\n",
            "Epoch 428/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1551e-09 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9798\n",
            "Epoch 429/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0995e-09 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9797\n",
            "Epoch 430/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1631e-09 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9797\n",
            "Epoch 431/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1392e-09 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9797\n",
            "Epoch 432/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1578e-09 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9797\n",
            "Epoch 433/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1181e-09 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9797\n",
            "Epoch 434/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1472e-09 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9797\n",
            "Epoch 435/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1763e-09 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9798\n",
            "Epoch 436/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1339e-09 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9795\n",
            "Epoch 437/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2028e-09 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9796\n",
            "Epoch 438/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2055e-09 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9797\n",
            "Epoch 439/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1657e-09 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9797\n",
            "Epoch 440/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1657e-09 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9797\n",
            "Epoch 441/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2426e-09 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9796\n",
            "Epoch 442/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1684e-09 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9797\n",
            "Epoch 443/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2108e-09 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9797\n",
            "Epoch 444/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1551e-09 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9797\n",
            "Epoch 445/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1869e-09 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9796\n",
            "Epoch 446/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1763e-09 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9797\n",
            "Epoch 447/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1869e-09 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9797\n",
            "Epoch 448/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1816e-09 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9796\n",
            "Epoch 449/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1657e-09 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.9795\n",
            "Epoch 450/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1763e-09 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9795\n",
            "Epoch 451/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2214e-09 - accuracy: 1.0000 - val_loss: 0.2025 - val_accuracy: 0.9795\n",
            "Epoch 452/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2108e-09 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9795\n",
            "Epoch 453/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1790e-09 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9795\n",
            "Epoch 454/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2505e-09 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.9795\n",
            "Epoch 455/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1869e-09 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9796\n",
            "Epoch 456/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2055e-09 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9795\n",
            "Epoch 457/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1843e-09 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 0.9795\n",
            "Epoch 458/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2849e-09 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.9795\n",
            "Epoch 459/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1684e-09 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9795\n",
            "Epoch 460/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2055e-09 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9794\n",
            "Epoch 461/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2240e-09 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 0.9795\n",
            "Epoch 462/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2028e-09 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 0.9795\n",
            "Epoch 463/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2399e-09 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9795\n",
            "Epoch 464/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1896e-09 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9794\n",
            "Epoch 465/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2002e-09 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9794\n",
            "Epoch 466/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2426e-09 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9794\n",
            "Epoch 467/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1975e-09 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9793\n",
            "Epoch 468/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2267e-09 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9794\n",
            "Epoch 469/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2320e-09 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9793\n",
            "Epoch 470/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1949e-09 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9794\n",
            "Epoch 471/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2134e-09 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9795\n",
            "Epoch 472/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2691e-09 - accuracy: 1.0000 - val_loss: 0.2038 - val_accuracy: 0.9794\n",
            "Epoch 473/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1737e-09 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9793\n",
            "Epoch 474/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2214e-09 - accuracy: 1.0000 - val_loss: 0.2038 - val_accuracy: 0.9795\n",
            "Epoch 475/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2955e-09 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 0.9793\n",
            "Epoch 476/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2240e-09 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9793\n",
            "Epoch 477/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2373e-09 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9793\n",
            "Epoch 478/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2585e-09 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9793\n",
            "Epoch 479/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2849e-09 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9793\n",
            "Epoch 480/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2955e-09 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9793\n",
            "Epoch 481/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2426e-09 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9793\n",
            "Epoch 482/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2717e-09 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9793\n",
            "Epoch 483/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3088e-09 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 0.9793\n",
            "Epoch 484/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1763e-09 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9794\n",
            "Epoch 485/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2638e-09 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9794\n",
            "Epoch 486/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2902e-09 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9794\n",
            "Epoch 487/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2664e-09 - accuracy: 1.0000 - val_loss: 0.2046 - val_accuracy: 0.9793\n",
            "Epoch 488/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2743e-09 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 0.9793\n",
            "Epoch 489/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2770e-09 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 0.9792\n",
            "Epoch 490/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3061e-09 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9793\n",
            "Epoch 491/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2743e-09 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.9793\n",
            "Epoch 492/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1922e-09 - accuracy: 1.0000 - val_loss: 0.2046 - val_accuracy: 0.9793\n",
            "Epoch 493/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2585e-09 - accuracy: 1.0000 - val_loss: 0.2046 - val_accuracy: 0.9792\n",
            "Epoch 494/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3432e-09 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.9791\n",
            "Epoch 495/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2929e-09 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.9793\n",
            "Epoch 496/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3088e-09 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 0.9791\n",
            "Epoch 497/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2479e-09 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 0.9792\n",
            "Epoch 498/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2823e-09 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 0.9792\n",
            "Epoch 499/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2743e-09 - accuracy: 1.0000 - val_loss: 0.2052 - val_accuracy: 0.9793\n",
            "Epoch 500/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3141e-09 - accuracy: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.9793\n",
            "Epoch 501/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3830e-09 - accuracy: 1.0000 - val_loss: 0.2051 - val_accuracy: 0.9792\n",
            "Epoch 502/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3035e-09 - accuracy: 1.0000 - val_loss: 0.2052 - val_accuracy: 0.9792\n",
            "Epoch 503/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2532e-09 - accuracy: 1.0000 - val_loss: 0.2053 - val_accuracy: 0.9792\n",
            "Epoch 504/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3061e-09 - accuracy: 1.0000 - val_loss: 0.2054 - val_accuracy: 0.9792\n",
            "Epoch 505/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3353e-09 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 0.9791\n",
            "Epoch 506/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3485e-09 - accuracy: 1.0000 - val_loss: 0.2054 - val_accuracy: 0.9793\n",
            "Epoch 507/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3300e-09 - accuracy: 1.0000 - val_loss: 0.2053 - val_accuracy: 0.9791\n",
            "Epoch 508/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2638e-09 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 0.9791\n",
            "Epoch 509/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2982e-09 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9792\n",
            "Epoch 510/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2320e-09 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9791\n",
            "Epoch 511/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3909e-09 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.9791\n",
            "Epoch 512/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3936e-09 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9791\n",
            "Epoch 513/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3326e-09 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.9791\n",
            "Epoch 514/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3273e-09 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9790\n",
            "Epoch 515/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3909e-09 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.9792\n",
            "Epoch 516/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3671e-09 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9792\n",
            "Epoch 517/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2770e-09 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9791\n",
            "Epoch 518/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3459e-09 - accuracy: 1.0000 - val_loss: 0.2060 - val_accuracy: 0.9791\n",
            "Epoch 519/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3777e-09 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9791\n",
            "Epoch 520/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3512e-09 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9792\n",
            "Epoch 521/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3326e-09 - accuracy: 1.0000 - val_loss: 0.2060 - val_accuracy: 0.9791\n",
            "Epoch 522/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3194e-09 - accuracy: 1.0000 - val_loss: 0.2062 - val_accuracy: 0.9791\n",
            "Epoch 523/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3512e-09 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9791\n",
            "Epoch 524/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3220e-09 - accuracy: 1.0000 - val_loss: 0.2062 - val_accuracy: 0.9791\n",
            "Epoch 525/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3379e-09 - accuracy: 1.0000 - val_loss: 0.2064 - val_accuracy: 0.9791\n",
            "Epoch 526/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4704e-09 - accuracy: 1.0000 - val_loss: 0.2065 - val_accuracy: 0.9791\n",
            "Epoch 527/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3220e-09 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9789\n",
            "Epoch 528/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4095e-09 - accuracy: 1.0000 - val_loss: 0.2066 - val_accuracy: 0.9792\n",
            "Epoch 529/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4439e-09 - accuracy: 1.0000 - val_loss: 0.2064 - val_accuracy: 0.9790\n",
            "Epoch 530/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3909e-09 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9791\n",
            "Epoch 531/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3300e-09 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9790\n",
            "Epoch 532/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4068e-09 - accuracy: 1.0000 - val_loss: 0.2066 - val_accuracy: 0.9791\n",
            "Epoch 533/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3777e-09 - accuracy: 1.0000 - val_loss: 0.2066 - val_accuracy: 0.9790\n",
            "Epoch 534/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3856e-09 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9791\n",
            "Epoch 535/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4148e-09 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9791\n",
            "Epoch 536/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3406e-09 - accuracy: 1.0000 - val_loss: 0.2070 - val_accuracy: 0.9791\n",
            "Epoch 537/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4598e-09 - accuracy: 1.0000 - val_loss: 0.2070 - val_accuracy: 0.9791\n",
            "Epoch 538/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3909e-09 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 0.9791\n",
            "Epoch 539/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4704e-09 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9790\n",
            "Epoch 540/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3724e-09 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9789\n",
            "Epoch 541/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5154e-09 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9790\n",
            "Epoch 542/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3989e-09 - accuracy: 1.0000 - val_loss: 0.2073 - val_accuracy: 0.9790\n",
            "Epoch 543/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4412e-09 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 0.9789\n",
            "Epoch 544/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4200e-09 - accuracy: 1.0000 - val_loss: 0.2073 - val_accuracy: 0.9791\n",
            "Epoch 545/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4253e-09 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9791\n",
            "Epoch 546/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4704e-09 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9791\n",
            "Epoch 547/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3803e-09 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 0.9790\n",
            "Epoch 548/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5101e-09 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9791\n",
            "Epoch 549/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3803e-09 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.9789\n",
            "Epoch 550/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4518e-09 - accuracy: 1.0000 - val_loss: 0.2077 - val_accuracy: 0.9789\n",
            "Epoch 551/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4439e-09 - accuracy: 1.0000 - val_loss: 0.2077 - val_accuracy: 0.9791\n",
            "Epoch 552/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4386e-09 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.9789\n",
            "Epoch 553/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4306e-09 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.9789\n",
            "Epoch 554/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4916e-09 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9790\n",
            "Epoch 555/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5048e-09 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.9789\n",
            "Epoch 556/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4439e-09 - accuracy: 1.0000 - val_loss: 0.2078 - val_accuracy: 0.9789\n",
            "Epoch 557/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4492e-09 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9789\n",
            "Epoch 558/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4942e-09 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9789\n",
            "Epoch 559/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4810e-09 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9790\n",
            "Epoch 560/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4969e-09 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9789\n",
            "Epoch 561/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5260e-09 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9790\n",
            "Epoch 562/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4969e-09 - accuracy: 1.0000 - val_loss: 0.2082 - val_accuracy: 0.9789\n",
            "Epoch 563/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4386e-09 - accuracy: 1.0000 - val_loss: 0.2082 - val_accuracy: 0.9789\n",
            "Epoch 564/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4995e-09 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9789\n",
            "Epoch 565/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5101e-09 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9789\n",
            "Epoch 566/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5128e-09 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.9789\n",
            "Epoch 567/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5075e-09 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9789\n",
            "Epoch 568/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5525e-09 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9789\n",
            "Epoch 569/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4863e-09 - accuracy: 1.0000 - val_loss: 0.2087 - val_accuracy: 0.9789\n",
            "Epoch 570/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5048e-09 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9789\n",
            "Epoch 571/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5260e-09 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9789\n",
            "Epoch 572/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4757e-09 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.9789\n",
            "Epoch 573/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5552e-09 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9789\n",
            "Epoch 574/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4280e-09 - accuracy: 1.0000 - val_loss: 0.2089 - val_accuracy: 0.9789\n",
            "Epoch 575/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5790e-09 - accuracy: 1.0000 - val_loss: 0.2089 - val_accuracy: 0.9789\n",
            "Epoch 576/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5446e-09 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9788\n",
            "Epoch 577/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5128e-09 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.9789\n",
            "Epoch 578/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5737e-09 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9789\n",
            "Epoch 579/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5816e-09 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9789\n",
            "Epoch 580/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5790e-09 - accuracy: 1.0000 - val_loss: 0.2089 - val_accuracy: 0.9789\n",
            "Epoch 581/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5605e-09 - accuracy: 1.0000 - val_loss: 0.2089 - val_accuracy: 0.9788\n",
            "Epoch 582/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6055e-09 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9789\n",
            "Epoch 583/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5419e-09 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9789\n",
            "Epoch 584/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5896e-09 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9789\n",
            "Epoch 585/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5684e-09 - accuracy: 1.0000 - val_loss: 0.2093 - val_accuracy: 0.9788\n",
            "Epoch 586/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5816e-09 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.9789\n",
            "Epoch 587/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6346e-09 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9789\n",
            "Epoch 588/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5525e-09 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.9789\n",
            "Epoch 589/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6055e-09 - accuracy: 1.0000 - val_loss: 0.2093 - val_accuracy: 0.9789\n",
            "Epoch 590/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5816e-09 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9788\n",
            "Epoch 591/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5737e-09 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9789\n",
            "Epoch 592/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5922e-09 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9788\n",
            "Epoch 593/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5737e-09 - accuracy: 1.0000 - val_loss: 0.2097 - val_accuracy: 0.9789\n",
            "Epoch 594/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5843e-09 - accuracy: 1.0000 - val_loss: 0.2097 - val_accuracy: 0.9788\n",
            "Epoch 595/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5922e-09 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9787\n",
            "Epoch 596/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6214e-09 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9788\n",
            "Epoch 597/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4677e-09 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9786\n",
            "Epoch 598/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5896e-09 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9789\n",
            "Epoch 599/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5366e-09 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9789\n",
            "Epoch 600/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5896e-09 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.9788\n",
            "Epoch 601/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5684e-09 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9789\n",
            "Epoch 602/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5631e-09 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9788\n",
            "Epoch 603/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6346e-09 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9787\n",
            "Epoch 604/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6081e-09 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.9787\n",
            "Epoch 605/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5975e-09 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9788\n",
            "Epoch 606/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5446e-09 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9788\n",
            "Epoch 607/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5657e-09 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 0.9787\n",
            "Epoch 608/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5710e-09 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 0.9787\n",
            "Epoch 609/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.6585e-09 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9788\n",
            "Epoch 610/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5657e-09 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 0.9787\n",
            "Epoch 611/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5922e-09 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.9789\n",
            "Epoch 612/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5816e-09 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 0.9788\n",
            "Epoch 613/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6055e-09 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9786\n",
            "Epoch 614/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6691e-09 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9787\n",
            "Epoch 615/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6108e-09 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 0.9788\n",
            "Epoch 616/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6214e-09 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 0.9787\n",
            "Epoch 617/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6479e-09 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9785\n",
            "Epoch 618/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6426e-09 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 0.9788\n",
            "Epoch 619/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6187e-09 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9786\n",
            "Epoch 620/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5472e-09 - accuracy: 1.0000 - val_loss: 0.2106 - val_accuracy: 0.9787\n",
            "Epoch 621/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6081e-09 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9786\n",
            "Epoch 622/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5949e-09 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9787\n",
            "Epoch 623/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6399e-09 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9785\n",
            "Epoch 624/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6214e-09 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9786\n",
            "Epoch 625/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6187e-09 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9787\n",
            "Epoch 626/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6399e-09 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9788\n",
            "Epoch 627/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6664e-09 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9787\n",
            "Epoch 628/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6161e-09 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9788\n",
            "Epoch 629/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6240e-09 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9787\n",
            "Epoch 630/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6479e-09 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9787\n",
            "Epoch 631/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6320e-09 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9787\n",
            "Epoch 632/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6850e-09 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9787\n",
            "Epoch 633/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6505e-09 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9784\n",
            "Epoch 634/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6532e-09 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9787\n",
            "Epoch 635/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5763e-09 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9786\n",
            "Epoch 636/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6823e-09 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9787\n",
            "Epoch 637/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7141e-09 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9787\n",
            "Epoch 638/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7194e-09 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9786\n",
            "Epoch 639/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6744e-09 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9785\n",
            "Epoch 640/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5843e-09 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9784\n",
            "Epoch 641/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7035e-09 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9786\n",
            "Epoch 642/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7379e-09 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9786\n",
            "Epoch 643/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6797e-09 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9785\n",
            "Epoch 644/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6876e-09 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9785\n",
            "Epoch 645/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7167e-09 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9786\n",
            "Epoch 646/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7062e-09 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9784\n",
            "Epoch 647/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7194e-09 - accuracy: 1.0000 - val_loss: 0.2117 - val_accuracy: 0.9785\n",
            "Epoch 648/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6558e-09 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9783\n",
            "Epoch 649/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6585e-09 - accuracy: 1.0000 - val_loss: 0.2119 - val_accuracy: 0.9783\n",
            "Epoch 650/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6770e-09 - accuracy: 1.0000 - val_loss: 0.2119 - val_accuracy: 0.9785\n",
            "Epoch 651/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7009e-09 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9782\n",
            "Epoch 652/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7459e-09 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9783\n",
            "Epoch 653/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6956e-09 - accuracy: 1.0000 - val_loss: 0.2117 - val_accuracy: 0.9784\n",
            "Epoch 654/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7724e-09 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9784\n",
            "Epoch 655/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7035e-09 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9782\n",
            "Epoch 656/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6691e-09 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9783\n",
            "Epoch 657/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7194e-09 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9784\n",
            "Epoch 658/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7406e-09 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9783\n",
            "Epoch 659/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7750e-09 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9782\n",
            "Epoch 660/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7009e-09 - accuracy: 1.0000 - val_loss: 0.2126 - val_accuracy: 0.9782\n",
            "Epoch 661/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7273e-09 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 0.9782\n",
            "Epoch 662/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7247e-09 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 0.9783\n",
            "Epoch 663/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7565e-09 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9783\n",
            "Epoch 664/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6876e-09 - accuracy: 1.0000 - val_loss: 0.2125 - val_accuracy: 0.9783\n",
            "Epoch 665/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8174e-09 - accuracy: 1.0000 - val_loss: 0.2126 - val_accuracy: 0.9783\n",
            "Epoch 666/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7326e-09 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 0.9784\n",
            "Epoch 667/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7088e-09 - accuracy: 1.0000 - val_loss: 0.2125 - val_accuracy: 0.9783\n",
            "Epoch 668/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7247e-09 - accuracy: 1.0000 - val_loss: 0.2126 - val_accuracy: 0.9783\n",
            "Epoch 669/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7432e-09 - accuracy: 1.0000 - val_loss: 0.2125 - val_accuracy: 0.9782\n",
            "Epoch 670/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7062e-09 - accuracy: 1.0000 - val_loss: 0.2126 - val_accuracy: 0.9784\n",
            "Epoch 671/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7724e-09 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 0.9784\n",
            "Epoch 672/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7936e-09 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 0.9784\n",
            "Epoch 673/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6214e-09 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9784\n",
            "Epoch 674/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7618e-09 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9782\n",
            "Epoch 675/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7830e-09 - accuracy: 1.0000 - val_loss: 0.2131 - val_accuracy: 0.9783\n",
            "Epoch 676/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7459e-09 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9783\n",
            "Epoch 677/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7777e-09 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 0.9783\n",
            "Epoch 678/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7538e-09 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9783\n",
            "Epoch 679/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7697e-09 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 0.9783\n",
            "Epoch 680/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7247e-09 - accuracy: 1.0000 - val_loss: 0.2128 - val_accuracy: 0.9783\n",
            "Epoch 681/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8307e-09 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9783\n",
            "Epoch 682/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7035e-09 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 0.9784\n",
            "Epoch 683/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7220e-09 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9783\n",
            "Epoch 684/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8121e-09 - accuracy: 1.0000 - val_loss: 0.2128 - val_accuracy: 0.9783\n",
            "Epoch 685/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7856e-09 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9783\n",
            "Epoch 686/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7379e-09 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 0.9783\n",
            "Epoch 687/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7750e-09 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9782\n",
            "Epoch 688/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6876e-09 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9781\n",
            "Epoch 689/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8360e-09 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.9783\n",
            "Epoch 690/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7485e-09 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9782\n",
            "Epoch 691/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7777e-09 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.9784\n",
            "Epoch 692/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7883e-09 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9782\n",
            "Epoch 693/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8545e-09 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9782\n",
            "Epoch 694/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8466e-09 - accuracy: 1.0000 - val_loss: 0.2133 - val_accuracy: 0.9781\n",
            "Epoch 695/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8360e-09 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9783\n",
            "Epoch 696/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8386e-09 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9781\n",
            "Epoch 697/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7167e-09 - accuracy: 1.0000 - val_loss: 0.2136 - val_accuracy: 0.9783\n",
            "Epoch 698/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7644e-09 - accuracy: 1.0000 - val_loss: 0.2133 - val_accuracy: 0.9785\n",
            "Epoch 699/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8386e-09 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9781\n",
            "Epoch 700/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8121e-09 - accuracy: 1.0000 - val_loss: 0.2138 - val_accuracy: 0.9781\n",
            "Epoch 701/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8624e-09 - accuracy: 1.0000 - val_loss: 0.2136 - val_accuracy: 0.9783\n",
            "Epoch 702/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7936e-09 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9782\n",
            "Epoch 703/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8677e-09 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.9782\n",
            "Epoch 704/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7989e-09 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9783\n",
            "Epoch 705/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8068e-09 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9781\n",
            "Epoch 706/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8492e-09 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9783\n",
            "Epoch 707/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7830e-09 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9781\n",
            "Epoch 708/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8598e-09 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9782\n",
            "Epoch 709/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8068e-09 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9781\n",
            "Epoch 710/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9340e-09 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9783\n",
            "Epoch 711/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8545e-09 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9781\n",
            "Epoch 712/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8519e-09 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9783\n",
            "Epoch 713/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8571e-09 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9781\n",
            "Epoch 714/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8068e-09 - accuracy: 1.0000 - val_loss: 0.2146 - val_accuracy: 0.9781\n",
            "Epoch 715/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8624e-09 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9780\n",
            "Epoch 716/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8492e-09 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9782\n",
            "Epoch 717/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8201e-09 - accuracy: 1.0000 - val_loss: 0.2138 - val_accuracy: 0.9782\n",
            "Epoch 718/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8201e-09 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9781\n",
            "Epoch 719/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8333e-09 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9783\n",
            "Epoch 720/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9154e-09 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.9782\n",
            "Epoch 721/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8545e-09 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9781\n",
            "Epoch 722/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9128e-09 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.9781\n",
            "Epoch 723/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8545e-09 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.9781\n",
            "Epoch 724/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8466e-09 - accuracy: 1.0000 - val_loss: 0.2148 - val_accuracy: 0.9781\n",
            "Epoch 725/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8174e-09 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9782\n",
            "Epoch 726/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8439e-09 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9781\n",
            "Epoch 727/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9260e-09 - accuracy: 1.0000 - val_loss: 0.2146 - val_accuracy: 0.9782\n",
            "Epoch 728/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8571e-09 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.9782\n",
            "Epoch 729/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8413e-09 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.9781\n",
            "Epoch 730/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8598e-09 - accuracy: 1.0000 - val_loss: 0.2146 - val_accuracy: 0.9782\n",
            "Epoch 731/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9181e-09 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9782\n",
            "Epoch 732/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9154e-09 - accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 0.9779\n",
            "Epoch 733/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9366e-09 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.9782\n",
            "Epoch 734/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8333e-09 - accuracy: 1.0000 - val_loss: 0.2148 - val_accuracy: 0.9781\n",
            "Epoch 735/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8889e-09 - accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 0.9784\n",
            "Epoch 736/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8651e-09 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9782\n",
            "Epoch 737/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8413e-09 - accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 0.9781\n",
            "Epoch 738/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9207e-09 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9780\n",
            "Epoch 739/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8466e-09 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9781\n",
            "Epoch 740/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8757e-09 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9780\n",
            "Epoch 741/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9075e-09 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9781\n",
            "Epoch 742/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9022e-09 - accuracy: 1.0000 - val_loss: 0.2155 - val_accuracy: 0.9781\n",
            "Epoch 743/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9923e-09 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 0.9783\n",
            "Epoch 744/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.9896e-09 - accuracy: 1.0000 - val_loss: 0.2155 - val_accuracy: 0.9779\n",
            "Epoch 745/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9472e-09 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9781\n",
            "Epoch 746/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8042e-09 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9779\n",
            "Epoch 747/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9260e-09 - accuracy: 1.0000 - val_loss: 0.2155 - val_accuracy: 0.9783\n",
            "Epoch 748/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9578e-09 - accuracy: 1.0000 - val_loss: 0.2151 - val_accuracy: 0.9781\n",
            "Epoch 749/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8783e-09 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9779\n",
            "Epoch 750/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0028e-09 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9781\n",
            "Epoch 751/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0664e-09 - accuracy: 1.0000 - val_loss: 0.2151 - val_accuracy: 0.9781\n",
            "Epoch 752/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8863e-09 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 0.9779\n",
            "Epoch 753/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9764e-09 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9781\n",
            "Epoch 754/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7936e-09 - accuracy: 1.0000 - val_loss: 0.2158 - val_accuracy: 0.9781\n",
            "Epoch 755/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9128e-09 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9781\n",
            "Epoch 756/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9128e-09 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9781\n",
            "Epoch 757/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8916e-09 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 0.9780\n",
            "Epoch 758/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0161e-09 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9779\n",
            "Epoch 759/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9631e-09 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9779\n",
            "Epoch 760/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9843e-09 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9781\n",
            "Epoch 761/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8889e-09 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 0.9779\n",
            "Epoch 762/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0558e-09 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 0.9780\n",
            "Epoch 763/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9260e-09 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 0.9781\n",
            "Epoch 764/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9048e-09 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9779\n",
            "Epoch 765/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0373e-09 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9782\n",
            "Epoch 766/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9790e-09 - accuracy: 1.0000 - val_loss: 0.2163 - val_accuracy: 0.9780\n",
            "Epoch 767/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9684e-09 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9779\n",
            "Epoch 768/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0161e-09 - accuracy: 1.0000 - val_loss: 0.2166 - val_accuracy: 0.9781\n",
            "Epoch 769/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8466e-09 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9778\n",
            "Epoch 770/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9472e-09 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9780\n",
            "Epoch 771/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9817e-09 - accuracy: 1.0000 - val_loss: 0.2163 - val_accuracy: 0.9782\n",
            "Epoch 772/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8810e-09 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9781\n",
            "Epoch 773/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9075e-09 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9782\n",
            "Epoch 774/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9631e-09 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9783\n",
            "Epoch 775/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9870e-09 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9780\n",
            "Epoch 776/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9101e-09 - accuracy: 1.0000 - val_loss: 0.2166 - val_accuracy: 0.9779\n",
            "Epoch 777/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9578e-09 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9779\n",
            "Epoch 778/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0399e-09 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9779\n",
            "Epoch 779/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9419e-09 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9780\n",
            "Epoch 780/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9499e-09 - accuracy: 1.0000 - val_loss: 0.2170 - val_accuracy: 0.9780\n",
            "Epoch 781/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9711e-09 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9780\n",
            "Epoch 782/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1433e-09 - accuracy: 1.0000 - val_loss: 0.2170 - val_accuracy: 0.9779\n",
            "Epoch 783/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9578e-09 - accuracy: 1.0000 - val_loss: 0.2173 - val_accuracy: 0.9781\n",
            "Epoch 784/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0585e-09 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9779\n",
            "Epoch 785/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0293e-09 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9780\n",
            "Epoch 786/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9790e-09 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9779\n",
            "Epoch 787/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8757e-09 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9779\n",
            "Epoch 788/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9658e-09 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9779\n",
            "Epoch 789/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9101e-09 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 0.9779\n",
            "Epoch 790/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0320e-09 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 0.9781\n",
            "Epoch 791/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9578e-09 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9780\n",
            "Epoch 792/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9393e-09 - accuracy: 1.0000 - val_loss: 0.2173 - val_accuracy: 0.9780\n",
            "Epoch 793/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9234e-09 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9779\n",
            "Epoch 794/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9790e-09 - accuracy: 1.0000 - val_loss: 0.2175 - val_accuracy: 0.9778\n",
            "Epoch 795/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9896e-09 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 0.9780\n",
            "Epoch 796/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0956e-09 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9778\n",
            "Epoch 797/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9552e-09 - accuracy: 1.0000 - val_loss: 0.2175 - val_accuracy: 0.9781\n",
            "Epoch 798/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0081e-09 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 0.9781\n",
            "Epoch 799/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9366e-09 - accuracy: 1.0000 - val_loss: 0.2179 - val_accuracy: 0.9779\n",
            "Epoch 800/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0664e-09 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9780\n",
            "Epoch 801/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9181e-09 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9780\n",
            "Epoch 802/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0532e-09 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9779\n",
            "Epoch 803/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0187e-09 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9779\n",
            "Epoch 804/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9896e-09 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9782\n",
            "Epoch 805/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9790e-09 - accuracy: 1.0000 - val_loss: 0.2173 - val_accuracy: 0.9779\n",
            "Epoch 806/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0108e-09 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9779\n",
            "Epoch 807/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9790e-09 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9779\n",
            "Epoch 808/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0532e-09 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9778\n",
            "Epoch 809/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9817e-09 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9781\n",
            "Epoch 810/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9817e-09 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9777\n",
            "Epoch 811/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9684e-09 - accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.9780\n",
            "Epoch 812/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0770e-09 - accuracy: 1.0000 - val_loss: 0.2189 - val_accuracy: 0.9777\n",
            "Epoch 813/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0797e-09 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 0.9781\n",
            "Epoch 814/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0134e-09 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9779\n",
            "Epoch 815/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9817e-09 - accuracy: 1.0000 - val_loss: 0.2189 - val_accuracy: 0.9780\n",
            "Epoch 816/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9843e-09 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9780\n",
            "Epoch 817/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9658e-09 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9779\n",
            "Epoch 818/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0823e-09 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9779\n",
            "Epoch 819/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0982e-09 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9779\n",
            "Epoch 820/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2227e-09 - accuracy: 1.0000 - val_loss: 0.2191 - val_accuracy: 0.9779\n",
            "Epoch 821/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0956e-09 - accuracy: 1.0000 - val_loss: 0.2191 - val_accuracy: 0.9779\n",
            "Epoch 822/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0876e-09 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9780\n",
            "Epoch 823/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9181e-09 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9778\n",
            "Epoch 824/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2413e-09 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9778\n",
            "Epoch 825/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0240e-09 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9777\n",
            "Epoch 826/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1115e-09 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9781\n",
            "Epoch 827/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0850e-09 - accuracy: 1.0000 - val_loss: 0.2194 - val_accuracy: 0.9780\n",
            "Epoch 828/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9843e-09 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9780\n",
            "Epoch 829/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9843e-09 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9781\n",
            "Epoch 830/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0214e-09 - accuracy: 1.0000 - val_loss: 0.2195 - val_accuracy: 0.9779\n",
            "Epoch 831/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0505e-09 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9781\n",
            "Epoch 832/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0426e-09 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9781\n",
            "Epoch 833/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1141e-09 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9781\n",
            "Epoch 834/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0611e-09 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9780\n",
            "Epoch 835/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0002e-09 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9781\n",
            "Epoch 836/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9764e-09 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9779\n",
            "Epoch 837/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2254e-09 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9780\n",
            "Epoch 838/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1353e-09 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9779\n",
            "Epoch 839/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0161e-09 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9779\n",
            "Epoch 840/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9313e-09 - accuracy: 1.0000 - val_loss: 0.2200 - val_accuracy: 0.9781\n",
            "Epoch 841/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9446e-09 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 0.9781\n",
            "Epoch 842/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2174e-09 - accuracy: 1.0000 - val_loss: 0.2209 - val_accuracy: 0.9779\n",
            "Epoch 843/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0406 - accuracy: 0.9948 - val_loss: 0.4707 - val_accuracy: 0.9630\n",
            "Epoch 844/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0458 - accuracy: 0.9919 - val_loss: 0.3089 - val_accuracy: 0.9735\n",
            "Epoch 845/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0106 - accuracy: 0.9975 - val_loss: 0.3042 - val_accuracy: 0.9728\n",
            "Epoch 846/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.2528 - val_accuracy: 0.9777\n",
            "Epoch 847/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.2471 - val_accuracy: 0.9779\n",
            "Epoch 848/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.6958e-04 - accuracy: 0.9998 - val_loss: 0.2576 - val_accuracy: 0.9773\n",
            "Epoch 849/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7325e-04 - accuracy: 0.9999 - val_loss: 0.2369 - val_accuracy: 0.9794\n",
            "Epoch 850/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5880e-04 - accuracy: 0.9999 - val_loss: 0.2454 - val_accuracy: 0.9785\n",
            "Epoch 851/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.6988e-06 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9793\n",
            "Epoch 852/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0688e-06 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9794\n",
            "Epoch 853/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6234e-06 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9793\n",
            "Epoch 854/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3600e-06 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9793\n",
            "Epoch 855/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1520e-06 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9793\n",
            "Epoch 856/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9791e-06 - accuracy: 1.0000 - val_loss: 0.2396 - val_accuracy: 0.9793\n",
            "Epoch 857/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8297e-06 - accuracy: 1.0000 - val_loss: 0.2395 - val_accuracy: 0.9793\n",
            "Epoch 858/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7005e-06 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9793\n",
            "Epoch 859/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5848e-06 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9793\n",
            "Epoch 860/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4819e-06 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9792\n",
            "Epoch 861/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3942e-06 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9793\n",
            "Epoch 862/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3070e-06 - accuracy: 1.0000 - val_loss: 0.2388 - val_accuracy: 0.9793\n",
            "Epoch 863/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2296e-06 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9793\n",
            "Epoch 864/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1588e-06 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9793\n",
            "Epoch 865/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0955e-06 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.9793\n",
            "Epoch 866/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0321e-06 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.9793\n",
            "Epoch 867/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.7887e-07 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 0.9793\n",
            "Epoch 868/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.2373e-07 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9793\n",
            "Epoch 869/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.7285e-07 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9793\n",
            "Epoch 870/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.2973e-07 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9793\n",
            "Epoch 871/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8503e-07 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9794\n",
            "Epoch 872/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4479e-07 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9794\n",
            "Epoch 873/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0527e-07 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9794\n",
            "Epoch 874/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7056e-07 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9794\n",
            "Epoch 875/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3602e-07 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9795\n",
            "Epoch 876/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0307e-07 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9795\n",
            "Epoch 877/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7382e-07 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9795\n",
            "Epoch 878/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4422e-07 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9794\n",
            "Epoch 879/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1696e-07 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9794\n",
            "Epoch 880/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.9148e-07 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9794\n",
            "Epoch 881/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.6662e-07 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9794\n",
            "Epoch 882/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.4346e-07 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9793\n",
            "Epoch 883/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.2139e-07 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9793\n",
            "Epoch 884/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.0039e-07 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9793\n",
            "Epoch 885/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.8151e-07 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9793\n",
            "Epoch 886/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6117e-07 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.9793\n",
            "Epoch 887/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.4374e-07 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9794\n",
            "Epoch 888/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.2700e-07 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9795\n",
            "Epoch 889/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1054e-07 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9793\n",
            "Epoch 890/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9461e-07 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 0.9794\n",
            "Epoch 891/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8027e-07 - accuracy: 1.0000 - val_loss: 0.2358 - val_accuracy: 0.9793\n",
            "Epoch 892/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6573e-07 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9795\n",
            "Epoch 893/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5255e-07 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9795\n",
            "Epoch 894/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3984e-07 - accuracy: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.9795\n",
            "Epoch 895/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2822e-07 - accuracy: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.9796\n",
            "Epoch 896/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1621e-07 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9796\n",
            "Epoch 897/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0537e-07 - accuracy: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.9797\n",
            "Epoch 898/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9477e-07 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9798\n",
            "Epoch 899/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8518e-07 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9797\n",
            "Epoch 900/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7537e-07 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9797\n",
            "Epoch 901/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6613e-07 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9798\n",
            "Epoch 902/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5776e-07 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9798\n",
            "Epoch 903/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4965e-07 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9797\n",
            "Epoch 904/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4188e-07 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9797\n",
            "Epoch 905/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3414e-07 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9797\n",
            "Epoch 906/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2750e-07 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9798\n",
            "Epoch 907/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2083e-07 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9798\n",
            "Epoch 908/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1433e-07 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9795\n",
            "Epoch 909/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0845e-07 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9797\n",
            "Epoch 910/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0291e-07 - accuracy: 1.0000 - val_loss: 0.2350 - val_accuracy: 0.9797\n",
            "Epoch 911/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.7394e-08 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9797\n",
            "Epoch 912/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.2281e-08 - accuracy: 1.0000 - val_loss: 0.2350 - val_accuracy: 0.9796\n",
            "Epoch 913/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.7701e-08 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9795\n",
            "Epoch 914/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.2813e-08 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9797\n",
            "Epoch 915/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8371e-08 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9796\n",
            "Epoch 916/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4431e-08 - accuracy: 1.0000 - val_loss: 0.2350 - val_accuracy: 0.9797\n",
            "Epoch 917/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0360e-08 - accuracy: 1.0000 - val_loss: 0.2350 - val_accuracy: 0.9796\n",
            "Epoch 918/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.6622e-08 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9797\n",
            "Epoch 919/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3062e-08 - accuracy: 1.0000 - val_loss: 0.2350 - val_accuracy: 0.9796\n",
            "Epoch 920/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9859e-08 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9797\n",
            "Epoch 921/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6881e-08 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9797\n",
            "Epoch 922/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3687e-08 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9797\n",
            "Epoch 923/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0849e-08 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9797\n",
            "Epoch 924/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.8190e-08 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9796\n",
            "Epoch 925/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.5567e-08 - accuracy: 1.0000 - val_loss: 0.2358 - val_accuracy: 0.9797\n",
            "Epoch 926/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.3249e-08 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9795\n",
            "Epoch 927/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.0934e-08 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 0.9797\n",
            "Epoch 928/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.8735e-08 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9795\n",
            "Epoch 929/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.7082e-08 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9796\n",
            "Epoch 930/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4767e-08 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9796\n",
            "Epoch 931/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3071e-08 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 0.9797\n",
            "Epoch 932/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1371e-08 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9796\n",
            "Epoch 933/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9627e-08 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9797\n",
            "Epoch 934/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8202e-08 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.9797\n",
            "Epoch 935/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6759e-08 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9798\n",
            "Epoch 936/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5286e-08 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9796\n",
            "Epoch 937/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4154e-08 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9796\n",
            "Epoch 938/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2862e-08 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9797\n",
            "Epoch 939/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1693e-08 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9797\n",
            "Epoch 940/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0713e-08 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9796\n",
            "Epoch 941/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9617e-08 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9797\n",
            "Epoch 942/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8732e-08 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9796\n",
            "Epoch 943/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7828e-08 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9797\n",
            "Epoch 944/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7111e-08 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.9798\n",
            "Epoch 945/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6263e-08 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9797\n",
            "Epoch 946/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5540e-08 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9797\n",
            "Epoch 947/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4830e-08 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9795\n",
            "Epoch 948/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4144e-08 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9795\n",
            "Epoch 949/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3603e-08 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9795\n",
            "Epoch 950/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2946e-08 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9797\n",
            "Epoch 951/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2464e-08 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9797\n",
            "Epoch 952/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1953e-08 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9795\n",
            "Epoch 953/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1391e-08 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9796\n",
            "Epoch 954/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0970e-08 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9797\n",
            "Epoch 955/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0535e-08 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9795\n",
            "Epoch 956/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0151e-08 - accuracy: 1.0000 - val_loss: 0.2398 - val_accuracy: 0.9795\n",
            "Epoch 957/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.7884e-09 - accuracy: 1.0000 - val_loss: 0.2398 - val_accuracy: 0.9795\n",
            "Epoch 958/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.3778e-09 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9795\n",
            "Epoch 959/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.0996e-09 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9795\n",
            "Epoch 960/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.7685e-09 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9796\n",
            "Epoch 961/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.5592e-09 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 0.9795\n",
            "Epoch 962/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.1380e-09 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9796\n",
            "Epoch 963/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.9234e-09 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9795\n",
            "Epoch 964/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.6850e-09 - accuracy: 1.0000 - val_loss: 0.2406 - val_accuracy: 0.9796\n",
            "Epoch 965/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4440e-09 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9795\n",
            "Epoch 966/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.1128e-09 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9795\n",
            "Epoch 967/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.9857e-09 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9793\n",
            "Epoch 968/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7949e-09 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9794\n",
            "Epoch 969/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5247e-09 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9794\n",
            "Epoch 970/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3419e-09 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9793\n",
            "Epoch 971/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2333e-09 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9793\n",
            "Epoch 972/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0161e-09 - accuracy: 1.0000 - val_loss: 0.2421 - val_accuracy: 0.9791\n",
            "Epoch 973/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8492e-09 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9793\n",
            "Epoch 974/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7247e-09 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9793\n",
            "Epoch 975/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5843e-09 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9792\n",
            "Epoch 976/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4836e-09 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9794\n",
            "Epoch 977/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3565e-09 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9793\n",
            "Epoch 978/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2187e-09 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.9794\n",
            "Epoch 979/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1154e-09 - accuracy: 1.0000 - val_loss: 0.2429 - val_accuracy: 0.9791\n",
            "Epoch 980/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.9882e-09 - accuracy: 1.0000 - val_loss: 0.2429 - val_accuracy: 0.9793\n",
            "Epoch 981/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.8134e-09 - accuracy: 1.0000 - val_loss: 0.2428 - val_accuracy: 0.9793\n",
            "Epoch 982/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.7445e-09 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9791\n",
            "Epoch 983/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.6995e-09 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9792\n",
            "Epoch 984/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.6280e-09 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9792\n",
            "Epoch 985/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5088e-09 - accuracy: 1.0000 - val_loss: 0.2437 - val_accuracy: 0.9791\n",
            "Epoch 986/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.3790e-09 - accuracy: 1.0000 - val_loss: 0.2441 - val_accuracy: 0.9789\n",
            "Epoch 987/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.3286e-09 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9791\n",
            "Epoch 988/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.2862e-09 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9795\n",
            "Epoch 989/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.1352e-09 - accuracy: 1.0000 - val_loss: 0.2443 - val_accuracy: 0.9788\n",
            "Epoch 990/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.0028e-09 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9789\n",
            "Epoch 991/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9948e-09 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9789\n",
            "Epoch 992/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9789e-09 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.9791\n",
            "Epoch 993/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9286e-09 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9791\n",
            "Epoch 994/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.8571e-09 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9791\n",
            "Epoch 995/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.7220e-09 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9790\n",
            "Epoch 996/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6796e-09 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.9789\n",
            "Epoch 997/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6240e-09 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9789\n",
            "Epoch 998/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.5736e-09 - accuracy: 1.0000 - val_loss: 0.2452 - val_accuracy: 0.9787\n",
            "Epoch 999/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.5365e-09 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9791\n",
            "Epoch 1000/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.4995e-09 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9789\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0614 - accuracy: 0.9947\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1914 - accuracy: 0.9814\n",
            "train accuracy :  0.9947333335876465 train loss :  0.06144125014543533\n",
            "test accuracy :  0.9814000129699707  test loss :  0.19138523936271667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdS1IgY3gEkQ"
      },
      "source": [
        "# 은닉층 2개(512/512) & epochs = 120 / 500 / 1000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pnjTow5yfwt2",
        "outputId": "831c87f3-44a4-4e61-dd08-a3e8d3db09aa"
      },
      "source": [
        "#신경망 학습2_1_2\n",
        "model2_1_2 = models.Sequential([\n",
        "                               Flatten(input_shape = (28, 28)),\n",
        "                               Dense(512, activation= 'relu'),\n",
        "                               Dense(512, activation= 'relu'),\n",
        "                               Dense(10, activation= 'softmax')\n",
        "                               ])\n",
        "\n",
        "model2_1_2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "hist2_1_2 = model2_1_2.fit(train_x, train_y, epochs = 120, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "#학습 그래프4\n",
        "plt.plot(hist2_1_2.history['accuracy'], 'b-')\n",
        "plt.plot(hist2_1_2.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train2_1_2 = model2_1_2.evaluate(train_x, train_y)\n",
        "sc_test2_1_2 = model2_1_2.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train2_1_2[1], \"train loss : \", sc_train2_1_2[0])\n",
        "print(\"test accuracy : \", sc_test2_1_2[1], \" test loss : \", sc_test2_1_2[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "176/176 [==============================] - 2s 7ms/step - loss: 0.2972 - accuracy: 0.9144 - val_loss: 0.1646 - val_accuracy: 0.9513\n",
            "Epoch 2/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.1050 - accuracy: 0.9685 - val_loss: 0.1087 - val_accuracy: 0.9677\n",
            "Epoch 3/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0638 - accuracy: 0.9812 - val_loss: 0.1035 - val_accuracy: 0.9678\n",
            "Epoch 4/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0410 - accuracy: 0.9875 - val_loss: 0.0903 - val_accuracy: 0.9729\n",
            "Epoch 5/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0272 - accuracy: 0.9921 - val_loss: 0.0877 - val_accuracy: 0.9747\n",
            "Epoch 6/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0208 - accuracy: 0.9934 - val_loss: 0.0895 - val_accuracy: 0.9757\n",
            "Epoch 7/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.1048 - val_accuracy: 0.9742\n",
            "Epoch 8/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.0958 - val_accuracy: 0.9762\n",
            "Epoch 9/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0074 - accuracy: 0.9980 - val_loss: 0.1120 - val_accuracy: 0.9745\n",
            "Epoch 10/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 0.1121 - val_accuracy: 0.9745\n",
            "Epoch 11/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.1088 - val_accuracy: 0.9759\n",
            "Epoch 12/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.1067 - val_accuracy: 0.9774\n",
            "Epoch 13/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0164 - accuracy: 0.9943 - val_loss: 0.1096 - val_accuracy: 0.9761\n",
            "Epoch 14/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.1111 - val_accuracy: 0.9773\n",
            "Epoch 15/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.1066 - val_accuracy: 0.9788\n",
            "Epoch 16/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.1353 - val_accuracy: 0.9747\n",
            "Epoch 17/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.1117 - val_accuracy: 0.9797\n",
            "Epoch 18/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.1271 - val_accuracy: 0.9772\n",
            "Epoch 19/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.1324 - val_accuracy: 0.9767\n",
            "Epoch 20/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.1300 - val_accuracy: 0.9759\n",
            "Epoch 21/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.1372 - val_accuracy: 0.9741\n",
            "Epoch 22/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.1214 - val_accuracy: 0.9784\n",
            "Epoch 23/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.1304 - val_accuracy: 0.9775\n",
            "Epoch 24/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.1280 - val_accuracy: 0.9789\n",
            "Epoch 25/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7544e-04 - accuracy: 0.9998 - val_loss: 0.1135 - val_accuracy: 0.9826\n",
            "Epoch 26/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1558e-04 - accuracy: 1.0000 - val_loss: 0.1156 - val_accuracy: 0.9824\n",
            "Epoch 27/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.2587e-04 - accuracy: 0.9999 - val_loss: 0.1222 - val_accuracy: 0.9823\n",
            "Epoch 28/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.1366 - val_accuracy: 0.9778\n",
            "Epoch 29/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0227 - accuracy: 0.9930 - val_loss: 0.1249 - val_accuracy: 0.9749\n",
            "Epoch 30/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.1190 - val_accuracy: 0.9775\n",
            "Epoch 31/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.1187 - val_accuracy: 0.9797\n",
            "Epoch 32/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.1177 - val_accuracy: 0.9810\n",
            "Epoch 33/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0194e-04 - accuracy: 0.9998 - val_loss: 0.1265 - val_accuracy: 0.9788\n",
            "Epoch 34/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6726e-04 - accuracy: 1.0000 - val_loss: 0.1164 - val_accuracy: 0.9812\n",
            "Epoch 35/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.4005e-05 - accuracy: 1.0000 - val_loss: 0.1177 - val_accuracy: 0.9809\n",
            "Epoch 36/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0233e-05 - accuracy: 1.0000 - val_loss: 0.1189 - val_accuracy: 0.9807\n",
            "Epoch 37/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4960e-05 - accuracy: 1.0000 - val_loss: 0.1197 - val_accuracy: 0.9810\n",
            "Epoch 38/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1308e-05 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 0.9811\n",
            "Epoch 39/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8438e-05 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 0.9809\n",
            "Epoch 40/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6166e-05 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9811\n",
            "Epoch 41/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4240e-05 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9809\n",
            "Epoch 42/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2651e-05 - accuracy: 1.0000 - val_loss: 0.1241 - val_accuracy: 0.9810\n",
            "Epoch 43/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1301e-05 - accuracy: 1.0000 - val_loss: 0.1249 - val_accuracy: 0.9811\n",
            "Epoch 44/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0134e-05 - accuracy: 1.0000 - val_loss: 0.1257 - val_accuracy: 0.9811\n",
            "Epoch 45/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.1063e-06 - accuracy: 1.0000 - val_loss: 0.1265 - val_accuracy: 0.9811\n",
            "Epoch 46/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.2332e-06 - accuracy: 1.0000 - val_loss: 0.1273 - val_accuracy: 0.9812\n",
            "Epoch 47/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4386e-06 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9812\n",
            "Epoch 48/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7506e-06 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 0.9812\n",
            "Epoch 49/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1116e-06 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9811\n",
            "Epoch 50/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5521e-06 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 0.9811\n",
            "Epoch 51/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0662e-06 - accuracy: 1.0000 - val_loss: 0.1311 - val_accuracy: 0.9812\n",
            "Epoch 52/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5947e-06 - accuracy: 1.0000 - val_loss: 0.1319 - val_accuracy: 0.9811\n",
            "Epoch 53/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.1949e-06 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 0.9812\n",
            "Epoch 54/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8175e-06 - accuracy: 1.0000 - val_loss: 0.1335 - val_accuracy: 0.9812\n",
            "Epoch 55/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.4823e-06 - accuracy: 1.0000 - val_loss: 0.1342 - val_accuracy: 0.9811\n",
            "Epoch 56/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1695e-06 - accuracy: 1.0000 - val_loss: 0.1350 - val_accuracy: 0.9811\n",
            "Epoch 57/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9002e-06 - accuracy: 1.0000 - val_loss: 0.1359 - val_accuracy: 0.9812\n",
            "Epoch 58/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6402e-06 - accuracy: 1.0000 - val_loss: 0.1366 - val_accuracy: 0.9812\n",
            "Epoch 59/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4088e-06 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.9813\n",
            "Epoch 60/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1967e-06 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9812\n",
            "Epoch 61/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0081e-06 - accuracy: 1.0000 - val_loss: 0.1390 - val_accuracy: 0.9813\n",
            "Epoch 62/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8321e-06 - accuracy: 1.0000 - val_loss: 0.1398 - val_accuracy: 0.9812\n",
            "Epoch 63/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6696e-06 - accuracy: 1.0000 - val_loss: 0.1406 - val_accuracy: 0.9812\n",
            "Epoch 64/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5255e-06 - accuracy: 1.0000 - val_loss: 0.1413 - val_accuracy: 0.9813\n",
            "Epoch 65/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3924e-06 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9813\n",
            "Epoch 66/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2701e-06 - accuracy: 1.0000 - val_loss: 0.1429 - val_accuracy: 0.9813\n",
            "Epoch 67/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1573e-06 - accuracy: 1.0000 - val_loss: 0.1437 - val_accuracy: 0.9813\n",
            "Epoch 68/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0580e-06 - accuracy: 1.0000 - val_loss: 0.1444 - val_accuracy: 0.9813\n",
            "Epoch 69/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.6434e-07 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.9814\n",
            "Epoch 70/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.8210e-07 - accuracy: 1.0000 - val_loss: 0.1461 - val_accuracy: 0.9814\n",
            "Epoch 71/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.0542e-07 - accuracy: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9814\n",
            "Epoch 72/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.3474e-07 - accuracy: 1.0000 - val_loss: 0.1480 - val_accuracy: 0.9815\n",
            "Epoch 73/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7092e-07 - accuracy: 1.0000 - val_loss: 0.1489 - val_accuracy: 0.9815\n",
            "Epoch 74/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1476e-07 - accuracy: 1.0000 - val_loss: 0.1497 - val_accuracy: 0.9815\n",
            "Epoch 75/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6211e-07 - accuracy: 1.0000 - val_loss: 0.1506 - val_accuracy: 0.9816\n",
            "Epoch 76/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1349e-07 - accuracy: 1.0000 - val_loss: 0.1515 - val_accuracy: 0.9816\n",
            "Epoch 77/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.6882e-07 - accuracy: 1.0000 - val_loss: 0.1522 - val_accuracy: 0.9815\n",
            "Epoch 78/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2892e-07 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9818\n",
            "Epoch 79/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9458e-07 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9817\n",
            "Epoch 80/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6027e-07 - accuracy: 1.0000 - val_loss: 0.1547 - val_accuracy: 0.9817\n",
            "Epoch 81/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.2904e-07 - accuracy: 1.0000 - val_loss: 0.1555 - val_accuracy: 0.9817\n",
            "Epoch 82/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0192e-07 - accuracy: 1.0000 - val_loss: 0.1563 - val_accuracy: 0.9818\n",
            "Epoch 83/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7663e-07 - accuracy: 1.0000 - val_loss: 0.1573 - val_accuracy: 0.9818\n",
            "Epoch 84/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5320e-07 - accuracy: 1.0000 - val_loss: 0.1582 - val_accuracy: 0.9817\n",
            "Epoch 85/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3138e-07 - accuracy: 1.0000 - val_loss: 0.1589 - val_accuracy: 0.9817\n",
            "Epoch 86/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1263e-07 - accuracy: 1.0000 - val_loss: 0.1598 - val_accuracy: 0.9817\n",
            "Epoch 87/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9473e-07 - accuracy: 1.0000 - val_loss: 0.1607 - val_accuracy: 0.9817\n",
            "Epoch 88/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7890e-07 - accuracy: 1.0000 - val_loss: 0.1615 - val_accuracy: 0.9817\n",
            "Epoch 89/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6344e-07 - accuracy: 1.0000 - val_loss: 0.1625 - val_accuracy: 0.9817\n",
            "Epoch 90/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5030e-07 - accuracy: 1.0000 - val_loss: 0.1634 - val_accuracy: 0.9817\n",
            "Epoch 91/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3799e-07 - accuracy: 1.0000 - val_loss: 0.1641 - val_accuracy: 0.9817\n",
            "Epoch 92/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2720e-07 - accuracy: 1.0000 - val_loss: 0.1649 - val_accuracy: 0.9816\n",
            "Epoch 93/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1655e-07 - accuracy: 1.0000 - val_loss: 0.1658 - val_accuracy: 0.9816\n",
            "Epoch 94/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0743e-07 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9817\n",
            "Epoch 95/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.8713e-08 - accuracy: 1.0000 - val_loss: 0.1676 - val_accuracy: 0.9817\n",
            "Epoch 96/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.0360e-08 - accuracy: 1.0000 - val_loss: 0.1682 - val_accuracy: 0.9817\n",
            "Epoch 97/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.3444e-08 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9817\n",
            "Epoch 98/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7163e-08 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.9817\n",
            "Epoch 99/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.0569e-08 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 0.9817\n",
            "Epoch 100/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5486e-08 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 0.9818\n",
            "Epoch 101/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0164e-08 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 0.9817\n",
            "Epoch 102/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5618e-08 - accuracy: 1.0000 - val_loss: 0.1732 - val_accuracy: 0.9817\n",
            "Epoch 103/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1157e-08 - accuracy: 1.0000 - val_loss: 0.1737 - val_accuracy: 0.9817\n",
            "Epoch 104/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.7162e-08 - accuracy: 1.0000 - val_loss: 0.1747 - val_accuracy: 0.9817\n",
            "Epoch 105/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.3752e-08 - accuracy: 1.0000 - val_loss: 0.1754 - val_accuracy: 0.9817\n",
            "Epoch 106/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0420e-08 - accuracy: 1.0000 - val_loss: 0.1761 - val_accuracy: 0.9817\n",
            "Epoch 107/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7421e-08 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9817\n",
            "Epoch 108/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.4605e-08 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 0.9817\n",
            "Epoch 109/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.2173e-08 - accuracy: 1.0000 - val_loss: 0.1783 - val_accuracy: 0.9819\n",
            "Epoch 110/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9845e-08 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.9818\n",
            "Epoch 111/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7442e-08 - accuracy: 1.0000 - val_loss: 0.1796 - val_accuracy: 0.9818\n",
            "Epoch 112/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5723e-08 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 0.9818\n",
            "Epoch 113/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3815e-08 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9818\n",
            "Epoch 114/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2213e-08 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9818\n",
            "Epoch 115/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0602e-08 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 0.9817\n",
            "Epoch 116/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9219e-08 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 0.9819\n",
            "Epoch 117/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7879e-08 - accuracy: 1.0000 - val_loss: 0.1839 - val_accuracy: 0.9819\n",
            "Epoch 118/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6628e-08 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.9819\n",
            "Epoch 119/120\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5418e-08 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9817\n",
            "Epoch 120/120\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4432e-08 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9819\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0464 - accuracy: 0.9955\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1451 - accuracy: 0.9842\n",
            "train accuracy :  0.9954833388328552 train loss :  0.04640447348356247\n",
            "test accuracy :  0.9842000007629395  test loss :  0.14507167041301727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KrkR_zWAB7zl",
        "outputId": "818bcbe1-9518-46fa-ad0d-fac20cdd9c8d"
      },
      "source": [
        "#신경망 학습2_1_3\n",
        "model2_1_3 = models.Sequential([\n",
        "                               Flatten(input_shape = (28, 28)),\n",
        "                               Dense(512, activation= 'relu'),\n",
        "                               Dense(512, activation= 'relu'),\n",
        "                               Dense(10, activation= 'softmax')\n",
        "                               ])\n",
        "\n",
        "model2_1_3.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "hist2_1_3 = model2_1_3.fit(train_x, train_y, epochs = 500, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "#학습 그래프4\n",
        "plt.plot(hist2_1_3.history['accuracy'], 'b-')\n",
        "plt.plot(hist2_1_3.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train2_1_3 = model2_1_3.evaluate(train_x, train_y)\n",
        "sc_test2_1_3 = model2_1_3.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train2_1_3[1], \"train loss : \", sc_train2_1_3[0])\n",
        "print(\"test accuracy : \", sc_test2_1_3[1], \" test loss : \", sc_test2_1_3[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "176/176 [==============================] - 2s 7ms/step - loss: 0.3107 - accuracy: 0.9103 - val_loss: 0.1500 - val_accuracy: 0.9563\n",
            "Epoch 2/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.1047 - accuracy: 0.9681 - val_loss: 0.1067 - val_accuracy: 0.9681\n",
            "Epoch 3/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0647 - accuracy: 0.9803 - val_loss: 0.0931 - val_accuracy: 0.9723\n",
            "Epoch 4/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0433 - accuracy: 0.9868 - val_loss: 0.0969 - val_accuracy: 0.9711\n",
            "Epoch 5/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0302 - accuracy: 0.9905 - val_loss: 0.0842 - val_accuracy: 0.9752\n",
            "Epoch 6/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.0873 - val_accuracy: 0.9739\n",
            "Epoch 7/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.0972 - val_accuracy: 0.9739\n",
            "Epoch 8/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.1066 - val_accuracy: 0.9707\n",
            "Epoch 9/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.1096 - val_accuracy: 0.9739\n",
            "Epoch 10/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.1116 - val_accuracy: 0.9749\n",
            "Epoch 11/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0108 - accuracy: 0.9962 - val_loss: 0.1101 - val_accuracy: 0.9747\n",
            "Epoch 12/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.1083 - val_accuracy: 0.9758\n",
            "Epoch 13/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.1104 - val_accuracy: 0.9751\n",
            "Epoch 14/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.1159 - val_accuracy: 0.9747\n",
            "Epoch 15/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.1309 - val_accuracy: 0.9739\n",
            "Epoch 16/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.1125 - val_accuracy: 0.9775\n",
            "Epoch 17/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.1349 - val_accuracy: 0.9752\n",
            "Epoch 18/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.1213 - val_accuracy: 0.9770\n",
            "Epoch 19/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.1278 - val_accuracy: 0.9760\n",
            "Epoch 20/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.1209 - val_accuracy: 0.9788\n",
            "Epoch 21/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.1273 - val_accuracy: 0.9764\n",
            "Epoch 22/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.1532 - val_accuracy: 0.9722\n",
            "Epoch 23/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.1195 - val_accuracy: 0.9783\n",
            "Epoch 24/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.1268 - val_accuracy: 0.9762\n",
            "Epoch 25/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.1423 - val_accuracy: 0.9733\n",
            "Epoch 26/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.1369 - val_accuracy: 0.9750\n",
            "Epoch 27/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.1307 - val_accuracy: 0.9779\n",
            "Epoch 28/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.1322 - val_accuracy: 0.9785\n",
            "Epoch 29/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.1475 - val_accuracy: 0.9750\n",
            "Epoch 30/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1337 - val_accuracy: 0.9775\n",
            "Epoch 31/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.1365 - val_accuracy: 0.9769\n",
            "Epoch 32/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.1382 - val_accuracy: 0.9775\n",
            "Epoch 33/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.8093e-04 - accuracy: 0.9998 - val_loss: 0.1149 - val_accuracy: 0.9808\n",
            "Epoch 34/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8110e-05 - accuracy: 1.0000 - val_loss: 0.1158 - val_accuracy: 0.9811\n",
            "Epoch 35/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3332e-05 - accuracy: 1.0000 - val_loss: 0.1178 - val_accuracy: 0.9813\n",
            "Epoch 36/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5598e-05 - accuracy: 1.0000 - val_loss: 0.1192 - val_accuracy: 0.9814\n",
            "Epoch 37/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1235e-05 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9814\n",
            "Epoch 38/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8122e-05 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9815\n",
            "Epoch 39/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5734e-05 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9815\n",
            "Epoch 40/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3815e-05 - accuracy: 1.0000 - val_loss: 0.1231 - val_accuracy: 0.9815\n",
            "Epoch 41/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2244e-05 - accuracy: 1.0000 - val_loss: 0.1240 - val_accuracy: 0.9816\n",
            "Epoch 42/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0895e-05 - accuracy: 1.0000 - val_loss: 0.1249 - val_accuracy: 0.9817\n",
            "Epoch 43/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.7784e-06 - accuracy: 1.0000 - val_loss: 0.1257 - val_accuracy: 0.9817\n",
            "Epoch 44/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7688e-06 - accuracy: 1.0000 - val_loss: 0.1265 - val_accuracy: 0.9818\n",
            "Epoch 45/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.9157e-06 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9817\n",
            "Epoch 46/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1442e-06 - accuracy: 1.0000 - val_loss: 0.1282 - val_accuracy: 0.9818\n",
            "Epoch 47/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4924e-06 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 0.9817\n",
            "Epoch 48/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8608e-06 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.9817\n",
            "Epoch 49/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3386e-06 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 0.9817\n",
            "Epoch 50/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.8615e-06 - accuracy: 1.0000 - val_loss: 0.1315 - val_accuracy: 0.9816\n",
            "Epoch 51/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.4283e-06 - accuracy: 1.0000 - val_loss: 0.1323 - val_accuracy: 0.9818\n",
            "Epoch 52/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0423e-06 - accuracy: 1.0000 - val_loss: 0.1330 - val_accuracy: 0.9818\n",
            "Epoch 53/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6929e-06 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.9819\n",
            "Epoch 54/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3705e-06 - accuracy: 1.0000 - val_loss: 0.1346 - val_accuracy: 0.9818\n",
            "Epoch 55/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0858e-06 - accuracy: 1.0000 - val_loss: 0.1353 - val_accuracy: 0.9819\n",
            "Epoch 56/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8136e-06 - accuracy: 1.0000 - val_loss: 0.1361 - val_accuracy: 0.9821\n",
            "Epoch 57/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5757e-06 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9822\n",
            "Epoch 58/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3556e-06 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9822\n",
            "Epoch 59/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1610e-06 - accuracy: 1.0000 - val_loss: 0.1384 - val_accuracy: 0.9821\n",
            "Epoch 60/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9701e-06 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9821\n",
            "Epoch 61/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8003e-06 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.9820\n",
            "Epoch 62/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6541e-06 - accuracy: 1.0000 - val_loss: 0.1409 - val_accuracy: 0.9820\n",
            "Epoch 63/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5130e-06 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 0.9820\n",
            "Epoch 64/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3860e-06 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 0.9819\n",
            "Epoch 65/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2669e-06 - accuracy: 1.0000 - val_loss: 0.1434 - val_accuracy: 0.9821\n",
            "Epoch 66/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1599e-06 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9820\n",
            "Epoch 67/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0629e-06 - accuracy: 1.0000 - val_loss: 0.1449 - val_accuracy: 0.9821\n",
            "Epoch 68/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7137e-07 - accuracy: 1.0000 - val_loss: 0.1457 - val_accuracy: 0.9822\n",
            "Epoch 69/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.9104e-07 - accuracy: 1.0000 - val_loss: 0.1466 - val_accuracy: 0.9821\n",
            "Epoch 70/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.1393e-07 - accuracy: 1.0000 - val_loss: 0.1474 - val_accuracy: 0.9821\n",
            "Epoch 71/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4433e-07 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 0.9822\n",
            "Epoch 72/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8204e-07 - accuracy: 1.0000 - val_loss: 0.1490 - val_accuracy: 0.9821\n",
            "Epoch 73/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2401e-07 - accuracy: 1.0000 - val_loss: 0.1498 - val_accuracy: 0.9821\n",
            "Epoch 74/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7021e-07 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9821\n",
            "Epoch 75/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2250e-07 - accuracy: 1.0000 - val_loss: 0.1516 - val_accuracy: 0.9822\n",
            "Epoch 76/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.7941e-07 - accuracy: 1.0000 - val_loss: 0.1524 - val_accuracy: 0.9822\n",
            "Epoch 77/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4015e-07 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9821\n",
            "Epoch 78/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.0230e-07 - accuracy: 1.0000 - val_loss: 0.1542 - val_accuracy: 0.9822\n",
            "Epoch 79/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6944e-07 - accuracy: 1.0000 - val_loss: 0.1550 - val_accuracy: 0.9821\n",
            "Epoch 80/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3722e-07 - accuracy: 1.0000 - val_loss: 0.1559 - val_accuracy: 0.9822\n",
            "Epoch 81/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1031e-07 - accuracy: 1.0000 - val_loss: 0.1565 - val_accuracy: 0.9823\n",
            "Epoch 82/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8404e-07 - accuracy: 1.0000 - val_loss: 0.1575 - val_accuracy: 0.9821\n",
            "Epoch 83/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6050e-07 - accuracy: 1.0000 - val_loss: 0.1584 - val_accuracy: 0.9822\n",
            "Epoch 84/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3802e-07 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 0.9823\n",
            "Epoch 85/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2055e-07 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 0.9823\n",
            "Epoch 86/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0069e-07 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9821\n",
            "Epoch 87/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8434e-07 - accuracy: 1.0000 - val_loss: 0.1617 - val_accuracy: 0.9821\n",
            "Epoch 88/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6766e-07 - accuracy: 1.0000 - val_loss: 0.1626 - val_accuracy: 0.9823\n",
            "Epoch 89/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5542e-07 - accuracy: 1.0000 - val_loss: 0.1635 - val_accuracy: 0.9822\n",
            "Epoch 90/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4187e-07 - accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 0.9821\n",
            "Epoch 91/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3028e-07 - accuracy: 1.0000 - val_loss: 0.1652 - val_accuracy: 0.9821\n",
            "Epoch 92/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1961e-07 - accuracy: 1.0000 - val_loss: 0.1662 - val_accuracy: 0.9821\n",
            "Epoch 93/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1058e-07 - accuracy: 1.0000 - val_loss: 0.1669 - val_accuracy: 0.9821\n",
            "Epoch 94/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0132e-07 - accuracy: 1.0000 - val_loss: 0.1679 - val_accuracy: 0.9821\n",
            "Epoch 95/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2665e-08 - accuracy: 1.0000 - val_loss: 0.1687 - val_accuracy: 0.9823\n",
            "Epoch 96/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.4824e-08 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 0.9821\n",
            "Epoch 97/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8148e-08 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 0.9822\n",
            "Epoch 98/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.2333e-08 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 0.9822\n",
            "Epoch 99/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6119e-08 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 0.9823\n",
            "Epoch 100/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0974e-08 - accuracy: 1.0000 - val_loss: 0.1732 - val_accuracy: 0.9822\n",
            "Epoch 101/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6336e-08 - accuracy: 1.0000 - val_loss: 0.1738 - val_accuracy: 0.9823\n",
            "Epoch 102/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2033e-08 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9823\n",
            "Epoch 103/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.8036e-08 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 0.9821\n",
            "Epoch 104/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.4280e-08 - accuracy: 1.0000 - val_loss: 0.1761 - val_accuracy: 0.9823\n",
            "Epoch 105/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.0899e-08 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.9822\n",
            "Epoch 106/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7728e-08 - accuracy: 1.0000 - val_loss: 0.1778 - val_accuracy: 0.9823\n",
            "Epoch 107/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.4931e-08 - accuracy: 1.0000 - val_loss: 0.1783 - val_accuracy: 0.9825\n",
            "Epoch 108/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2229e-08 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 0.9821\n",
            "Epoch 109/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9940e-08 - accuracy: 1.0000 - val_loss: 0.1801 - val_accuracy: 0.9823\n",
            "Epoch 110/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7916e-08 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 0.9822\n",
            "Epoch 111/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5797e-08 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 0.9821\n",
            "Epoch 112/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3823e-08 - accuracy: 1.0000 - val_loss: 0.1824 - val_accuracy: 0.9821\n",
            "Epoch 113/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2038e-08 - accuracy: 1.0000 - val_loss: 0.1826 - val_accuracy: 0.9822\n",
            "Epoch 114/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0554e-08 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9821\n",
            "Epoch 115/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9105e-08 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 0.9822\n",
            "Epoch 116/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7876e-08 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 0.9822\n",
            "Epoch 117/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6589e-08 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9822\n",
            "Epoch 118/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5471e-08 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 0.9821\n",
            "Epoch 119/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4446e-08 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9822\n",
            "Epoch 120/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3561e-08 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9822\n",
            "Epoch 121/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2705e-08 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9823\n",
            "Epoch 122/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1828e-08 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9821\n",
            "Epoch 123/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1084e-08 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9821\n",
            "Epoch 124/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0419e-08 - accuracy: 1.0000 - val_loss: 0.1895 - val_accuracy: 0.9822\n",
            "Epoch 125/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6374e-09 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9822\n",
            "Epoch 126/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0864e-09 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9821\n",
            "Epoch 127/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4294e-09 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9819\n",
            "Epoch 128/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9870e-09 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9818\n",
            "Epoch 129/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.5075e-09 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9821\n",
            "Epoch 130/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1181e-09 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 0.9821\n",
            "Epoch 131/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8055e-09 - accuracy: 1.0000 - val_loss: 0.1931 - val_accuracy: 0.9820\n",
            "Epoch 132/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3737e-09 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 0.9819\n",
            "Epoch 133/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0002e-09 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9821\n",
            "Epoch 134/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6638e-09 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9819\n",
            "Epoch 135/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3406e-09 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9821\n",
            "Epoch 136/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0969e-09 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9820\n",
            "Epoch 137/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.7763e-09 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.9819\n",
            "Epoch 138/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5617e-09 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 0.9820\n",
            "Epoch 139/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.3525e-09 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.9819\n",
            "Epoch 140/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.1193e-09 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9823\n",
            "Epoch 141/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9021e-09 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9819\n",
            "Epoch 142/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.7405e-09 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9821\n",
            "Epoch 143/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5153e-09 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9821\n",
            "Epoch 144/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3749e-09 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9819\n",
            "Epoch 145/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1657e-09 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.9821\n",
            "Epoch 146/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0014e-09 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.9820\n",
            "Epoch 147/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8796e-09 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.9819\n",
            "Epoch 148/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7392e-09 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9822\n",
            "Epoch 149/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6358e-09 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9822\n",
            "Epoch 150/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5140e-09 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9821\n",
            "Epoch 151/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4054e-09 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9822\n",
            "Epoch 152/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3233e-09 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9822\n",
            "Epoch 153/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2491e-09 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.9822\n",
            "Epoch 154/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1034e-09 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.9823\n",
            "Epoch 155/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0319e-09 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9822\n",
            "Epoch 156/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9471e-09 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9822\n",
            "Epoch 157/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8729e-09 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9821\n",
            "Epoch 158/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8093e-09 - accuracy: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.9822\n",
            "Epoch 159/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7537e-09 - accuracy: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.9821\n",
            "Epoch 160/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6901e-09 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9821\n",
            "Epoch 161/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6159e-09 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9821\n",
            "Epoch 162/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5683e-09 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9821\n",
            "Epoch 163/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5126e-09 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9821\n",
            "Epoch 164/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4755e-09 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9821\n",
            "Epoch 165/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4332e-09 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9821\n",
            "Epoch 166/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3749e-09 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9821\n",
            "Epoch 167/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3749e-09 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9821\n",
            "Epoch 168/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3034e-09 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9821\n",
            "Epoch 169/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2742e-09 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9821\n",
            "Epoch 170/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2345e-09 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9821\n",
            "Epoch 171/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2133e-09 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9821\n",
            "Epoch 172/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2133e-09 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9822\n",
            "Epoch 173/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1868e-09 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9821\n",
            "Epoch 174/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1047e-09 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9822\n",
            "Epoch 175/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0676e-09 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9822\n",
            "Epoch 176/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0914e-09 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9821\n",
            "Epoch 177/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0093e-09 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9822\n",
            "Epoch 178/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9606e-10 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9821\n",
            "Epoch 179/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0040e-09 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9822\n",
            "Epoch 180/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.6957e-10 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9822\n",
            "Epoch 181/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.5897e-10 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9823\n",
            "Epoch 182/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.7222e-10 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9823\n",
            "Epoch 183/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.0864e-10 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9823\n",
            "Epoch 184/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2189e-10 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9823\n",
            "Epoch 185/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.7155e-10 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9823\n",
            "Epoch 186/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.2983e-10 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9822\n",
            "Epoch 187/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.4771e-10 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9823\n",
            "Epoch 188/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4241e-10 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9823\n",
            "Epoch 189/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.4241e-10 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9824\n",
            "Epoch 190/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1327e-10 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9824\n",
            "Epoch 191/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.2917e-10 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9823\n",
            "Epoch 192/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1592e-10 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9824\n",
            "Epoch 193/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6559e-10 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9824\n",
            "Epoch 194/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.1857e-10 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9823\n",
            "Epoch 195/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.5234e-10 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9823\n",
            "Epoch 196/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.9208e-10 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9823\n",
            "Epoch 197/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8678e-10 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9822\n",
            "Epoch 198/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.6294e-10 - accuracy: 1.0000 - val_loss: 0.2025 - val_accuracy: 0.9823\n",
            "Epoch 199/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5499e-10 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.9822\n",
            "Epoch 200/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.3910e-10 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9822\n",
            "Epoch 201/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0996e-10 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.9822\n",
            "Epoch 202/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4704e-10 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9821\n",
            "Epoch 203/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0731e-10 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9822\n",
            "Epoch 204/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1790e-10 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 0.9821\n",
            "Epoch 205/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.1261e-10 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9821\n",
            "Epoch 206/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.9406e-10 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9821\n",
            "Epoch 207/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8876e-10 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9821\n",
            "Epoch 208/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.0996e-10 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9821\n",
            "Epoch 209/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8612e-10 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9821\n",
            "Epoch 210/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.6757e-10 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9821\n",
            "Epoch 211/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.6227e-10 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 0.9821\n",
            "Epoch 212/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6492e-10 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9820\n",
            "Epoch 213/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5168e-10 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9821\n",
            "Epoch 214/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5168e-10 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9820\n",
            "Epoch 215/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7022e-10 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.9821\n",
            "Epoch 216/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5433e-10 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.9820\n",
            "Epoch 217/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3578e-10 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9821\n",
            "Epoch 218/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3843e-10 - accuracy: 1.0000 - val_loss: 0.2046 - val_accuracy: 0.9821\n",
            "Epoch 219/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8347e-10 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.9821\n",
            "Epoch 220/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3578e-10 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 0.9821\n",
            "Epoch 221/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4108e-10 - accuracy: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.9821\n",
            "Epoch 222/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8810e-10 - accuracy: 1.0000 - val_loss: 0.2053 - val_accuracy: 0.9821\n",
            "Epoch 223/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4903e-10 - accuracy: 1.0000 - val_loss: 0.2052 - val_accuracy: 0.9820\n",
            "Epoch 224/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.4108e-10 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9821\n",
            "Epoch 225/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4903e-10 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9820\n",
            "Epoch 226/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1194e-10 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9819\n",
            "Epoch 227/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0929e-10 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9819\n",
            "Epoch 228/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2254e-10 - accuracy: 1.0000 - val_loss: 0.2062 - val_accuracy: 0.9819\n",
            "Epoch 229/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2519e-10 - accuracy: 1.0000 - val_loss: 0.2064 - val_accuracy: 0.9819\n",
            "Epoch 230/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0929e-10 - accuracy: 1.0000 - val_loss: 0.2066 - val_accuracy: 0.9819\n",
            "Epoch 231/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4638e-10 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9819\n",
            "Epoch 232/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2784e-10 - accuracy: 1.0000 - val_loss: 0.2070 - val_accuracy: 0.9819\n",
            "Epoch 233/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1989e-10 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9818\n",
            "Epoch 234/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0399e-10 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9818\n",
            "Epoch 235/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0929e-10 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9818\n",
            "Epoch 236/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1459e-10 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9817\n",
            "Epoch 237/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1724e-10 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9817\n",
            "Epoch 238/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0399e-10 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.9818\n",
            "Epoch 239/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1194e-10 - accuracy: 1.0000 - val_loss: 0.2083 - val_accuracy: 0.9818\n",
            "Epoch 240/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0929e-10 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9818\n",
            "Epoch 241/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5962e-10 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9817\n",
            "Epoch 242/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3578e-10 - accuracy: 1.0000 - val_loss: 0.2089 - val_accuracy: 0.9817\n",
            "Epoch 243/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3578e-10 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 0.9817\n",
            "Epoch 244/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0929e-10 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9817\n",
            "Epoch 245/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0929e-10 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9817\n",
            "Epoch 246/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.4903e-10 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9817\n",
            "Epoch 247/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9870e-10 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9818\n",
            "Epoch 248/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2254e-10 - accuracy: 1.0000 - val_loss: 0.2104 - val_accuracy: 0.9817\n",
            "Epoch 249/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1989e-10 - accuracy: 1.0000 - val_loss: 0.2106 - val_accuracy: 0.9816\n",
            "Epoch 250/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2784e-10 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9817\n",
            "Epoch 251/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3578e-10 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9817\n",
            "Epoch 252/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5168e-10 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9817\n",
            "Epoch 253/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1459e-10 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9816\n",
            "Epoch 254/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4108e-10 - accuracy: 1.0000 - val_loss: 0.2119 - val_accuracy: 0.9817\n",
            "Epoch 255/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3578e-10 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9816\n",
            "Epoch 256/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3843e-10 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 0.9816\n",
            "Epoch 257/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.4903e-10 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 0.9815\n",
            "Epoch 258/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3048e-10 - accuracy: 1.0000 - val_loss: 0.2128 - val_accuracy: 0.9816\n",
            "Epoch 259/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5962e-10 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9814\n",
            "Epoch 260/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3843e-10 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9814\n",
            "Epoch 261/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5962e-10 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9814\n",
            "Epoch 262/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.6757e-10 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9813\n",
            "Epoch 263/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8876e-10 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9813\n",
            "Epoch 264/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7287e-10 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9814\n",
            "Epoch 265/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2254e-10 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9814\n",
            "Epoch 266/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7817e-10 - accuracy: 1.0000 - val_loss: 0.2149 - val_accuracy: 0.9813\n",
            "Epoch 267/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7022e-10 - accuracy: 1.0000 - val_loss: 0.2151 - val_accuracy: 0.9814\n",
            "Epoch 268/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7287e-10 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9813\n",
            "Epoch 269/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.9671e-10 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9814\n",
            "Epoch 270/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2320e-10 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9815\n",
            "Epoch 271/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8612e-10 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 0.9813\n",
            "Epoch 272/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7817e-10 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9813\n",
            "Epoch 273/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3115e-10 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9812\n",
            "Epoch 274/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4440e-10 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9811\n",
            "Epoch 275/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1526e-10 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9811\n",
            "Epoch 276/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1261e-10 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9811\n",
            "Epoch 277/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.9141e-10 - accuracy: 1.0000 - val_loss: 0.2179 - val_accuracy: 0.9813\n",
            "Epoch 278/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.0466e-10 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9813\n",
            "Epoch 279/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2585e-10 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 0.9812\n",
            "Epoch 280/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6029e-10 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9812\n",
            "Epoch 281/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5499e-10 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9813\n",
            "Epoch 282/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8148e-10 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9812\n",
            "Epoch 283/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6559e-10 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9811\n",
            "Epoch 284/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.4175e-10 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9811\n",
            "Epoch 285/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4440e-10 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9810\n",
            "Epoch 286/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5764e-10 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9811\n",
            "Epoch 287/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9473e-10 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 0.9811\n",
            "Epoch 288/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0003e-10 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9810\n",
            "Epoch 289/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.9473e-10 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9810\n",
            "Epoch 290/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3711e-10 - accuracy: 1.0000 - val_loss: 0.2215 - val_accuracy: 0.9811\n",
            "Epoch 291/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1062e-10 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 0.9811\n",
            "Epoch 292/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.1062e-10 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9810\n",
            "Epoch 293/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.3446e-10 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9809\n",
            "Epoch 294/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3182e-10 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9809\n",
            "Epoch 295/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4506e-10 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9809\n",
            "Epoch 296/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1592e-10 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9809\n",
            "Epoch 297/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6361e-10 - accuracy: 1.0000 - val_loss: 0.2237 - val_accuracy: 0.9810\n",
            "Epoch 298/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4506e-10 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9809\n",
            "Epoch 299/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.5566e-10 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9811\n",
            "Epoch 300/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1327e-10 - accuracy: 1.0000 - val_loss: 0.2247 - val_accuracy: 0.9809\n",
            "Epoch 301/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7420e-10 - accuracy: 1.0000 - val_loss: 0.2252 - val_accuracy: 0.9810\n",
            "Epoch 302/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0069e-10 - accuracy: 1.0000 - val_loss: 0.2255 - val_accuracy: 0.9811\n",
            "Epoch 303/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0599e-10 - accuracy: 1.0000 - val_loss: 0.2257 - val_accuracy: 0.9809\n",
            "Epoch 304/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0599e-10 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9809\n",
            "Epoch 305/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7685e-10 - accuracy: 1.0000 - val_loss: 0.2265 - val_accuracy: 0.9809\n",
            "Epoch 306/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7950e-10 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 0.9811\n",
            "Epoch 307/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3513e-10 - accuracy: 1.0000 - val_loss: 0.2268 - val_accuracy: 0.9809\n",
            "Epoch 308/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9275e-10 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9809\n",
            "Epoch 309/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.9539e-10 - accuracy: 1.0000 - val_loss: 0.2273 - val_accuracy: 0.9809\n",
            "Epoch 310/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5632e-10 - accuracy: 1.0000 - val_loss: 0.2274 - val_accuracy: 0.9808\n",
            "Epoch 311/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6096e-10 - accuracy: 1.0000 - val_loss: 0.2280 - val_accuracy: 0.9808\n",
            "Epoch 312/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5897e-10 - accuracy: 1.0000 - val_loss: 0.2282 - val_accuracy: 0.9809\n",
            "Epoch 313/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4838e-10 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9807\n",
            "Epoch 314/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.8281e-10 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.9807\n",
            "Epoch 315/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9871e-10 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9807\n",
            "Epoch 316/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2453e-10 - accuracy: 1.0000 - val_loss: 0.2294 - val_accuracy: 0.9807\n",
            "Epoch 317/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4573e-10 - accuracy: 1.0000 - val_loss: 0.2302 - val_accuracy: 0.9808\n",
            "Epoch 318/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.2718e-10 - accuracy: 1.0000 - val_loss: 0.2296 - val_accuracy: 0.9807\n",
            "Epoch 319/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3248e-10 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.9807\n",
            "Epoch 320/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0014e-09 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 0.9807\n",
            "Epoch 321/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.8546e-10 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9807\n",
            "Epoch 322/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6427e-10 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.9806\n",
            "Epoch 323/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6427e-10 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.9805\n",
            "Epoch 324/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2189e-10 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.9806\n",
            "Epoch 325/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0226e-09 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9808\n",
            "Epoch 326/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0093e-09 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.9805\n",
            "Epoch 327/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0146e-09 - accuracy: 1.0000 - val_loss: 0.2328 - val_accuracy: 0.9808\n",
            "Epoch 328/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0093e-09 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.9807\n",
            "Epoch 329/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0146e-09 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9807\n",
            "Epoch 330/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0358e-09 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9807\n",
            "Epoch 331/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0464e-09 - accuracy: 1.0000 - val_loss: 0.2348 - val_accuracy: 0.9807\n",
            "Epoch 332/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0358e-09 - accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 0.9809\n",
            "Epoch 333/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0199e-09 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9809\n",
            "Epoch 334/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0596e-09 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9805\n",
            "Epoch 335/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0384e-09 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9808\n",
            "Epoch 336/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0755e-09 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9807\n",
            "Epoch 337/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0994e-09 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9807\n",
            "Epoch 338/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0702e-09 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9805\n",
            "Epoch 339/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0517e-09 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 0.9806\n",
            "Epoch 340/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0835e-09 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9809\n",
            "Epoch 341/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0994e-09 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 0.9805\n",
            "Epoch 342/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0861e-09 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9807\n",
            "Epoch 343/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1100e-09 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9807\n",
            "Epoch 344/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0994e-09 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9807\n",
            "Epoch 345/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0729e-09 - accuracy: 1.0000 - val_loss: 0.2396 - val_accuracy: 0.9807\n",
            "Epoch 346/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1206e-09 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 0.9808\n",
            "Epoch 347/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1206e-09 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9808\n",
            "Epoch 348/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1391e-09 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9807\n",
            "Epoch 349/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1418e-09 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9808\n",
            "Epoch 350/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1020e-09 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9806\n",
            "Epoch 351/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1100e-09 - accuracy: 1.0000 - val_loss: 0.2420 - val_accuracy: 0.9807\n",
            "Epoch 352/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1656e-09 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9807\n",
            "Epoch 353/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1471e-09 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9807\n",
            "Epoch 354/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1603e-09 - accuracy: 1.0000 - val_loss: 0.2429 - val_accuracy: 0.9807\n",
            "Epoch 355/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2000e-09 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9805\n",
            "Epoch 356/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1471e-09 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9806\n",
            "Epoch 357/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2186e-09 - accuracy: 1.0000 - val_loss: 0.2437 - val_accuracy: 0.9805\n",
            "Epoch 358/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2106e-09 - accuracy: 1.0000 - val_loss: 0.2442 - val_accuracy: 0.9806\n",
            "Epoch 359/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1947e-09 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9805\n",
            "Epoch 360/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1921e-09 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9804\n",
            "Epoch 361/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2557e-09 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.9807\n",
            "Epoch 362/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2159e-09 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9808\n",
            "Epoch 363/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2133e-09 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9807\n",
            "Epoch 364/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2027e-09 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9803\n",
            "Epoch 365/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2663e-09 - accuracy: 1.0000 - val_loss: 0.2472 - val_accuracy: 0.9807\n",
            "Epoch 366/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2318e-09 - accuracy: 1.0000 - val_loss: 0.2474 - val_accuracy: 0.9805\n",
            "Epoch 367/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2689e-09 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.9807\n",
            "Epoch 368/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3140e-09 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.9805\n",
            "Epoch 369/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2424e-09 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9805\n",
            "Epoch 370/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3245e-09 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9805\n",
            "Epoch 371/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3140e-09 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.9806\n",
            "Epoch 372/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2981e-09 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9803\n",
            "Epoch 373/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3034e-09 - accuracy: 1.0000 - val_loss: 0.2496 - val_accuracy: 0.9806\n",
            "Epoch 374/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3007e-09 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9805\n",
            "Epoch 375/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3272e-09 - accuracy: 1.0000 - val_loss: 0.2511 - val_accuracy: 0.9803\n",
            "Epoch 376/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3484e-09 - accuracy: 1.0000 - val_loss: 0.2516 - val_accuracy: 0.9803\n",
            "Epoch 377/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3007e-09 - accuracy: 1.0000 - val_loss: 0.2509 - val_accuracy: 0.9805\n",
            "Epoch 378/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3537e-09 - accuracy: 1.0000 - val_loss: 0.2517 - val_accuracy: 0.9805\n",
            "Epoch 379/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3775e-09 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9803\n",
            "Epoch 380/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3378e-09 - accuracy: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.9801\n",
            "Epoch 381/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3616e-09 - accuracy: 1.0000 - val_loss: 0.2531 - val_accuracy: 0.9802\n",
            "Epoch 382/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4755e-09 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9801\n",
            "Epoch 383/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3908e-09 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.9807\n",
            "Epoch 384/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4888e-09 - accuracy: 1.0000 - val_loss: 0.2546 - val_accuracy: 0.9801\n",
            "Epoch 385/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4994e-09 - accuracy: 1.0000 - val_loss: 0.2514 - val_accuracy: 0.9800\n",
            "Epoch 386/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5312e-09 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.9802\n",
            "Epoch 387/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4782e-09 - accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 0.9799\n",
            "Epoch 388/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3590e-09 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.9800\n",
            "Epoch 389/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4438e-09 - accuracy: 1.0000 - val_loss: 0.2567 - val_accuracy: 0.9799\n",
            "Epoch 390/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4755e-09 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9801\n",
            "Epoch 391/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4967e-09 - accuracy: 1.0000 - val_loss: 0.2565 - val_accuracy: 0.9799\n",
            "Epoch 392/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7299e-09 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9799\n",
            "Epoch 393/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5762e-09 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9797\n",
            "Epoch 394/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.2304 - accuracy: 0.9835 - val_loss: 0.2196 - val_accuracy: 0.9767\n",
            "Epoch 395/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.1852 - val_accuracy: 0.9783\n",
            "Epoch 396/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.1878 - val_accuracy: 0.9781\n",
            "Epoch 397/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3081e-04 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9792\n",
            "Epoch 398/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4109e-05 - accuracy: 1.0000 - val_loss: 0.1839 - val_accuracy: 0.9791\n",
            "Epoch 399/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4925e-05 - accuracy: 1.0000 - val_loss: 0.1837 - val_accuracy: 0.9793\n",
            "Epoch 400/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0617e-05 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9792\n",
            "Epoch 401/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7665e-05 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 0.9795\n",
            "Epoch 402/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5427e-05 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 0.9795\n",
            "Epoch 403/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3659e-05 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 0.9796\n",
            "Epoch 404/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1981e-05 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 0.9796\n",
            "Epoch 405/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0737e-05 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 0.9798\n",
            "Epoch 406/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6045e-06 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9797\n",
            "Epoch 407/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6811e-06 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9798\n",
            "Epoch 408/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.8358e-06 - accuracy: 1.0000 - val_loss: 0.1837 - val_accuracy: 0.9797\n",
            "Epoch 409/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1090e-06 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.9799\n",
            "Epoch 410/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4801e-06 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.9799\n",
            "Epoch 411/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.9094e-06 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.9799\n",
            "Epoch 412/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.3802e-06 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.9799\n",
            "Epoch 413/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.9228e-06 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 0.9799\n",
            "Epoch 414/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5101e-06 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.9800\n",
            "Epoch 415/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1292e-06 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9801\n",
            "Epoch 416/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.8017e-06 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9801\n",
            "Epoch 417/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.4899e-06 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9801\n",
            "Epoch 418/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2104e-06 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9801\n",
            "Epoch 419/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9562e-06 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9801\n",
            "Epoch 420/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7360e-06 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9801\n",
            "Epoch 421/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5243e-06 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9801\n",
            "Epoch 422/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3296e-06 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9801\n",
            "Epoch 423/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1508e-06 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9800\n",
            "Epoch 424/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9822e-06 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9799\n",
            "Epoch 425/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8253e-06 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9801\n",
            "Epoch 426/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6824e-06 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9801\n",
            "Epoch 427/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5598e-06 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9801\n",
            "Epoch 428/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4411e-06 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9801\n",
            "Epoch 429/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3263e-06 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.9801\n",
            "Epoch 430/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2322e-06 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9804\n",
            "Epoch 431/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1375e-06 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9805\n",
            "Epoch 432/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0515e-06 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 0.9803\n",
            "Epoch 433/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.7096e-07 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9802\n",
            "Epoch 434/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.0068e-07 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9803\n",
            "Epoch 435/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3481e-07 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9803\n",
            "Epoch 436/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7296e-07 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9801\n",
            "Epoch 437/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1233e-07 - accuracy: 1.0000 - val_loss: 0.1922 - val_accuracy: 0.9805\n",
            "Epoch 438/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6475e-07 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9802\n",
            "Epoch 439/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.1087e-07 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9803\n",
            "Epoch 440/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.6594e-07 - accuracy: 1.0000 - val_loss: 0.1935 - val_accuracy: 0.9803\n",
            "Epoch 441/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2464e-07 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 0.9803\n",
            "Epoch 442/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.8505e-07 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9804\n",
            "Epoch 443/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4908e-07 - accuracy: 1.0000 - val_loss: 0.1954 - val_accuracy: 0.9803\n",
            "Epoch 444/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1707e-07 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 0.9804\n",
            "Epoch 445/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8711e-07 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 0.9804\n",
            "Epoch 446/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.5896e-07 - accuracy: 1.0000 - val_loss: 0.1969 - val_accuracy: 0.9803\n",
            "Epoch 447/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3397e-07 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9805\n",
            "Epoch 448/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0959e-07 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9805\n",
            "Epoch 449/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8763e-07 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9805\n",
            "Epoch 450/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6718e-07 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9805\n",
            "Epoch 451/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4808e-07 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9804\n",
            "Epoch 452/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3052e-07 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9807\n",
            "Epoch 453/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1399e-07 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9805\n",
            "Epoch 454/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9895e-07 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9807\n",
            "Epoch 455/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8452e-07 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9808\n",
            "Epoch 456/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7154e-07 - accuracy: 1.0000 - val_loss: 0.2025 - val_accuracy: 0.9807\n",
            "Epoch 457/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5963e-07 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 0.9807\n",
            "Epoch 458/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4819e-07 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9807\n",
            "Epoch 459/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3746e-07 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 0.9807\n",
            "Epoch 460/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2788e-07 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9807\n",
            "Epoch 461/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1887e-07 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9807\n",
            "Epoch 462/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1028e-07 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9805\n",
            "Epoch 463/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0269e-07 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9807\n",
            "Epoch 464/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5587e-08 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9806\n",
            "Epoch 465/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8827e-08 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9805\n",
            "Epoch 466/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.2379e-08 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9805\n",
            "Epoch 467/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.6498e-08 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.9805\n",
            "Epoch 468/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1327e-08 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9804\n",
            "Epoch 469/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6113e-08 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 0.9803\n",
            "Epoch 470/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1745e-08 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9802\n",
            "Epoch 471/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.7329e-08 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9806\n",
            "Epoch 472/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3215e-08 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 0.9804\n",
            "Epoch 473/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9514e-08 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9803\n",
            "Epoch 474/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6057e-08 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9804\n",
            "Epoch 475/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2889e-08 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9805\n",
            "Epoch 476/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.9824e-08 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9805\n",
            "Epoch 477/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7146e-08 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9805\n",
            "Epoch 478/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.4510e-08 - accuracy: 1.0000 - val_loss: 0.2163 - val_accuracy: 0.9805\n",
            "Epoch 479/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2128e-08 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9805\n",
            "Epoch 480/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9866e-08 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9805\n",
            "Epoch 481/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7940e-08 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9805\n",
            "Epoch 482/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5990e-08 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9805\n",
            "Epoch 483/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4186e-08 - accuracy: 1.0000 - val_loss: 0.2194 - val_accuracy: 0.9805\n",
            "Epoch 484/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2459e-08 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 0.9806\n",
            "Epoch 485/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0875e-08 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9805\n",
            "Epoch 486/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9574e-08 - accuracy: 1.0000 - val_loss: 0.2215 - val_accuracy: 0.9806\n",
            "Epoch 487/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8069e-08 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9807\n",
            "Epoch 488/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6981e-08 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9807\n",
            "Epoch 489/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5783e-08 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9807\n",
            "Epoch 490/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4726e-08 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9805\n",
            "Epoch 491/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3738e-08 - accuracy: 1.0000 - val_loss: 0.2245 - val_accuracy: 0.9807\n",
            "Epoch 492/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2806e-08 - accuracy: 1.0000 - val_loss: 0.2252 - val_accuracy: 0.9807\n",
            "Epoch 493/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2067e-08 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9807\n",
            "Epoch 494/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1134e-08 - accuracy: 1.0000 - val_loss: 0.2265 - val_accuracy: 0.9807\n",
            "Epoch 495/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0392e-08 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9806\n",
            "Epoch 496/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7752e-09 - accuracy: 1.0000 - val_loss: 0.2278 - val_accuracy: 0.9807\n",
            "Epoch 497/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0943e-09 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9807\n",
            "Epoch 498/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5725e-09 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9808\n",
            "Epoch 499/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9817e-09 - accuracy: 1.0000 - val_loss: 0.2298 - val_accuracy: 0.9807\n",
            "Epoch 500/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.4810e-09 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 0.9808\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0576 - accuracy: 0.9952\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1875 - accuracy: 0.9835\n",
            "train accuracy :  0.995199978351593 train loss :  0.057611025869846344\n",
            "test accuracy :  0.9835000038146973  test loss :  0.187482550740242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UQcfQBlHB74M",
        "outputId": "cb9e19c4-890c-4d34-e4ad-a4988b5cbcb3"
      },
      "source": [
        "#신경망 학습2_1_4\n",
        "model2_1_4 = models.Sequential([\n",
        "                               Flatten(input_shape = (28, 28)),\n",
        "                               Dense(512, activation= 'relu'),\n",
        "                               Dense(512, activation= 'relu'),\n",
        "                               Dense(10, activation= 'softmax')\n",
        "                               ])\n",
        "\n",
        "model2_1_4.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "hist2_1_4 = model2_1_4.fit(train_x, train_y, epochs = 1000, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "#학습 그래프4\n",
        "plt.plot(hist2_1_4.history['accuracy'], 'b-')\n",
        "plt.plot(hist2_1_4.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train2_1_4 = model2_1_4.evaluate(train_x, train_y)\n",
        "sc_test2_1_4 = model2_1_4.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train2_1_4[1], \"train loss : \", sc_train2_1_4[0])\n",
        "print(\"test accuracy : \", sc_test2_1_4[1], \" test loss : \", sc_test2_1_4[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "176/176 [==============================] - 2s 7ms/step - loss: 0.3058 - accuracy: 0.9132 - val_loss: 0.1477 - val_accuracy: 0.9569\n",
            "Epoch 2/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.1050 - accuracy: 0.9688 - val_loss: 0.1042 - val_accuracy: 0.9693\n",
            "Epoch 3/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0647 - accuracy: 0.9802 - val_loss: 0.0917 - val_accuracy: 0.9721\n",
            "Epoch 4/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0441 - accuracy: 0.9863 - val_loss: 0.0966 - val_accuracy: 0.9705\n",
            "Epoch 5/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0295 - accuracy: 0.9907 - val_loss: 0.1008 - val_accuracy: 0.9696\n",
            "Epoch 6/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.1017 - val_accuracy: 0.9722\n",
            "Epoch 7/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.0937 - val_accuracy: 0.9758\n",
            "Epoch 8/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0144 - accuracy: 0.9952 - val_loss: 0.0997 - val_accuracy: 0.9752\n",
            "Epoch 9/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.0922 - val_accuracy: 0.9768\n",
            "Epoch 10/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.1044 - val_accuracy: 0.9746\n",
            "Epoch 11/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.1136 - val_accuracy: 0.9727\n",
            "Epoch 12/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.1083 - val_accuracy: 0.9753\n",
            "Epoch 13/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.1094 - val_accuracy: 0.9765\n",
            "Epoch 14/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.0976 - val_accuracy: 0.9783\n",
            "Epoch 15/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.1157 - val_accuracy: 0.9759\n",
            "Epoch 16/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.1302 - val_accuracy: 0.9727\n",
            "Epoch 17/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.1462 - val_accuracy: 0.9707\n",
            "Epoch 18/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.1219 - val_accuracy: 0.9757\n",
            "Epoch 19/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.1173 - val_accuracy: 0.9757\n",
            "Epoch 20/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.1180 - val_accuracy: 0.9769\n",
            "Epoch 21/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.1171 - val_accuracy: 0.9775\n",
            "Epoch 22/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1359 - val_accuracy: 0.9758\n",
            "Epoch 23/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.1470 - val_accuracy: 0.9721\n",
            "Epoch 24/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.1348 - val_accuracy: 0.9749\n",
            "Epoch 25/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.1239 - val_accuracy: 0.9771\n",
            "Epoch 26/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.1223 - val_accuracy: 0.9787\n",
            "Epoch 27/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.1552 - val_accuracy: 0.9742\n",
            "Epoch 28/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.1178 - val_accuracy: 0.9778\n",
            "Epoch 29/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.1402 - val_accuracy: 0.9776\n",
            "Epoch 30/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.1244 - val_accuracy: 0.9794\n",
            "Epoch 31/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.8910e-04 - accuracy: 0.9998 - val_loss: 0.1231 - val_accuracy: 0.9791\n",
            "Epoch 32/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5386e-04 - accuracy: 0.9997 - val_loss: 0.1171 - val_accuracy: 0.9796\n",
            "Epoch 33/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.9709e-05 - accuracy: 1.0000 - val_loss: 0.1161 - val_accuracy: 0.9805\n",
            "Epoch 34/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8426e-05 - accuracy: 1.0000 - val_loss: 0.1167 - val_accuracy: 0.9805\n",
            "Epoch 35/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2583e-05 - accuracy: 1.0000 - val_loss: 0.1175 - val_accuracy: 0.9807\n",
            "Epoch 36/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9133e-05 - accuracy: 1.0000 - val_loss: 0.1183 - val_accuracy: 0.9807\n",
            "Epoch 37/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6557e-05 - accuracy: 1.0000 - val_loss: 0.1191 - val_accuracy: 0.9807\n",
            "Epoch 38/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4522e-05 - accuracy: 1.0000 - val_loss: 0.1198 - val_accuracy: 0.9805\n",
            "Epoch 39/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2860e-05 - accuracy: 1.0000 - val_loss: 0.1204 - val_accuracy: 0.9808\n",
            "Epoch 40/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1472e-05 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9807\n",
            "Epoch 41/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0296e-05 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 0.9805\n",
            "Epoch 42/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2633e-06 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 0.9805\n",
            "Epoch 43/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3571e-06 - accuracy: 1.0000 - val_loss: 0.1235 - val_accuracy: 0.9806\n",
            "Epoch 44/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5834e-06 - accuracy: 1.0000 - val_loss: 0.1242 - val_accuracy: 0.9805\n",
            "Epoch 45/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8769e-06 - accuracy: 1.0000 - val_loss: 0.1249 - val_accuracy: 0.9805\n",
            "Epoch 46/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2479e-06 - accuracy: 1.0000 - val_loss: 0.1256 - val_accuracy: 0.9805\n",
            "Epoch 47/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6974e-06 - accuracy: 1.0000 - val_loss: 0.1264 - val_accuracy: 0.9805\n",
            "Epoch 48/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1800e-06 - accuracy: 1.0000 - val_loss: 0.1271 - val_accuracy: 0.9806\n",
            "Epoch 49/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7262e-06 - accuracy: 1.0000 - val_loss: 0.1278 - val_accuracy: 0.9805\n",
            "Epoch 50/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3188e-06 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9805\n",
            "Epoch 51/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9444e-06 - accuracy: 1.0000 - val_loss: 0.1293 - val_accuracy: 0.9805\n",
            "Epoch 52/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6128e-06 - accuracy: 1.0000 - val_loss: 0.1300 - val_accuracy: 0.9807\n",
            "Epoch 53/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.2986e-06 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9805\n",
            "Epoch 54/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0184e-06 - accuracy: 1.0000 - val_loss: 0.1314 - val_accuracy: 0.9806\n",
            "Epoch 55/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7663e-06 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.9807\n",
            "Epoch 56/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5303e-06 - accuracy: 1.0000 - val_loss: 0.1330 - val_accuracy: 0.9808\n",
            "Epoch 57/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3200e-06 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.9807\n",
            "Epoch 58/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1277e-06 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.9809\n",
            "Epoch 59/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9490e-06 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.9808\n",
            "Epoch 60/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7851e-06 - accuracy: 1.0000 - val_loss: 0.1360 - val_accuracy: 0.9809\n",
            "Epoch 61/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6390e-06 - accuracy: 1.0000 - val_loss: 0.1367 - val_accuracy: 0.9807\n",
            "Epoch 62/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5045e-06 - accuracy: 1.0000 - val_loss: 0.1374 - val_accuracy: 0.9807\n",
            "Epoch 63/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3780e-06 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9807\n",
            "Epoch 64/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2661e-06 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9807\n",
            "Epoch 65/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1600e-06 - accuracy: 1.0000 - val_loss: 0.1398 - val_accuracy: 0.9807\n",
            "Epoch 66/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0676e-06 - accuracy: 1.0000 - val_loss: 0.1405 - val_accuracy: 0.9808\n",
            "Epoch 67/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7715e-07 - accuracy: 1.0000 - val_loss: 0.1413 - val_accuracy: 0.9807\n",
            "Epoch 68/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.9623e-07 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9808\n",
            "Epoch 69/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.2278e-07 - accuracy: 1.0000 - val_loss: 0.1428 - val_accuracy: 0.9807\n",
            "Epoch 70/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5588e-07 - accuracy: 1.0000 - val_loss: 0.1436 - val_accuracy: 0.9807\n",
            "Epoch 71/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.9497e-07 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9808\n",
            "Epoch 72/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3787e-07 - accuracy: 1.0000 - val_loss: 0.1451 - val_accuracy: 0.9808\n",
            "Epoch 73/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8580e-07 - accuracy: 1.0000 - val_loss: 0.1458 - val_accuracy: 0.9808\n",
            "Epoch 74/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3840e-07 - accuracy: 1.0000 - val_loss: 0.1466 - val_accuracy: 0.9808\n",
            "Epoch 75/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.9353e-07 - accuracy: 1.0000 - val_loss: 0.1474 - val_accuracy: 0.9808\n",
            "Epoch 76/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.5482e-07 - accuracy: 1.0000 - val_loss: 0.1481 - val_accuracy: 0.9808\n",
            "Epoch 77/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1663e-07 - accuracy: 1.0000 - val_loss: 0.1488 - val_accuracy: 0.9808\n",
            "Epoch 78/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.8487e-07 - accuracy: 1.0000 - val_loss: 0.1497 - val_accuracy: 0.9807\n",
            "Epoch 79/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.5226e-07 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 0.9808\n",
            "Epoch 80/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.2443e-07 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9809\n",
            "Epoch 81/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9852e-07 - accuracy: 1.0000 - val_loss: 0.1518 - val_accuracy: 0.9808\n",
            "Epoch 82/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7446e-07 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9806\n",
            "Epoch 83/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5227e-07 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9805\n",
            "Epoch 84/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3180e-07 - accuracy: 1.0000 - val_loss: 0.1541 - val_accuracy: 0.9805\n",
            "Epoch 85/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1266e-07 - accuracy: 1.0000 - val_loss: 0.1548 - val_accuracy: 0.9807\n",
            "Epoch 86/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9688e-07 - accuracy: 1.0000 - val_loss: 0.1558 - val_accuracy: 0.9805\n",
            "Epoch 87/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8029e-07 - accuracy: 1.0000 - val_loss: 0.1563 - val_accuracy: 0.9805\n",
            "Epoch 88/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6637e-07 - accuracy: 1.0000 - val_loss: 0.1573 - val_accuracy: 0.9806\n",
            "Epoch 89/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5317e-07 - accuracy: 1.0000 - val_loss: 0.1579 - val_accuracy: 0.9805\n",
            "Epoch 90/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4118e-07 - accuracy: 1.0000 - val_loss: 0.1589 - val_accuracy: 0.9803\n",
            "Epoch 91/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2989e-07 - accuracy: 1.0000 - val_loss: 0.1593 - val_accuracy: 0.9803\n",
            "Epoch 92/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2021e-07 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9805\n",
            "Epoch 93/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1030e-07 - accuracy: 1.0000 - val_loss: 0.1607 - val_accuracy: 0.9803\n",
            "Epoch 94/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0172e-07 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.9802\n",
            "Epoch 95/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4390e-08 - accuracy: 1.0000 - val_loss: 0.1624 - val_accuracy: 0.9803\n",
            "Epoch 96/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.6972e-08 - accuracy: 1.0000 - val_loss: 0.1630 - val_accuracy: 0.9803\n",
            "Epoch 97/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9952e-08 - accuracy: 1.0000 - val_loss: 0.1638 - val_accuracy: 0.9803\n",
            "Epoch 98/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3979e-08 - accuracy: 1.0000 - val_loss: 0.1644 - val_accuracy: 0.9803\n",
            "Epoch 99/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8182e-08 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9803\n",
            "Epoch 100/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3038e-08 - accuracy: 1.0000 - val_loss: 0.1658 - val_accuracy: 0.9801\n",
            "Epoch 101/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8405e-08 - accuracy: 1.0000 - val_loss: 0.1665 - val_accuracy: 0.9803\n",
            "Epoch 102/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3835e-08 - accuracy: 1.0000 - val_loss: 0.1674 - val_accuracy: 0.9801\n",
            "Epoch 103/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9790e-08 - accuracy: 1.0000 - val_loss: 0.1681 - val_accuracy: 0.9801\n",
            "Epoch 104/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.6142e-08 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9802\n",
            "Epoch 105/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.2801e-08 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 0.9803\n",
            "Epoch 106/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9495e-08 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 0.9803\n",
            "Epoch 107/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6489e-08 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9803\n",
            "Epoch 108/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3906e-08 - accuracy: 1.0000 - val_loss: 0.1714 - val_accuracy: 0.9803\n",
            "Epoch 109/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1416e-08 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 0.9803\n",
            "Epoch 110/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9140e-08 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 0.9804\n",
            "Epoch 111/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7074e-08 - accuracy: 1.0000 - val_loss: 0.1733 - val_accuracy: 0.9803\n",
            "Epoch 112/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5156e-08 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 0.9805\n",
            "Epoch 113/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3455e-08 - accuracy: 1.0000 - val_loss: 0.1747 - val_accuracy: 0.9803\n",
            "Epoch 114/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1842e-08 - accuracy: 1.0000 - val_loss: 0.1754 - val_accuracy: 0.9805\n",
            "Epoch 115/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0231e-08 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 0.9804\n",
            "Epoch 116/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8936e-08 - accuracy: 1.0000 - val_loss: 0.1762 - val_accuracy: 0.9805\n",
            "Epoch 117/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7630e-08 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.9806\n",
            "Epoch 118/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6459e-08 - accuracy: 1.0000 - val_loss: 0.1776 - val_accuracy: 0.9805\n",
            "Epoch 119/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5349e-08 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 0.9809\n",
            "Epoch 120/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4355e-08 - accuracy: 1.0000 - val_loss: 0.1787 - val_accuracy: 0.9807\n",
            "Epoch 121/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3439e-08 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 0.9807\n",
            "Epoch 122/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2520e-08 - accuracy: 1.0000 - val_loss: 0.1798 - val_accuracy: 0.9807\n",
            "Epoch 123/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1770e-08 - accuracy: 1.0000 - val_loss: 0.1804 - val_accuracy: 0.9807\n",
            "Epoch 124/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1055e-08 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9807\n",
            "Epoch 125/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0390e-08 - accuracy: 1.0000 - val_loss: 0.1813 - val_accuracy: 0.9807\n",
            "Epoch 126/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.7381e-09 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9808\n",
            "Epoch 127/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.1208e-09 - accuracy: 1.0000 - val_loss: 0.1826 - val_accuracy: 0.9807\n",
            "Epoch 128/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5645e-09 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 0.9809\n",
            "Epoch 129/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.0797e-09 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 0.9807\n",
            "Epoch 130/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.5923e-09 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9809\n",
            "Epoch 131/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1367e-09 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.9807\n",
            "Epoch 132/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7525e-09 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 0.9808\n",
            "Epoch 133/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3287e-09 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9809\n",
            "Epoch 134/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.9976e-09 - accuracy: 1.0000 - val_loss: 0.1853 - val_accuracy: 0.9808\n",
            "Epoch 135/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7485e-09 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 0.9809\n",
            "Epoch 136/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4095e-09 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9808\n",
            "Epoch 137/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1392e-09 - accuracy: 1.0000 - val_loss: 0.1864 - val_accuracy: 0.9809\n",
            "Epoch 138/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.8902e-09 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 0.9809\n",
            "Epoch 139/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6094e-09 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9809\n",
            "Epoch 140/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4134e-09 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9809\n",
            "Epoch 141/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1829e-09 - accuracy: 1.0000 - val_loss: 0.1879 - val_accuracy: 0.9807\n",
            "Epoch 142/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.0187e-09 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9808\n",
            "Epoch 143/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7829e-09 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 0.9807\n",
            "Epoch 144/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6213e-09 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.9809\n",
            "Epoch 145/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4465e-09 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9807\n",
            "Epoch 146/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2637e-09 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9808\n",
            "Epoch 147/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1180e-09 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.9810\n",
            "Epoch 148/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9882e-09 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9809\n",
            "Epoch 149/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8875e-09 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9809\n",
            "Epoch 150/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7921e-09 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9809\n",
            "Epoch 151/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6782e-09 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9807\n",
            "Epoch 152/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5696e-09 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9809\n",
            "Epoch 153/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4716e-09 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.9808\n",
            "Epoch 154/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3656e-09 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9809\n",
            "Epoch 155/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2703e-09 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9809\n",
            "Epoch 156/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2014e-09 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9808\n",
            "Epoch 157/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1378e-09 - accuracy: 1.0000 - val_loss: 0.1916 - val_accuracy: 0.9809\n",
            "Epoch 158/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0319e-09 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 0.9809\n",
            "Epoch 159/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9683e-09 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 0.9810\n",
            "Epoch 160/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9418e-09 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9808\n",
            "Epoch 161/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8491e-09 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9810\n",
            "Epoch 162/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7749e-09 - accuracy: 1.0000 - val_loss: 0.1922 - val_accuracy: 0.9809\n",
            "Epoch 163/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7060e-09 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9810\n",
            "Epoch 164/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6716e-09 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9809\n",
            "Epoch 165/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6159e-09 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9809\n",
            "Epoch 166/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5471e-09 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 0.9809\n",
            "Epoch 167/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4967e-09 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9810\n",
            "Epoch 168/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4888e-09 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9809\n",
            "Epoch 169/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4199e-09 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9809\n",
            "Epoch 170/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3987e-09 - accuracy: 1.0000 - val_loss: 0.1932 - val_accuracy: 0.9808\n",
            "Epoch 171/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3669e-09 - accuracy: 1.0000 - val_loss: 0.1932 - val_accuracy: 0.9809\n",
            "Epoch 172/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3510e-09 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9808\n",
            "Epoch 173/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3113e-09 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9809\n",
            "Epoch 174/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2557e-09 - accuracy: 1.0000 - val_loss: 0.1935 - val_accuracy: 0.9809\n",
            "Epoch 175/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2292e-09 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 0.9809\n",
            "Epoch 176/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2239e-09 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 0.9809\n",
            "Epoch 177/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1524e-09 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 0.9809\n",
            "Epoch 178/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1762e-09 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 0.9809\n",
            "Epoch 179/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1179e-09 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 0.9809\n",
            "Epoch 180/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1285e-09 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9809\n",
            "Epoch 181/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0914e-09 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9809\n",
            "Epoch 182/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0649e-09 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9809\n",
            "Epoch 183/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0570e-09 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9809\n",
            "Epoch 184/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0173e-09 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 0.9809\n",
            "Epoch 185/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0040e-09 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9809\n",
            "Epoch 186/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.8811e-10 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9809\n",
            "Epoch 187/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.5632e-10 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9809\n",
            "Epoch 188/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.3778e-10 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9807\n",
            "Epoch 189/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.7222e-10 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 0.9809\n",
            "Epoch 190/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4838e-10 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9809\n",
            "Epoch 191/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1129e-10 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 0.9808\n",
            "Epoch 192/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2453e-10 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9808\n",
            "Epoch 193/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.1129e-10 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9809\n",
            "Epoch 194/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.9539e-10 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.9807\n",
            "Epoch 195/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9010e-10 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 0.9807\n",
            "Epoch 196/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.4506e-10 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9808\n",
            "Epoch 197/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6890e-10 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 0.9809\n",
            "Epoch 198/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.1857e-10 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9809\n",
            "Epoch 199/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5036e-10 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9808\n",
            "Epoch 200/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.6890e-10 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9809\n",
            "Epoch 201/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.1592e-10 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.9809\n",
            "Epoch 202/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.5831e-10 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9808\n",
            "Epoch 203/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2122e-10 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9809\n",
            "Epoch 204/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.2122e-10 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 0.9807\n",
            "Epoch 205/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.0797e-10 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 0.9807\n",
            "Epoch 206/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.6294e-10 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 0.9809\n",
            "Epoch 207/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.0797e-10 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.9807\n",
            "Epoch 208/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8413e-10 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9807\n",
            "Epoch 209/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.3380e-10 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9807\n",
            "Epoch 210/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.0003e-10 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.9806\n",
            "Epoch 211/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7354e-10 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.9806\n",
            "Epoch 212/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7883e-10 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.9806\n",
            "Epoch 213/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.6824e-10 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9805\n",
            "Epoch 214/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4175e-10 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 0.9805\n",
            "Epoch 215/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8148e-10 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9805\n",
            "Epoch 216/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7618e-10 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9805\n",
            "Epoch 217/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.1790e-10 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9807\n",
            "Epoch 218/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8678e-10 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9807\n",
            "Epoch 219/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.3115e-10 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9804\n",
            "Epoch 220/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.2055e-10 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9805\n",
            "Epoch 221/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4704e-10 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9805\n",
            "Epoch 222/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.3115e-10 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 0.9805\n",
            "Epoch 223/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.3380e-10 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9805\n",
            "Epoch 224/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3115e-10 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.9805\n",
            "Epoch 225/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4969e-10 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9805\n",
            "Epoch 226/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.2850e-10 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.9805\n",
            "Epoch 227/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4440e-10 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9805\n",
            "Epoch 228/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.2320e-10 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9805\n",
            "Epoch 229/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2055e-10 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9805\n",
            "Epoch 230/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.1790e-10 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9805\n",
            "Epoch 231/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.2585e-10 - accuracy: 1.0000 - val_loss: 0.1996 - val_accuracy: 0.9806\n",
            "Epoch 232/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0731e-10 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.9805\n",
            "Epoch 233/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.6559e-10 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9805\n",
            "Epoch 234/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.2585e-10 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.9805\n",
            "Epoch 235/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1790e-10 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9807\n",
            "Epoch 236/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.1526e-10 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9806\n",
            "Epoch 237/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.5499e-10 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9807\n",
            "Epoch 238/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0996e-10 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9806\n",
            "Epoch 239/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5234e-10 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9806\n",
            "Epoch 240/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4969e-10 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9807\n",
            "Epoch 241/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.5234e-10 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9807\n",
            "Epoch 242/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7089e-10 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9805\n",
            "Epoch 243/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.1526e-10 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9805\n",
            "Epoch 244/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.3910e-10 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9805\n",
            "Epoch 245/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4704e-10 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9805\n",
            "Epoch 246/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4704e-10 - accuracy: 1.0000 - val_loss: 0.2025 - val_accuracy: 0.9806\n",
            "Epoch 247/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.6559e-10 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9805\n",
            "Epoch 248/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4440e-10 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9805\n",
            "Epoch 249/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6559e-10 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9805\n",
            "Epoch 250/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.6824e-10 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9804\n",
            "Epoch 251/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1261e-10 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9804\n",
            "Epoch 252/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8413e-10 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.9805\n",
            "Epoch 253/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4704e-10 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9805\n",
            "Epoch 254/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7089e-10 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 0.9804\n",
            "Epoch 255/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2585e-10 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 0.9805\n",
            "Epoch 256/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9473e-10 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9804\n",
            "Epoch 257/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.5234e-10 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9804\n",
            "Epoch 258/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.6294e-10 - accuracy: 1.0000 - val_loss: 0.2051 - val_accuracy: 0.9804\n",
            "Epoch 259/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7618e-10 - accuracy: 1.0000 - val_loss: 0.2053 - val_accuracy: 0.9804\n",
            "Epoch 260/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7354e-10 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9804\n",
            "Epoch 261/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4704e-10 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9803\n",
            "Epoch 262/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.0268e-10 - accuracy: 1.0000 - val_loss: 0.2062 - val_accuracy: 0.9803\n",
            "Epoch 263/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.0003e-10 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9803\n",
            "Epoch 264/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.0268e-10 - accuracy: 1.0000 - val_loss: 0.2064 - val_accuracy: 0.9803\n",
            "Epoch 265/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1062e-10 - accuracy: 1.0000 - val_loss: 0.2066 - val_accuracy: 0.9803\n",
            "Epoch 266/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.0003e-10 - accuracy: 1.0000 - val_loss: 0.2070 - val_accuracy: 0.9803\n",
            "Epoch 267/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8943e-10 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9803\n",
            "Epoch 268/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.1327e-10 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9802\n",
            "Epoch 269/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0797e-10 - accuracy: 1.0000 - val_loss: 0.2078 - val_accuracy: 0.9803\n",
            "Epoch 270/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.0268e-10 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9803\n",
            "Epoch 271/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2917e-10 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9802\n",
            "Epoch 272/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.4241e-10 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9803\n",
            "Epoch 273/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1062e-10 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9801\n",
            "Epoch 274/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.1062e-10 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.9802\n",
            "Epoch 275/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.5831e-10 - accuracy: 1.0000 - val_loss: 0.2093 - val_accuracy: 0.9802\n",
            "Epoch 276/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.3976e-10 - accuracy: 1.0000 - val_loss: 0.2097 - val_accuracy: 0.9802\n",
            "Epoch 277/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2652e-10 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 0.9803\n",
            "Epoch 278/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2122e-10 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 0.9804\n",
            "Epoch 279/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.1129e-10 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 0.9804\n",
            "Epoch 280/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2917e-10 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9804\n",
            "Epoch 281/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0334e-10 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9803\n",
            "Epoch 282/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5831e-10 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9803\n",
            "Epoch 283/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.6096e-10 - accuracy: 1.0000 - val_loss: 0.2117 - val_accuracy: 0.9803\n",
            "Epoch 284/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.9010e-10 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9805\n",
            "Epoch 285/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9804e-10 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 0.9805\n",
            "Epoch 286/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.6096e-10 - accuracy: 1.0000 - val_loss: 0.2126 - val_accuracy: 0.9804\n",
            "Epoch 287/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.2189e-10 - accuracy: 1.0000 - val_loss: 0.2131 - val_accuracy: 0.9803\n",
            "Epoch 288/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.1659e-10 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9805\n",
            "Epoch 289/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0599e-10 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9803\n",
            "Epoch 290/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.2983e-10 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9805\n",
            "Epoch 291/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1659e-10 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9803\n",
            "Epoch 292/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.3248e-10 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9803\n",
            "Epoch 293/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3513e-10 - accuracy: 1.0000 - val_loss: 0.2149 - val_accuracy: 0.9803\n",
            "Epoch 294/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3248e-10 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 0.9803\n",
            "Epoch 295/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.8281e-10 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9803\n",
            "Epoch 296/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.2983e-10 - accuracy: 1.0000 - val_loss: 0.2158 - val_accuracy: 0.9802\n",
            "Epoch 297/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7222e-10 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 0.9802\n",
            "Epoch 298/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9076e-10 - accuracy: 1.0000 - val_loss: 0.2166 - val_accuracy: 0.9804\n",
            "Epoch 299/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7487e-10 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9802\n",
            "Epoch 300/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.8017e-10 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9802\n",
            "Epoch 301/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.8811e-10 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9803\n",
            "Epoch 302/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.9871e-10 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9803\n",
            "Epoch 303/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0067e-09 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9803\n",
            "Epoch 304/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0437e-09 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9803\n",
            "Epoch 305/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9341e-10 - accuracy: 1.0000 - val_loss: 0.2191 - val_accuracy: 0.9803\n",
            "Epoch 306/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0384e-09 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 0.9803\n",
            "Epoch 307/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0676e-09 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9803\n",
            "Epoch 308/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0384e-09 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9804\n",
            "Epoch 309/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0146e-09 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9803\n",
            "Epoch 310/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0755e-09 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9803\n",
            "Epoch 311/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0782e-09 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9803\n",
            "Epoch 312/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0252e-09 - accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 0.9804\n",
            "Epoch 313/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0835e-09 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9804\n",
            "Epoch 314/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0623e-09 - accuracy: 1.0000 - val_loss: 0.2226 - val_accuracy: 0.9804\n",
            "Epoch 315/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1285e-09 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9803\n",
            "Epoch 316/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0941e-09 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.9803\n",
            "Epoch 317/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1047e-09 - accuracy: 1.0000 - val_loss: 0.2239 - val_accuracy: 0.9803\n",
            "Epoch 318/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1418e-09 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.9803\n",
            "Epoch 319/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1126e-09 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9803\n",
            "Epoch 320/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1391e-09 - accuracy: 1.0000 - val_loss: 0.2249 - val_accuracy: 0.9802\n",
            "Epoch 321/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1259e-09 - accuracy: 1.0000 - val_loss: 0.2251 - val_accuracy: 0.9802\n",
            "Epoch 322/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1418e-09 - accuracy: 1.0000 - val_loss: 0.2257 - val_accuracy: 0.9802\n",
            "Epoch 323/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1709e-09 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9801\n",
            "Epoch 324/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1418e-09 - accuracy: 1.0000 - val_loss: 0.2265 - val_accuracy: 0.9801\n",
            "Epoch 325/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1683e-09 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9803\n",
            "Epoch 326/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1603e-09 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9801\n",
            "Epoch 327/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1709e-09 - accuracy: 1.0000 - val_loss: 0.2278 - val_accuracy: 0.9802\n",
            "Epoch 328/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1894e-09 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 0.9801\n",
            "Epoch 329/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1444e-09 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9801\n",
            "Epoch 330/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1868e-09 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.9802\n",
            "Epoch 331/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1921e-09 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9801\n",
            "Epoch 332/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2159e-09 - accuracy: 1.0000 - val_loss: 0.2296 - val_accuracy: 0.9800\n",
            "Epoch 333/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1974e-09 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.9801\n",
            "Epoch 334/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2000e-09 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 0.9803\n",
            "Epoch 335/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2106e-09 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9801\n",
            "Epoch 336/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1947e-09 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9801\n",
            "Epoch 337/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2424e-09 - accuracy: 1.0000 - val_loss: 0.2315 - val_accuracy: 0.9802\n",
            "Epoch 338/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2186e-09 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9803\n",
            "Epoch 339/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2000e-09 - accuracy: 1.0000 - val_loss: 0.2327 - val_accuracy: 0.9801\n",
            "Epoch 340/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2477e-09 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.9801\n",
            "Epoch 341/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2345e-09 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9801\n",
            "Epoch 342/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2530e-09 - accuracy: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9803\n",
            "Epoch 343/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2477e-09 - accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 0.9801\n",
            "Epoch 344/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2557e-09 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9802\n",
            "Epoch 345/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3325e-09 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9803\n",
            "Epoch 346/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2053e-09 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9802\n",
            "Epoch 347/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3404e-09 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9801\n",
            "Epoch 348/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2663e-09 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9801\n",
            "Epoch 349/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2928e-09 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9802\n",
            "Epoch 350/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2769e-09 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9801\n",
            "Epoch 351/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2981e-09 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9800\n",
            "Epoch 352/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3298e-09 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9801\n",
            "Epoch 353/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3510e-09 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9799\n",
            "Epoch 354/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2954e-09 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9798\n",
            "Epoch 355/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3192e-09 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9799\n",
            "Epoch 356/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3378e-09 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9798\n",
            "Epoch 357/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3510e-09 - accuracy: 1.0000 - val_loss: 0.2407 - val_accuracy: 0.9797\n",
            "Epoch 358/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3537e-09 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9797\n",
            "Epoch 359/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3802e-09 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 0.9796\n",
            "Epoch 360/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3272e-09 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9796\n",
            "Epoch 361/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4040e-09 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9796\n",
            "Epoch 362/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4014e-09 - accuracy: 1.0000 - val_loss: 0.2429 - val_accuracy: 0.9795\n",
            "Epoch 363/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3802e-09 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9797\n",
            "Epoch 364/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4067e-09 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9794\n",
            "Epoch 365/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3934e-09 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9795\n",
            "Epoch 366/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4067e-09 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9795\n",
            "Epoch 367/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4040e-09 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9793\n",
            "Epoch 368/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4226e-09 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9797\n",
            "Epoch 369/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4411e-09 - accuracy: 1.0000 - val_loss: 0.2461 - val_accuracy: 0.9797\n",
            "Epoch 370/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4491e-09 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9793\n",
            "Epoch 371/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4464e-09 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9795\n",
            "Epoch 372/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4623e-09 - accuracy: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.9797\n",
            "Epoch 373/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4676e-09 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9795\n",
            "Epoch 374/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4623e-09 - accuracy: 1.0000 - val_loss: 0.2486 - val_accuracy: 0.9797\n",
            "Epoch 375/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4332e-09 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.9795\n",
            "Epoch 376/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4888e-09 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9795\n",
            "Epoch 377/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4808e-09 - accuracy: 1.0000 - val_loss: 0.2496 - val_accuracy: 0.9791\n",
            "Epoch 378/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5126e-09 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9796\n",
            "Epoch 379/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4570e-09 - accuracy: 1.0000 - val_loss: 0.2499 - val_accuracy: 0.9793\n",
            "Epoch 380/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5603e-09 - accuracy: 1.0000 - val_loss: 0.2507 - val_accuracy: 0.9793\n",
            "Epoch 381/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5444e-09 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.9794\n",
            "Epoch 382/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5683e-09 - accuracy: 1.0000 - val_loss: 0.2520 - val_accuracy: 0.9793\n",
            "Epoch 383/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5365e-09 - accuracy: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.9790\n",
            "Epoch 384/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5550e-09 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9791\n",
            "Epoch 385/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6663e-09 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.9791\n",
            "Epoch 386/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5789e-09 - accuracy: 1.0000 - val_loss: 0.2537 - val_accuracy: 0.9792\n",
            "Epoch 387/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5683e-09 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.9791\n",
            "Epoch 388/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6106e-09 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.9791\n",
            "Epoch 389/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6345e-09 - accuracy: 1.0000 - val_loss: 0.2554 - val_accuracy: 0.9791\n",
            "Epoch 390/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5709e-09 - accuracy: 1.0000 - val_loss: 0.2547 - val_accuracy: 0.9791\n",
            "Epoch 391/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5895e-09 - accuracy: 1.0000 - val_loss: 0.2561 - val_accuracy: 0.9789\n",
            "Epoch 392/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6451e-09 - accuracy: 1.0000 - val_loss: 0.2572 - val_accuracy: 0.9789\n",
            "Epoch 393/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6159e-09 - accuracy: 1.0000 - val_loss: 0.2570 - val_accuracy: 0.9789\n",
            "Epoch 394/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6822e-09 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.9790\n",
            "Epoch 395/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6848e-09 - accuracy: 1.0000 - val_loss: 0.2577 - val_accuracy: 0.9790\n",
            "Epoch 396/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6530e-09 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9789\n",
            "Epoch 397/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8093e-09 - accuracy: 1.0000 - val_loss: 0.2588 - val_accuracy: 0.9791\n",
            "Epoch 398/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7722e-09 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9788\n",
            "Epoch 399/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7484e-09 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.9788\n",
            "Epoch 400/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8835e-09 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.9790\n",
            "Epoch 401/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8358e-09 - accuracy: 1.0000 - val_loss: 0.2610 - val_accuracy: 0.9789\n",
            "Epoch 402/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7802e-09 - accuracy: 1.0000 - val_loss: 0.2616 - val_accuracy: 0.9787\n",
            "Epoch 403/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7961e-09 - accuracy: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.9789\n",
            "Epoch 404/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7378e-09 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9787\n",
            "Epoch 405/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8385e-09 - accuracy: 1.0000 - val_loss: 0.2622 - val_accuracy: 0.9789\n",
            "Epoch 406/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.1632 - accuracy: 0.9863 - val_loss: 0.1691 - val_accuracy: 0.9775\n",
            "Epoch 407/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.1538 - val_accuracy: 0.9784\n",
            "Epoch 408/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.1514 - val_accuracy: 0.9801\n",
            "Epoch 409/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2773e-04 - accuracy: 0.9999 - val_loss: 0.1475 - val_accuracy: 0.9802\n",
            "Epoch 410/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1892e-05 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 0.9805\n",
            "Epoch 411/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9480e-05 - accuracy: 1.0000 - val_loss: 0.1480 - val_accuracy: 0.9806\n",
            "Epoch 412/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3018e-05 - accuracy: 1.0000 - val_loss: 0.1481 - val_accuracy: 0.9806\n",
            "Epoch 413/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8311e-05 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 0.9807\n",
            "Epoch 414/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4625e-05 - accuracy: 1.0000 - val_loss: 0.1485 - val_accuracy: 0.9806\n",
            "Epoch 415/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1680e-05 - accuracy: 1.0000 - val_loss: 0.1488 - val_accuracy: 0.9805\n",
            "Epoch 416/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9213e-05 - accuracy: 1.0000 - val_loss: 0.1490 - val_accuracy: 0.9805\n",
            "Epoch 417/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7169e-05 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.9804\n",
            "Epoch 418/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5454e-05 - accuracy: 1.0000 - val_loss: 0.1495 - val_accuracy: 0.9804\n",
            "Epoch 419/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3922e-05 - accuracy: 1.0000 - val_loss: 0.1498 - val_accuracy: 0.9805\n",
            "Epoch 420/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2636e-05 - accuracy: 1.0000 - val_loss: 0.1502 - val_accuracy: 0.9805\n",
            "Epoch 421/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1495e-05 - accuracy: 1.0000 - val_loss: 0.1505 - val_accuracy: 0.9806\n",
            "Epoch 422/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0481e-05 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 0.9807\n",
            "Epoch 423/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5808e-06 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 0.9807\n",
            "Epoch 424/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7758e-06 - accuracy: 1.0000 - val_loss: 0.1513 - val_accuracy: 0.9807\n",
            "Epoch 425/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0479e-06 - accuracy: 1.0000 - val_loss: 0.1515 - val_accuracy: 0.9808\n",
            "Epoch 426/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4018e-06 - accuracy: 1.0000 - val_loss: 0.1519 - val_accuracy: 0.9809\n",
            "Epoch 427/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7653e-06 - accuracy: 1.0000 - val_loss: 0.1522 - val_accuracy: 0.9808\n",
            "Epoch 428/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2324e-06 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 0.9808\n",
            "Epoch 429/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7281e-06 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9808\n",
            "Epoch 430/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2603e-06 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9809\n",
            "Epoch 431/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.8435e-06 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9805\n",
            "Epoch 432/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.4523e-06 - accuracy: 1.0000 - val_loss: 0.1541 - val_accuracy: 0.9807\n",
            "Epoch 433/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1013e-06 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 0.9805\n",
            "Epoch 434/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7729e-06 - accuracy: 1.0000 - val_loss: 0.1548 - val_accuracy: 0.9805\n",
            "Epoch 435/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.4777e-06 - accuracy: 1.0000 - val_loss: 0.1551 - val_accuracy: 0.9803\n",
            "Epoch 436/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2023e-06 - accuracy: 1.0000 - val_loss: 0.1557 - val_accuracy: 0.9805\n",
            "Epoch 437/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9399e-06 - accuracy: 1.0000 - val_loss: 0.1561 - val_accuracy: 0.9806\n",
            "Epoch 438/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7044e-06 - accuracy: 1.0000 - val_loss: 0.1564 - val_accuracy: 0.9807\n",
            "Epoch 439/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4868e-06 - accuracy: 1.0000 - val_loss: 0.1569 - val_accuracy: 0.9806\n",
            "Epoch 440/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2880e-06 - accuracy: 1.0000 - val_loss: 0.1572 - val_accuracy: 0.9808\n",
            "Epoch 441/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1052e-06 - accuracy: 1.0000 - val_loss: 0.1579 - val_accuracy: 0.9807\n",
            "Epoch 442/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9320e-06 - accuracy: 1.0000 - val_loss: 0.1582 - val_accuracy: 0.9809\n",
            "Epoch 443/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7783e-06 - accuracy: 1.0000 - val_loss: 0.1587 - val_accuracy: 0.9809\n",
            "Epoch 444/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6383e-06 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 0.9807\n",
            "Epoch 445/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5063e-06 - accuracy: 1.0000 - val_loss: 0.1597 - val_accuracy: 0.9809\n",
            "Epoch 446/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3835e-06 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9809\n",
            "Epoch 447/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2765e-06 - accuracy: 1.0000 - val_loss: 0.1607 - val_accuracy: 0.9809\n",
            "Epoch 448/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1683e-06 - accuracy: 1.0000 - val_loss: 0.1610 - val_accuracy: 0.9811\n",
            "Epoch 449/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0774e-06 - accuracy: 1.0000 - val_loss: 0.1616 - val_accuracy: 0.9811\n",
            "Epoch 450/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.8939e-07 - accuracy: 1.0000 - val_loss: 0.1623 - val_accuracy: 0.9810\n",
            "Epoch 451/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.1377e-07 - accuracy: 1.0000 - val_loss: 0.1629 - val_accuracy: 0.9810\n",
            "Epoch 452/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3999e-07 - accuracy: 1.0000 - val_loss: 0.1634 - val_accuracy: 0.9809\n",
            "Epoch 453/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7611e-07 - accuracy: 1.0000 - val_loss: 0.1639 - val_accuracy: 0.9808\n",
            "Epoch 454/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1195e-07 - accuracy: 1.0000 - val_loss: 0.1644 - val_accuracy: 0.9809\n",
            "Epoch 455/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5642e-07 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9808\n",
            "Epoch 456/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0445e-07 - accuracy: 1.0000 - val_loss: 0.1657 - val_accuracy: 0.9811\n",
            "Epoch 457/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5528e-07 - accuracy: 1.0000 - val_loss: 0.1662 - val_accuracy: 0.9810\n",
            "Epoch 458/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1225e-07 - accuracy: 1.0000 - val_loss: 0.1667 - val_accuracy: 0.9809\n",
            "Epoch 459/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7145e-07 - accuracy: 1.0000 - val_loss: 0.1674 - val_accuracy: 0.9810\n",
            "Epoch 460/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.3434e-07 - accuracy: 1.0000 - val_loss: 0.1680 - val_accuracy: 0.9810\n",
            "Epoch 461/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0036e-07 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9811\n",
            "Epoch 462/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6808e-07 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 0.9810\n",
            "Epoch 463/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3890e-07 - accuracy: 1.0000 - val_loss: 0.1700 - val_accuracy: 0.9810\n",
            "Epoch 464/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1287e-07 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 0.9812\n",
            "Epoch 465/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8718e-07 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 0.9809\n",
            "Epoch 466/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6450e-07 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 0.9809\n",
            "Epoch 467/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4299e-07 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 0.9810\n",
            "Epoch 468/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2408e-07 - accuracy: 1.0000 - val_loss: 0.1733 - val_accuracy: 0.9811\n",
            "Epoch 469/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0666e-07 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 0.9810\n",
            "Epoch 470/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9045e-07 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9809\n",
            "Epoch 471/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7474e-07 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 0.9809\n",
            "Epoch 472/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6150e-07 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 0.9809\n",
            "Epoch 473/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4873e-07 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 0.9809\n",
            "Epoch 474/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3721e-07 - accuracy: 1.0000 - val_loss: 0.1773 - val_accuracy: 0.9810\n",
            "Epoch 475/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2681e-07 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 0.9812\n",
            "Epoch 476/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1677e-07 - accuracy: 1.0000 - val_loss: 0.1785 - val_accuracy: 0.9813\n",
            "Epoch 477/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0819e-07 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.9811\n",
            "Epoch 478/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9812e-08 - accuracy: 1.0000 - val_loss: 0.1798 - val_accuracy: 0.9812\n",
            "Epoch 479/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2225e-08 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 0.9811\n",
            "Epoch 480/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.5205e-08 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 0.9812\n",
            "Epoch 481/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.8659e-08 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9811\n",
            "Epoch 482/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.2585e-08 - accuracy: 1.0000 - val_loss: 0.1823 - val_accuracy: 0.9811\n",
            "Epoch 483/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7112e-08 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 0.9812\n",
            "Epoch 484/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.2121e-08 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9812\n",
            "Epoch 485/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7528e-08 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9811\n",
            "Epoch 486/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.3260e-08 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9812\n",
            "Epoch 487/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.9398e-08 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9813\n",
            "Epoch 488/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5570e-08 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9813\n",
            "Epoch 489/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.2322e-08 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9813\n",
            "Epoch 490/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.9066e-08 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9813\n",
            "Epoch 491/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6444e-08 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.9813\n",
            "Epoch 492/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3768e-08 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 0.9813\n",
            "Epoch 493/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1320e-08 - accuracy: 1.0000 - val_loss: 0.1892 - val_accuracy: 0.9813\n",
            "Epoch 494/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9220e-08 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9813\n",
            "Epoch 495/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7050e-08 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 0.9813\n",
            "Epoch 496/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5092e-08 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9813\n",
            "Epoch 497/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3421e-08 - accuracy: 1.0000 - val_loss: 0.1916 - val_accuracy: 0.9814\n",
            "Epoch 498/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1651e-08 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9816\n",
            "Epoch 499/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0189e-08 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9815\n",
            "Epoch 500/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8774e-08 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9816\n",
            "Epoch 501/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7540e-08 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9815\n",
            "Epoch 502/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6340e-08 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9815\n",
            "Epoch 503/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5338e-08 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9815\n",
            "Epoch 504/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4157e-08 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9815\n",
            "Epoch 505/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3293e-08 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.9815\n",
            "Epoch 506/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2350e-08 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9815\n",
            "Epoch 507/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1537e-08 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 0.9815\n",
            "Epoch 508/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0782e-08 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 0.9815\n",
            "Epoch 509/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0104e-08 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.9815\n",
            "Epoch 510/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.5103e-09 - accuracy: 1.0000 - val_loss: 0.1996 - val_accuracy: 0.9816\n",
            "Epoch 511/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8612e-09 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.9816\n",
            "Epoch 512/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.2705e-09 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9815\n",
            "Epoch 513/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.7618e-09 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9815\n",
            "Epoch 514/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2373e-09 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9815\n",
            "Epoch 515/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7737e-09 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.9816\n",
            "Epoch 516/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3764e-09 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9815\n",
            "Epoch 517/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.9287e-09 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9816\n",
            "Epoch 518/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.6134e-09 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 0.9816\n",
            "Epoch 519/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2717e-09 - accuracy: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.9815\n",
            "Epoch 520/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9644e-09 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9814\n",
            "Epoch 521/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6836e-09 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9815\n",
            "Epoch 522/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.4266e-09 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9815\n",
            "Epoch 523/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.2041e-09 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9814\n",
            "Epoch 524/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9816e-09 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9815\n",
            "Epoch 525/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7458e-09 - accuracy: 1.0000 - val_loss: 0.2087 - val_accuracy: 0.9814\n",
            "Epoch 526/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5233e-09 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 0.9815\n",
            "Epoch 527/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3061e-09 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9814\n",
            "Epoch 528/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0915e-09 - accuracy: 1.0000 - val_loss: 0.2106 - val_accuracy: 0.9814\n",
            "Epoch 529/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9590e-09 - accuracy: 1.0000 - val_loss: 0.2112 - val_accuracy: 0.9814\n",
            "Epoch 530/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7630e-09 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9814\n",
            "Epoch 531/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6200e-09 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 0.9815\n",
            "Epoch 532/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4822e-09 - accuracy: 1.0000 - val_loss: 0.2131 - val_accuracy: 0.9815\n",
            "Epoch 533/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3471e-09 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9814\n",
            "Epoch 534/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2252e-09 - accuracy: 1.0000 - val_loss: 0.2146 - val_accuracy: 0.9815\n",
            "Epoch 535/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0610e-09 - accuracy: 1.0000 - val_loss: 0.2155 - val_accuracy: 0.9815\n",
            "Epoch 536/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9524e-09 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 0.9815\n",
            "Epoch 537/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8676e-09 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9817\n",
            "Epoch 538/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8014e-09 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9817\n",
            "Epoch 539/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7193e-09 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9817\n",
            "Epoch 540/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6424e-09 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9817\n",
            "Epoch 541/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6265e-09 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9817\n",
            "Epoch 542/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5206e-09 - accuracy: 1.0000 - val_loss: 0.2206 - val_accuracy: 0.9817\n",
            "Epoch 543/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4782e-09 - accuracy: 1.0000 - val_loss: 0.2215 - val_accuracy: 0.9815\n",
            "Epoch 544/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4093e-09 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9815\n",
            "Epoch 545/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3510e-09 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9815\n",
            "Epoch 546/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3325e-09 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9815\n",
            "Epoch 547/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2795e-09 - accuracy: 1.0000 - val_loss: 0.2247 - val_accuracy: 0.9813\n",
            "Epoch 548/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2318e-09 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.9813\n",
            "Epoch 549/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2027e-09 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9814\n",
            "Epoch 550/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1577e-09 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9813\n",
            "Epoch 551/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1444e-09 - accuracy: 1.0000 - val_loss: 0.2277 - val_accuracy: 0.9812\n",
            "Epoch 552/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1285e-09 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9811\n",
            "Epoch 553/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1206e-09 - accuracy: 1.0000 - val_loss: 0.2294 - val_accuracy: 0.9811\n",
            "Epoch 554/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0808e-09 - accuracy: 1.0000 - val_loss: 0.2301 - val_accuracy: 0.9811\n",
            "Epoch 555/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0914e-09 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.9811\n",
            "Epoch 556/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0570e-09 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9809\n",
            "Epoch 557/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0120e-09 - accuracy: 1.0000 - val_loss: 0.2324 - val_accuracy: 0.9809\n",
            "Epoch 558/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0411e-09 - accuracy: 1.0000 - val_loss: 0.2332 - val_accuracy: 0.9809\n",
            "Epoch 559/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0278e-09 - accuracy: 1.0000 - val_loss: 0.2337 - val_accuracy: 0.9809\n",
            "Epoch 560/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.9341e-10 - accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 0.9807\n",
            "Epoch 561/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0067e-09 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9808\n",
            "Epoch 562/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.4838e-10 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9807\n",
            "Epoch 563/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4838e-10 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9806\n",
            "Epoch 564/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.8811e-10 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.9807\n",
            "Epoch 565/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.6692e-10 - accuracy: 1.0000 - val_loss: 0.2384 - val_accuracy: 0.9806\n",
            "Epoch 566/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7222e-10 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9806\n",
            "Epoch 567/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2189e-10 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9806\n",
            "Epoch 568/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.4838e-10 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9807\n",
            "Epoch 569/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.5367e-10 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9807\n",
            "Epoch 570/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4573e-10 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9807\n",
            "Epoch 571/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3778e-10 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9807\n",
            "Epoch 572/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1394e-10 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9807\n",
            "Epoch 573/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.2718e-10 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9806\n",
            "Epoch 574/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.6957e-10 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9806\n",
            "Epoch 575/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5897e-10 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9806\n",
            "Epoch 576/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1129e-10 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9805\n",
            "Epoch 577/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2189e-10 - accuracy: 1.0000 - val_loss: 0.2472 - val_accuracy: 0.9805\n",
            "Epoch 578/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2718e-10 - accuracy: 1.0000 - val_loss: 0.2478 - val_accuracy: 0.9806\n",
            "Epoch 579/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3778e-10 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9804\n",
            "Epoch 580/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.8546e-10 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9805\n",
            "Epoch 581/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4043e-10 - accuracy: 1.0000 - val_loss: 0.2499 - val_accuracy: 0.9804\n",
            "Epoch 582/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.7950e-10 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9804\n",
            "Epoch 583/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6427e-10 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9804\n",
            "Epoch 584/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.5103e-10 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.9803\n",
            "Epoch 585/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.5632e-10 - accuracy: 1.0000 - val_loss: 0.2528 - val_accuracy: 0.9805\n",
            "Epoch 586/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.4838e-10 - accuracy: 1.0000 - val_loss: 0.2535 - val_accuracy: 0.9805\n",
            "Epoch 587/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4838e-10 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.9805\n",
            "Epoch 588/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6427e-10 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9805\n",
            "Epoch 589/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3778e-10 - accuracy: 1.0000 - val_loss: 0.2557 - val_accuracy: 0.9806\n",
            "Epoch 590/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7487e-10 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9805\n",
            "Epoch 591/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9341e-10 - accuracy: 1.0000 - val_loss: 0.2571 - val_accuracy: 0.9804\n",
            "Epoch 592/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.7222e-10 - accuracy: 1.0000 - val_loss: 0.2574 - val_accuracy: 0.9803\n",
            "Epoch 593/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3248e-10 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.9804\n",
            "Epoch 594/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7752e-10 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9805\n",
            "Epoch 595/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6427e-10 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.9805\n",
            "Epoch 596/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5632e-10 - accuracy: 1.0000 - val_loss: 0.2598 - val_accuracy: 0.9805\n",
            "Epoch 597/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5632e-10 - accuracy: 1.0000 - val_loss: 0.2603 - val_accuracy: 0.9805\n",
            "Epoch 598/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.8546e-10 - accuracy: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.9803\n",
            "Epoch 599/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.6692e-10 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.9806\n",
            "Epoch 600/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.6957e-10 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.9803\n",
            "Epoch 601/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3778e-10 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9806\n",
            "Epoch 602/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.6957e-10 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9805\n",
            "Epoch 603/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.8546e-10 - accuracy: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.9805\n",
            "Epoch 604/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4573e-10 - accuracy: 1.0000 - val_loss: 0.2644 - val_accuracy: 0.9804\n",
            "Epoch 605/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6957e-10 - accuracy: 1.0000 - val_loss: 0.2645 - val_accuracy: 0.9803\n",
            "Epoch 606/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0014e-09 - accuracy: 1.0000 - val_loss: 0.2656 - val_accuracy: 0.9805\n",
            "Epoch 607/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5367e-10 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.9805\n",
            "Epoch 608/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.9076e-10 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.9804\n",
            "Epoch 609/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6427e-10 - accuracy: 1.0000 - val_loss: 0.2679 - val_accuracy: 0.9804\n",
            "Epoch 610/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6162e-10 - accuracy: 1.0000 - val_loss: 0.2683 - val_accuracy: 0.9804\n",
            "Epoch 611/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0173e-09 - accuracy: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.9803\n",
            "Epoch 612/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.8281e-10 - accuracy: 1.0000 - val_loss: 0.2700 - val_accuracy: 0.9803\n",
            "Epoch 613/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0014e-09 - accuracy: 1.0000 - val_loss: 0.2700 - val_accuracy: 0.9804\n",
            "Epoch 614/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9076e-10 - accuracy: 1.0000 - val_loss: 0.2708 - val_accuracy: 0.9804\n",
            "Epoch 615/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.8281e-10 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.9803\n",
            "Epoch 616/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.9871e-10 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9800\n",
            "Epoch 617/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9606e-10 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9801\n",
            "Epoch 618/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0199e-09 - accuracy: 1.0000 - val_loss: 0.2734 - val_accuracy: 0.9803\n",
            "Epoch 619/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.9606e-10 - accuracy: 1.0000 - val_loss: 0.2734 - val_accuracy: 0.9803\n",
            "Epoch 620/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.8281e-10 - accuracy: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.9801\n",
            "Epoch 621/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0252e-09 - accuracy: 1.0000 - val_loss: 0.2753 - val_accuracy: 0.9799\n",
            "Epoch 622/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0305e-09 - accuracy: 1.0000 - val_loss: 0.2757 - val_accuracy: 0.9803\n",
            "Epoch 623/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0226e-09 - accuracy: 1.0000 - val_loss: 0.2761 - val_accuracy: 0.9802\n",
            "Epoch 624/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0173e-09 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9801\n",
            "Epoch 625/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0146e-09 - accuracy: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.9803\n",
            "Epoch 626/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0173e-09 - accuracy: 1.0000 - val_loss: 0.2778 - val_accuracy: 0.9803\n",
            "Epoch 627/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0384e-09 - accuracy: 1.0000 - val_loss: 0.2787 - val_accuracy: 0.9800\n",
            "Epoch 628/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0676e-09 - accuracy: 1.0000 - val_loss: 0.2791 - val_accuracy: 0.9802\n",
            "Epoch 629/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0543e-09 - accuracy: 1.0000 - val_loss: 0.2805 - val_accuracy: 0.9802\n",
            "Epoch 630/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0384e-09 - accuracy: 1.0000 - val_loss: 0.2797 - val_accuracy: 0.9803\n",
            "Epoch 631/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0305e-09 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9801\n",
            "Epoch 632/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0596e-09 - accuracy: 1.0000 - val_loss: 0.2810 - val_accuracy: 0.9802\n",
            "Epoch 633/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0278e-09 - accuracy: 1.0000 - val_loss: 0.2812 - val_accuracy: 0.9802\n",
            "Epoch 634/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0331e-09 - accuracy: 1.0000 - val_loss: 0.2827 - val_accuracy: 0.9802\n",
            "Epoch 635/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0517e-09 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.9801\n",
            "Epoch 636/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0835e-09 - accuracy: 1.0000 - val_loss: 0.2830 - val_accuracy: 0.9803\n",
            "Epoch 637/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0808e-09 - accuracy: 1.0000 - val_loss: 0.2845 - val_accuracy: 0.9799\n",
            "Epoch 638/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1073e-09 - accuracy: 1.0000 - val_loss: 0.2845 - val_accuracy: 0.9801\n",
            "Epoch 639/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1232e-09 - accuracy: 1.0000 - val_loss: 0.2850 - val_accuracy: 0.9802\n",
            "Epoch 640/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0729e-09 - accuracy: 1.0000 - val_loss: 0.2852 - val_accuracy: 0.9799\n",
            "Epoch 641/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0994e-09 - accuracy: 1.0000 - val_loss: 0.2858 - val_accuracy: 0.9802\n",
            "Epoch 642/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1312e-09 - accuracy: 1.0000 - val_loss: 0.2869 - val_accuracy: 0.9800\n",
            "Epoch 643/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1153e-09 - accuracy: 1.0000 - val_loss: 0.2869 - val_accuracy: 0.9801\n",
            "Epoch 644/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1179e-09 - accuracy: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.9801\n",
            "Epoch 645/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1312e-09 - accuracy: 1.0000 - val_loss: 0.2889 - val_accuracy: 0.9803\n",
            "Epoch 646/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0941e-09 - accuracy: 1.0000 - val_loss: 0.2903 - val_accuracy: 0.9802\n",
            "Epoch 647/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1497e-09 - accuracy: 1.0000 - val_loss: 0.2898 - val_accuracy: 0.9804\n",
            "Epoch 648/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1338e-09 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.9800\n",
            "Epoch 649/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2159e-09 - accuracy: 1.0000 - val_loss: 0.2910 - val_accuracy: 0.9803\n",
            "Epoch 650/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1947e-09 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9802\n",
            "Epoch 651/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1312e-09 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.9802\n",
            "Epoch 652/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1524e-09 - accuracy: 1.0000 - val_loss: 0.2910 - val_accuracy: 0.9803\n",
            "Epoch 653/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2159e-09 - accuracy: 1.0000 - val_loss: 0.2932 - val_accuracy: 0.9803\n",
            "Epoch 654/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2133e-09 - accuracy: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.9803\n",
            "Epoch 655/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2000e-09 - accuracy: 1.0000 - val_loss: 0.2948 - val_accuracy: 0.9800\n",
            "Epoch 656/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2239e-09 - accuracy: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.9799\n",
            "Epoch 657/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1630e-09 - accuracy: 1.0000 - val_loss: 0.2944 - val_accuracy: 0.9802\n",
            "Epoch 658/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1206e-09 - accuracy: 1.0000 - val_loss: 0.2961 - val_accuracy: 0.9801\n",
            "Epoch 659/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2371e-09 - accuracy: 1.0000 - val_loss: 0.2958 - val_accuracy: 0.9802\n",
            "Epoch 660/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1921e-09 - accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.9803\n",
            "Epoch 661/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1735e-09 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.9799\n",
            "Epoch 662/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2000e-09 - accuracy: 1.0000 - val_loss: 0.2993 - val_accuracy: 0.9801\n",
            "Epoch 663/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2451e-09 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.9801\n",
            "Epoch 664/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0720 - accuracy: 0.9948 - val_loss: 0.6291 - val_accuracy: 0.9613\n",
            "Epoch 665/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0604 - accuracy: 0.9907 - val_loss: 0.2002 - val_accuracy: 0.9755\n",
            "Epoch 666/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.1824 - val_accuracy: 0.9786\n",
            "Epoch 667/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6063e-04 - accuracy: 0.9997 - val_loss: 0.1836 - val_accuracy: 0.9780\n",
            "Epoch 668/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.8903e-04 - accuracy: 0.9999 - val_loss: 0.1744 - val_accuracy: 0.9792\n",
            "Epoch 669/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9776e-04 - accuracy: 0.9999 - val_loss: 0.1790 - val_accuracy: 0.9789\n",
            "Epoch 670/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7706e-05 - accuracy: 1.0000 - val_loss: 0.1767 - val_accuracy: 0.9790\n",
            "Epoch 671/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6538e-05 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9791\n",
            "Epoch 672/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3927e-05 - accuracy: 1.0000 - val_loss: 0.1773 - val_accuracy: 0.9789\n",
            "Epoch 673/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1989e-05 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 0.9790\n",
            "Epoch 674/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0614e-05 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 0.9789\n",
            "Epoch 675/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.5486e-06 - accuracy: 1.0000 - val_loss: 0.1781 - val_accuracy: 0.9789\n",
            "Epoch 676/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.6131e-06 - accuracy: 1.0000 - val_loss: 0.1783 - val_accuracy: 0.9791\n",
            "Epoch 677/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.8115e-06 - accuracy: 1.0000 - val_loss: 0.1787 - val_accuracy: 0.9792\n",
            "Epoch 678/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1191e-06 - accuracy: 1.0000 - val_loss: 0.1784 - val_accuracy: 0.9791\n",
            "Epoch 679/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5836e-06 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 0.9793\n",
            "Epoch 680/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.8924e-06 - accuracy: 1.0000 - val_loss: 0.1794 - val_accuracy: 0.9793\n",
            "Epoch 681/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.4015e-06 - accuracy: 1.0000 - val_loss: 0.1799 - val_accuracy: 0.9793\n",
            "Epoch 682/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.9181e-06 - accuracy: 1.0000 - val_loss: 0.1801 - val_accuracy: 0.9795\n",
            "Epoch 683/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4770e-06 - accuracy: 1.0000 - val_loss: 0.1808 - val_accuracy: 0.9797\n",
            "Epoch 684/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0983e-06 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9797\n",
            "Epoch 685/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.7031e-06 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9798\n",
            "Epoch 686/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3467e-06 - accuracy: 1.0000 - val_loss: 0.1826 - val_accuracy: 0.9798\n",
            "Epoch 687/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8428e-06 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9797\n",
            "Epoch 688/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0840e-06 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 0.9795\n",
            "Epoch 689/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5163e-06 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 0.9798\n",
            "Epoch 690/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1149e-06 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 0.9798\n",
            "Epoch 691/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.4952e-07 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9800\n",
            "Epoch 692/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.9007e-07 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9801\n",
            "Epoch 693/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6290e-07 - accuracy: 1.0000 - val_loss: 0.2158 - val_accuracy: 0.9801\n",
            "Epoch 694/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2633e-07 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9801\n",
            "Epoch 695/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.8222e-07 - accuracy: 1.0000 - val_loss: 0.2215 - val_accuracy: 0.9803\n",
            "Epoch 696/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3202e-07 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9802\n",
            "Epoch 697/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8225e-07 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9803\n",
            "Epoch 698/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8297e-07 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9802\n",
            "Epoch 699/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2674e-07 - accuracy: 1.0000 - val_loss: 0.2268 - val_accuracy: 0.9805\n",
            "Epoch 700/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9716e-07 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.9804\n",
            "Epoch 701/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7363e-07 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9803\n",
            "Epoch 702/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4916e-07 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.9805\n",
            "Epoch 703/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3572e-07 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.9804\n",
            "Epoch 704/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1671e-07 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9805\n",
            "Epoch 705/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0406e-07 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9803\n",
            "Epoch 706/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9522e-07 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9804\n",
            "Epoch 707/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7400e-07 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.9803\n",
            "Epoch 708/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7143e-07 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9804\n",
            "Epoch 709/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5433e-07 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9805\n",
            "Epoch 710/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1414e-07 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 0.9805\n",
            "Epoch 711/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7099e-07 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9805\n",
            "Epoch 712/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4125e-07 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9805\n",
            "Epoch 713/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2724e-07 - accuracy: 1.0000 - val_loss: 0.2388 - val_accuracy: 0.9804\n",
            "Epoch 714/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1951e-07 - accuracy: 1.0000 - val_loss: 0.2395 - val_accuracy: 0.9804\n",
            "Epoch 715/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0969e-07 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9804\n",
            "Epoch 716/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0472e-07 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9805\n",
            "Epoch 717/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6564e-08 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9805\n",
            "Epoch 718/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.2307e-08 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9804\n",
            "Epoch 719/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.5865e-08 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9804\n",
            "Epoch 720/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0283e-08 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.9804\n",
            "Epoch 721/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.5176e-08 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9804\n",
            "Epoch 722/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2150e-08 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.9804\n",
            "Epoch 723/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.7946e-08 - accuracy: 1.0000 - val_loss: 0.2471 - val_accuracy: 0.9804\n",
            "Epoch 724/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3462e-08 - accuracy: 1.0000 - val_loss: 0.2473 - val_accuracy: 0.9803\n",
            "Epoch 725/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.8993e-08 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9801\n",
            "Epoch 726/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7422e-08 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.9804\n",
            "Epoch 727/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.2049e-08 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.9803\n",
            "Epoch 728/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9488e-08 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.9803\n",
            "Epoch 729/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6144e-08 - accuracy: 1.0000 - val_loss: 0.2507 - val_accuracy: 0.9803\n",
            "Epoch 730/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.3999e-08 - accuracy: 1.0000 - val_loss: 0.2507 - val_accuracy: 0.9803\n",
            "Epoch 731/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0499e-08 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.9801\n",
            "Epoch 732/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.9106e-08 - accuracy: 1.0000 - val_loss: 0.2523 - val_accuracy: 0.9802\n",
            "Epoch 733/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6934e-08 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9801\n",
            "Epoch 734/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4160e-08 - accuracy: 1.0000 - val_loss: 0.2535 - val_accuracy: 0.9801\n",
            "Epoch 735/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3334e-08 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.9802\n",
            "Epoch 736/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0412e-08 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.9803\n",
            "Epoch 737/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8035e-08 - accuracy: 1.0000 - val_loss: 0.2554 - val_accuracy: 0.9801\n",
            "Epoch 738/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6970e-08 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9801\n",
            "Epoch 739/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5105e-08 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9801\n",
            "Epoch 740/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3135e-08 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9803\n",
            "Epoch 741/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2337e-08 - accuracy: 1.0000 - val_loss: 0.2574 - val_accuracy: 0.9800\n",
            "Epoch 742/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0568e-08 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9803\n",
            "Epoch 743/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9569e-08 - accuracy: 1.0000 - val_loss: 0.2582 - val_accuracy: 0.9801\n",
            "Epoch 744/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8075e-08 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.9803\n",
            "Epoch 745/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7028e-08 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.9799\n",
            "Epoch 746/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6125e-08 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.9805\n",
            "Epoch 747/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4959e-08 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9801\n",
            "Epoch 748/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4035e-08 - accuracy: 1.0000 - val_loss: 0.2616 - val_accuracy: 0.9801\n",
            "Epoch 749/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3317e-08 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.9801\n",
            "Epoch 750/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2353e-08 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9802\n",
            "Epoch 751/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1537e-08 - accuracy: 1.0000 - val_loss: 0.2633 - val_accuracy: 0.9801\n",
            "Epoch 752/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0890e-08 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9803\n",
            "Epoch 753/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0167e-08 - accuracy: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.9801\n",
            "Epoch 754/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.5103e-09 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9800\n",
            "Epoch 755/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.9990e-09 - accuracy: 1.0000 - val_loss: 0.2662 - val_accuracy: 0.9801\n",
            "Epoch 756/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.4003e-09 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9801\n",
            "Epoch 757/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8334e-09 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9801\n",
            "Epoch 758/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3194e-09 - accuracy: 1.0000 - val_loss: 0.2683 - val_accuracy: 0.9800\n",
            "Epoch 759/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.9115e-09 - accuracy: 1.0000 - val_loss: 0.2688 - val_accuracy: 0.9801\n",
            "Epoch 760/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.5009e-09 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.9801\n",
            "Epoch 761/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1115e-09 - accuracy: 1.0000 - val_loss: 0.2702 - val_accuracy: 0.9801\n",
            "Epoch 762/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.7644e-09 - accuracy: 1.0000 - val_loss: 0.2706 - val_accuracy: 0.9800\n",
            "Epoch 763/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3459e-09 - accuracy: 1.0000 - val_loss: 0.2714 - val_accuracy: 0.9801\n",
            "Epoch 764/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0730e-09 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9800\n",
            "Epoch 765/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7313e-09 - accuracy: 1.0000 - val_loss: 0.2729 - val_accuracy: 0.9800\n",
            "Epoch 766/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4796e-09 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.9800\n",
            "Epoch 767/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.1909e-09 - accuracy: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.9799\n",
            "Epoch 768/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9313e-09 - accuracy: 1.0000 - val_loss: 0.2747 - val_accuracy: 0.9799\n",
            "Epoch 769/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7326e-09 - accuracy: 1.0000 - val_loss: 0.2757 - val_accuracy: 0.9801\n",
            "Epoch 770/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5153e-09 - accuracy: 1.0000 - val_loss: 0.2767 - val_accuracy: 0.9799\n",
            "Epoch 771/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3352e-09 - accuracy: 1.0000 - val_loss: 0.2771 - val_accuracy: 0.9799\n",
            "Epoch 772/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1418e-09 - accuracy: 1.0000 - val_loss: 0.2778 - val_accuracy: 0.9799\n",
            "Epoch 773/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9617e-09 - accuracy: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.9799\n",
            "Epoch 774/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7895e-09 - accuracy: 1.0000 - val_loss: 0.2794 - val_accuracy: 0.9799\n",
            "Epoch 775/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6464e-09 - accuracy: 1.0000 - val_loss: 0.2800 - val_accuracy: 0.9801\n",
            "Epoch 776/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5484e-09 - accuracy: 1.0000 - val_loss: 0.2804 - val_accuracy: 0.9801\n",
            "Epoch 777/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3815e-09 - accuracy: 1.0000 - val_loss: 0.2815 - val_accuracy: 0.9799\n",
            "Epoch 778/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2199e-09 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.9800\n",
            "Epoch 779/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1802e-09 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.9799\n",
            "Epoch 780/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0213e-09 - accuracy: 1.0000 - val_loss: 0.2840 - val_accuracy: 0.9798\n",
            "Epoch 781/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9418e-09 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.9799\n",
            "Epoch 782/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8650e-09 - accuracy: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.9799\n",
            "Epoch 783/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7696e-09 - accuracy: 1.0000 - val_loss: 0.2864 - val_accuracy: 0.9801\n",
            "Epoch 784/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7034e-09 - accuracy: 1.0000 - val_loss: 0.2869 - val_accuracy: 0.9799\n",
            "Epoch 785/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6477e-09 - accuracy: 1.0000 - val_loss: 0.2878 - val_accuracy: 0.9800\n",
            "Epoch 786/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5656e-09 - accuracy: 1.0000 - val_loss: 0.2888 - val_accuracy: 0.9801\n",
            "Epoch 787/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4994e-09 - accuracy: 1.0000 - val_loss: 0.2893 - val_accuracy: 0.9801\n",
            "Epoch 788/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4252e-09 - accuracy: 1.0000 - val_loss: 0.2899 - val_accuracy: 0.9799\n",
            "Epoch 789/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3537e-09 - accuracy: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.9802\n",
            "Epoch 790/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2769e-09 - accuracy: 1.0000 - val_loss: 0.2925 - val_accuracy: 0.9800\n",
            "Epoch 791/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3219e-09 - accuracy: 1.0000 - val_loss: 0.2925 - val_accuracy: 0.9799\n",
            "Epoch 792/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2027e-09 - accuracy: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.9800\n",
            "Epoch 793/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1868e-09 - accuracy: 1.0000 - val_loss: 0.2945 - val_accuracy: 0.9798\n",
            "Epoch 794/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1391e-09 - accuracy: 1.0000 - val_loss: 0.2955 - val_accuracy: 0.9799\n",
            "Epoch 795/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0888e-09 - accuracy: 1.0000 - val_loss: 0.2965 - val_accuracy: 0.9799\n",
            "Epoch 796/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0702e-09 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.9799\n",
            "Epoch 797/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0252e-09 - accuracy: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.9799\n",
            "Epoch 798/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0384e-09 - accuracy: 1.0000 - val_loss: 0.2994 - val_accuracy: 0.9799\n",
            "Epoch 799/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0120e-09 - accuracy: 1.0000 - val_loss: 0.3005 - val_accuracy: 0.9797\n",
            "Epoch 800/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0093e-09 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.9797\n",
            "Epoch 801/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.8281e-10 - accuracy: 1.0000 - val_loss: 0.3022 - val_accuracy: 0.9797\n",
            "Epoch 802/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5103e-10 - accuracy: 1.0000 - val_loss: 0.3022 - val_accuracy: 0.9796\n",
            "Epoch 803/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1129e-10 - accuracy: 1.0000 - val_loss: 0.3036 - val_accuracy: 0.9796\n",
            "Epoch 804/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4573e-10 - accuracy: 1.0000 - val_loss: 0.3045 - val_accuracy: 0.9797\n",
            "Epoch 805/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3513e-10 - accuracy: 1.0000 - val_loss: 0.3052 - val_accuracy: 0.9795\n",
            "Epoch 806/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0599e-10 - accuracy: 1.0000 - val_loss: 0.3064 - val_accuracy: 0.9795\n",
            "Epoch 807/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.7420e-10 - accuracy: 1.0000 - val_loss: 0.3072 - val_accuracy: 0.9795\n",
            "Epoch 808/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5831e-10 - accuracy: 1.0000 - val_loss: 0.3080 - val_accuracy: 0.9796\n",
            "Epoch 809/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.9010e-10 - accuracy: 1.0000 - val_loss: 0.3089 - val_accuracy: 0.9795\n",
            "Epoch 810/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.8745e-10 - accuracy: 1.0000 - val_loss: 0.3104 - val_accuracy: 0.9795\n",
            "Epoch 811/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7420e-10 - accuracy: 1.0000 - val_loss: 0.3107 - val_accuracy: 0.9796\n",
            "Epoch 812/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7950e-10 - accuracy: 1.0000 - val_loss: 0.3111 - val_accuracy: 0.9796\n",
            "Epoch 813/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9010e-10 - accuracy: 1.0000 - val_loss: 0.3128 - val_accuracy: 0.9795\n",
            "Epoch 814/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5301e-10 - accuracy: 1.0000 - val_loss: 0.3123 - val_accuracy: 0.9797\n",
            "Epoch 815/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.2122e-10 - accuracy: 1.0000 - val_loss: 0.3144 - val_accuracy: 0.9793\n",
            "Epoch 816/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.2453e-10 - accuracy: 1.0000 - val_loss: 0.3150 - val_accuracy: 0.9793\n",
            "Epoch 817/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5831e-10 - accuracy: 1.0000 - val_loss: 0.3151 - val_accuracy: 0.9794\n",
            "Epoch 818/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5036e-10 - accuracy: 1.0000 - val_loss: 0.3162 - val_accuracy: 0.9795\n",
            "Epoch 819/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1592e-10 - accuracy: 1.0000 - val_loss: 0.3169 - val_accuracy: 0.9793\n",
            "Epoch 820/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2122e-10 - accuracy: 1.0000 - val_loss: 0.3185 - val_accuracy: 0.9793\n",
            "Epoch 821/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3446e-10 - accuracy: 1.0000 - val_loss: 0.3184 - val_accuracy: 0.9793\n",
            "Epoch 822/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7155e-10 - accuracy: 1.0000 - val_loss: 0.3195 - val_accuracy: 0.9796\n",
            "Epoch 823/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2387e-10 - accuracy: 1.0000 - val_loss: 0.3207 - val_accuracy: 0.9794\n",
            "Epoch 824/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3976e-10 - accuracy: 1.0000 - val_loss: 0.3206 - val_accuracy: 0.9796\n",
            "Epoch 825/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.1857e-10 - accuracy: 1.0000 - val_loss: 0.3216 - val_accuracy: 0.9795\n",
            "Epoch 826/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6824e-10 - accuracy: 1.0000 - val_loss: 0.3226 - val_accuracy: 0.9797\n",
            "Epoch 827/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.1592e-10 - accuracy: 1.0000 - val_loss: 0.3228 - val_accuracy: 0.9793\n",
            "Epoch 828/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8148e-10 - accuracy: 1.0000 - val_loss: 0.3235 - val_accuracy: 0.9794\n",
            "Epoch 829/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.8943e-10 - accuracy: 1.0000 - val_loss: 0.3248 - val_accuracy: 0.9796\n",
            "Epoch 830/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0268e-10 - accuracy: 1.0000 - val_loss: 0.3251 - val_accuracy: 0.9795\n",
            "Epoch 831/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1327e-10 - accuracy: 1.0000 - val_loss: 0.3253 - val_accuracy: 0.9795\n",
            "Epoch 832/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4771e-10 - accuracy: 1.0000 - val_loss: 0.3265 - val_accuracy: 0.9791\n",
            "Epoch 833/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.1327e-10 - accuracy: 1.0000 - val_loss: 0.3276 - val_accuracy: 0.9794\n",
            "Epoch 834/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0797e-10 - accuracy: 1.0000 - val_loss: 0.3279 - val_accuracy: 0.9795\n",
            "Epoch 835/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4506e-10 - accuracy: 1.0000 - val_loss: 0.3295 - val_accuracy: 0.9795\n",
            "Epoch 836/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0543e-09 - accuracy: 1.0000 - val_loss: 0.3292 - val_accuracy: 0.9793\n",
            "Epoch 837/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7420e-10 - accuracy: 1.0000 - val_loss: 0.3299 - val_accuracy: 0.9797\n",
            "Epoch 838/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.7883e-10 - accuracy: 1.0000 - val_loss: 0.3310 - val_accuracy: 0.9796\n",
            "Epoch 839/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8943e-10 - accuracy: 1.0000 - val_loss: 0.3319 - val_accuracy: 0.9793\n",
            "Epoch 840/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.4969e-10 - accuracy: 1.0000 - val_loss: 0.3319 - val_accuracy: 0.9794\n",
            "Epoch 841/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.0268e-10 - accuracy: 1.0000 - val_loss: 0.3337 - val_accuracy: 0.9793\n",
            "Epoch 842/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1129e-10 - accuracy: 1.0000 - val_loss: 0.3349 - val_accuracy: 0.9791\n",
            "Epoch 843/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1259 - accuracy: 0.9869 - val_loss: 0.1767 - val_accuracy: 0.9747\n",
            "Epoch 844/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.1526 - val_accuracy: 0.9800\n",
            "Epoch 845/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.4984e-04 - accuracy: 0.9997 - val_loss: 0.1501 - val_accuracy: 0.9805\n",
            "Epoch 846/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7888e-04 - accuracy: 1.0000 - val_loss: 0.1487 - val_accuracy: 0.9812\n",
            "Epoch 847/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5620e-05 - accuracy: 1.0000 - val_loss: 0.1479 - val_accuracy: 0.9814\n",
            "Epoch 848/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0513e-05 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9815\n",
            "Epoch 849/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9742e-05 - accuracy: 1.0000 - val_loss: 0.1673 - val_accuracy: 0.9813\n",
            "Epoch 850/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.8285e-06 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 0.9811\n",
            "Epoch 851/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2709e-06 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.9810\n",
            "Epoch 852/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5166e-06 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 0.9808\n",
            "Epoch 853/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9772e-06 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9810\n",
            "Epoch 854/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7192e-06 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9813\n",
            "Epoch 855/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0969e-06 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9814\n",
            "Epoch 856/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6483e-06 - accuracy: 1.0000 - val_loss: 0.2060 - val_accuracy: 0.9812\n",
            "Epoch 857/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4057e-06 - accuracy: 1.0000 - val_loss: 0.2089 - val_accuracy: 0.9812\n",
            "Epoch 858/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2305e-06 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9811\n",
            "Epoch 859/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0598e-06 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9812\n",
            "Epoch 860/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1698e-07 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9812\n",
            "Epoch 861/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.6632e-07 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9812\n",
            "Epoch 862/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.4780e-07 - accuracy: 1.0000 - val_loss: 0.2195 - val_accuracy: 0.9811\n",
            "Epoch 863/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7091e-07 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9811\n",
            "Epoch 864/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1320e-07 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9812\n",
            "Epoch 865/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5745e-07 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9810\n",
            "Epoch 866/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.0385e-07 - accuracy: 1.0000 - val_loss: 0.2257 - val_accuracy: 0.9809\n",
            "Epoch 867/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6944e-07 - accuracy: 1.0000 - val_loss: 0.2260 - val_accuracy: 0.9811\n",
            "Epoch 868/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.2568e-07 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9809\n",
            "Epoch 869/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.9542e-07 - accuracy: 1.0000 - val_loss: 0.2296 - val_accuracy: 0.9812\n",
            "Epoch 870/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6873e-07 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.9813\n",
            "Epoch 871/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3002e-07 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.9811\n",
            "Epoch 872/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0606e-07 - accuracy: 1.0000 - val_loss: 0.2331 - val_accuracy: 0.9812\n",
            "Epoch 873/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8278e-07 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9813\n",
            "Epoch 874/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6557e-07 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9813\n",
            "Epoch 875/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3768e-07 - accuracy: 1.0000 - val_loss: 0.2348 - val_accuracy: 0.9813\n",
            "Epoch 876/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3436e-07 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9813\n",
            "Epoch 877/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1142e-07 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9811\n",
            "Epoch 878/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9687e-07 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9812\n",
            "Epoch 879/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8279e-07 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9810\n",
            "Epoch 880/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7294e-07 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9811\n",
            "Epoch 881/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5690e-07 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9813\n",
            "Epoch 882/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5001e-07 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9812\n",
            "Epoch 883/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3736e-07 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9811\n",
            "Epoch 884/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2726e-07 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9812\n",
            "Epoch 885/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1955e-07 - accuracy: 1.0000 - val_loss: 0.2441 - val_accuracy: 0.9812\n",
            "Epoch 886/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0895e-07 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9809\n",
            "Epoch 887/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0633e-07 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9812\n",
            "Epoch 888/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0399e-07 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.9812\n",
            "Epoch 889/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2469e-08 - accuracy: 1.0000 - val_loss: 0.2471 - val_accuracy: 0.9812\n",
            "Epoch 890/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6818e-08 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.9811\n",
            "Epoch 891/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.1033e-08 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9811\n",
            "Epoch 892/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9003e-08 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9811\n",
            "Epoch 893/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3557e-08 - accuracy: 1.0000 - val_loss: 0.2507 - val_accuracy: 0.9811\n",
            "Epoch 894/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1462e-08 - accuracy: 1.0000 - val_loss: 0.2507 - val_accuracy: 0.9811\n",
            "Epoch 895/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3557e-08 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.9814\n",
            "Epoch 896/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.9159e-08 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9810\n",
            "Epoch 897/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.6751e-08 - accuracy: 1.0000 - val_loss: 0.2531 - val_accuracy: 0.9811\n",
            "Epoch 898/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2290e-08 - accuracy: 1.0000 - val_loss: 0.2543 - val_accuracy: 0.9811\n",
            "Epoch 899/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0725e-08 - accuracy: 1.0000 - val_loss: 0.2554 - val_accuracy: 0.9812\n",
            "Epoch 900/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.7000e-08 - accuracy: 1.0000 - val_loss: 0.2558 - val_accuracy: 0.9810\n",
            "Epoch 901/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5233e-08 - accuracy: 1.0000 - val_loss: 0.2557 - val_accuracy: 0.9813\n",
            "Epoch 902/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.2958e-08 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9813\n",
            "Epoch 903/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.0113e-08 - accuracy: 1.0000 - val_loss: 0.2568 - val_accuracy: 0.9812\n",
            "Epoch 904/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6732e-08 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9813\n",
            "Epoch 905/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4499e-08 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.9812\n",
            "Epoch 906/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2496e-08 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.9811\n",
            "Epoch 907/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0430e-08 - accuracy: 1.0000 - val_loss: 0.2596 - val_accuracy: 0.9811\n",
            "Epoch 908/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8441e-08 - accuracy: 1.0000 - val_loss: 0.2612 - val_accuracy: 0.9813\n",
            "Epoch 909/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7209e-08 - accuracy: 1.0000 - val_loss: 0.2616 - val_accuracy: 0.9812\n",
            "Epoch 910/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5301e-08 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9813\n",
            "Epoch 911/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3434e-08 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9813\n",
            "Epoch 912/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2202e-08 - accuracy: 1.0000 - val_loss: 0.2636 - val_accuracy: 0.9812\n",
            "Epoch 913/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1156e-08 - accuracy: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.9815\n",
            "Epoch 914/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9624e-08 - accuracy: 1.0000 - val_loss: 0.2652 - val_accuracy: 0.9811\n",
            "Epoch 915/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8578e-08 - accuracy: 1.0000 - val_loss: 0.2664 - val_accuracy: 0.9816\n",
            "Epoch 916/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7595e-08 - accuracy: 1.0000 - val_loss: 0.2656 - val_accuracy: 0.9813\n",
            "Epoch 917/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6785e-08 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9814\n",
            "Epoch 918/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5540e-08 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.9815\n",
            "Epoch 919/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4453e-08 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.9815\n",
            "Epoch 920/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3741e-08 - accuracy: 1.0000 - val_loss: 0.2691 - val_accuracy: 0.9814\n",
            "Epoch 921/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2888e-08 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.9814\n",
            "Epoch 922/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2302e-08 - accuracy: 1.0000 - val_loss: 0.2701 - val_accuracy: 0.9815\n",
            "Epoch 923/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1619e-08 - accuracy: 1.0000 - val_loss: 0.2707 - val_accuracy: 0.9817\n",
            "Epoch 924/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0694e-08 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.9817\n",
            "Epoch 925/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0204e-08 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9816\n",
            "Epoch 926/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7725e-09 - accuracy: 1.0000 - val_loss: 0.2725 - val_accuracy: 0.9815\n",
            "Epoch 927/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0308e-09 - accuracy: 1.0000 - val_loss: 0.2733 - val_accuracy: 0.9815\n",
            "Epoch 928/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.5009e-09 - accuracy: 1.0000 - val_loss: 0.2743 - val_accuracy: 0.9816\n",
            "Epoch 929/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.0135e-09 - accuracy: 1.0000 - val_loss: 0.2750 - val_accuracy: 0.9816\n",
            "Epoch 930/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.5234e-09 - accuracy: 1.0000 - val_loss: 0.2757 - val_accuracy: 0.9816\n",
            "Epoch 931/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1579e-09 - accuracy: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.9815\n",
            "Epoch 932/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6015e-09 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.9817\n",
            "Epoch 933/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.3366e-09 - accuracy: 1.0000 - val_loss: 0.2774 - val_accuracy: 0.9817\n",
            "Epoch 934/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8466e-09 - accuracy: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.9815\n",
            "Epoch 935/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.5287e-09 - accuracy: 1.0000 - val_loss: 0.2793 - val_accuracy: 0.9818\n",
            "Epoch 936/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.2982e-09 - accuracy: 1.0000 - val_loss: 0.2799 - val_accuracy: 0.9816\n",
            "Epoch 937/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.9962e-09 - accuracy: 1.0000 - val_loss: 0.2808 - val_accuracy: 0.9816\n",
            "Epoch 938/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.6306e-09 - accuracy: 1.0000 - val_loss: 0.2815 - val_accuracy: 0.9817\n",
            "Epoch 939/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.3737e-09 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.9817\n",
            "Epoch 940/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0982e-09 - accuracy: 1.0000 - val_loss: 0.2830 - val_accuracy: 0.9815\n",
            "Epoch 941/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9286e-09 - accuracy: 1.0000 - val_loss: 0.2839 - val_accuracy: 0.9816\n",
            "Epoch 942/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6981e-09 - accuracy: 1.0000 - val_loss: 0.2845 - val_accuracy: 0.9816\n",
            "Epoch 943/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.4650e-09 - accuracy: 1.0000 - val_loss: 0.2851 - val_accuracy: 0.9816\n",
            "Epoch 944/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2690e-09 - accuracy: 1.0000 - val_loss: 0.2859 - val_accuracy: 0.9815\n",
            "Epoch 945/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0703e-09 - accuracy: 1.0000 - val_loss: 0.2871 - val_accuracy: 0.9817\n",
            "Epoch 946/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8875e-09 - accuracy: 1.0000 - val_loss: 0.2878 - val_accuracy: 0.9816\n",
            "Epoch 947/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7471e-09 - accuracy: 1.0000 - val_loss: 0.2884 - val_accuracy: 0.9815\n",
            "Epoch 948/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6358e-09 - accuracy: 1.0000 - val_loss: 0.2892 - val_accuracy: 0.9816\n",
            "Epoch 949/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4186e-09 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.9817\n",
            "Epoch 950/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2703e-09 - accuracy: 1.0000 - val_loss: 0.2910 - val_accuracy: 0.9814\n",
            "Epoch 951/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1908e-09 - accuracy: 1.0000 - val_loss: 0.2919 - val_accuracy: 0.9815\n",
            "Epoch 952/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1352e-09 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.9813\n",
            "Epoch 953/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9709e-09 - accuracy: 1.0000 - val_loss: 0.2930 - val_accuracy: 0.9815\n",
            "Epoch 954/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8623e-09 - accuracy: 1.0000 - val_loss: 0.2942 - val_accuracy: 0.9814\n",
            "Epoch 955/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7590e-09 - accuracy: 1.0000 - val_loss: 0.2950 - val_accuracy: 0.9814\n",
            "Epoch 956/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6583e-09 - accuracy: 1.0000 - val_loss: 0.2959 - val_accuracy: 0.9814\n",
            "Epoch 957/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5577e-09 - accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.9814\n",
            "Epoch 958/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5206e-09 - accuracy: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.9814\n",
            "Epoch 959/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4570e-09 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.9814\n",
            "Epoch 960/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3802e-09 - accuracy: 1.0000 - val_loss: 0.2994 - val_accuracy: 0.9815\n",
            "Epoch 961/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3060e-09 - accuracy: 1.0000 - val_loss: 0.3004 - val_accuracy: 0.9813\n",
            "Epoch 962/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2451e-09 - accuracy: 1.0000 - val_loss: 0.3015 - val_accuracy: 0.9814\n",
            "Epoch 963/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1921e-09 - accuracy: 1.0000 - val_loss: 0.3024 - val_accuracy: 0.9814\n",
            "Epoch 964/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1524e-09 - accuracy: 1.0000 - val_loss: 0.3035 - val_accuracy: 0.9814\n",
            "Epoch 965/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1020e-09 - accuracy: 1.0000 - val_loss: 0.3044 - val_accuracy: 0.9813\n",
            "Epoch 966/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0702e-09 - accuracy: 1.0000 - val_loss: 0.3053 - val_accuracy: 0.9813\n",
            "Epoch 967/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0437e-09 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.9813\n",
            "Epoch 968/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0067e-09 - accuracy: 1.0000 - val_loss: 0.3073 - val_accuracy: 0.9813\n",
            "Epoch 969/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9871e-10 - accuracy: 1.0000 - val_loss: 0.3083 - val_accuracy: 0.9813\n",
            "Epoch 970/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5103e-10 - accuracy: 1.0000 - val_loss: 0.3095 - val_accuracy: 0.9813\n",
            "Epoch 971/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2453e-10 - accuracy: 1.0000 - val_loss: 0.3104 - val_accuracy: 0.9813\n",
            "Epoch 972/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8215e-10 - accuracy: 1.0000 - val_loss: 0.3117 - val_accuracy: 0.9813\n",
            "Epoch 973/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0069e-10 - accuracy: 1.0000 - val_loss: 0.3129 - val_accuracy: 0.9812\n",
            "Epoch 974/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.7950e-10 - accuracy: 1.0000 - val_loss: 0.3132 - val_accuracy: 0.9813\n",
            "Epoch 975/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5831e-10 - accuracy: 1.0000 - val_loss: 0.3143 - val_accuracy: 0.9813\n",
            "Epoch 976/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.9473e-10 - accuracy: 1.0000 - val_loss: 0.3156 - val_accuracy: 0.9814\n",
            "Epoch 977/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1327e-10 - accuracy: 1.0000 - val_loss: 0.3163 - val_accuracy: 0.9814\n",
            "Epoch 978/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6559e-10 - accuracy: 1.0000 - val_loss: 0.3173 - val_accuracy: 0.9813\n",
            "Epoch 979/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2055e-10 - accuracy: 1.0000 - val_loss: 0.3188 - val_accuracy: 0.9813\n",
            "Epoch 980/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5234e-10 - accuracy: 1.0000 - val_loss: 0.3197 - val_accuracy: 0.9814\n",
            "Epoch 981/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5234e-10 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 0.9815\n",
            "Epoch 982/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.5234e-10 - accuracy: 1.0000 - val_loss: 0.3215 - val_accuracy: 0.9812\n",
            "Epoch 983/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1790e-10 - accuracy: 1.0000 - val_loss: 0.3228 - val_accuracy: 0.9813\n",
            "Epoch 984/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6029e-10 - accuracy: 1.0000 - val_loss: 0.3235 - val_accuracy: 0.9814\n",
            "Epoch 985/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.9406e-10 - accuracy: 1.0000 - val_loss: 0.3241 - val_accuracy: 0.9812\n",
            "Epoch 986/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6757e-10 - accuracy: 1.0000 - val_loss: 0.3253 - val_accuracy: 0.9815\n",
            "Epoch 987/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5168e-10 - accuracy: 1.0000 - val_loss: 0.3258 - val_accuracy: 0.9814\n",
            "Epoch 988/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.9141e-10 - accuracy: 1.0000 - val_loss: 0.3263 - val_accuracy: 0.9816\n",
            "Epoch 989/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.3048e-10 - accuracy: 1.0000 - val_loss: 0.3279 - val_accuracy: 0.9810\n",
            "Epoch 990/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.3578e-10 - accuracy: 1.0000 - val_loss: 0.3288 - val_accuracy: 0.9815\n",
            "Epoch 991/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.2254e-10 - accuracy: 1.0000 - val_loss: 0.3305 - val_accuracy: 0.9813\n",
            "Epoch 992/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4903e-10 - accuracy: 1.0000 - val_loss: 0.3308 - val_accuracy: 0.9813\n",
            "Epoch 993/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8876e-10 - accuracy: 1.0000 - val_loss: 0.3311 - val_accuracy: 0.9813\n",
            "Epoch 994/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3843e-10 - accuracy: 1.0000 - val_loss: 0.3326 - val_accuracy: 0.9813\n",
            "Epoch 995/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2254e-10 - accuracy: 1.0000 - val_loss: 0.3330 - val_accuracy: 0.9810\n",
            "Epoch 996/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4108e-10 - accuracy: 1.0000 - val_loss: 0.3349 - val_accuracy: 0.9810\n",
            "Epoch 997/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.2254e-10 - accuracy: 1.0000 - val_loss: 0.3353 - val_accuracy: 0.9812\n",
            "Epoch 998/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0929e-10 - accuracy: 1.0000 - val_loss: 0.3361 - val_accuracy: 0.9809\n",
            "Epoch 999/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.2254e-10 - accuracy: 1.0000 - val_loss: 0.3370 - val_accuracy: 0.9811\n",
            "Epoch 1000/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.3578e-10 - accuracy: 1.0000 - val_loss: 0.3384 - val_accuracy: 0.9810\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0846 - accuracy: 0.9952\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2703 - accuracy: 0.9822\n",
            "train accuracy :  0.9952499866485596 train loss :  0.08460886776447296\n",
            "test accuracy :  0.982200026512146  test loss :  0.2703184485435486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFDjWj30V1HW",
        "outputId": "158549e0-1f5b-40bf-db91-3dff33eebaa2"
      },
      "source": [
        "#정리\n",
        "print(\"=========== [은닉층 1개] ===========\")\n",
        "print(\"=========== epochs = 12 ===========\")\n",
        "print(\"train accuracy : \", sc_train1_1[1], \"train loss : \", sc_train1_1[0])\n",
        "print(\"test accuracy : \", sc_test1_1[1], \" test loss : \", sc_test1_1[0])\n",
        "print(\"/n\")\n",
        "\n",
        "print(\"=========== epochs = 120 ===========\")\n",
        "print(\"train accuracy : \", sc_train1_2[1], \"train loss : \", sc_train1_2[0])\n",
        "print(\"test accuracy : \", sc_test1_2[1], \" test loss : \", sc_test1_2[0])\n",
        "print(\"/n\")\n",
        "\n",
        "print(\"=========== epochs = 500 ===========\")\n",
        "print(\"train accuracy : \", sc_train1_3[1], \"train loss : \", sc_train1_3[0])\n",
        "print(\"test accuracy : \", sc_test1_3[1], \" test loss : \", sc_test1_3[0])\n",
        "print(\"/n\")\n",
        "\n",
        "print(\"=========== epochs = 1000 ===========\")\n",
        "print(\"train accuracy : \", sc_train1_4[1], \"train loss : \", sc_train1_4[0])\n",
        "print(\"test accuracy : \", sc_test1_4[1], \" test loss : \", sc_test1_4[0])\n",
        "print(\"/n\")\n",
        "\n",
        "print(\"=========== [은닉층 2개 & 뉴런의 수 512/512] ===========\")\n",
        "print(\"=========== epochs = 12 ===========\")\n",
        "print(\"train accuracy : \", sc_train2_1[1], \"train loss : \", sc_train2_1[0])\n",
        "print(\"test accuracy : \", sc_test2_1[1], \" test loss : \", sc_test2_1[0])\n",
        "print(\"/n\")\n",
        "\n",
        "print(\"=========== epochs = 120 ===========\")\n",
        "print(\"train accuracy : \", sc_train2_1_2[1], \"train loss : \", sc_train2_1_2[0])\n",
        "print(\"test accuracy : \", sc_test2_1_2[1], \" test loss : \", sc_test2_1_2[0])\n",
        "print(\"/n\")\n",
        "\n",
        "print(\"=========== epochs = 500 ===========\")\n",
        "print(\"train accuracy : \", sc_train2_1_3[1], \"train loss : \", sc_train2_1_3[0])\n",
        "print(\"test accuracy : \", sc_test2_1_3[1], \" test loss : \", sc_test2_1_3[0])\n",
        "print(\"/n\")\n",
        "\n",
        "print(\"=========== epochs = 1000 ===========\")\n",
        "print(\"train accuracy : \", sc_train2_1_4[1], \"train loss : \", sc_train2_1_4[0])\n",
        "print(\"test accuracy : \", sc_test2_1_4[1], \" test loss : \", sc_test2_1_4[0])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========== [은닉층 1개] ===========\n",
            "=========== epochs = 12 ===========\n",
            "train accuracy :  0.9937999844551086 train loss :  0.02729642763733864\n",
            "test accuracy :  0.9811999797821045  test loss :  0.06480918824672699\n",
            "/n\n",
            "=========== epochs = 120 ===========\n",
            "train accuracy :  0.9949333071708679 train loss :  0.0372379831969738\n",
            "test accuracy :  0.9807000160217285  test loss :  0.11860010027885437\n",
            "/n\n",
            "=========== epochs = 500 ===========\n",
            "train accuracy :  0.994866669178009 train loss :  0.05115368217229843\n",
            "test accuracy :  0.9815999865531921  test loss :  0.15946437418460846\n",
            "/n\n",
            "=========== epochs = 1000 ===========\n",
            "train accuracy :  0.9947333335876465 train loss :  0.06144125014543533\n",
            "test accuracy :  0.9814000129699707  test loss :  0.19138523936271667\n",
            "/n\n",
            "=========== [은닉층 2개 & 뉴런의 수 512/512] ===========\n",
            "=========== epochs = 12 ===========\n",
            "train accuracy :  0.9912999868392944 train loss :  0.034651078283786774\n",
            "test accuracy :  0.9800999760627747  test loss :  0.08432424813508987\n",
            "/n\n",
            "=========== epochs = 120 ===========\n",
            "train accuracy :  0.9954833388328552 train loss :  0.04640447348356247\n",
            "test accuracy :  0.9842000007629395  test loss :  0.14507167041301727\n",
            "/n\n",
            "=========== epochs = 500 ===========\n",
            "train accuracy :  0.995199978351593 train loss :  0.057611025869846344\n",
            "test accuracy :  0.9835000038146973  test loss :  0.187482550740242\n",
            "/n\n",
            "=========== epochs = 1000 ===========\n",
            "train accuracy :  0.9952499866485596 train loss :  0.08460886776447296\n",
            "test accuracy :  0.982200026512146  test loss :  0.2703184485435486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjBbLF6UY65m"
      },
      "source": [
        "epochs를 늘렸을 때 두 모델 모두 시험 데이터의 정확도가 98.3% 이상을 넘기지 못하는 결과를 보여주고 있다.\n",
        "\n",
        "가장 좋은 정확도를 보여주고 있는 모델은 은닉층이 2개(512/512)이고, epochs = 120일때 결과가 가장 좋았다\n",
        "test accuracy는  98.42%이고, train accuracy는 99.55%으로 나타났다,\n",
        "\n",
        "은닉층 2개인 모델일때 렐루 함수에 특화된 가중치 초기값으로\n",
        " he 초기값을 이용해 epochs를 12, 120, 1000, 2000으로 학습해 보았다\n",
        " 또한 비교를 위해 은닉층 2개인 모델 일때 epochs = 2000인 모델도 실행하였다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "941R2pg0nVVV",
        "outputId": "966556b1-5f1a-4591-c53d-7e6bb1c439d2"
      },
      "source": [
        "#신경망 학습2_1_5\n",
        "model2_1_5 = models.Sequential([\n",
        "                               Flatten(input_shape = (28, 28)),\n",
        "                               Dense(512, activation= 'relu'),\n",
        "                               Dense(512, activation= 'relu'),\n",
        "                               Dense(10, activation= 'softmax')\n",
        "                               ])\n",
        "\n",
        "model2_1_5.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "hist2_1_5 = model2_1_5.fit(train_x, train_y, epochs = 2000, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "#학습 그래프5\n",
        "plt.plot(hist2_1_5.history['accuracy'], 'b-')\n",
        "plt.plot(hist2_1_5.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train2_1_5 = model2_1_5.evaluate(train_x, train_y)\n",
        "sc_test2_1_5 = model2_1_5.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train2_1_5[1], \"train loss : \", sc_train2_1_5[0])\n",
        "print(\"test accuracy : \", sc_test2_1_5[1], \" test loss : \", sc_test2_1_5[0])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "176/176 [==============================] - 2s 7ms/step - loss: 0.3041 - accuracy: 0.9136 - val_loss: 0.1456 - val_accuracy: 0.9565\n",
            "Epoch 2/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.1048 - accuracy: 0.9692 - val_loss: 0.1098 - val_accuracy: 0.9665\n",
            "Epoch 3/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0645 - accuracy: 0.9796 - val_loss: 0.0936 - val_accuracy: 0.9723\n",
            "Epoch 4/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0430 - accuracy: 0.9868 - val_loss: 0.1005 - val_accuracy: 0.9715\n",
            "Epoch 5/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0300 - accuracy: 0.9906 - val_loss: 0.0849 - val_accuracy: 0.9751\n",
            "Epoch 6/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0212 - accuracy: 0.9936 - val_loss: 0.0957 - val_accuracy: 0.9729\n",
            "Epoch 7/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0140 - accuracy: 0.9955 - val_loss: 0.0917 - val_accuracy: 0.9764\n",
            "Epoch 8/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.0903 - val_accuracy: 0.9775\n",
            "Epoch 9/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.0946 - val_accuracy: 0.9775\n",
            "Epoch 10/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.0981 - val_accuracy: 0.9765\n",
            "Epoch 11/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.1075 - val_accuracy: 0.9747\n",
            "Epoch 12/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 0.1183 - val_accuracy: 0.9745\n",
            "Epoch 13/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0981 - val_accuracy: 0.9789\n",
            "Epoch 14/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.1137 - val_accuracy: 0.9765\n",
            "Epoch 15/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.1296 - val_accuracy: 0.9715\n",
            "Epoch 16/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.1358 - val_accuracy: 0.9739\n",
            "Epoch 17/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.1096 - val_accuracy: 0.9786\n",
            "Epoch 18/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.1083 - val_accuracy: 0.9801\n",
            "Epoch 19/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9888e-04 - accuracy: 0.9999 - val_loss: 0.1065 - val_accuracy: 0.9809\n",
            "Epoch 20/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0879e-04 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9809\n",
            "Epoch 21/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0137e-05 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9809\n",
            "Epoch 22/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6159e-05 - accuracy: 1.0000 - val_loss: 0.1087 - val_accuracy: 0.9810\n",
            "Epoch 23/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6764e-05 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9811\n",
            "Epoch 24/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0544e-05 - accuracy: 1.0000 - val_loss: 0.1110 - val_accuracy: 0.9809\n",
            "Epoch 25/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.5668e-05 - accuracy: 1.0000 - val_loss: 0.1121 - val_accuracy: 0.9809\n",
            "Epoch 26/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1498e-05 - accuracy: 1.0000 - val_loss: 0.1134 - val_accuracy: 0.9809\n",
            "Epoch 27/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8277e-05 - accuracy: 1.0000 - val_loss: 0.1142 - val_accuracy: 0.9809\n",
            "Epoch 28/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5413e-05 - accuracy: 1.0000 - val_loss: 0.1149 - val_accuracy: 0.9809\n",
            "Epoch 29/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2829e-05 - accuracy: 1.0000 - val_loss: 0.1160 - val_accuracy: 0.9811\n",
            "Epoch 30/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0620e-05 - accuracy: 1.0000 - val_loss: 0.1170 - val_accuracy: 0.9809\n",
            "Epoch 31/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8699e-05 - accuracy: 1.0000 - val_loss: 0.1181 - val_accuracy: 0.9809\n",
            "Epoch 32/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6958e-05 - accuracy: 1.0000 - val_loss: 0.1188 - val_accuracy: 0.9812\n",
            "Epoch 33/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5464e-05 - accuracy: 1.0000 - val_loss: 0.1195 - val_accuracy: 0.9811\n",
            "Epoch 34/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4147e-05 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 0.9813\n",
            "Epoch 35/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2922e-05 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9813\n",
            "Epoch 36/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1827e-05 - accuracy: 1.0000 - val_loss: 0.1223 - val_accuracy: 0.9813\n",
            "Epoch 37/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0826e-05 - accuracy: 1.0000 - val_loss: 0.1231 - val_accuracy: 0.9813\n",
            "Epoch 38/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9164e-06 - accuracy: 1.0000 - val_loss: 0.1239 - val_accuracy: 0.9812\n",
            "Epoch 39/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0828e-06 - accuracy: 1.0000 - val_loss: 0.1249 - val_accuracy: 0.9811\n",
            "Epoch 40/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.4062e-06 - accuracy: 1.0000 - val_loss: 0.1256 - val_accuracy: 0.9811\n",
            "Epoch 41/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6701e-06 - accuracy: 1.0000 - val_loss: 0.1263 - val_accuracy: 0.9812\n",
            "Epoch 42/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0729e-06 - accuracy: 1.0000 - val_loss: 0.1272 - val_accuracy: 0.9812\n",
            "Epoch 43/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.4475e-06 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9812\n",
            "Epoch 44/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9379e-06 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 0.9812\n",
            "Epoch 45/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.4673e-06 - accuracy: 1.0000 - val_loss: 0.1295 - val_accuracy: 0.9815\n",
            "Epoch 46/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.9816e-06 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 0.9814\n",
            "Epoch 47/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5547e-06 - accuracy: 1.0000 - val_loss: 0.1311 - val_accuracy: 0.9815\n",
            "Epoch 48/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.2170e-06 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 0.9813\n",
            "Epoch 49/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8453e-06 - accuracy: 1.0000 - val_loss: 0.1327 - val_accuracy: 0.9815\n",
            "Epoch 50/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5524e-06 - accuracy: 1.0000 - val_loss: 0.1335 - val_accuracy: 0.9815\n",
            "Epoch 51/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2797e-06 - accuracy: 1.0000 - val_loss: 0.1343 - val_accuracy: 0.9815\n",
            "Epoch 52/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9628e-06 - accuracy: 1.0000 - val_loss: 0.1350 - val_accuracy: 0.9812\n",
            "Epoch 53/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7279e-06 - accuracy: 1.0000 - val_loss: 0.1361 - val_accuracy: 0.9813\n",
            "Epoch 54/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4975e-06 - accuracy: 1.0000 - val_loss: 0.1367 - val_accuracy: 0.9815\n",
            "Epoch 55/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3009e-06 - accuracy: 1.0000 - val_loss: 0.1374 - val_accuracy: 0.9815\n",
            "Epoch 56/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1074e-06 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9816\n",
            "Epoch 57/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9300e-06 - accuracy: 1.0000 - val_loss: 0.1392 - val_accuracy: 0.9813\n",
            "Epoch 58/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7569e-06 - accuracy: 1.0000 - val_loss: 0.1398 - val_accuracy: 0.9815\n",
            "Epoch 59/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6148e-06 - accuracy: 1.0000 - val_loss: 0.1407 - val_accuracy: 0.9816\n",
            "Epoch 60/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4786e-06 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 0.9815\n",
            "Epoch 61/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3558e-06 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 0.9815\n",
            "Epoch 62/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2370e-06 - accuracy: 1.0000 - val_loss: 0.1430 - val_accuracy: 0.9814\n",
            "Epoch 63/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1428e-06 - accuracy: 1.0000 - val_loss: 0.1437 - val_accuracy: 0.9815\n",
            "Epoch 64/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0458e-06 - accuracy: 1.0000 - val_loss: 0.1447 - val_accuracy: 0.9814\n",
            "Epoch 65/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.5447e-07 - accuracy: 1.0000 - val_loss: 0.1457 - val_accuracy: 0.9816\n",
            "Epoch 66/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7144e-07 - accuracy: 1.0000 - val_loss: 0.1465 - val_accuracy: 0.9814\n",
            "Epoch 67/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.9860e-07 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.9815\n",
            "Epoch 68/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.2864e-07 - accuracy: 1.0000 - val_loss: 0.1486 - val_accuracy: 0.9815\n",
            "Epoch 69/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7173e-07 - accuracy: 1.0000 - val_loss: 0.1493 - val_accuracy: 0.9813\n",
            "Epoch 70/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0972e-07 - accuracy: 1.0000 - val_loss: 0.1498 - val_accuracy: 0.9815\n",
            "Epoch 71/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6035e-07 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9813\n",
            "Epoch 72/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0969e-07 - accuracy: 1.0000 - val_loss: 0.1515 - val_accuracy: 0.9813\n",
            "Epoch 73/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6833e-07 - accuracy: 1.0000 - val_loss: 0.1523 - val_accuracy: 0.9815\n",
            "Epoch 74/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3390e-07 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9817\n",
            "Epoch 75/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9665e-07 - accuracy: 1.0000 - val_loss: 0.1546 - val_accuracy: 0.9815\n",
            "Epoch 76/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6164e-07 - accuracy: 1.0000 - val_loss: 0.1548 - val_accuracy: 0.9814\n",
            "Epoch 77/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.2737e-07 - accuracy: 1.0000 - val_loss: 0.1554 - val_accuracy: 0.9816\n",
            "Epoch 78/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0532e-07 - accuracy: 1.0000 - val_loss: 0.1566 - val_accuracy: 0.9814\n",
            "Epoch 79/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7846e-07 - accuracy: 1.0000 - val_loss: 0.1574 - val_accuracy: 0.9814\n",
            "Epoch 80/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5409e-07 - accuracy: 1.0000 - val_loss: 0.1583 - val_accuracy: 0.9817\n",
            "Epoch 81/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3408e-07 - accuracy: 1.0000 - val_loss: 0.1591 - val_accuracy: 0.9815\n",
            "Epoch 82/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1380e-07 - accuracy: 1.0000 - val_loss: 0.1596 - val_accuracy: 0.9815\n",
            "Epoch 83/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9729e-07 - accuracy: 1.0000 - val_loss: 0.1606 - val_accuracy: 0.9815\n",
            "Epoch 84/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8105e-07 - accuracy: 1.0000 - val_loss: 0.1617 - val_accuracy: 0.9814\n",
            "Epoch 85/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6613e-07 - accuracy: 1.0000 - val_loss: 0.1623 - val_accuracy: 0.9815\n",
            "Epoch 86/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5261e-07 - accuracy: 1.0000 - val_loss: 0.1631 - val_accuracy: 0.9815\n",
            "Epoch 87/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3934e-07 - accuracy: 1.0000 - val_loss: 0.1635 - val_accuracy: 0.9815\n",
            "Epoch 88/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3026e-07 - accuracy: 1.0000 - val_loss: 0.1647 - val_accuracy: 0.9814\n",
            "Epoch 89/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1863e-07 - accuracy: 1.0000 - val_loss: 0.1653 - val_accuracy: 0.9813\n",
            "Epoch 90/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0840e-07 - accuracy: 1.0000 - val_loss: 0.1661 - val_accuracy: 0.9814\n",
            "Epoch 91/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0003e-07 - accuracy: 1.0000 - val_loss: 0.1667 - val_accuracy: 0.9815\n",
            "Epoch 92/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.2475e-08 - accuracy: 1.0000 - val_loss: 0.1678 - val_accuracy: 0.9813\n",
            "Epoch 93/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.4339e-08 - accuracy: 1.0000 - val_loss: 0.1684 - val_accuracy: 0.9813\n",
            "Epoch 94/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7648e-08 - accuracy: 1.0000 - val_loss: 0.1692 - val_accuracy: 0.9815\n",
            "Epoch 95/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1608e-08 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 0.9812\n",
            "Epoch 96/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6773e-08 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 0.9811\n",
            "Epoch 97/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0927e-08 - accuracy: 1.0000 - val_loss: 0.1712 - val_accuracy: 0.9815\n",
            "Epoch 98/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6656e-08 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 0.9811\n",
            "Epoch 99/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2563e-08 - accuracy: 1.0000 - val_loss: 0.1731 - val_accuracy: 0.9811\n",
            "Epoch 100/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.8086e-08 - accuracy: 1.0000 - val_loss: 0.1735 - val_accuracy: 0.9814\n",
            "Epoch 101/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.4650e-08 - accuracy: 1.0000 - val_loss: 0.1743 - val_accuracy: 0.9813\n",
            "Epoch 102/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1344e-08 - accuracy: 1.0000 - val_loss: 0.1750 - val_accuracy: 0.9813\n",
            "Epoch 103/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.8295e-08 - accuracy: 1.0000 - val_loss: 0.1756 - val_accuracy: 0.9813\n",
            "Epoch 104/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.5487e-08 - accuracy: 1.0000 - val_loss: 0.1761 - val_accuracy: 0.9811\n",
            "Epoch 105/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2790e-08 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9812\n",
            "Epoch 106/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0634e-08 - accuracy: 1.0000 - val_loss: 0.1775 - val_accuracy: 0.9813\n",
            "Epoch 107/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8478e-08 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 0.9815\n",
            "Epoch 108/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6438e-08 - accuracy: 1.0000 - val_loss: 0.1788 - val_accuracy: 0.9813\n",
            "Epoch 109/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4509e-08 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 0.9813\n",
            "Epoch 110/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2727e-08 - accuracy: 1.0000 - val_loss: 0.1801 - val_accuracy: 0.9814\n",
            "Epoch 111/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1100e-08 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 0.9813\n",
            "Epoch 112/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9964e-08 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 0.9812\n",
            "Epoch 113/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8538e-08 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9814\n",
            "Epoch 114/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7354e-08 - accuracy: 1.0000 - val_loss: 0.1823 - val_accuracy: 0.9813\n",
            "Epoch 115/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6295e-08 - accuracy: 1.0000 - val_loss: 0.1831 - val_accuracy: 0.9813\n",
            "Epoch 116/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5193e-08 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9813\n",
            "Epoch 117/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4249e-08 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.9813\n",
            "Epoch 118/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3253e-08 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 0.9813\n",
            "Epoch 119/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2557e-08 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 0.9812\n",
            "Epoch 120/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1725e-08 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9813\n",
            "Epoch 121/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0986e-08 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9814\n",
            "Epoch 122/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0321e-08 - accuracy: 1.0000 - val_loss: 0.1864 - val_accuracy: 0.9812\n",
            "Epoch 123/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7222e-09 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9813\n",
            "Epoch 124/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.2030e-09 - accuracy: 1.0000 - val_loss: 0.1874 - val_accuracy: 0.9815\n",
            "Epoch 125/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.6361e-09 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 0.9813\n",
            "Epoch 126/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.1301e-09 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9813\n",
            "Epoch 127/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7327e-09 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 0.9812\n",
            "Epoch 128/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.3353e-09 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9814\n",
            "Epoch 129/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.8982e-09 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9813\n",
            "Epoch 130/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.6148e-09 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9815\n",
            "Epoch 131/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3446e-09 - accuracy: 1.0000 - val_loss: 0.1907 - val_accuracy: 0.9813\n",
            "Epoch 132/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9207e-09 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9813\n",
            "Epoch 133/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.6797e-09 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.9814\n",
            "Epoch 134/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.4200e-09 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9814\n",
            "Epoch 135/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1869e-09 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9814\n",
            "Epoch 136/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.9326e-09 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9814\n",
            "Epoch 137/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7472e-09 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9815\n",
            "Epoch 138/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.5035e-09 - accuracy: 1.0000 - val_loss: 0.1931 - val_accuracy: 0.9814\n",
            "Epoch 139/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2836e-09 - accuracy: 1.0000 - val_loss: 0.1931 - val_accuracy: 0.9815\n",
            "Epoch 140/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.0902e-09 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 0.9814\n",
            "Epoch 141/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9445e-09 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 0.9814\n",
            "Epoch 142/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.7697e-09 - accuracy: 1.0000 - val_loss: 0.1939 - val_accuracy: 0.9814\n",
            "Epoch 143/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.5789e-09 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9814\n",
            "Epoch 144/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4703e-09 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9813\n",
            "Epoch 145/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3140e-09 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9813\n",
            "Epoch 146/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1657e-09 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.9814\n",
            "Epoch 147/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0597e-09 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9815\n",
            "Epoch 148/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9511e-09 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 0.9815\n",
            "Epoch 149/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8345e-09 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9815\n",
            "Epoch 150/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7498e-09 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.9816\n",
            "Epoch 151/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6253e-09 - accuracy: 1.0000 - val_loss: 0.1958 - val_accuracy: 0.9817\n",
            "Epoch 152/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5590e-09 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.9815\n",
            "Epoch 153/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4239e-09 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.9815\n",
            "Epoch 154/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3948e-09 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.9815\n",
            "Epoch 155/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3074e-09 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9815\n",
            "Epoch 156/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2756e-09 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9814\n",
            "Epoch 157/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2332e-09 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9815\n",
            "Epoch 158/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2040e-09 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 0.9814\n",
            "Epoch 159/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0557e-09 - accuracy: 1.0000 - val_loss: 0.1971 - val_accuracy: 0.9816\n",
            "Epoch 160/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0769e-09 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9815\n",
            "Epoch 161/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0319e-09 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 0.9813\n",
            "Epoch 162/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9524e-09 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 0.9815\n",
            "Epoch 163/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9338e-09 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9814\n",
            "Epoch 164/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9497e-09 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9815\n",
            "Epoch 165/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8411e-09 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 0.9817\n",
            "Epoch 166/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8252e-09 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 0.9813\n",
            "Epoch 167/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8146e-09 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.9815\n",
            "Epoch 168/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7564e-09 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.9815\n",
            "Epoch 169/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7060e-09 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9815\n",
            "Epoch 170/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7431e-09 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.9815\n",
            "Epoch 171/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6742e-09 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 0.9814\n",
            "Epoch 172/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6583e-09 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.9816\n",
            "Epoch 173/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6477e-09 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9815\n",
            "Epoch 174/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6027e-09 - accuracy: 1.0000 - val_loss: 0.1994 - val_accuracy: 0.9814\n",
            "Epoch 175/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6106e-09 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.9814\n",
            "Epoch 176/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5974e-09 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9813\n",
            "Epoch 177/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5683e-09 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.9813\n",
            "Epoch 178/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5709e-09 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9813\n",
            "Epoch 179/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5815e-09 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9815\n",
            "Epoch 180/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5418e-09 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9814\n",
            "Epoch 181/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5338e-09 - accuracy: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.9814\n",
            "Epoch 182/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5444e-09 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9813\n",
            "Epoch 183/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4914e-09 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9814\n",
            "Epoch 184/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5153e-09 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9813\n",
            "Epoch 185/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4782e-09 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9813\n",
            "Epoch 186/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5126e-09 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9813\n",
            "Epoch 187/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4491e-09 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9813\n",
            "Epoch 188/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5153e-09 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9814\n",
            "Epoch 189/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4597e-09 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9813\n",
            "Epoch 190/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4702e-09 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9814\n",
            "Epoch 191/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4994e-09 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9814\n",
            "Epoch 192/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5365e-09 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9816\n",
            "Epoch 193/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4914e-09 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9815\n",
            "Epoch 194/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4835e-09 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 0.9816\n",
            "Epoch 195/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5179e-09 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 0.9815\n",
            "Epoch 196/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5179e-09 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 0.9815\n",
            "Epoch 197/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5577e-09 - accuracy: 1.0000 - val_loss: 0.2051 - val_accuracy: 0.9816\n",
            "Epoch 198/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5285e-09 - accuracy: 1.0000 - val_loss: 0.2052 - val_accuracy: 0.9815\n",
            "Epoch 199/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5020e-09 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 0.9815\n",
            "Epoch 200/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5338e-09 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9816\n",
            "Epoch 201/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5842e-09 - accuracy: 1.0000 - val_loss: 0.2060 - val_accuracy: 0.9815\n",
            "Epoch 202/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4861e-09 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9815\n",
            "Epoch 203/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5656e-09 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9816\n",
            "Epoch 204/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5365e-09 - accuracy: 1.0000 - val_loss: 0.2070 - val_accuracy: 0.9815\n",
            "Epoch 205/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5683e-09 - accuracy: 1.0000 - val_loss: 0.2073 - val_accuracy: 0.9815\n",
            "Epoch 206/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5709e-09 - accuracy: 1.0000 - val_loss: 0.2077 - val_accuracy: 0.9815\n",
            "Epoch 207/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5497e-09 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.9815\n",
            "Epoch 208/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6027e-09 - accuracy: 1.0000 - val_loss: 0.2082 - val_accuracy: 0.9815\n",
            "Epoch 209/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6001e-09 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9815\n",
            "Epoch 210/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5577e-09 - accuracy: 1.0000 - val_loss: 0.2093 - val_accuracy: 0.9815\n",
            "Epoch 211/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5921e-09 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9815\n",
            "Epoch 212/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6345e-09 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9813\n",
            "Epoch 213/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5921e-09 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9814\n",
            "Epoch 214/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6212e-09 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 0.9814\n",
            "Epoch 215/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6345e-09 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9814\n",
            "Epoch 216/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6001e-09 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9814\n",
            "Epoch 217/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6371e-09 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9814\n",
            "Epoch 218/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6557e-09 - accuracy: 1.0000 - val_loss: 0.2119 - val_accuracy: 0.9813\n",
            "Epoch 219/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6451e-09 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9813\n",
            "Epoch 220/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6663e-09 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 0.9811\n",
            "Epoch 221/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6716e-09 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9810\n",
            "Epoch 222/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6663e-09 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.9811\n",
            "Epoch 223/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6795e-09 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9809\n",
            "Epoch 224/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6928e-09 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9811\n",
            "Epoch 225/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7140e-09 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9809\n",
            "Epoch 226/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7193e-09 - accuracy: 1.0000 - val_loss: 0.2149 - val_accuracy: 0.9810\n",
            "Epoch 227/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7060e-09 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9809\n",
            "Epoch 228/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7669e-09 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9810\n",
            "Epoch 229/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7564e-09 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9809\n",
            "Epoch 230/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7564e-09 - accuracy: 1.0000 - val_loss: 0.2165 - val_accuracy: 0.9809\n",
            "Epoch 231/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7855e-09 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9808\n",
            "Epoch 232/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7325e-09 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 0.9810\n",
            "Epoch 233/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7511e-09 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9809\n",
            "Epoch 234/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8093e-09 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9808\n",
            "Epoch 235/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7749e-09 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9808\n",
            "Epoch 236/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7696e-09 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 0.9808\n",
            "Epoch 237/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7828e-09 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 0.9806\n",
            "Epoch 238/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7802e-09 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9807\n",
            "Epoch 239/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8040e-09 - accuracy: 1.0000 - val_loss: 0.2200 - val_accuracy: 0.9809\n",
            "Epoch 240/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8146e-09 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 0.9808\n",
            "Epoch 241/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8067e-09 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 0.9809\n",
            "Epoch 242/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8120e-09 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9809\n",
            "Epoch 243/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8385e-09 - accuracy: 1.0000 - val_loss: 0.2217 - val_accuracy: 0.9809\n",
            "Epoch 244/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9285e-09 - accuracy: 1.0000 - val_loss: 0.2221 - val_accuracy: 0.9809\n",
            "Epoch 245/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8809e-09 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9808\n",
            "Epoch 246/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8252e-09 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9810\n",
            "Epoch 247/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8888e-09 - accuracy: 1.0000 - val_loss: 0.2240 - val_accuracy: 0.9808\n",
            "Epoch 248/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9259e-09 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 0.9810\n",
            "Epoch 249/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9206e-09 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9808\n",
            "Epoch 250/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9126e-09 - accuracy: 1.0000 - val_loss: 0.2249 - val_accuracy: 0.9808\n",
            "Epoch 251/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8782e-09 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9809\n",
            "Epoch 252/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9471e-09 - accuracy: 1.0000 - val_loss: 0.2255 - val_accuracy: 0.9809\n",
            "Epoch 253/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9021e-09 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9808\n",
            "Epoch 254/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9444e-09 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9809\n",
            "Epoch 255/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9232e-09 - accuracy: 1.0000 - val_loss: 0.2274 - val_accuracy: 0.9807\n",
            "Epoch 256/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9232e-09 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9807\n",
            "Epoch 257/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9497e-09 - accuracy: 1.0000 - val_loss: 0.2273 - val_accuracy: 0.9807\n",
            "Epoch 258/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9762e-09 - accuracy: 1.0000 - val_loss: 0.2282 - val_accuracy: 0.9807\n",
            "Epoch 259/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0133e-09 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9808\n",
            "Epoch 260/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0160e-09 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9808\n",
            "Epoch 261/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0213e-09 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9809\n",
            "Epoch 262/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0213e-09 - accuracy: 1.0000 - val_loss: 0.2289 - val_accuracy: 0.9809\n",
            "Epoch 263/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0319e-09 - accuracy: 1.0000 - val_loss: 0.2298 - val_accuracy: 0.9807\n",
            "Epoch 264/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0027e-09 - accuracy: 1.0000 - val_loss: 0.2301 - val_accuracy: 0.9808\n",
            "Epoch 265/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0107e-09 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.9808\n",
            "Epoch 266/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0822e-09 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.9809\n",
            "Epoch 267/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0398e-09 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9808\n",
            "Epoch 268/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1007e-09 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9807\n",
            "Epoch 269/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0504e-09 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9807\n",
            "Epoch 270/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0716e-09 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9808\n",
            "Epoch 271/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1272e-09 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.9807\n",
            "Epoch 272/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1590e-09 - accuracy: 1.0000 - val_loss: 0.2337 - val_accuracy: 0.9808\n",
            "Epoch 273/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1882e-09 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9810\n",
            "Epoch 274/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2014e-09 - accuracy: 1.0000 - val_loss: 0.2343 - val_accuracy: 0.9807\n",
            "Epoch 275/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1908e-09 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9808\n",
            "Epoch 276/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1987e-09 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9809\n",
            "Epoch 277/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1113e-09 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9805\n",
            "Epoch 278/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1935e-09 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9806\n",
            "Epoch 279/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3180e-09 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9808\n",
            "Epoch 280/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2888e-09 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9808\n",
            "Epoch 281/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2120e-09 - accuracy: 1.0000 - val_loss: 0.2373 - val_accuracy: 0.9807\n",
            "Epoch 282/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2968e-09 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9807\n",
            "Epoch 283/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3339e-09 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9808\n",
            "Epoch 284/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2888e-09 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9806\n",
            "Epoch 285/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3206e-09 - accuracy: 1.0000 - val_loss: 0.2396 - val_accuracy: 0.9806\n",
            "Epoch 286/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3127e-09 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.9807\n",
            "Epoch 287/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1180 - accuracy: 0.9898 - val_loss: 0.2047 - val_accuracy: 0.9667\n",
            "Epoch 288/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0270 - accuracy: 0.9923 - val_loss: 0.1247 - val_accuracy: 0.9773\n",
            "Epoch 289/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.1291 - val_accuracy: 0.9782\n",
            "Epoch 290/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.0756e-04 - accuracy: 0.9998 - val_loss: 0.1323 - val_accuracy: 0.9789\n",
            "Epoch 291/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1518e-04 - accuracy: 1.0000 - val_loss: 0.1311 - val_accuracy: 0.9793\n",
            "Epoch 292/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0000e-04 - accuracy: 1.0000 - val_loss: 0.1313 - val_accuracy: 0.9799\n",
            "Epoch 293/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7384e-05 - accuracy: 1.0000 - val_loss: 0.1325 - val_accuracy: 0.9801\n",
            "Epoch 294/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4704e-05 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.9802\n",
            "Epoch 295/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5631e-05 - accuracy: 1.0000 - val_loss: 0.1345 - val_accuracy: 0.9800\n",
            "Epoch 296/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.8553e-05 - accuracy: 1.0000 - val_loss: 0.1355 - val_accuracy: 0.9801\n",
            "Epoch 297/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.2853e-05 - accuracy: 1.0000 - val_loss: 0.1363 - val_accuracy: 0.9801\n",
            "Epoch 298/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8144e-05 - accuracy: 1.0000 - val_loss: 0.1374 - val_accuracy: 0.9804\n",
            "Epoch 299/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4059e-05 - accuracy: 1.0000 - val_loss: 0.1381 - val_accuracy: 0.9803\n",
            "Epoch 300/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0522e-05 - accuracy: 1.0000 - val_loss: 0.1392 - val_accuracy: 0.9802\n",
            "Epoch 301/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7464e-05 - accuracy: 1.0000 - val_loss: 0.1401 - val_accuracy: 0.9803\n",
            "Epoch 302/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4794e-05 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9803\n",
            "Epoch 303/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2365e-05 - accuracy: 1.0000 - val_loss: 0.1419 - val_accuracy: 0.9805\n",
            "Epoch 304/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0324e-05 - accuracy: 1.0000 - val_loss: 0.1428 - val_accuracy: 0.9803\n",
            "Epoch 305/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8444e-05 - accuracy: 1.0000 - val_loss: 0.1438 - val_accuracy: 0.9805\n",
            "Epoch 306/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6770e-05 - accuracy: 1.0000 - val_loss: 0.1446 - val_accuracy: 0.9805\n",
            "Epoch 307/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5252e-05 - accuracy: 1.0000 - val_loss: 0.1454 - val_accuracy: 0.9803\n",
            "Epoch 308/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3932e-05 - accuracy: 1.0000 - val_loss: 0.1464 - val_accuracy: 0.9804\n",
            "Epoch 309/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2668e-05 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.9805\n",
            "Epoch 310/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1577e-05 - accuracy: 1.0000 - val_loss: 0.1479 - val_accuracy: 0.9806\n",
            "Epoch 311/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0580e-05 - accuracy: 1.0000 - val_loss: 0.1489 - val_accuracy: 0.9805\n",
            "Epoch 312/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.6629e-06 - accuracy: 1.0000 - val_loss: 0.1498 - val_accuracy: 0.9806\n",
            "Epoch 313/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8551e-06 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9807\n",
            "Epoch 314/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0853e-06 - accuracy: 1.0000 - val_loss: 0.1516 - val_accuracy: 0.9807\n",
            "Epoch 315/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.3871e-06 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9808\n",
            "Epoch 316/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7635e-06 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9805\n",
            "Epoch 317/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.1888e-06 - accuracy: 1.0000 - val_loss: 0.1542 - val_accuracy: 0.9805\n",
            "Epoch 318/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7076e-06 - accuracy: 1.0000 - val_loss: 0.1550 - val_accuracy: 0.9805\n",
            "Epoch 319/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2024e-06 - accuracy: 1.0000 - val_loss: 0.1559 - val_accuracy: 0.9805\n",
            "Epoch 320/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.7754e-06 - accuracy: 1.0000 - val_loss: 0.1566 - val_accuracy: 0.9805\n",
            "Epoch 321/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3780e-06 - accuracy: 1.0000 - val_loss: 0.1577 - val_accuracy: 0.9805\n",
            "Epoch 322/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.0154e-06 - accuracy: 1.0000 - val_loss: 0.1584 - val_accuracy: 0.9805\n",
            "Epoch 323/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6820e-06 - accuracy: 1.0000 - val_loss: 0.1594 - val_accuracy: 0.9806\n",
            "Epoch 324/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3693e-06 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 0.9807\n",
            "Epoch 325/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0877e-06 - accuracy: 1.0000 - val_loss: 0.1612 - val_accuracy: 0.9808\n",
            "Epoch 326/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8343e-06 - accuracy: 1.0000 - val_loss: 0.1622 - val_accuracy: 0.9809\n",
            "Epoch 327/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5940e-06 - accuracy: 1.0000 - val_loss: 0.1629 - val_accuracy: 0.9806\n",
            "Epoch 328/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3783e-06 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9807\n",
            "Epoch 329/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1739e-06 - accuracy: 1.0000 - val_loss: 0.1648 - val_accuracy: 0.9807\n",
            "Epoch 330/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9985e-06 - accuracy: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9805\n",
            "Epoch 331/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8267e-06 - accuracy: 1.0000 - val_loss: 0.1665 - val_accuracy: 0.9809\n",
            "Epoch 332/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6739e-06 - accuracy: 1.0000 - val_loss: 0.1674 - val_accuracy: 0.9806\n",
            "Epoch 333/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5319e-06 - accuracy: 1.0000 - val_loss: 0.1685 - val_accuracy: 0.9805\n",
            "Epoch 334/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4026e-06 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 0.9807\n",
            "Epoch 335/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2875e-06 - accuracy: 1.0000 - val_loss: 0.1700 - val_accuracy: 0.9808\n",
            "Epoch 336/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1755e-06 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 0.9807\n",
            "Epoch 337/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0847e-06 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 0.9808\n",
            "Epoch 338/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9209e-07 - accuracy: 1.0000 - val_loss: 0.1729 - val_accuracy: 0.9807\n",
            "Epoch 339/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0741e-07 - accuracy: 1.0000 - val_loss: 0.1735 - val_accuracy: 0.9808\n",
            "Epoch 340/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3159e-07 - accuracy: 1.0000 - val_loss: 0.1745 - val_accuracy: 0.9807\n",
            "Epoch 341/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6481e-07 - accuracy: 1.0000 - val_loss: 0.1754 - val_accuracy: 0.9807\n",
            "Epoch 342/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0002e-07 - accuracy: 1.0000 - val_loss: 0.1762 - val_accuracy: 0.9811\n",
            "Epoch 343/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3812e-07 - accuracy: 1.0000 - val_loss: 0.1773 - val_accuracy: 0.9811\n",
            "Epoch 344/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8733e-07 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9811\n",
            "Epoch 345/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3567e-07 - accuracy: 1.0000 - val_loss: 0.1787 - val_accuracy: 0.9811\n",
            "Epoch 346/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9488e-07 - accuracy: 1.0000 - val_loss: 0.1798 - val_accuracy: 0.9809\n",
            "Epoch 347/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.5195e-07 - accuracy: 1.0000 - val_loss: 0.1807 - val_accuracy: 0.9811\n",
            "Epoch 348/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.1443e-07 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 0.9810\n",
            "Epoch 349/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7877e-07 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 0.9811\n",
            "Epoch 350/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4705e-07 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 0.9808\n",
            "Epoch 351/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1828e-07 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 0.9812\n",
            "Epoch 352/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9290e-07 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 0.9811\n",
            "Epoch 353/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6964e-07 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9812\n",
            "Epoch 354/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4621e-07 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9812\n",
            "Epoch 355/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2657e-07 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 0.9809\n",
            "Epoch 356/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0842e-07 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9813\n",
            "Epoch 357/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9263e-07 - accuracy: 1.0000 - val_loss: 0.1895 - val_accuracy: 0.9813\n",
            "Epoch 358/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7663e-07 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 0.9812\n",
            "Epoch 359/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6242e-07 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.9813\n",
            "Epoch 360/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4946e-07 - accuracy: 1.0000 - val_loss: 0.1920 - val_accuracy: 0.9811\n",
            "Epoch 361/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3748e-07 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9813\n",
            "Epoch 362/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2607e-07 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9813\n",
            "Epoch 363/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1670e-07 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9813\n",
            "Epoch 364/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0782e-07 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 0.9812\n",
            "Epoch 365/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9118e-08 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 0.9811\n",
            "Epoch 366/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1354e-08 - accuracy: 1.0000 - val_loss: 0.1969 - val_accuracy: 0.9810\n",
            "Epoch 367/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.4448e-08 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9812\n",
            "Epoch 368/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.7772e-08 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9811\n",
            "Epoch 369/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1960e-08 - accuracy: 1.0000 - val_loss: 0.1994 - val_accuracy: 0.9811\n",
            "Epoch 370/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6002e-08 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9812\n",
            "Epoch 371/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.0945e-08 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9813\n",
            "Epoch 372/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.6574e-08 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9811\n",
            "Epoch 373/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.2211e-08 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9812\n",
            "Epoch 374/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.8243e-08 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9811\n",
            "Epoch 375/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4754e-08 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 0.9812\n",
            "Epoch 376/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.1313e-08 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 0.9811\n",
            "Epoch 377/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8311e-08 - accuracy: 1.0000 - val_loss: 0.2054 - val_accuracy: 0.9812\n",
            "Epoch 378/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5365e-08 - accuracy: 1.0000 - val_loss: 0.2062 - val_accuracy: 0.9811\n",
            "Epoch 379/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2902e-08 - accuracy: 1.0000 - val_loss: 0.2071 - val_accuracy: 0.9813\n",
            "Epoch 380/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0417e-08 - accuracy: 1.0000 - val_loss: 0.2078 - val_accuracy: 0.9811\n",
            "Epoch 381/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8189e-08 - accuracy: 1.0000 - val_loss: 0.2083 - val_accuracy: 0.9812\n",
            "Epoch 382/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6205e-08 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.9811\n",
            "Epoch 383/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4266e-08 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 0.9809\n",
            "Epoch 384/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2586e-08 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9809\n",
            "Epoch 385/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0925e-08 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9811\n",
            "Epoch 386/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9394e-08 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 0.9811\n",
            "Epoch 387/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8032e-08 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9811\n",
            "Epoch 388/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6888e-08 - accuracy: 1.0000 - val_loss: 0.2138 - val_accuracy: 0.9811\n",
            "Epoch 389/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5717e-08 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9810\n",
            "Epoch 390/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4673e-08 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 0.9811\n",
            "Epoch 391/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3741e-08 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9813\n",
            "Epoch 392/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2861e-08 - accuracy: 1.0000 - val_loss: 0.2166 - val_accuracy: 0.9813\n",
            "Epoch 393/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1868e-08 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9813\n",
            "Epoch 394/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1113e-08 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9814\n",
            "Epoch 395/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0432e-08 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9812\n",
            "Epoch 396/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.8122e-09 - accuracy: 1.0000 - val_loss: 0.2195 - val_accuracy: 0.9811\n",
            "Epoch 397/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1765e-09 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 0.9814\n",
            "Epoch 398/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6255e-09 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9813\n",
            "Epoch 399/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0665e-09 - accuracy: 1.0000 - val_loss: 0.2217 - val_accuracy: 0.9815\n",
            "Epoch 400/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5738e-09 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.9813\n",
            "Epoch 401/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1287e-09 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9813\n",
            "Epoch 402/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7075e-09 - accuracy: 1.0000 - val_loss: 0.2239 - val_accuracy: 0.9814\n",
            "Epoch 403/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2969e-09 - accuracy: 1.0000 - val_loss: 0.2245 - val_accuracy: 0.9815\n",
            "Epoch 404/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.9552e-09 - accuracy: 1.0000 - val_loss: 0.2252 - val_accuracy: 0.9815\n",
            "Epoch 405/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5710e-09 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9813\n",
            "Epoch 406/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3035e-09 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 0.9814\n",
            "Epoch 407/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.0227e-09 - accuracy: 1.0000 - val_loss: 0.2273 - val_accuracy: 0.9815\n",
            "Epoch 408/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7207e-09 - accuracy: 1.0000 - val_loss: 0.2280 - val_accuracy: 0.9815\n",
            "Epoch 409/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4929e-09 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9814\n",
            "Epoch 410/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3180e-09 - accuracy: 1.0000 - val_loss: 0.2293 - val_accuracy: 0.9813\n",
            "Epoch 411/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0346e-09 - accuracy: 1.0000 - val_loss: 0.2302 - val_accuracy: 0.9813\n",
            "Epoch 412/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8650e-09 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 0.9813\n",
            "Epoch 413/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6743e-09 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.9814\n",
            "Epoch 414/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4783e-09 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9813\n",
            "Epoch 415/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2637e-09 - accuracy: 1.0000 - val_loss: 0.2326 - val_accuracy: 0.9813\n",
            "Epoch 416/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1180e-09 - accuracy: 1.0000 - val_loss: 0.2331 - val_accuracy: 0.9815\n",
            "Epoch 417/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9855e-09 - accuracy: 1.0000 - val_loss: 0.2341 - val_accuracy: 0.9813\n",
            "Epoch 418/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8398e-09 - accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 0.9811\n",
            "Epoch 419/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7312e-09 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9813\n",
            "Epoch 420/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6041e-09 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9812\n",
            "Epoch 421/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4928e-09 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9812\n",
            "Epoch 422/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4054e-09 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9812\n",
            "Epoch 423/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3074e-09 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9811\n",
            "Epoch 424/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1511e-09 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9809\n",
            "Epoch 425/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0875e-09 - accuracy: 1.0000 - val_loss: 0.2398 - val_accuracy: 0.9811\n",
            "Epoch 426/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0107e-09 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9812\n",
            "Epoch 427/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9868e-09 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9811\n",
            "Epoch 428/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9047e-09 - accuracy: 1.0000 - val_loss: 0.2415 - val_accuracy: 0.9809\n",
            "Epoch 429/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8464e-09 - accuracy: 1.0000 - val_loss: 0.2421 - val_accuracy: 0.9809\n",
            "Epoch 430/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7855e-09 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9809\n",
            "Epoch 431/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7378e-09 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9808\n",
            "Epoch 432/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6981e-09 - accuracy: 1.0000 - val_loss: 0.2442 - val_accuracy: 0.9808\n",
            "Epoch 433/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6424e-09 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.9807\n",
            "Epoch 434/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6557e-09 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9809\n",
            "Epoch 435/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5974e-09 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9807\n",
            "Epoch 436/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5338e-09 - accuracy: 1.0000 - val_loss: 0.2470 - val_accuracy: 0.9807\n",
            "Epoch 437/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5312e-09 - accuracy: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.9808\n",
            "Epoch 438/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4914e-09 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.9807\n",
            "Epoch 439/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5259e-09 - accuracy: 1.0000 - val_loss: 0.2491 - val_accuracy: 0.9807\n",
            "Epoch 440/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4914e-09 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9808\n",
            "Epoch 441/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4491e-09 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9807\n",
            "Epoch 442/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4014e-09 - accuracy: 1.0000 - val_loss: 0.2508 - val_accuracy: 0.9808\n",
            "Epoch 443/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4040e-09 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9807\n",
            "Epoch 444/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3881e-09 - accuracy: 1.0000 - val_loss: 0.2520 - val_accuracy: 0.9808\n",
            "Epoch 445/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3643e-09 - accuracy: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.9809\n",
            "Epoch 446/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3802e-09 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.9809\n",
            "Epoch 447/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3378e-09 - accuracy: 1.0000 - val_loss: 0.2538 - val_accuracy: 0.9809\n",
            "Epoch 448/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3431e-09 - accuracy: 1.0000 - val_loss: 0.2545 - val_accuracy: 0.9808\n",
            "Epoch 449/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3351e-09 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9806\n",
            "Epoch 450/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3219e-09 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.9809\n",
            "Epoch 451/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3219e-09 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9808\n",
            "Epoch 452/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2954e-09 - accuracy: 1.0000 - val_loss: 0.2571 - val_accuracy: 0.9807\n",
            "Epoch 453/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3166e-09 - accuracy: 1.0000 - val_loss: 0.2575 - val_accuracy: 0.9808\n",
            "Epoch 454/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2848e-09 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.9807\n",
            "Epoch 455/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2451e-09 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.9808\n",
            "Epoch 456/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3087e-09 - accuracy: 1.0000 - val_loss: 0.2596 - val_accuracy: 0.9807\n",
            "Epoch 457/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3404e-09 - accuracy: 1.0000 - val_loss: 0.2602 - val_accuracy: 0.9807\n",
            "Epoch 458/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2610e-09 - accuracy: 1.0000 - val_loss: 0.2608 - val_accuracy: 0.9809\n",
            "Epoch 459/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2663e-09 - accuracy: 1.0000 - val_loss: 0.2612 - val_accuracy: 0.9807\n",
            "Epoch 460/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3192e-09 - accuracy: 1.0000 - val_loss: 0.2621 - val_accuracy: 0.9807\n",
            "Epoch 461/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2583e-09 - accuracy: 1.0000 - val_loss: 0.2627 - val_accuracy: 0.9806\n",
            "Epoch 462/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3616e-09 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9807\n",
            "Epoch 463/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2928e-09 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9805\n",
            "Epoch 464/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2848e-09 - accuracy: 1.0000 - val_loss: 0.2641 - val_accuracy: 0.9807\n",
            "Epoch 465/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2610e-09 - accuracy: 1.0000 - val_loss: 0.2646 - val_accuracy: 0.9807\n",
            "Epoch 466/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2769e-09 - accuracy: 1.0000 - val_loss: 0.2651 - val_accuracy: 0.9804\n",
            "Epoch 467/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2928e-09 - accuracy: 1.0000 - val_loss: 0.2660 - val_accuracy: 0.9805\n",
            "Epoch 468/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2477e-09 - accuracy: 1.0000 - val_loss: 0.2665 - val_accuracy: 0.9805\n",
            "Epoch 469/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3060e-09 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9805\n",
            "Epoch 470/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3192e-09 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9806\n",
            "Epoch 471/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2716e-09 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9803\n",
            "Epoch 472/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2583e-09 - accuracy: 1.0000 - val_loss: 0.2689 - val_accuracy: 0.9805\n",
            "Epoch 473/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3325e-09 - accuracy: 1.0000 - val_loss: 0.2693 - val_accuracy: 0.9805\n",
            "Epoch 474/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3192e-09 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.9805\n",
            "Epoch 475/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3192e-09 - accuracy: 1.0000 - val_loss: 0.2702 - val_accuracy: 0.9803\n",
            "Epoch 476/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2901e-09 - accuracy: 1.0000 - val_loss: 0.2708 - val_accuracy: 0.9802\n",
            "Epoch 477/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3563e-09 - accuracy: 1.0000 - val_loss: 0.2714 - val_accuracy: 0.9804\n",
            "Epoch 478/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3537e-09 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9802\n",
            "Epoch 479/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3643e-09 - accuracy: 1.0000 - val_loss: 0.2725 - val_accuracy: 0.9802\n",
            "Epoch 480/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3404e-09 - accuracy: 1.0000 - val_loss: 0.2732 - val_accuracy: 0.9800\n",
            "Epoch 481/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3722e-09 - accuracy: 1.0000 - val_loss: 0.2739 - val_accuracy: 0.9799\n",
            "Epoch 482/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3643e-09 - accuracy: 1.0000 - val_loss: 0.2741 - val_accuracy: 0.9802\n",
            "Epoch 483/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3802e-09 - accuracy: 1.0000 - val_loss: 0.2745 - val_accuracy: 0.9801\n",
            "Epoch 484/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2981e-09 - accuracy: 1.0000 - val_loss: 0.2751 - val_accuracy: 0.9802\n",
            "Epoch 485/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3908e-09 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9802\n",
            "Epoch 486/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3351e-09 - accuracy: 1.0000 - val_loss: 0.2763 - val_accuracy: 0.9802\n",
            "Epoch 487/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3669e-09 - accuracy: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.9803\n",
            "Epoch 488/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3987e-09 - accuracy: 1.0000 - val_loss: 0.2773 - val_accuracy: 0.9802\n",
            "Epoch 489/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4014e-09 - accuracy: 1.0000 - val_loss: 0.2775 - val_accuracy: 0.9801\n",
            "Epoch 490/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3510e-09 - accuracy: 1.0000 - val_loss: 0.2781 - val_accuracy: 0.9803\n",
            "Epoch 491/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3987e-09 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9800\n",
            "Epoch 492/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4040e-09 - accuracy: 1.0000 - val_loss: 0.2791 - val_accuracy: 0.9801\n",
            "Epoch 493/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3643e-09 - accuracy: 1.0000 - val_loss: 0.2801 - val_accuracy: 0.9800\n",
            "Epoch 494/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4173e-09 - accuracy: 1.0000 - val_loss: 0.2806 - val_accuracy: 0.9803\n",
            "Epoch 495/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4146e-09 - accuracy: 1.0000 - val_loss: 0.2805 - val_accuracy: 0.9805\n",
            "Epoch 496/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5179e-09 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9803\n",
            "Epoch 497/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4729e-09 - accuracy: 1.0000 - val_loss: 0.2821 - val_accuracy: 0.9802\n",
            "Epoch 498/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4623e-09 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.9802\n",
            "Epoch 499/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4438e-09 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.9805\n",
            "Epoch 500/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4649e-09 - accuracy: 1.0000 - val_loss: 0.2830 - val_accuracy: 0.9803\n",
            "Epoch 501/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4252e-09 - accuracy: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.9805\n",
            "Epoch 502/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4941e-09 - accuracy: 1.0000 - val_loss: 0.2842 - val_accuracy: 0.9803\n",
            "Epoch 503/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5073e-09 - accuracy: 1.0000 - val_loss: 0.2845 - val_accuracy: 0.9805\n",
            "Epoch 504/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7193e-09 - accuracy: 1.0000 - val_loss: 0.2850 - val_accuracy: 0.9803\n",
            "Epoch 505/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5683e-09 - accuracy: 1.0000 - val_loss: 0.2850 - val_accuracy: 0.9803\n",
            "Epoch 506/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4994e-09 - accuracy: 1.0000 - val_loss: 0.2859 - val_accuracy: 0.9803\n",
            "Epoch 507/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4411e-09 - accuracy: 1.0000 - val_loss: 0.2869 - val_accuracy: 0.9803\n",
            "Epoch 508/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5789e-09 - accuracy: 1.0000 - val_loss: 0.2876 - val_accuracy: 0.9803\n",
            "Epoch 509/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5524e-09 - accuracy: 1.0000 - val_loss: 0.2872 - val_accuracy: 0.9804\n",
            "Epoch 510/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4914e-09 - accuracy: 1.0000 - val_loss: 0.2883 - val_accuracy: 0.9802\n",
            "Epoch 511/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5312e-09 - accuracy: 1.0000 - val_loss: 0.2891 - val_accuracy: 0.9801\n",
            "Epoch 512/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5232e-09 - accuracy: 1.0000 - val_loss: 0.2887 - val_accuracy: 0.9803\n",
            "Epoch 513/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5895e-09 - accuracy: 1.0000 - val_loss: 0.2897 - val_accuracy: 0.9803\n",
            "Epoch 514/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5683e-09 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.9804\n",
            "Epoch 515/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6186e-09 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.9801\n",
            "Epoch 516/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5524e-09 - accuracy: 1.0000 - val_loss: 0.2910 - val_accuracy: 0.9805\n",
            "Epoch 517/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6716e-09 - accuracy: 1.0000 - val_loss: 0.2924 - val_accuracy: 0.9798\n",
            "Epoch 518/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6001e-09 - accuracy: 1.0000 - val_loss: 0.2917 - val_accuracy: 0.9801\n",
            "Epoch 519/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5577e-09 - accuracy: 1.0000 - val_loss: 0.2926 - val_accuracy: 0.9804\n",
            "Epoch 520/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6265e-09 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.9803\n",
            "Epoch 521/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5974e-09 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.9799\n",
            "Epoch 522/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6795e-09 - accuracy: 1.0000 - val_loss: 0.2944 - val_accuracy: 0.9802\n",
            "Epoch 523/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6371e-09 - accuracy: 1.0000 - val_loss: 0.2947 - val_accuracy: 0.9803\n",
            "Epoch 524/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6530e-09 - accuracy: 1.0000 - val_loss: 0.2956 - val_accuracy: 0.9803\n",
            "Epoch 525/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7246e-09 - accuracy: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.9803\n",
            "Epoch 526/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1487 - accuracy: 0.9897 - val_loss: 0.4248 - val_accuracy: 0.9678\n",
            "Epoch 527/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0366 - accuracy: 0.9933 - val_loss: 0.2497 - val_accuracy: 0.9738\n",
            "Epoch 528/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.2093 - val_accuracy: 0.9779\n",
            "Epoch 529/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9720e-04 - accuracy: 0.9997 - val_loss: 0.2088 - val_accuracy: 0.9784\n",
            "Epoch 530/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0160e-04 - accuracy: 0.9998 - val_loss: 0.2089 - val_accuracy: 0.9781\n",
            "Epoch 531/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0796e-04 - accuracy: 0.9999 - val_loss: 0.2058 - val_accuracy: 0.9779\n",
            "Epoch 532/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8274e-04 - accuracy: 0.9999 - val_loss: 0.2050 - val_accuracy: 0.9783\n",
            "Epoch 533/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.9461e-05 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9782\n",
            "Epoch 534/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3044e-05 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9785\n",
            "Epoch 535/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5904e-06 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9785\n",
            "Epoch 536/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3674e-06 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 0.9785\n",
            "Epoch 537/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4702e-06 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.9785\n",
            "Epoch 538/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7603e-06 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 0.9786\n",
            "Epoch 539/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1850e-06 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 0.9787\n",
            "Epoch 540/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.6901e-06 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 0.9787\n",
            "Epoch 541/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2465e-06 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 0.9787\n",
            "Epoch 542/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.8615e-06 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.9787\n",
            "Epoch 543/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5185e-06 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 0.9787\n",
            "Epoch 544/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2069e-06 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 0.9787\n",
            "Epoch 545/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9251e-06 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9787\n",
            "Epoch 546/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6637e-06 - accuracy: 1.0000 - val_loss: 0.2046 - val_accuracy: 0.9785\n",
            "Epoch 547/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4243e-06 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.9786\n",
            "Epoch 548/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1985e-06 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9786\n",
            "Epoch 549/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9907e-06 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 0.9786\n",
            "Epoch 550/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7957e-06 - accuracy: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.9787\n",
            "Epoch 551/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6157e-06 - accuracy: 1.0000 - val_loss: 0.2052 - val_accuracy: 0.9788\n",
            "Epoch 552/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4470e-06 - accuracy: 1.0000 - val_loss: 0.2053 - val_accuracy: 0.9788\n",
            "Epoch 553/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2919e-06 - accuracy: 1.0000 - val_loss: 0.2054 - val_accuracy: 0.9789\n",
            "Epoch 554/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1425e-06 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9789\n",
            "Epoch 555/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0019e-06 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.9789\n",
            "Epoch 556/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8738e-06 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9791\n",
            "Epoch 557/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7507e-06 - accuracy: 1.0000 - val_loss: 0.2061 - val_accuracy: 0.9789\n",
            "Epoch 558/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6366e-06 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9791\n",
            "Epoch 559/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5314e-06 - accuracy: 1.0000 - val_loss: 0.2066 - val_accuracy: 0.9791\n",
            "Epoch 560/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4314e-06 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9791\n",
            "Epoch 561/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3403e-06 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 0.9791\n",
            "Epoch 562/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2506e-06 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9792\n",
            "Epoch 563/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1683e-06 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 0.9793\n",
            "Epoch 564/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0889e-06 - accuracy: 1.0000 - val_loss: 0.2077 - val_accuracy: 0.9794\n",
            "Epoch 565/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0196e-06 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9793\n",
            "Epoch 566/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.4927e-07 - accuracy: 1.0000 - val_loss: 0.2083 - val_accuracy: 0.9793\n",
            "Epoch 567/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8557e-07 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9794\n",
            "Epoch 568/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2548e-07 - accuracy: 1.0000 - val_loss: 0.2089 - val_accuracy: 0.9795\n",
            "Epoch 569/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6909e-07 - accuracy: 1.0000 - val_loss: 0.2093 - val_accuracy: 0.9795\n",
            "Epoch 570/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1659e-07 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9795\n",
            "Epoch 571/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6825e-07 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9795\n",
            "Epoch 572/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.2287e-07 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.9796\n",
            "Epoch 573/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7956e-07 - accuracy: 1.0000 - val_loss: 0.2106 - val_accuracy: 0.9795\n",
            "Epoch 574/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.4050e-07 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9795\n",
            "Epoch 575/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0297e-07 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9795\n",
            "Epoch 576/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.6852e-07 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9795\n",
            "Epoch 577/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3741e-07 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9795\n",
            "Epoch 578/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0595e-07 - accuracy: 1.0000 - val_loss: 0.2126 - val_accuracy: 0.9795\n",
            "Epoch 579/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.7732e-07 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9795\n",
            "Epoch 580/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.5167e-07 - accuracy: 1.0000 - val_loss: 0.2133 - val_accuracy: 0.9795\n",
            "Epoch 581/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2731e-07 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9795\n",
            "Epoch 582/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0438e-07 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9794\n",
            "Epoch 583/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8345e-07 - accuracy: 1.0000 - val_loss: 0.2146 - val_accuracy: 0.9793\n",
            "Epoch 584/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6345e-07 - accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 0.9795\n",
            "Epoch 585/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4504e-07 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9793\n",
            "Epoch 586/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2769e-07 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 0.9794\n",
            "Epoch 587/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1212e-07 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 0.9796\n",
            "Epoch 588/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9715e-07 - accuracy: 1.0000 - val_loss: 0.2166 - val_accuracy: 0.9796\n",
            "Epoch 589/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8364e-07 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9795\n",
            "Epoch 590/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7057e-07 - accuracy: 1.0000 - val_loss: 0.2175 - val_accuracy: 0.9796\n",
            "Epoch 591/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5851e-07 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9797\n",
            "Epoch 592/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4771e-07 - accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.9797\n",
            "Epoch 593/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3720e-07 - accuracy: 1.0000 - val_loss: 0.2189 - val_accuracy: 0.9797\n",
            "Epoch 594/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2762e-07 - accuracy: 1.0000 - val_loss: 0.2194 - val_accuracy: 0.9797\n",
            "Epoch 595/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1845e-07 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9796\n",
            "Epoch 596/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1023e-07 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9797\n",
            "Epoch 597/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0255e-07 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 0.9798\n",
            "Epoch 598/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5020e-08 - accuracy: 1.0000 - val_loss: 0.2214 - val_accuracy: 0.9799\n",
            "Epoch 599/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8358e-08 - accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 0.9800\n",
            "Epoch 600/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2371e-08 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9801\n",
            "Epoch 601/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6535e-08 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9801\n",
            "Epoch 602/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1245e-08 - accuracy: 1.0000 - val_loss: 0.2233 - val_accuracy: 0.9801\n",
            "Epoch 603/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6129e-08 - accuracy: 1.0000 - val_loss: 0.2237 - val_accuracy: 0.9801\n",
            "Epoch 604/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.1385e-08 - accuracy: 1.0000 - val_loss: 0.2245 - val_accuracy: 0.9801\n",
            "Epoch 605/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7101e-08 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9801\n",
            "Epoch 606/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3080e-08 - accuracy: 1.0000 - val_loss: 0.2257 - val_accuracy: 0.9801\n",
            "Epoch 607/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9337e-08 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9801\n",
            "Epoch 608/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5729e-08 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 0.9800\n",
            "Epoch 609/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2423e-08 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9801\n",
            "Epoch 610/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.9509e-08 - accuracy: 1.0000 - val_loss: 0.2275 - val_accuracy: 0.9801\n",
            "Epoch 611/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6621e-08 - accuracy: 1.0000 - val_loss: 0.2282 - val_accuracy: 0.9800\n",
            "Epoch 612/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.4171e-08 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9799\n",
            "Epoch 613/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1633e-08 - accuracy: 1.0000 - val_loss: 0.2293 - val_accuracy: 0.9800\n",
            "Epoch 614/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9633e-08 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 0.9799\n",
            "Epoch 615/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7476e-08 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 0.9800\n",
            "Epoch 616/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5574e-08 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9799\n",
            "Epoch 617/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3792e-08 - accuracy: 1.0000 - val_loss: 0.2318 - val_accuracy: 0.9799\n",
            "Epoch 618/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2146e-08 - accuracy: 1.0000 - val_loss: 0.2323 - val_accuracy: 0.9800\n",
            "Epoch 619/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0599e-08 - accuracy: 1.0000 - val_loss: 0.2331 - val_accuracy: 0.9798\n",
            "Epoch 620/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9219e-08 - accuracy: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.9801\n",
            "Epoch 621/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7797e-08 - accuracy: 1.0000 - val_loss: 0.2344 - val_accuracy: 0.9799\n",
            "Epoch 622/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6610e-08 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9799\n",
            "Epoch 623/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5518e-08 - accuracy: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.9801\n",
            "Epoch 624/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4379e-08 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9801\n",
            "Epoch 625/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3391e-08 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9798\n",
            "Epoch 626/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2551e-08 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.9799\n",
            "Epoch 627/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1600e-08 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9799\n",
            "Epoch 628/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0822e-08 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9802\n",
            "Epoch 629/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0048e-08 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.9802\n",
            "Epoch 630/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4255e-09 - accuracy: 1.0000 - val_loss: 0.2407 - val_accuracy: 0.9801\n",
            "Epoch 631/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7844e-09 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 0.9801\n",
            "Epoch 632/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2572e-09 - accuracy: 1.0000 - val_loss: 0.2420 - val_accuracy: 0.9803\n",
            "Epoch 633/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6930e-09 - accuracy: 1.0000 - val_loss: 0.2429 - val_accuracy: 0.9801\n",
            "Epoch 634/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1658e-09 - accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 0.9801\n",
            "Epoch 635/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.7446e-09 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9802\n",
            "Epoch 636/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.2784e-09 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.9801\n",
            "Epoch 637/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8863e-09 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9801\n",
            "Epoch 638/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.4757e-09 - accuracy: 1.0000 - val_loss: 0.2471 - val_accuracy: 0.9801\n",
            "Epoch 639/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1207e-09 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9801\n",
            "Epoch 640/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.8293e-09 - accuracy: 1.0000 - val_loss: 0.2488 - val_accuracy: 0.9801\n",
            "Epoch 641/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.4982e-09 - accuracy: 1.0000 - val_loss: 0.2496 - val_accuracy: 0.9801\n",
            "Epoch 642/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.2280e-09 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9801\n",
            "Epoch 643/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0081e-09 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9802\n",
            "Epoch 644/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7273e-09 - accuracy: 1.0000 - val_loss: 0.2523 - val_accuracy: 0.9801\n",
            "Epoch 645/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4862e-09 - accuracy: 1.0000 - val_loss: 0.2533 - val_accuracy: 0.9801\n",
            "Epoch 646/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3087e-09 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.9803\n",
            "Epoch 647/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0730e-09 - accuracy: 1.0000 - val_loss: 0.2552 - val_accuracy: 0.9801\n",
            "Epoch 648/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9220e-09 - accuracy: 1.0000 - val_loss: 0.2561 - val_accuracy: 0.9803\n",
            "Epoch 649/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7604e-09 - accuracy: 1.0000 - val_loss: 0.2571 - val_accuracy: 0.9801\n",
            "Epoch 650/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6279e-09 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9801\n",
            "Epoch 651/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4478e-09 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.9803\n",
            "Epoch 652/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2941e-09 - accuracy: 1.0000 - val_loss: 0.2602 - val_accuracy: 0.9801\n",
            "Epoch 653/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2199e-09 - accuracy: 1.0000 - val_loss: 0.2610 - val_accuracy: 0.9801\n",
            "Epoch 654/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0981e-09 - accuracy: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.9801\n",
            "Epoch 655/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9285e-09 - accuracy: 1.0000 - val_loss: 0.2632 - val_accuracy: 0.9802\n",
            "Epoch 656/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8570e-09 - accuracy: 1.0000 - val_loss: 0.2641 - val_accuracy: 0.9802\n",
            "Epoch 657/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7802e-09 - accuracy: 1.0000 - val_loss: 0.2651 - val_accuracy: 0.9802\n",
            "Epoch 658/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6663e-09 - accuracy: 1.0000 - val_loss: 0.2662 - val_accuracy: 0.9802\n",
            "Epoch 659/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6318e-09 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9801\n",
            "Epoch 660/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5444e-09 - accuracy: 1.0000 - val_loss: 0.2683 - val_accuracy: 0.9801\n",
            "Epoch 661/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4649e-09 - accuracy: 1.0000 - val_loss: 0.2697 - val_accuracy: 0.9802\n",
            "Epoch 662/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4411e-09 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9801\n",
            "Epoch 663/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3404e-09 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9800\n",
            "Epoch 664/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3219e-09 - accuracy: 1.0000 - val_loss: 0.2724 - val_accuracy: 0.9801\n",
            "Epoch 665/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2318e-09 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9800\n",
            "Epoch 666/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2106e-09 - accuracy: 1.0000 - val_loss: 0.2748 - val_accuracy: 0.9800\n",
            "Epoch 667/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1683e-09 - accuracy: 1.0000 - val_loss: 0.2758 - val_accuracy: 0.9800\n",
            "Epoch 668/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1471e-09 - accuracy: 1.0000 - val_loss: 0.2772 - val_accuracy: 0.9800\n",
            "Epoch 669/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1418e-09 - accuracy: 1.0000 - val_loss: 0.2779 - val_accuracy: 0.9799\n",
            "Epoch 670/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0411e-09 - accuracy: 1.0000 - val_loss: 0.2793 - val_accuracy: 0.9801\n",
            "Epoch 671/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0517e-09 - accuracy: 1.0000 - val_loss: 0.2803 - val_accuracy: 0.9800\n",
            "Epoch 672/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0729e-09 - accuracy: 1.0000 - val_loss: 0.2812 - val_accuracy: 0.9801\n",
            "Epoch 673/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0278e-09 - accuracy: 1.0000 - val_loss: 0.2823 - val_accuracy: 0.9800\n",
            "Epoch 674/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9341e-10 - accuracy: 1.0000 - val_loss: 0.2834 - val_accuracy: 0.9799\n",
            "Epoch 675/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.8281e-10 - accuracy: 1.0000 - val_loss: 0.2842 - val_accuracy: 0.9801\n",
            "Epoch 676/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3248e-10 - accuracy: 1.0000 - val_loss: 0.2851 - val_accuracy: 0.9801\n",
            "Epoch 677/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.4838e-10 - accuracy: 1.0000 - val_loss: 0.2863 - val_accuracy: 0.9800\n",
            "Epoch 678/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3513e-10 - accuracy: 1.0000 - val_loss: 0.2875 - val_accuracy: 0.9799\n",
            "Epoch 679/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.6692e-10 - accuracy: 1.0000 - val_loss: 0.2881 - val_accuracy: 0.9800\n",
            "Epoch 680/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.0069e-10 - accuracy: 1.0000 - val_loss: 0.2890 - val_accuracy: 0.9799\n",
            "Epoch 681/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0599e-10 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.9800\n",
            "Epoch 682/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7420e-10 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.9799\n",
            "Epoch 683/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9539e-10 - accuracy: 1.0000 - val_loss: 0.2916 - val_accuracy: 0.9801\n",
            "Epoch 684/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5301e-10 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.9800\n",
            "Epoch 685/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1062e-10 - accuracy: 1.0000 - val_loss: 0.2944 - val_accuracy: 0.9797\n",
            "Epoch 686/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6096e-10 - accuracy: 1.0000 - val_loss: 0.2949 - val_accuracy: 0.9799\n",
            "Epoch 687/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8215e-10 - accuracy: 1.0000 - val_loss: 0.2955 - val_accuracy: 0.9799\n",
            "Epoch 688/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4506e-10 - accuracy: 1.0000 - val_loss: 0.2964 - val_accuracy: 0.9797\n",
            "Epoch 689/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4506e-10 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.9799\n",
            "Epoch 690/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2652e-10 - accuracy: 1.0000 - val_loss: 0.2978 - val_accuracy: 0.9799\n",
            "Epoch 691/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4506e-10 - accuracy: 1.0000 - val_loss: 0.2991 - val_accuracy: 0.9797\n",
            "Epoch 692/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.3976e-10 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 0.9797\n",
            "Epoch 693/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2652e-10 - accuracy: 1.0000 - val_loss: 0.3006 - val_accuracy: 0.9797\n",
            "Epoch 694/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2122e-10 - accuracy: 1.0000 - val_loss: 0.3017 - val_accuracy: 0.9796\n",
            "Epoch 695/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.2917e-10 - accuracy: 1.0000 - val_loss: 0.3025 - val_accuracy: 0.9797\n",
            "Epoch 696/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0003e-10 - accuracy: 1.0000 - val_loss: 0.3038 - val_accuracy: 0.9797\n",
            "Epoch 697/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3446e-10 - accuracy: 1.0000 - val_loss: 0.3040 - val_accuracy: 0.9798\n",
            "Epoch 698/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3182e-10 - accuracy: 1.0000 - val_loss: 0.3046 - val_accuracy: 0.9797\n",
            "Epoch 699/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1327e-10 - accuracy: 1.0000 - val_loss: 0.3053 - val_accuracy: 0.9799\n",
            "Epoch 700/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3446e-10 - accuracy: 1.0000 - val_loss: 0.3066 - val_accuracy: 0.9795\n",
            "Epoch 701/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.2652e-10 - accuracy: 1.0000 - val_loss: 0.3070 - val_accuracy: 0.9797\n",
            "Epoch 702/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0532e-10 - accuracy: 1.0000 - val_loss: 0.3083 - val_accuracy: 0.9795\n",
            "Epoch 703/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7618e-10 - accuracy: 1.0000 - val_loss: 0.3083 - val_accuracy: 0.9795\n",
            "Epoch 704/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9738e-10 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.9795\n",
            "Epoch 705/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9473e-10 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.9797\n",
            "Epoch 706/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.7883e-10 - accuracy: 1.0000 - val_loss: 0.3110 - val_accuracy: 0.9797\n",
            "Epoch 707/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8148e-10 - accuracy: 1.0000 - val_loss: 0.3119 - val_accuracy: 0.9794\n",
            "Epoch 708/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1857e-10 - accuracy: 1.0000 - val_loss: 0.3122 - val_accuracy: 0.9796\n",
            "Epoch 709/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2917e-10 - accuracy: 1.0000 - val_loss: 0.3133 - val_accuracy: 0.9795\n",
            "Epoch 710/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.9473e-10 - accuracy: 1.0000 - val_loss: 0.3141 - val_accuracy: 0.9795\n",
            "Epoch 711/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4506e-10 - accuracy: 1.0000 - val_loss: 0.3155 - val_accuracy: 0.9793\n",
            "Epoch 712/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.1327e-10 - accuracy: 1.0000 - val_loss: 0.3160 - val_accuracy: 0.9795\n",
            "Epoch 713/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0532e-10 - accuracy: 1.0000 - val_loss: 0.3167 - val_accuracy: 0.9794\n",
            "Epoch 714/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.1062e-10 - accuracy: 1.0000 - val_loss: 0.3181 - val_accuracy: 0.9793\n",
            "Epoch 715/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3446e-10 - accuracy: 1.0000 - val_loss: 0.3180 - val_accuracy: 0.9794\n",
            "Epoch 716/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4506e-10 - accuracy: 1.0000 - val_loss: 0.3184 - val_accuracy: 0.9794\n",
            "Epoch 717/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.8678e-10 - accuracy: 1.0000 - val_loss: 0.3194 - val_accuracy: 0.9796\n",
            "Epoch 718/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5036e-10 - accuracy: 1.0000 - val_loss: 0.3206 - val_accuracy: 0.9793\n",
            "Epoch 719/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4506e-10 - accuracy: 1.0000 - val_loss: 0.3213 - val_accuracy: 0.9793\n",
            "Epoch 720/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3182e-10 - accuracy: 1.0000 - val_loss: 0.3219 - val_accuracy: 0.9794\n",
            "Epoch 721/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4506e-10 - accuracy: 1.0000 - val_loss: 0.3224 - val_accuracy: 0.9792\n",
            "Epoch 722/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5301e-10 - accuracy: 1.0000 - val_loss: 0.3242 - val_accuracy: 0.9794\n",
            "Epoch 723/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.7420e-10 - accuracy: 1.0000 - val_loss: 0.3229 - val_accuracy: 0.9792\n",
            "Epoch 724/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4771e-10 - accuracy: 1.0000 - val_loss: 0.3246 - val_accuracy: 0.9794\n",
            "Epoch 725/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8745e-10 - accuracy: 1.0000 - val_loss: 0.3257 - val_accuracy: 0.9789\n",
            "Epoch 726/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.8215e-10 - accuracy: 1.0000 - val_loss: 0.3254 - val_accuracy: 0.9793\n",
            "Epoch 727/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.0069e-10 - accuracy: 1.0000 - val_loss: 0.3268 - val_accuracy: 0.9790\n",
            "Epoch 728/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.8546e-10 - accuracy: 1.0000 - val_loss: 0.3278 - val_accuracy: 0.9788\n",
            "Epoch 729/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.1127 - accuracy: 0.9924 - val_loss: 0.6858 - val_accuracy: 0.9535\n",
            "Epoch 730/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0544 - accuracy: 0.9911 - val_loss: 0.2152 - val_accuracy: 0.9769\n",
            "Epoch 731/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.2217 - val_accuracy: 0.9763\n",
            "Epoch 732/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.1967 - val_accuracy: 0.9795\n",
            "Epoch 733/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.0908e-04 - accuracy: 0.9998 - val_loss: 0.2036 - val_accuracy: 0.9791\n",
            "Epoch 734/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7009e-05 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9799\n",
            "Epoch 735/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3780e-05 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9799\n",
            "Epoch 736/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5599e-05 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9798\n",
            "Epoch 737/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3165e-05 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9795\n",
            "Epoch 738/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1540e-05 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9795\n",
            "Epoch 739/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0233e-05 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9795\n",
            "Epoch 740/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1853e-06 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 0.9796\n",
            "Epoch 741/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.2639e-06 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.9796\n",
            "Epoch 742/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.4700e-06 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.9797\n",
            "Epoch 743/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7310e-06 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9796\n",
            "Epoch 744/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0761e-06 - accuracy: 1.0000 - val_loss: 0.1994 - val_accuracy: 0.9797\n",
            "Epoch 745/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5038e-06 - accuracy: 1.0000 - val_loss: 0.1996 - val_accuracy: 0.9796\n",
            "Epoch 746/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.9705e-06 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9795\n",
            "Epoch 747/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5051e-06 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9796\n",
            "Epoch 748/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1112e-06 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9795\n",
            "Epoch 749/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7509e-06 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9796\n",
            "Epoch 750/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4204e-06 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9796\n",
            "Epoch 751/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1094e-06 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9796\n",
            "Epoch 752/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8178e-06 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9793\n",
            "Epoch 753/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5579e-06 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9794\n",
            "Epoch 754/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3302e-06 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9793\n",
            "Epoch 755/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0964e-06 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 0.9793\n",
            "Epoch 756/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8595e-06 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 0.9791\n",
            "Epoch 757/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5410e-06 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9793\n",
            "Epoch 758/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2534e-06 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9793\n",
            "Epoch 759/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4044e-07 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9794\n",
            "Epoch 760/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4488e-07 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9795\n",
            "Epoch 761/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.0981e-07 - accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 0.9795\n",
            "Epoch 762/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0351e-07 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9793\n",
            "Epoch 763/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2551e-07 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9794\n",
            "Epoch 764/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8763e-07 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9795\n",
            "Epoch 765/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3680e-07 - accuracy: 1.0000 - val_loss: 0.2478 - val_accuracy: 0.9795\n",
            "Epoch 766/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1294e-07 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9796\n",
            "Epoch 767/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8097e-07 - accuracy: 1.0000 - val_loss: 0.2519 - val_accuracy: 0.9794\n",
            "Epoch 768/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5184e-07 - accuracy: 1.0000 - val_loss: 0.2537 - val_accuracy: 0.9795\n",
            "Epoch 769/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3198e-07 - accuracy: 1.0000 - val_loss: 0.2554 - val_accuracy: 0.9794\n",
            "Epoch 770/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1184e-07 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.9796\n",
            "Epoch 771/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0010e-07 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.9795\n",
            "Epoch 772/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8107e-07 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.9796\n",
            "Epoch 773/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7378e-07 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9793\n",
            "Epoch 774/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5971e-07 - accuracy: 1.0000 - val_loss: 0.2619 - val_accuracy: 0.9796\n",
            "Epoch 775/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5191e-07 - accuracy: 1.0000 - val_loss: 0.2627 - val_accuracy: 0.9796\n",
            "Epoch 776/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3562e-07 - accuracy: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.9797\n",
            "Epoch 777/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2720e-07 - accuracy: 1.0000 - val_loss: 0.2652 - val_accuracy: 0.9795\n",
            "Epoch 778/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1923e-07 - accuracy: 1.0000 - val_loss: 0.2664 - val_accuracy: 0.9797\n",
            "Epoch 779/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1240e-07 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.9797\n",
            "Epoch 780/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0560e-07 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9797\n",
            "Epoch 781/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0081e-07 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.9797\n",
            "Epoch 782/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3947e-08 - accuracy: 1.0000 - val_loss: 0.2698 - val_accuracy: 0.9797\n",
            "Epoch 783/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6296e-08 - accuracy: 1.0000 - val_loss: 0.2707 - val_accuracy: 0.9797\n",
            "Epoch 784/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2360e-08 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9797\n",
            "Epoch 785/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8709e-08 - accuracy: 1.0000 - val_loss: 0.2719 - val_accuracy: 0.9797\n",
            "Epoch 786/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.2611e-08 - accuracy: 1.0000 - val_loss: 0.2730 - val_accuracy: 0.9796\n",
            "Epoch 787/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.7830e-08 - accuracy: 1.0000 - val_loss: 0.2739 - val_accuracy: 0.9795\n",
            "Epoch 788/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.3051e-08 - accuracy: 1.0000 - val_loss: 0.2746 - val_accuracy: 0.9797\n",
            "Epoch 789/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.0431e-08 - accuracy: 1.0000 - val_loss: 0.2749 - val_accuracy: 0.9797\n",
            "Epoch 790/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.6656e-08 - accuracy: 1.0000 - val_loss: 0.2759 - val_accuracy: 0.9795\n",
            "Epoch 791/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3223e-08 - accuracy: 1.0000 - val_loss: 0.2764 - val_accuracy: 0.9797\n",
            "Epoch 792/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0343e-08 - accuracy: 1.0000 - val_loss: 0.2773 - val_accuracy: 0.9797\n",
            "Epoch 793/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7543e-08 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9797\n",
            "Epoch 794/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4621e-08 - accuracy: 1.0000 - val_loss: 0.2787 - val_accuracy: 0.9797\n",
            "Epoch 795/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1572e-08 - accuracy: 1.0000 - val_loss: 0.2796 - val_accuracy: 0.9797\n",
            "Epoch 796/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9387e-08 - accuracy: 1.0000 - val_loss: 0.2805 - val_accuracy: 0.9797\n",
            "Epoch 797/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6523e-08 - accuracy: 1.0000 - val_loss: 0.2809 - val_accuracy: 0.9799\n",
            "Epoch 798/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.4489e-08 - accuracy: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.9798\n",
            "Epoch 799/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2658e-08 - accuracy: 1.0000 - val_loss: 0.2822 - val_accuracy: 0.9797\n",
            "Epoch 800/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0504e-08 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.9796\n",
            "Epoch 801/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8888e-08 - accuracy: 1.0000 - val_loss: 0.2841 - val_accuracy: 0.9799\n",
            "Epoch 802/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7021e-08 - accuracy: 1.0000 - val_loss: 0.2845 - val_accuracy: 0.9799\n",
            "Epoch 803/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5564e-08 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.9799\n",
            "Epoch 804/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3911e-08 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.9799\n",
            "Epoch 805/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2274e-08 - accuracy: 1.0000 - val_loss: 0.2865 - val_accuracy: 0.9799\n",
            "Epoch 806/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0954e-08 - accuracy: 1.0000 - val_loss: 0.2875 - val_accuracy: 0.9799\n",
            "Epoch 807/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9847e-08 - accuracy: 1.0000 - val_loss: 0.2879 - val_accuracy: 0.9798\n",
            "Epoch 808/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8650e-08 - accuracy: 1.0000 - val_loss: 0.2885 - val_accuracy: 0.9799\n",
            "Epoch 809/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7336e-08 - accuracy: 1.0000 - val_loss: 0.2897 - val_accuracy: 0.9801\n",
            "Epoch 810/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6366e-08 - accuracy: 1.0000 - val_loss: 0.2899 - val_accuracy: 0.9799\n",
            "Epoch 811/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5333e-08 - accuracy: 1.0000 - val_loss: 0.2911 - val_accuracy: 0.9799\n",
            "Epoch 812/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4446e-08 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9801\n",
            "Epoch 813/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3611e-08 - accuracy: 1.0000 - val_loss: 0.2924 - val_accuracy: 0.9800\n",
            "Epoch 814/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2838e-08 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.9801\n",
            "Epoch 815/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2035e-08 - accuracy: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.9799\n",
            "Epoch 816/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1333e-08 - accuracy: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.9799\n",
            "Epoch 817/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0657e-08 - accuracy: 1.0000 - val_loss: 0.2947 - val_accuracy: 0.9800\n",
            "Epoch 818/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9791e-09 - accuracy: 1.0000 - val_loss: 0.2948 - val_accuracy: 0.9801\n",
            "Epoch 819/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.4281e-09 - accuracy: 1.0000 - val_loss: 0.2959 - val_accuracy: 0.9799\n",
            "Epoch 820/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9433e-09 - accuracy: 1.0000 - val_loss: 0.2964 - val_accuracy: 0.9799\n",
            "Epoch 821/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.3235e-09 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.9798\n",
            "Epoch 822/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8440e-09 - accuracy: 1.0000 - val_loss: 0.2979 - val_accuracy: 0.9798\n",
            "Epoch 823/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4042e-09 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.9799\n",
            "Epoch 824/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.9830e-09 - accuracy: 1.0000 - val_loss: 0.2991 - val_accuracy: 0.9798\n",
            "Epoch 825/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.5909e-09 - accuracy: 1.0000 - val_loss: 0.2999 - val_accuracy: 0.9799\n",
            "Epoch 826/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1830e-09 - accuracy: 1.0000 - val_loss: 0.3006 - val_accuracy: 0.9799\n",
            "Epoch 827/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.8095e-09 - accuracy: 1.0000 - val_loss: 0.3016 - val_accuracy: 0.9799\n",
            "Epoch 828/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.4995e-09 - accuracy: 1.0000 - val_loss: 0.3023 - val_accuracy: 0.9799\n",
            "Epoch 829/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2134e-09 - accuracy: 1.0000 - val_loss: 0.3028 - val_accuracy: 0.9798\n",
            "Epoch 830/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9300e-09 - accuracy: 1.0000 - val_loss: 0.3037 - val_accuracy: 0.9797\n",
            "Epoch 831/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.6015e-09 - accuracy: 1.0000 - val_loss: 0.3043 - val_accuracy: 0.9798\n",
            "Epoch 832/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.3578e-09 - accuracy: 1.0000 - val_loss: 0.3050 - val_accuracy: 0.9800\n",
            "Epoch 833/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.1670e-09 - accuracy: 1.0000 - val_loss: 0.3058 - val_accuracy: 0.9799\n",
            "Epoch 834/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.8677e-09 - accuracy: 1.0000 - val_loss: 0.3068 - val_accuracy: 0.9797\n",
            "Epoch 835/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6796e-09 - accuracy: 1.0000 - val_loss: 0.3076 - val_accuracy: 0.9799\n",
            "Epoch 836/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.5021e-09 - accuracy: 1.0000 - val_loss: 0.3083 - val_accuracy: 0.9799\n",
            "Epoch 837/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3273e-09 - accuracy: 1.0000 - val_loss: 0.3090 - val_accuracy: 0.9798\n",
            "Epoch 838/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0968e-09 - accuracy: 1.0000 - val_loss: 0.3096 - val_accuracy: 0.9799\n",
            "Epoch 839/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9511e-09 - accuracy: 1.0000 - val_loss: 0.3106 - val_accuracy: 0.9797\n",
            "Epoch 840/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7763e-09 - accuracy: 1.0000 - val_loss: 0.3117 - val_accuracy: 0.9798\n",
            "Epoch 841/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6438e-09 - accuracy: 1.0000 - val_loss: 0.3124 - val_accuracy: 0.9797\n",
            "Epoch 842/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5113e-09 - accuracy: 1.0000 - val_loss: 0.3133 - val_accuracy: 0.9798\n",
            "Epoch 843/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3789e-09 - accuracy: 1.0000 - val_loss: 0.3141 - val_accuracy: 0.9795\n",
            "Epoch 844/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2146e-09 - accuracy: 1.0000 - val_loss: 0.3153 - val_accuracy: 0.9797\n",
            "Epoch 845/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1272e-09 - accuracy: 1.0000 - val_loss: 0.3159 - val_accuracy: 0.9797\n",
            "Epoch 846/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0372e-09 - accuracy: 1.0000 - val_loss: 0.3171 - val_accuracy: 0.9796\n",
            "Epoch 847/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9153e-09 - accuracy: 1.0000 - val_loss: 0.3177 - val_accuracy: 0.9797\n",
            "Epoch 848/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8093e-09 - accuracy: 1.0000 - val_loss: 0.3187 - val_accuracy: 0.9797\n",
            "Epoch 849/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7299e-09 - accuracy: 1.0000 - val_loss: 0.3195 - val_accuracy: 0.9797\n",
            "Epoch 850/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6265e-09 - accuracy: 1.0000 - val_loss: 0.3209 - val_accuracy: 0.9796\n",
            "Epoch 851/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5842e-09 - accuracy: 1.0000 - val_loss: 0.3215 - val_accuracy: 0.9796\n",
            "Epoch 852/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4782e-09 - accuracy: 1.0000 - val_loss: 0.3226 - val_accuracy: 0.9796\n",
            "Epoch 853/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4517e-09 - accuracy: 1.0000 - val_loss: 0.3236 - val_accuracy: 0.9796\n",
            "Epoch 854/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3987e-09 - accuracy: 1.0000 - val_loss: 0.3246 - val_accuracy: 0.9795\n",
            "Epoch 855/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3192e-09 - accuracy: 1.0000 - val_loss: 0.3254 - val_accuracy: 0.9796\n",
            "Epoch 856/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3034e-09 - accuracy: 1.0000 - val_loss: 0.3262 - val_accuracy: 0.9796\n",
            "Epoch 857/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1894e-09 - accuracy: 1.0000 - val_loss: 0.3271 - val_accuracy: 0.9797\n",
            "Epoch 858/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1815e-09 - accuracy: 1.0000 - val_loss: 0.3283 - val_accuracy: 0.9797\n",
            "Epoch 859/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1285e-09 - accuracy: 1.0000 - val_loss: 0.3292 - val_accuracy: 0.9795\n",
            "Epoch 860/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1073e-09 - accuracy: 1.0000 - val_loss: 0.3304 - val_accuracy: 0.9796\n",
            "Epoch 861/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0941e-09 - accuracy: 1.0000 - val_loss: 0.3310 - val_accuracy: 0.9795\n",
            "Epoch 862/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0120e-09 - accuracy: 1.0000 - val_loss: 0.3326 - val_accuracy: 0.9795\n",
            "Epoch 863/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0490e-09 - accuracy: 1.0000 - val_loss: 0.3331 - val_accuracy: 0.9793\n",
            "Epoch 864/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9606e-10 - accuracy: 1.0000 - val_loss: 0.3339 - val_accuracy: 0.9793\n",
            "Epoch 865/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.7752e-10 - accuracy: 1.0000 - val_loss: 0.3353 - val_accuracy: 0.9794\n",
            "Epoch 866/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3248e-10 - accuracy: 1.0000 - val_loss: 0.3359 - val_accuracy: 0.9795\n",
            "Epoch 867/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.9606e-10 - accuracy: 1.0000 - val_loss: 0.3368 - val_accuracy: 0.9793\n",
            "Epoch 868/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0864e-10 - accuracy: 1.0000 - val_loss: 0.3378 - val_accuracy: 0.9794\n",
            "Epoch 869/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0334e-10 - accuracy: 1.0000 - val_loss: 0.3386 - val_accuracy: 0.9793\n",
            "Epoch 870/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9804e-10 - accuracy: 1.0000 - val_loss: 0.3395 - val_accuracy: 0.9795\n",
            "Epoch 871/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.2718e-10 - accuracy: 1.0000 - val_loss: 0.3400 - val_accuracy: 0.9796\n",
            "Epoch 872/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.6625e-10 - accuracy: 1.0000 - val_loss: 0.3409 - val_accuracy: 0.9794\n",
            "Epoch 873/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4771e-10 - accuracy: 1.0000 - val_loss: 0.3417 - val_accuracy: 0.9795\n",
            "Epoch 874/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.4241e-10 - accuracy: 1.0000 - val_loss: 0.3429 - val_accuracy: 0.9795\n",
            "Epoch 875/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6890e-10 - accuracy: 1.0000 - val_loss: 0.3433 - val_accuracy: 0.9795\n",
            "Epoch 876/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.1857e-10 - accuracy: 1.0000 - val_loss: 0.3441 - val_accuracy: 0.9793\n",
            "Epoch 877/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.0003e-10 - accuracy: 1.0000 - val_loss: 0.3449 - val_accuracy: 0.9795\n",
            "Epoch 878/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.2917e-10 - accuracy: 1.0000 - val_loss: 0.3452 - val_accuracy: 0.9793\n",
            "Epoch 879/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0797e-10 - accuracy: 1.0000 - val_loss: 0.3459 - val_accuracy: 0.9794\n",
            "Epoch 880/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0797e-10 - accuracy: 1.0000 - val_loss: 0.3471 - val_accuracy: 0.9794\n",
            "Epoch 881/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5764e-10 - accuracy: 1.0000 - val_loss: 0.3483 - val_accuracy: 0.9797\n",
            "Epoch 882/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.0003e-10 - accuracy: 1.0000 - val_loss: 0.3484 - val_accuracy: 0.9794\n",
            "Epoch 883/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9738e-10 - accuracy: 1.0000 - val_loss: 0.3498 - val_accuracy: 0.9797\n",
            "Epoch 884/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4969e-10 - accuracy: 1.0000 - val_loss: 0.3498 - val_accuracy: 0.9793\n",
            "Epoch 885/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6559e-10 - accuracy: 1.0000 - val_loss: 0.3513 - val_accuracy: 0.9795\n",
            "Epoch 886/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.6559e-10 - accuracy: 1.0000 - val_loss: 0.3519 - val_accuracy: 0.9795\n",
            "Epoch 887/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4969e-10 - accuracy: 1.0000 - val_loss: 0.3530 - val_accuracy: 0.9795\n",
            "Epoch 888/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9208e-10 - accuracy: 1.0000 - val_loss: 0.3524 - val_accuracy: 0.9793\n",
            "Epoch 889/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3115e-10 - accuracy: 1.0000 - val_loss: 0.3544 - val_accuracy: 0.9795\n",
            "Epoch 890/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5764e-10 - accuracy: 1.0000 - val_loss: 0.3546 - val_accuracy: 0.9795\n",
            "Epoch 891/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4440e-10 - accuracy: 1.0000 - val_loss: 0.3551 - val_accuracy: 0.9796\n",
            "Epoch 892/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.0466e-10 - accuracy: 1.0000 - val_loss: 0.3554 - val_accuracy: 0.9795\n",
            "Epoch 893/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.1790e-10 - accuracy: 1.0000 - val_loss: 0.3566 - val_accuracy: 0.9795\n",
            "Epoch 894/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6294e-10 - accuracy: 1.0000 - val_loss: 0.3568 - val_accuracy: 0.9795\n",
            "Epoch 895/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4440e-10 - accuracy: 1.0000 - val_loss: 0.3573 - val_accuracy: 0.9795\n",
            "Epoch 896/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.0466e-10 - accuracy: 1.0000 - val_loss: 0.3582 - val_accuracy: 0.9795\n",
            "Epoch 897/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5433e-10 - accuracy: 1.0000 - val_loss: 0.3590 - val_accuracy: 0.9796\n",
            "Epoch 898/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4175e-10 - accuracy: 1.0000 - val_loss: 0.3594 - val_accuracy: 0.9795\n",
            "Epoch 899/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7022e-10 - accuracy: 1.0000 - val_loss: 0.3597 - val_accuracy: 0.9794\n",
            "Epoch 900/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7420e-10 - accuracy: 1.0000 - val_loss: 0.3608 - val_accuracy: 0.9796\n",
            "Epoch 901/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.9738e-10 - accuracy: 1.0000 - val_loss: 0.3610 - val_accuracy: 0.9794\n",
            "Epoch 902/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1194e-10 - accuracy: 1.0000 - val_loss: 0.3609 - val_accuracy: 0.9794\n",
            "Epoch 903/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.1790e-10 - accuracy: 1.0000 - val_loss: 0.3616 - val_accuracy: 0.9792\n",
            "Epoch 904/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7022e-10 - accuracy: 1.0000 - val_loss: 0.3631 - val_accuracy: 0.9792\n",
            "Epoch 905/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4903e-10 - accuracy: 1.0000 - val_loss: 0.3634 - val_accuracy: 0.9793\n",
            "Epoch 906/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.1361 - accuracy: 0.9886 - val_loss: 0.3102 - val_accuracy: 0.9717\n",
            "Epoch 907/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0207 - accuracy: 0.9951 - val_loss: 0.2000 - val_accuracy: 0.9768\n",
            "Epoch 908/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.1965 - val_accuracy: 0.9784\n",
            "Epoch 909/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0008e-04 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 0.9787\n",
            "Epoch 910/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.3474e-05 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9793\n",
            "Epoch 911/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3206e-05 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 0.9797\n",
            "Epoch 912/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6280e-05 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9798\n",
            "Epoch 913/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0633e-05 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9795\n",
            "Epoch 914/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6702e-05 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9796\n",
            "Epoch 915/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2607e-05 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.9799\n",
            "Epoch 916/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5756e-06 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 0.9800\n",
            "Epoch 917/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7026e-06 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9800\n",
            "Epoch 918/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.1020e-06 - accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 0.9800\n",
            "Epoch 919/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6795e-06 - accuracy: 1.0000 - val_loss: 0.2327 - val_accuracy: 0.9800\n",
            "Epoch 920/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9876e-06 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9798\n",
            "Epoch 921/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5712e-06 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9801\n",
            "Epoch 922/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2735e-06 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.9800\n",
            "Epoch 923/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0428e-06 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.9797\n",
            "Epoch 924/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3921e-07 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9799\n",
            "Epoch 925/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.1010e-07 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9795\n",
            "Epoch 926/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4751e-07 - accuracy: 1.0000 - val_loss: 0.2646 - val_accuracy: 0.9795\n",
            "Epoch 927/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.9249e-07 - accuracy: 1.0000 - val_loss: 0.2704 - val_accuracy: 0.9796\n",
            "Epoch 928/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2996e-07 - accuracy: 1.0000 - val_loss: 0.2743 - val_accuracy: 0.9796\n",
            "Epoch 929/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.7093e-07 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9797\n",
            "Epoch 930/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0059e-07 - accuracy: 1.0000 - val_loss: 0.2856 - val_accuracy: 0.9800\n",
            "Epoch 931/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0437 - accuracy: 0.9906 - val_loss: 0.1621 - val_accuracy: 0.9757\n",
            "Epoch 932/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.1534 - val_accuracy: 0.9784\n",
            "Epoch 933/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.1452 - val_accuracy: 0.9789\n",
            "Epoch 934/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2558e-04 - accuracy: 0.9999 - val_loss: 0.1479 - val_accuracy: 0.9793\n",
            "Epoch 935/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0308e-05 - accuracy: 1.0000 - val_loss: 0.1478 - val_accuracy: 0.9797\n",
            "Epoch 936/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7088e-05 - accuracy: 1.0000 - val_loss: 0.1481 - val_accuracy: 0.9798\n",
            "Epoch 937/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7122e-05 - accuracy: 1.0000 - val_loss: 0.1562 - val_accuracy: 0.9799\n",
            "Epoch 938/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0120e-05 - accuracy: 1.0000 - val_loss: 0.1794 - val_accuracy: 0.9801\n",
            "Epoch 939/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1851e-06 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9802\n",
            "Epoch 940/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1650e-06 - accuracy: 1.0000 - val_loss: 0.2117 - val_accuracy: 0.9802\n",
            "Epoch 941/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5505e-06 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9804\n",
            "Epoch 942/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1955e-06 - accuracy: 1.0000 - val_loss: 0.2252 - val_accuracy: 0.9803\n",
            "Epoch 943/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2741e-07 - accuracy: 1.0000 - val_loss: 0.2329 - val_accuracy: 0.9803\n",
            "Epoch 944/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.6011e-07 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.9805\n",
            "Epoch 945/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4967e-07 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9805\n",
            "Epoch 946/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8857e-07 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9803\n",
            "Epoch 947/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9719e-07 - accuracy: 1.0000 - val_loss: 0.2478 - val_accuracy: 0.9805\n",
            "Epoch 948/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4765e-07 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9807\n",
            "Epoch 949/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9890e-07 - accuracy: 1.0000 - val_loss: 0.2536 - val_accuracy: 0.9807\n",
            "Epoch 950/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.4625e-07 - accuracy: 1.0000 - val_loss: 0.2548 - val_accuracy: 0.9805\n",
            "Epoch 951/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2486e-07 - accuracy: 1.0000 - val_loss: 0.2572 - val_accuracy: 0.9805\n",
            "Epoch 952/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9988e-07 - accuracy: 1.0000 - val_loss: 0.2592 - val_accuracy: 0.9806\n",
            "Epoch 953/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6092e-07 - accuracy: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.9805\n",
            "Epoch 954/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4213e-07 - accuracy: 1.0000 - val_loss: 0.2632 - val_accuracy: 0.9806\n",
            "Epoch 955/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2432e-07 - accuracy: 1.0000 - val_loss: 0.2649 - val_accuracy: 0.9806\n",
            "Epoch 956/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1521e-07 - accuracy: 1.0000 - val_loss: 0.2659 - val_accuracy: 0.9806\n",
            "Epoch 957/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0742e-07 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9807\n",
            "Epoch 958/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8764e-07 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.9805\n",
            "Epoch 959/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7446e-07 - accuracy: 1.0000 - val_loss: 0.2694 - val_accuracy: 0.9805\n",
            "Epoch 960/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5515e-07 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.9805\n",
            "Epoch 961/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4452e-07 - accuracy: 1.0000 - val_loss: 0.2729 - val_accuracy: 0.9805\n",
            "Epoch 962/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3235e-07 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9805\n",
            "Epoch 963/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2501e-07 - accuracy: 1.0000 - val_loss: 0.2761 - val_accuracy: 0.9805\n",
            "Epoch 964/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1823e-07 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9804\n",
            "Epoch 965/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0847e-07 - accuracy: 1.0000 - val_loss: 0.2780 - val_accuracy: 0.9803\n",
            "Epoch 966/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0071e-07 - accuracy: 1.0000 - val_loss: 0.2801 - val_accuracy: 0.9804\n",
            "Epoch 967/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.2966e-08 - accuracy: 1.0000 - val_loss: 0.2811 - val_accuracy: 0.9805\n",
            "Epoch 968/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.1928e-08 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9805\n",
            "Epoch 969/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9318e-08 - accuracy: 1.0000 - val_loss: 0.2822 - val_accuracy: 0.9802\n",
            "Epoch 970/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7120e-08 - accuracy: 1.0000 - val_loss: 0.2848 - val_accuracy: 0.9806\n",
            "Epoch 971/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.3117e-08 - accuracy: 1.0000 - val_loss: 0.2854 - val_accuracy: 0.9804\n",
            "Epoch 972/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5697e-08 - accuracy: 1.0000 - val_loss: 0.2862 - val_accuracy: 0.9803\n",
            "Epoch 973/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.4659e-08 - accuracy: 1.0000 - val_loss: 0.2866 - val_accuracy: 0.9803\n",
            "Epoch 974/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8923e-08 - accuracy: 1.0000 - val_loss: 0.2884 - val_accuracy: 0.9803\n",
            "Epoch 975/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8039e-08 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.9806\n",
            "Epoch 976/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3024e-08 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.9807\n",
            "Epoch 977/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.8356e-08 - accuracy: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.9805\n",
            "Epoch 978/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5946e-08 - accuracy: 1.0000 - val_loss: 0.2929 - val_accuracy: 0.9801\n",
            "Epoch 979/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2497e-08 - accuracy: 1.0000 - val_loss: 0.2944 - val_accuracy: 0.9806\n",
            "Epoch 980/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9580e-08 - accuracy: 1.0000 - val_loss: 0.2950 - val_accuracy: 0.9805\n",
            "Epoch 981/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6727e-08 - accuracy: 1.0000 - val_loss: 0.2962 - val_accuracy: 0.9805\n",
            "Epoch 982/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.4971e-08 - accuracy: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.9805\n",
            "Epoch 983/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1810e-08 - accuracy: 1.0000 - val_loss: 0.2987 - val_accuracy: 0.9806\n",
            "Epoch 984/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0311e-08 - accuracy: 1.0000 - val_loss: 0.2991 - val_accuracy: 0.9803\n",
            "Epoch 985/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9037e-08 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.9803\n",
            "Epoch 986/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8377e-08 - accuracy: 1.0000 - val_loss: 0.3009 - val_accuracy: 0.9803\n",
            "Epoch 987/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5188e-08 - accuracy: 1.0000 - val_loss: 0.3019 - val_accuracy: 0.9803\n",
            "Epoch 988/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3847e-08 - accuracy: 1.0000 - val_loss: 0.3028 - val_accuracy: 0.9807\n",
            "Epoch 989/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2046e-08 - accuracy: 1.0000 - val_loss: 0.3037 - val_accuracy: 0.9805\n",
            "Epoch 990/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1145e-08 - accuracy: 1.0000 - val_loss: 0.3051 - val_accuracy: 0.9803\n",
            "Epoch 991/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9415e-08 - accuracy: 1.0000 - val_loss: 0.3053 - val_accuracy: 0.9803\n",
            "Epoch 992/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8181e-08 - accuracy: 1.0000 - val_loss: 0.3068 - val_accuracy: 0.9803\n",
            "Epoch 993/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7216e-08 - accuracy: 1.0000 - val_loss: 0.3077 - val_accuracy: 0.9804\n",
            "Epoch 994/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6321e-08 - accuracy: 1.0000 - val_loss: 0.3080 - val_accuracy: 0.9805\n",
            "Epoch 995/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5163e-08 - accuracy: 1.0000 - val_loss: 0.3091 - val_accuracy: 0.9803\n",
            "Epoch 996/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4077e-08 - accuracy: 1.0000 - val_loss: 0.3104 - val_accuracy: 0.9804\n",
            "Epoch 997/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3052e-08 - accuracy: 1.0000 - val_loss: 0.3108 - val_accuracy: 0.9803\n",
            "Epoch 998/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2787e-08 - accuracy: 1.0000 - val_loss: 0.3112 - val_accuracy: 0.9803\n",
            "Epoch 999/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1947e-08 - accuracy: 1.0000 - val_loss: 0.3117 - val_accuracy: 0.9805\n",
            "Epoch 1000/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1092e-08 - accuracy: 1.0000 - val_loss: 0.3130 - val_accuracy: 0.9805\n",
            "Epoch 1001/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0464e-08 - accuracy: 1.0000 - val_loss: 0.3131 - val_accuracy: 0.9804\n",
            "Epoch 1002/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.9315e-09 - accuracy: 1.0000 - val_loss: 0.3149 - val_accuracy: 0.9803\n",
            "Epoch 1003/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1871e-09 - accuracy: 1.0000 - val_loss: 0.3160 - val_accuracy: 0.9804\n",
            "Epoch 1004/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6546e-09 - accuracy: 1.0000 - val_loss: 0.3167 - val_accuracy: 0.9805\n",
            "Epoch 1005/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1672e-09 - accuracy: 1.0000 - val_loss: 0.3171 - val_accuracy: 0.9804\n",
            "Epoch 1006/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6691e-09 - accuracy: 1.0000 - val_loss: 0.3178 - val_accuracy: 0.9805\n",
            "Epoch 1007/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2267e-09 - accuracy: 1.0000 - val_loss: 0.3183 - val_accuracy: 0.9804\n",
            "Epoch 1008/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7923e-09 - accuracy: 1.0000 - val_loss: 0.3193 - val_accuracy: 0.9803\n",
            "Epoch 1009/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4241e-09 - accuracy: 1.0000 - val_loss: 0.3201 - val_accuracy: 0.9804\n",
            "Epoch 1010/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0558e-09 - accuracy: 1.0000 - val_loss: 0.3206 - val_accuracy: 0.9805\n",
            "Epoch 1011/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.6320e-09 - accuracy: 1.0000 - val_loss: 0.3216 - val_accuracy: 0.9805\n",
            "Epoch 1012/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2955e-09 - accuracy: 1.0000 - val_loss: 0.3222 - val_accuracy: 0.9805\n",
            "Epoch 1013/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.9141e-09 - accuracy: 1.0000 - val_loss: 0.3231 - val_accuracy: 0.9805\n",
            "Epoch 1014/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.7048e-09 - accuracy: 1.0000 - val_loss: 0.3239 - val_accuracy: 0.9805\n",
            "Epoch 1015/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4081e-09 - accuracy: 1.0000 - val_loss: 0.3252 - val_accuracy: 0.9805\n",
            "Epoch 1016/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.1087e-09 - accuracy: 1.0000 - val_loss: 0.3253 - val_accuracy: 0.9805\n",
            "Epoch 1017/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9286e-09 - accuracy: 1.0000 - val_loss: 0.3266 - val_accuracy: 0.9804\n",
            "Epoch 1018/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6743e-09 - accuracy: 1.0000 - val_loss: 0.3271 - val_accuracy: 0.9805\n",
            "Epoch 1019/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4915e-09 - accuracy: 1.0000 - val_loss: 0.3281 - val_accuracy: 0.9805\n",
            "Epoch 1020/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2266e-09 - accuracy: 1.0000 - val_loss: 0.3287 - val_accuracy: 0.9805\n",
            "Epoch 1021/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0915e-09 - accuracy: 1.0000 - val_loss: 0.3295 - val_accuracy: 0.9805\n",
            "Epoch 1022/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9008e-09 - accuracy: 1.0000 - val_loss: 0.3303 - val_accuracy: 0.9804\n",
            "Epoch 1023/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7551e-09 - accuracy: 1.0000 - val_loss: 0.3312 - val_accuracy: 0.9804\n",
            "Epoch 1024/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5829e-09 - accuracy: 1.0000 - val_loss: 0.3319 - val_accuracy: 0.9805\n",
            "Epoch 1025/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4160e-09 - accuracy: 1.0000 - val_loss: 0.3328 - val_accuracy: 0.9803\n",
            "Epoch 1026/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2782e-09 - accuracy: 1.0000 - val_loss: 0.3337 - val_accuracy: 0.9806\n",
            "Epoch 1027/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1882e-09 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9804\n",
            "Epoch 1028/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0345e-09 - accuracy: 1.0000 - val_loss: 0.3350 - val_accuracy: 0.9805\n",
            "Epoch 1029/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9126e-09 - accuracy: 1.0000 - val_loss: 0.3358 - val_accuracy: 0.9803\n",
            "Epoch 1030/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8067e-09 - accuracy: 1.0000 - val_loss: 0.3367 - val_accuracy: 0.9805\n",
            "Epoch 1031/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7113e-09 - accuracy: 1.0000 - val_loss: 0.3373 - val_accuracy: 0.9803\n",
            "Epoch 1032/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6477e-09 - accuracy: 1.0000 - val_loss: 0.3382 - val_accuracy: 0.9803\n",
            "Epoch 1033/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5550e-09 - accuracy: 1.0000 - val_loss: 0.3391 - val_accuracy: 0.9802\n",
            "Epoch 1034/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4914e-09 - accuracy: 1.0000 - val_loss: 0.3397 - val_accuracy: 0.9804\n",
            "Epoch 1035/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4014e-09 - accuracy: 1.0000 - val_loss: 0.3400 - val_accuracy: 0.9804\n",
            "Epoch 1036/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2901e-09 - accuracy: 1.0000 - val_loss: 0.3409 - val_accuracy: 0.9804\n",
            "Epoch 1037/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2557e-09 - accuracy: 1.0000 - val_loss: 0.3416 - val_accuracy: 0.9803\n",
            "Epoch 1038/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1630e-09 - accuracy: 1.0000 - val_loss: 0.3426 - val_accuracy: 0.9803\n",
            "Epoch 1039/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0835e-09 - accuracy: 1.0000 - val_loss: 0.3435 - val_accuracy: 0.9804\n",
            "Epoch 1040/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0278e-09 - accuracy: 1.0000 - val_loss: 0.3440 - val_accuracy: 0.9803\n",
            "Epoch 1041/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.8546e-10 - accuracy: 1.0000 - val_loss: 0.3449 - val_accuracy: 0.9802\n",
            "Epoch 1042/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6957e-10 - accuracy: 1.0000 - val_loss: 0.3459 - val_accuracy: 0.9803\n",
            "Epoch 1043/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6361e-10 - accuracy: 1.0000 - val_loss: 0.3465 - val_accuracy: 0.9802\n",
            "Epoch 1044/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3711e-10 - accuracy: 1.0000 - val_loss: 0.3470 - val_accuracy: 0.9802\n",
            "Epoch 1045/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.9738e-10 - accuracy: 1.0000 - val_loss: 0.3480 - val_accuracy: 0.9802\n",
            "Epoch 1046/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6294e-10 - accuracy: 1.0000 - val_loss: 0.3488 - val_accuracy: 0.9802\n",
            "Epoch 1047/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.9671e-10 - accuracy: 1.0000 - val_loss: 0.3497 - val_accuracy: 0.9801\n",
            "Epoch 1048/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.0731e-10 - accuracy: 1.0000 - val_loss: 0.3506 - val_accuracy: 0.9800\n",
            "Epoch 1049/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7552e-10 - accuracy: 1.0000 - val_loss: 0.3514 - val_accuracy: 0.9801\n",
            "Epoch 1050/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2784e-10 - accuracy: 1.0000 - val_loss: 0.3524 - val_accuracy: 0.9801\n",
            "Epoch 1051/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2784e-10 - accuracy: 1.0000 - val_loss: 0.3532 - val_accuracy: 0.9801\n",
            "Epoch 1052/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.0399e-10 - accuracy: 1.0000 - val_loss: 0.3539 - val_accuracy: 0.9800\n",
            "Epoch 1053/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3777e-10 - accuracy: 1.0000 - val_loss: 0.3547 - val_accuracy: 0.9801\n",
            "Epoch 1054/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.2982e-10 - accuracy: 1.0000 - val_loss: 0.3554 - val_accuracy: 0.9801\n",
            "Epoch 1055/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1392e-10 - accuracy: 1.0000 - val_loss: 0.3561 - val_accuracy: 0.9800\n",
            "Epoch 1056/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.8478e-10 - accuracy: 1.0000 - val_loss: 0.3572 - val_accuracy: 0.9799\n",
            "Epoch 1057/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7154e-10 - accuracy: 1.0000 - val_loss: 0.3580 - val_accuracy: 0.9800\n",
            "Epoch 1058/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.6624e-10 - accuracy: 1.0000 - val_loss: 0.3586 - val_accuracy: 0.9799\n",
            "Epoch 1059/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5564e-10 - accuracy: 1.0000 - val_loss: 0.3598 - val_accuracy: 0.9801\n",
            "Epoch 1060/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5300e-10 - accuracy: 1.0000 - val_loss: 0.3603 - val_accuracy: 0.9799\n",
            "Epoch 1061/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1591e-10 - accuracy: 1.0000 - val_loss: 0.3612 - val_accuracy: 0.9800\n",
            "Epoch 1062/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9472e-10 - accuracy: 1.0000 - val_loss: 0.3620 - val_accuracy: 0.9802\n",
            "Epoch 1063/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.9736e-10 - accuracy: 1.0000 - val_loss: 0.3628 - val_accuracy: 0.9800\n",
            "Epoch 1064/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0266e-10 - accuracy: 1.0000 - val_loss: 0.3636 - val_accuracy: 0.9801\n",
            "Epoch 1065/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.9207e-10 - accuracy: 1.0000 - val_loss: 0.3641 - val_accuracy: 0.9801\n",
            "Epoch 1066/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8677e-10 - accuracy: 1.0000 - val_loss: 0.3652 - val_accuracy: 0.9800\n",
            "Epoch 1067/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7617e-10 - accuracy: 1.0000 - val_loss: 0.3657 - val_accuracy: 0.9801\n",
            "Epoch 1068/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7617e-10 - accuracy: 1.0000 - val_loss: 0.3665 - val_accuracy: 0.9800\n",
            "Epoch 1069/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6028e-10 - accuracy: 1.0000 - val_loss: 0.3672 - val_accuracy: 0.9799\n",
            "Epoch 1070/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6028e-10 - accuracy: 1.0000 - val_loss: 0.3677 - val_accuracy: 0.9801\n",
            "Epoch 1071/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7087e-10 - accuracy: 1.0000 - val_loss: 0.3686 - val_accuracy: 0.9802\n",
            "Epoch 1072/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3908e-10 - accuracy: 1.0000 - val_loss: 0.3690 - val_accuracy: 0.9800\n",
            "Epoch 1073/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2849e-10 - accuracy: 1.0000 - val_loss: 0.3696 - val_accuracy: 0.9802\n",
            "Epoch 1074/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5763e-10 - accuracy: 1.0000 - val_loss: 0.3708 - val_accuracy: 0.9801\n",
            "Epoch 1075/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3644e-10 - accuracy: 1.0000 - val_loss: 0.3714 - val_accuracy: 0.9801\n",
            "Epoch 1076/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1789e-10 - accuracy: 1.0000 - val_loss: 0.3718 - val_accuracy: 0.9801\n",
            "Epoch 1077/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3379e-10 - accuracy: 1.0000 - val_loss: 0.3726 - val_accuracy: 0.9801\n",
            "Epoch 1078/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4438e-10 - accuracy: 1.0000 - val_loss: 0.3733 - val_accuracy: 0.9801\n",
            "Epoch 1079/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1789e-10 - accuracy: 1.0000 - val_loss: 0.3737 - val_accuracy: 0.9800\n",
            "Epoch 1080/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4173e-10 - accuracy: 1.0000 - val_loss: 0.3741 - val_accuracy: 0.9801\n",
            "Epoch 1081/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2054e-10 - accuracy: 1.0000 - val_loss: 0.3751 - val_accuracy: 0.9800\n",
            "Epoch 1082/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5233e-10 - accuracy: 1.0000 - val_loss: 0.3756 - val_accuracy: 0.9799\n",
            "Epoch 1083/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3908e-10 - accuracy: 1.0000 - val_loss: 0.3766 - val_accuracy: 0.9801\n",
            "Epoch 1084/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2319e-10 - accuracy: 1.0000 - val_loss: 0.3767 - val_accuracy: 0.9799\n",
            "Epoch 1085/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.5233e-10 - accuracy: 1.0000 - val_loss: 0.3773 - val_accuracy: 0.9798\n",
            "Epoch 1086/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.4968e-10 - accuracy: 1.0000 - val_loss: 0.3786 - val_accuracy: 0.9801\n",
            "Epoch 1087/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2849e-10 - accuracy: 1.0000 - val_loss: 0.3789 - val_accuracy: 0.9800\n",
            "Epoch 1088/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4438e-10 - accuracy: 1.0000 - val_loss: 0.3801 - val_accuracy: 0.9799\n",
            "Epoch 1089/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2849e-10 - accuracy: 1.0000 - val_loss: 0.3804 - val_accuracy: 0.9801\n",
            "Epoch 1090/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2584e-10 - accuracy: 1.0000 - val_loss: 0.3808 - val_accuracy: 0.9801\n",
            "Epoch 1091/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3379e-10 - accuracy: 1.0000 - val_loss: 0.3819 - val_accuracy: 0.9802\n",
            "Epoch 1092/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.5498e-10 - accuracy: 1.0000 - val_loss: 0.3819 - val_accuracy: 0.9799\n",
            "Epoch 1093/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3644e-10 - accuracy: 1.0000 - val_loss: 0.3828 - val_accuracy: 0.9801\n",
            "Epoch 1094/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4968e-10 - accuracy: 1.0000 - val_loss: 0.3835 - val_accuracy: 0.9800\n",
            "Epoch 1095/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.5233e-10 - accuracy: 1.0000 - val_loss: 0.3841 - val_accuracy: 0.9798\n",
            "Epoch 1096/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4968e-10 - accuracy: 1.0000 - val_loss: 0.3844 - val_accuracy: 0.9800\n",
            "Epoch 1097/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4703e-10 - accuracy: 1.0000 - val_loss: 0.3849 - val_accuracy: 0.9798\n",
            "Epoch 1098/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.4173e-10 - accuracy: 1.0000 - val_loss: 0.3859 - val_accuracy: 0.9799\n",
            "Epoch 1099/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3908e-10 - accuracy: 1.0000 - val_loss: 0.3862 - val_accuracy: 0.9801\n",
            "Epoch 1100/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2849e-10 - accuracy: 1.0000 - val_loss: 0.3868 - val_accuracy: 0.9798\n",
            "Epoch 1101/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3908e-10 - accuracy: 1.0000 - val_loss: 0.3870 - val_accuracy: 0.9798\n",
            "Epoch 1102/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6558e-10 - accuracy: 1.0000 - val_loss: 0.3875 - val_accuracy: 0.9798\n",
            "Epoch 1103/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6558e-10 - accuracy: 1.0000 - val_loss: 0.3886 - val_accuracy: 0.9798\n",
            "Epoch 1104/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3379e-10 - accuracy: 1.0000 - val_loss: 0.3885 - val_accuracy: 0.9799\n",
            "Epoch 1105/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3114e-10 - accuracy: 1.0000 - val_loss: 0.3887 - val_accuracy: 0.9798\n",
            "Epoch 1106/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.5763e-10 - accuracy: 1.0000 - val_loss: 0.3898 - val_accuracy: 0.9797\n",
            "Epoch 1107/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3908e-10 - accuracy: 1.0000 - val_loss: 0.3902 - val_accuracy: 0.9797\n",
            "Epoch 1108/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5763e-10 - accuracy: 1.0000 - val_loss: 0.3906 - val_accuracy: 0.9797\n",
            "Epoch 1109/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4703e-10 - accuracy: 1.0000 - val_loss: 0.3911 - val_accuracy: 0.9797\n",
            "Epoch 1110/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1524e-10 - accuracy: 1.0000 - val_loss: 0.3915 - val_accuracy: 0.9797\n",
            "Epoch 1111/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.5233e-10 - accuracy: 1.0000 - val_loss: 0.3925 - val_accuracy: 0.9797\n",
            "Epoch 1112/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4968e-10 - accuracy: 1.0000 - val_loss: 0.3925 - val_accuracy: 0.9799\n",
            "Epoch 1113/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9207e-10 - accuracy: 1.0000 - val_loss: 0.3926 - val_accuracy: 0.9798\n",
            "Epoch 1114/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.9472e-10 - accuracy: 1.0000 - val_loss: 0.3938 - val_accuracy: 0.9795\n",
            "Epoch 1115/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.4703e-10 - accuracy: 1.0000 - val_loss: 0.3942 - val_accuracy: 0.9797\n",
            "Epoch 1116/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6028e-10 - accuracy: 1.0000 - val_loss: 0.3947 - val_accuracy: 0.9796\n",
            "Epoch 1117/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0994e-10 - accuracy: 1.0000 - val_loss: 0.3952 - val_accuracy: 0.9799\n",
            "Epoch 1118/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5763e-10 - accuracy: 1.0000 - val_loss: 0.3963 - val_accuracy: 0.9799\n",
            "Epoch 1119/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.3512e-10 - accuracy: 1.0000 - val_loss: 0.3959 - val_accuracy: 0.9797\n",
            "Epoch 1120/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2849e-10 - accuracy: 1.0000 - val_loss: 0.3966 - val_accuracy: 0.9799\n",
            "Epoch 1121/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1856e-10 - accuracy: 1.0000 - val_loss: 0.3976 - val_accuracy: 0.9798\n",
            "Epoch 1122/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4968e-10 - accuracy: 1.0000 - val_loss: 0.3970 - val_accuracy: 0.9799\n",
            "Epoch 1123/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0994e-10 - accuracy: 1.0000 - val_loss: 0.3977 - val_accuracy: 0.9797\n",
            "Epoch 1124/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.4968e-10 - accuracy: 1.0000 - val_loss: 0.3981 - val_accuracy: 0.9796\n",
            "Epoch 1125/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6558e-10 - accuracy: 1.0000 - val_loss: 0.3982 - val_accuracy: 0.9797\n",
            "Epoch 1126/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1789e-10 - accuracy: 1.0000 - val_loss: 0.3980 - val_accuracy: 0.9795\n",
            "Epoch 1127/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7352e-10 - accuracy: 1.0000 - val_loss: 0.3994 - val_accuracy: 0.9797\n",
            "Epoch 1128/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5763e-10 - accuracy: 1.0000 - val_loss: 0.3998 - val_accuracy: 0.9797\n",
            "Epoch 1129/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.8412e-10 - accuracy: 1.0000 - val_loss: 0.3990 - val_accuracy: 0.9799\n",
            "Epoch 1130/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7617e-10 - accuracy: 1.0000 - val_loss: 0.4009 - val_accuracy: 0.9795\n",
            "Epoch 1131/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8412e-10 - accuracy: 1.0000 - val_loss: 0.4004 - val_accuracy: 0.9797\n",
            "Epoch 1132/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2585e-10 - accuracy: 1.0000 - val_loss: 0.4014 - val_accuracy: 0.9796\n",
            "Epoch 1133/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3180e-10 - accuracy: 1.0000 - val_loss: 0.4018 - val_accuracy: 0.9797\n",
            "Epoch 1134/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8147e-10 - accuracy: 1.0000 - val_loss: 0.4029 - val_accuracy: 0.9797\n",
            "Epoch 1135/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.8942e-10 - accuracy: 1.0000 - val_loss: 0.4017 - val_accuracy: 0.9797\n",
            "Epoch 1136/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0838 - accuracy: 0.9948 - val_loss: 0.9915 - val_accuracy: 0.9580\n",
            "Epoch 1137/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0760 - accuracy: 0.9915 - val_loss: 0.2560 - val_accuracy: 0.9765\n",
            "Epoch 1138/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.2305 - val_accuracy: 0.9783\n",
            "Epoch 1139/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.2259 - val_accuracy: 0.9790\n",
            "Epoch 1140/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0322e-04 - accuracy: 0.9998 - val_loss: 0.2185 - val_accuracy: 0.9791\n",
            "Epoch 1141/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.7335e-05 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9793\n",
            "Epoch 1142/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8638e-05 - accuracy: 1.0000 - val_loss: 0.2200 - val_accuracy: 0.9793\n",
            "Epoch 1143/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4429e-05 - accuracy: 1.0000 - val_loss: 0.2204 - val_accuracy: 0.9791\n",
            "Epoch 1144/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1981e-05 - accuracy: 1.0000 - val_loss: 0.2209 - val_accuracy: 0.9793\n",
            "Epoch 1145/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0406e-05 - accuracy: 1.0000 - val_loss: 0.2216 - val_accuracy: 0.9793\n",
            "Epoch 1146/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8442e-06 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 0.9793\n",
            "Epoch 1147/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7330e-06 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9793\n",
            "Epoch 1148/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7638e-06 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9794\n",
            "Epoch 1149/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.9859e-06 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9794\n",
            "Epoch 1150/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2228e-06 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9794\n",
            "Epoch 1151/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.4720e-06 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9794\n",
            "Epoch 1152/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.8580e-06 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9795\n",
            "Epoch 1153/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3187e-06 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9796\n",
            "Epoch 1154/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7936e-06 - accuracy: 1.0000 - val_loss: 0.2326 - val_accuracy: 0.9797\n",
            "Epoch 1155/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3259e-06 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9794\n",
            "Epoch 1156/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8074e-06 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9797\n",
            "Epoch 1157/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3458e-06 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.9795\n",
            "Epoch 1158/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0508e-06 - accuracy: 1.0000 - val_loss: 0.2546 - val_accuracy: 0.9795\n",
            "Epoch 1159/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.5277e-07 - accuracy: 1.0000 - val_loss: 0.2591 - val_accuracy: 0.9795\n",
            "Epoch 1160/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.0129e-07 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9797\n",
            "Epoch 1161/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8807e-07 - accuracy: 1.0000 - val_loss: 0.2692 - val_accuracy: 0.9799\n",
            "Epoch 1162/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.0858e-07 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9799\n",
            "Epoch 1163/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3491e-07 - accuracy: 1.0000 - val_loss: 0.2766 - val_accuracy: 0.9801\n",
            "Epoch 1164/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7385e-07 - accuracy: 1.0000 - val_loss: 0.2797 - val_accuracy: 0.9799\n",
            "Epoch 1165/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3285e-07 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.9799\n",
            "Epoch 1166/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9684e-07 - accuracy: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.9799\n",
            "Epoch 1167/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6476e-07 - accuracy: 1.0000 - val_loss: 0.2888 - val_accuracy: 0.9799\n",
            "Epoch 1168/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3744e-07 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9801\n",
            "Epoch 1169/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1651e-07 - accuracy: 1.0000 - val_loss: 0.2948 - val_accuracy: 0.9798\n",
            "Epoch 1170/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9897e-07 - accuracy: 1.0000 - val_loss: 0.2966 - val_accuracy: 0.9799\n",
            "Epoch 1171/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8105e-07 - accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 0.9799\n",
            "Epoch 1172/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6718e-07 - accuracy: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.9798\n",
            "Epoch 1173/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5283e-07 - accuracy: 1.0000 - val_loss: 0.3027 - val_accuracy: 0.9799\n",
            "Epoch 1174/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3893e-07 - accuracy: 1.0000 - val_loss: 0.3051 - val_accuracy: 0.9799\n",
            "Epoch 1175/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2830e-07 - accuracy: 1.0000 - val_loss: 0.3068 - val_accuracy: 0.9799\n",
            "Epoch 1176/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1905e-07 - accuracy: 1.0000 - val_loss: 0.3085 - val_accuracy: 0.9799\n",
            "Epoch 1177/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0914e-07 - accuracy: 1.0000 - val_loss: 0.3108 - val_accuracy: 0.9799\n",
            "Epoch 1178/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0100e-07 - accuracy: 1.0000 - val_loss: 0.3116 - val_accuracy: 0.9800\n",
            "Epoch 1179/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.3395e-08 - accuracy: 1.0000 - val_loss: 0.3139 - val_accuracy: 0.9799\n",
            "Epoch 1180/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6709e-08 - accuracy: 1.0000 - val_loss: 0.3161 - val_accuracy: 0.9799\n",
            "Epoch 1181/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1329e-08 - accuracy: 1.0000 - val_loss: 0.3167 - val_accuracy: 0.9799\n",
            "Epoch 1182/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5803e-08 - accuracy: 1.0000 - val_loss: 0.3188 - val_accuracy: 0.9798\n",
            "Epoch 1183/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.9236e-08 - accuracy: 1.0000 - val_loss: 0.3201 - val_accuracy: 0.9799\n",
            "Epoch 1184/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4606e-08 - accuracy: 1.0000 - val_loss: 0.3217 - val_accuracy: 0.9799\n",
            "Epoch 1185/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.0886e-08 - accuracy: 1.0000 - val_loss: 0.3226 - val_accuracy: 0.9799\n",
            "Epoch 1186/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.6092e-08 - accuracy: 1.0000 - val_loss: 0.3244 - val_accuracy: 0.9797\n",
            "Epoch 1187/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.2653e-08 - accuracy: 1.0000 - val_loss: 0.3256 - val_accuracy: 0.9797\n",
            "Epoch 1188/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.9265e-08 - accuracy: 1.0000 - val_loss: 0.3274 - val_accuracy: 0.9798\n",
            "Epoch 1189/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6285e-08 - accuracy: 1.0000 - val_loss: 0.3282 - val_accuracy: 0.9799\n",
            "Epoch 1190/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3879e-08 - accuracy: 1.0000 - val_loss: 0.3292 - val_accuracy: 0.9799\n",
            "Epoch 1191/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0920e-08 - accuracy: 1.0000 - val_loss: 0.3299 - val_accuracy: 0.9798\n",
            "Epoch 1192/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8081e-08 - accuracy: 1.0000 - val_loss: 0.3315 - val_accuracy: 0.9798\n",
            "Epoch 1193/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.5932e-08 - accuracy: 1.0000 - val_loss: 0.3323 - val_accuracy: 0.9798\n",
            "Epoch 1194/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3424e-08 - accuracy: 1.0000 - val_loss: 0.3336 - val_accuracy: 0.9799\n",
            "Epoch 1195/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1442e-08 - accuracy: 1.0000 - val_loss: 0.3351 - val_accuracy: 0.9797\n",
            "Epoch 1196/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9349e-08 - accuracy: 1.0000 - val_loss: 0.3361 - val_accuracy: 0.9798\n",
            "Epoch 1197/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7394e-08 - accuracy: 1.0000 - val_loss: 0.3371 - val_accuracy: 0.9798\n",
            "Epoch 1198/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5860e-08 - accuracy: 1.0000 - val_loss: 0.3375 - val_accuracy: 0.9799\n",
            "Epoch 1199/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4594e-08 - accuracy: 1.0000 - val_loss: 0.3384 - val_accuracy: 0.9798\n",
            "Epoch 1200/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3007e-08 - accuracy: 1.0000 - val_loss: 0.3401 - val_accuracy: 0.9797\n",
            "Epoch 1201/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1463e-08 - accuracy: 1.0000 - val_loss: 0.3410 - val_accuracy: 0.9798\n",
            "Epoch 1202/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0273e-08 - accuracy: 1.0000 - val_loss: 0.3421 - val_accuracy: 0.9799\n",
            "Epoch 1203/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9028e-08 - accuracy: 1.0000 - val_loss: 0.3431 - val_accuracy: 0.9800\n",
            "Epoch 1204/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7805e-08 - accuracy: 1.0000 - val_loss: 0.3442 - val_accuracy: 0.9799\n",
            "Epoch 1205/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7110e-08 - accuracy: 1.0000 - val_loss: 0.3443 - val_accuracy: 0.9798\n",
            "Epoch 1206/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6006e-08 - accuracy: 1.0000 - val_loss: 0.3452 - val_accuracy: 0.9799\n",
            "Epoch 1207/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4967e-08 - accuracy: 1.0000 - val_loss: 0.3463 - val_accuracy: 0.9799\n",
            "Epoch 1208/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4006e-08 - accuracy: 1.0000 - val_loss: 0.3471 - val_accuracy: 0.9797\n",
            "Epoch 1209/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3343e-08 - accuracy: 1.0000 - val_loss: 0.3479 - val_accuracy: 0.9799\n",
            "Epoch 1210/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2480e-08 - accuracy: 1.0000 - val_loss: 0.3488 - val_accuracy: 0.9797\n",
            "Epoch 1211/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1735e-08 - accuracy: 1.0000 - val_loss: 0.3493 - val_accuracy: 0.9797\n",
            "Epoch 1212/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1116e-08 - accuracy: 1.0000 - val_loss: 0.3499 - val_accuracy: 0.9798\n",
            "Epoch 1213/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0464e-08 - accuracy: 1.0000 - val_loss: 0.3511 - val_accuracy: 0.9800\n",
            "Epoch 1214/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.8758e-09 - accuracy: 1.0000 - val_loss: 0.3515 - val_accuracy: 0.9798\n",
            "Epoch 1215/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.3089e-09 - accuracy: 1.0000 - val_loss: 0.3522 - val_accuracy: 0.9799\n",
            "Epoch 1216/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.7341e-09 - accuracy: 1.0000 - val_loss: 0.3532 - val_accuracy: 0.9799\n",
            "Epoch 1217/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2466e-09 - accuracy: 1.0000 - val_loss: 0.3543 - val_accuracy: 0.9799\n",
            "Epoch 1218/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7565e-09 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 0.9799\n",
            "Epoch 1219/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3115e-09 - accuracy: 1.0000 - val_loss: 0.3557 - val_accuracy: 0.9798\n",
            "Epoch 1220/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8982e-09 - accuracy: 1.0000 - val_loss: 0.3561 - val_accuracy: 0.9797\n",
            "Epoch 1221/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5115e-09 - accuracy: 1.0000 - val_loss: 0.3566 - val_accuracy: 0.9798\n",
            "Epoch 1222/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.1353e-09 - accuracy: 1.0000 - val_loss: 0.3576 - val_accuracy: 0.9798\n",
            "Epoch 1223/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8042e-09 - accuracy: 1.0000 - val_loss: 0.3583 - val_accuracy: 0.9797\n",
            "Epoch 1224/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.4836e-09 - accuracy: 1.0000 - val_loss: 0.3591 - val_accuracy: 0.9797\n",
            "Epoch 1225/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1392e-09 - accuracy: 1.0000 - val_loss: 0.3597 - val_accuracy: 0.9797\n",
            "Epoch 1226/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.8399e-09 - accuracy: 1.0000 - val_loss: 0.3607 - val_accuracy: 0.9797\n",
            "Epoch 1227/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5353e-09 - accuracy: 1.0000 - val_loss: 0.3612 - val_accuracy: 0.9797\n",
            "Epoch 1228/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3127e-09 - accuracy: 1.0000 - val_loss: 0.3621 - val_accuracy: 0.9797\n",
            "Epoch 1229/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.0717e-09 - accuracy: 1.0000 - val_loss: 0.3628 - val_accuracy: 0.9798\n",
            "Epoch 1230/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.8120e-09 - accuracy: 1.0000 - val_loss: 0.3636 - val_accuracy: 0.9799\n",
            "Epoch 1231/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.5842e-09 - accuracy: 1.0000 - val_loss: 0.3644 - val_accuracy: 0.9799\n",
            "Epoch 1232/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3644e-09 - accuracy: 1.0000 - val_loss: 0.3653 - val_accuracy: 0.9799\n",
            "Epoch 1233/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1657e-09 - accuracy: 1.0000 - val_loss: 0.3663 - val_accuracy: 0.9798\n",
            "Epoch 1234/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0173e-09 - accuracy: 1.0000 - val_loss: 0.3672 - val_accuracy: 0.9799\n",
            "Epoch 1235/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8054e-09 - accuracy: 1.0000 - val_loss: 0.3679 - val_accuracy: 0.9799\n",
            "Epoch 1236/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6809e-09 - accuracy: 1.0000 - val_loss: 0.3689 - val_accuracy: 0.9799\n",
            "Epoch 1237/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4663e-09 - accuracy: 1.0000 - val_loss: 0.3699 - val_accuracy: 0.9798\n",
            "Epoch 1238/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3180e-09 - accuracy: 1.0000 - val_loss: 0.3711 - val_accuracy: 0.9799\n",
            "Epoch 1239/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1776e-09 - accuracy: 1.0000 - val_loss: 0.3720 - val_accuracy: 0.9799\n",
            "Epoch 1240/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0848e-09 - accuracy: 1.0000 - val_loss: 0.3730 - val_accuracy: 0.9799\n",
            "Epoch 1241/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9391e-09 - accuracy: 1.0000 - val_loss: 0.3742 - val_accuracy: 0.9797\n",
            "Epoch 1242/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8517e-09 - accuracy: 1.0000 - val_loss: 0.3749 - val_accuracy: 0.9799\n",
            "Epoch 1243/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7431e-09 - accuracy: 1.0000 - val_loss: 0.3762 - val_accuracy: 0.9797\n",
            "Epoch 1244/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6822e-09 - accuracy: 1.0000 - val_loss: 0.3770 - val_accuracy: 0.9798\n",
            "Epoch 1245/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5471e-09 - accuracy: 1.0000 - val_loss: 0.3778 - val_accuracy: 0.9799\n",
            "Epoch 1246/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4649e-09 - accuracy: 1.0000 - val_loss: 0.3789 - val_accuracy: 0.9799\n",
            "Epoch 1247/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3722e-09 - accuracy: 1.0000 - val_loss: 0.3800 - val_accuracy: 0.9799\n",
            "Epoch 1248/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2875e-09 - accuracy: 1.0000 - val_loss: 0.3811 - val_accuracy: 0.9799\n",
            "Epoch 1249/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2133e-09 - accuracy: 1.0000 - val_loss: 0.3823 - val_accuracy: 0.9799\n",
            "Epoch 1250/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1259e-09 - accuracy: 1.0000 - val_loss: 0.3838 - val_accuracy: 0.9799\n",
            "Epoch 1251/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0861e-09 - accuracy: 1.0000 - val_loss: 0.3848 - val_accuracy: 0.9798\n",
            "Epoch 1252/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0146e-09 - accuracy: 1.0000 - val_loss: 0.3864 - val_accuracy: 0.9799\n",
            "Epoch 1253/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9341e-10 - accuracy: 1.0000 - val_loss: 0.3877 - val_accuracy: 0.9798\n",
            "Epoch 1254/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.4308e-10 - accuracy: 1.0000 - val_loss: 0.3889 - val_accuracy: 0.9799\n",
            "Epoch 1255/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7420e-10 - accuracy: 1.0000 - val_loss: 0.3902 - val_accuracy: 0.9799\n",
            "Epoch 1256/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2387e-10 - accuracy: 1.0000 - val_loss: 0.3916 - val_accuracy: 0.9799\n",
            "Epoch 1257/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7089e-10 - accuracy: 1.0000 - val_loss: 0.3931 - val_accuracy: 0.9799\n",
            "Epoch 1258/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.1526e-10 - accuracy: 1.0000 - val_loss: 0.3949 - val_accuracy: 0.9798\n",
            "Epoch 1259/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.0201e-10 - accuracy: 1.0000 - val_loss: 0.3963 - val_accuracy: 0.9798\n",
            "Epoch 1260/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6757e-10 - accuracy: 1.0000 - val_loss: 0.3980 - val_accuracy: 0.9797\n",
            "Epoch 1261/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4108e-10 - accuracy: 1.0000 - val_loss: 0.3992 - val_accuracy: 0.9797\n",
            "Epoch 1262/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.0399e-10 - accuracy: 1.0000 - val_loss: 0.4010 - val_accuracy: 0.9797\n",
            "Epoch 1263/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.6161e-10 - accuracy: 1.0000 - val_loss: 0.4027 - val_accuracy: 0.9797\n",
            "Epoch 1264/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3247e-10 - accuracy: 1.0000 - val_loss: 0.4041 - val_accuracy: 0.9797\n",
            "Epoch 1265/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.2452e-10 - accuracy: 1.0000 - val_loss: 0.4058 - val_accuracy: 0.9797\n",
            "Epoch 1266/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.8478e-10 - accuracy: 1.0000 - val_loss: 0.4076 - val_accuracy: 0.9797\n",
            "Epoch 1267/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.8478e-10 - accuracy: 1.0000 - val_loss: 0.4093 - val_accuracy: 0.9797\n",
            "Epoch 1268/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.2650e-10 - accuracy: 1.0000 - val_loss: 0.4114 - val_accuracy: 0.9797\n",
            "Epoch 1269/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2386e-10 - accuracy: 1.0000 - val_loss: 0.4134 - val_accuracy: 0.9797\n",
            "Epoch 1270/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.2121e-10 - accuracy: 1.0000 - val_loss: 0.4149 - val_accuracy: 0.9796\n",
            "Epoch 1271/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8677e-10 - accuracy: 1.0000 - val_loss: 0.4171 - val_accuracy: 0.9796\n",
            "Epoch 1272/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6028e-10 - accuracy: 1.0000 - val_loss: 0.4195 - val_accuracy: 0.9796\n",
            "Epoch 1273/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8677e-10 - accuracy: 1.0000 - val_loss: 0.4210 - val_accuracy: 0.9795\n",
            "Epoch 1274/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6293e-10 - accuracy: 1.0000 - val_loss: 0.4228 - val_accuracy: 0.9796\n",
            "Epoch 1275/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8412e-10 - accuracy: 1.0000 - val_loss: 0.4242 - val_accuracy: 0.9795\n",
            "Epoch 1276/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.7087e-10 - accuracy: 1.0000 - val_loss: 0.4256 - val_accuracy: 0.9795\n",
            "Epoch 1277/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3379e-10 - accuracy: 1.0000 - val_loss: 0.4273 - val_accuracy: 0.9797\n",
            "Epoch 1278/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.7352e-10 - accuracy: 1.0000 - val_loss: 0.4287 - val_accuracy: 0.9795\n",
            "Epoch 1279/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1524e-10 - accuracy: 1.0000 - val_loss: 0.4302 - val_accuracy: 0.9793\n",
            "Epoch 1280/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2584e-10 - accuracy: 1.0000 - val_loss: 0.4321 - val_accuracy: 0.9795\n",
            "Epoch 1281/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0730e-10 - accuracy: 1.0000 - val_loss: 0.4330 - val_accuracy: 0.9793\n",
            "Epoch 1282/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0994e-10 - accuracy: 1.0000 - val_loss: 0.4349 - val_accuracy: 0.9794\n",
            "Epoch 1283/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2584e-10 - accuracy: 1.0000 - val_loss: 0.4361 - val_accuracy: 0.9793\n",
            "Epoch 1284/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9405e-10 - accuracy: 1.0000 - val_loss: 0.4375 - val_accuracy: 0.9794\n",
            "Epoch 1285/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8610e-10 - accuracy: 1.0000 - val_loss: 0.4386 - val_accuracy: 0.9794\n",
            "Epoch 1286/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8610e-10 - accuracy: 1.0000 - val_loss: 0.4397 - val_accuracy: 0.9794\n",
            "Epoch 1287/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5961e-10 - accuracy: 1.0000 - val_loss: 0.4412 - val_accuracy: 0.9794\n",
            "Epoch 1288/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7286e-10 - accuracy: 1.0000 - val_loss: 0.4426 - val_accuracy: 0.9794\n",
            "Epoch 1289/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6756e-10 - accuracy: 1.0000 - val_loss: 0.4438 - val_accuracy: 0.9795\n",
            "Epoch 1290/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7021e-10 - accuracy: 1.0000 - val_loss: 0.4451 - val_accuracy: 0.9795\n",
            "Epoch 1291/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6756e-10 - accuracy: 1.0000 - val_loss: 0.4464 - val_accuracy: 0.9793\n",
            "Epoch 1292/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8345e-10 - accuracy: 1.0000 - val_loss: 0.4477 - val_accuracy: 0.9793\n",
            "Epoch 1293/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4901e-10 - accuracy: 1.0000 - val_loss: 0.4492 - val_accuracy: 0.9794\n",
            "Epoch 1294/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6226e-10 - accuracy: 1.0000 - val_loss: 0.4500 - val_accuracy: 0.9793\n",
            "Epoch 1295/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4637e-10 - accuracy: 1.0000 - val_loss: 0.4510 - val_accuracy: 0.9793\n",
            "Epoch 1296/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4107e-10 - accuracy: 1.0000 - val_loss: 0.4528 - val_accuracy: 0.9794\n",
            "Epoch 1297/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6226e-10 - accuracy: 1.0000 - val_loss: 0.4536 - val_accuracy: 0.9793\n",
            "Epoch 1298/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3577e-10 - accuracy: 1.0000 - val_loss: 0.4552 - val_accuracy: 0.9793\n",
            "Epoch 1299/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3842e-10 - accuracy: 1.0000 - val_loss: 0.4560 - val_accuracy: 0.9793\n",
            "Epoch 1300/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3312e-10 - accuracy: 1.0000 - val_loss: 0.4577 - val_accuracy: 0.9793\n",
            "Epoch 1301/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5961e-10 - accuracy: 1.0000 - val_loss: 0.4583 - val_accuracy: 0.9793\n",
            "Epoch 1302/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6756e-10 - accuracy: 1.0000 - val_loss: 0.4593 - val_accuracy: 0.9793\n",
            "Epoch 1303/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3577e-10 - accuracy: 1.0000 - val_loss: 0.4607 - val_accuracy: 0.9793\n",
            "Epoch 1304/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4372e-10 - accuracy: 1.0000 - val_loss: 0.4610 - val_accuracy: 0.9793\n",
            "Epoch 1305/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2252e-10 - accuracy: 1.0000 - val_loss: 0.4625 - val_accuracy: 0.9793\n",
            "Epoch 1306/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5166e-10 - accuracy: 1.0000 - val_loss: 0.4634 - val_accuracy: 0.9793\n",
            "Epoch 1307/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4107e-10 - accuracy: 1.0000 - val_loss: 0.4645 - val_accuracy: 0.9793\n",
            "Epoch 1308/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4372e-10 - accuracy: 1.0000 - val_loss: 0.4651 - val_accuracy: 0.9793\n",
            "Epoch 1309/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2782e-10 - accuracy: 1.0000 - val_loss: 0.4662 - val_accuracy: 0.9793\n",
            "Epoch 1310/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3312e-10 - accuracy: 1.0000 - val_loss: 0.4663 - val_accuracy: 0.9793\n",
            "Epoch 1311/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3577e-10 - accuracy: 1.0000 - val_loss: 0.4673 - val_accuracy: 0.9793\n",
            "Epoch 1312/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1458e-10 - accuracy: 1.0000 - val_loss: 0.4687 - val_accuracy: 0.9793\n",
            "Epoch 1313/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2782e-10 - accuracy: 1.0000 - val_loss: 0.4695 - val_accuracy: 0.9794\n",
            "Epoch 1314/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1723e-10 - accuracy: 1.0000 - val_loss: 0.4703 - val_accuracy: 0.9794\n",
            "Epoch 1315/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0928e-10 - accuracy: 1.0000 - val_loss: 0.4712 - val_accuracy: 0.9793\n",
            "Epoch 1316/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1193e-10 - accuracy: 1.0000 - val_loss: 0.4724 - val_accuracy: 0.9793\n",
            "Epoch 1317/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3047e-10 - accuracy: 1.0000 - val_loss: 0.4732 - val_accuracy: 0.9793\n",
            "Epoch 1318/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2782e-10 - accuracy: 1.0000 - val_loss: 0.4739 - val_accuracy: 0.9793\n",
            "Epoch 1319/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2782e-10 - accuracy: 1.0000 - val_loss: 0.4749 - val_accuracy: 0.9793\n",
            "Epoch 1320/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2782e-10 - accuracy: 1.0000 - val_loss: 0.4756 - val_accuracy: 0.9792\n",
            "Epoch 1321/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2782e-10 - accuracy: 1.0000 - val_loss: 0.4764 - val_accuracy: 0.9793\n",
            "Epoch 1322/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1723e-10 - accuracy: 1.0000 - val_loss: 0.4772 - val_accuracy: 0.9792\n",
            "Epoch 1323/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2782e-10 - accuracy: 1.0000 - val_loss: 0.4779 - val_accuracy: 0.9791\n",
            "Epoch 1324/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2517e-10 - accuracy: 1.0000 - val_loss: 0.4780 - val_accuracy: 0.9792\n",
            "Epoch 1325/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3047e-10 - accuracy: 1.0000 - val_loss: 0.4797 - val_accuracy: 0.9792\n",
            "Epoch 1326/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0133e-10 - accuracy: 1.0000 - val_loss: 0.4799 - val_accuracy: 0.9793\n",
            "Epoch 1327/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0928e-10 - accuracy: 1.0000 - val_loss: 0.4804 - val_accuracy: 0.9793\n",
            "Epoch 1328/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1458e-10 - accuracy: 1.0000 - val_loss: 0.4810 - val_accuracy: 0.9789\n",
            "Epoch 1329/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2252e-10 - accuracy: 1.0000 - val_loss: 0.4822 - val_accuracy: 0.9793\n",
            "Epoch 1330/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2252e-10 - accuracy: 1.0000 - val_loss: 0.4829 - val_accuracy: 0.9791\n",
            "Epoch 1331/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0663e-10 - accuracy: 1.0000 - val_loss: 0.4829 - val_accuracy: 0.9793\n",
            "Epoch 1332/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3047e-10 - accuracy: 1.0000 - val_loss: 0.4841 - val_accuracy: 0.9791\n",
            "Epoch 1333/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0928e-10 - accuracy: 1.0000 - val_loss: 0.4850 - val_accuracy: 0.9791\n",
            "Epoch 1334/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1987e-10 - accuracy: 1.0000 - val_loss: 0.4852 - val_accuracy: 0.9791\n",
            "Epoch 1335/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2252e-10 - accuracy: 1.0000 - val_loss: 0.4857 - val_accuracy: 0.9791\n",
            "Epoch 1336/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0398e-10 - accuracy: 1.0000 - val_loss: 0.4869 - val_accuracy: 0.9791\n",
            "Epoch 1337/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3047e-10 - accuracy: 1.0000 - val_loss: 0.4867 - val_accuracy: 0.9791\n",
            "Epoch 1338/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0133e-10 - accuracy: 1.0000 - val_loss: 0.4874 - val_accuracy: 0.9791\n",
            "Epoch 1339/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1723e-10 - accuracy: 1.0000 - val_loss: 0.4881 - val_accuracy: 0.9791\n",
            "Epoch 1340/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3577e-10 - accuracy: 1.0000 - val_loss: 0.4881 - val_accuracy: 0.9792\n",
            "Epoch 1341/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3312e-10 - accuracy: 1.0000 - val_loss: 0.4890 - val_accuracy: 0.9791\n",
            "Epoch 1342/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4901e-10 - accuracy: 1.0000 - val_loss: 0.4898 - val_accuracy: 0.9793\n",
            "Epoch 1343/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3577e-10 - accuracy: 1.0000 - val_loss: 0.4903 - val_accuracy: 0.9790\n",
            "Epoch 1344/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2517e-10 - accuracy: 1.0000 - val_loss: 0.4899 - val_accuracy: 0.9791\n",
            "Epoch 1345/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2517e-10 - accuracy: 1.0000 - val_loss: 0.4907 - val_accuracy: 0.9791\n",
            "Epoch 1346/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2782e-10 - accuracy: 1.0000 - val_loss: 0.4907 - val_accuracy: 0.9791\n",
            "Epoch 1347/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2517e-10 - accuracy: 1.0000 - val_loss: 0.4919 - val_accuracy: 0.9791\n",
            "Epoch 1348/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7021e-10 - accuracy: 1.0000 - val_loss: 0.4927 - val_accuracy: 0.9791\n",
            "Epoch 1349/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3577e-10 - accuracy: 1.0000 - val_loss: 0.4930 - val_accuracy: 0.9793\n",
            "Epoch 1350/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5431e-10 - accuracy: 1.0000 - val_loss: 0.4924 - val_accuracy: 0.9789\n",
            "Epoch 1351/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1027 - accuracy: 0.9909 - val_loss: 0.1784 - val_accuracy: 0.9763\n",
            "Epoch 1352/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.1613 - val_accuracy: 0.9793\n",
            "Epoch 1353/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.1833 - val_accuracy: 0.9794\n",
            "Epoch 1354/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.7475e-05 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 0.9800\n",
            "Epoch 1355/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4071e-05 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9803\n",
            "Epoch 1356/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2145e-05 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9804\n",
            "Epoch 1357/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2159e-06 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.9803\n",
            "Epoch 1358/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2253e-06 - accuracy: 1.0000 - val_loss: 0.2189 - val_accuracy: 0.9805\n",
            "Epoch 1359/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.8494e-06 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9808\n",
            "Epoch 1360/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8784e-06 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9808\n",
            "Epoch 1361/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0861e-06 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.9807\n",
            "Epoch 1362/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4700e-06 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9805\n",
            "Epoch 1363/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9961e-06 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 0.9807\n",
            "Epoch 1364/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5753e-06 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9805\n",
            "Epoch 1365/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2333e-06 - accuracy: 1.0000 - val_loss: 0.2529 - val_accuracy: 0.9805\n",
            "Epoch 1366/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7777e-07 - accuracy: 1.0000 - val_loss: 0.2589 - val_accuracy: 0.9804\n",
            "Epoch 1367/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5933e-07 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9805\n",
            "Epoch 1368/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0299e-07 - accuracy: 1.0000 - val_loss: 0.2683 - val_accuracy: 0.9803\n",
            "Epoch 1369/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.9028e-07 - accuracy: 1.0000 - val_loss: 0.2738 - val_accuracy: 0.9804\n",
            "Epoch 1370/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.1265e-07 - accuracy: 1.0000 - val_loss: 0.2791 - val_accuracy: 0.9805\n",
            "Epoch 1371/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3523e-07 - accuracy: 1.0000 - val_loss: 0.2837 - val_accuracy: 0.9805\n",
            "Epoch 1372/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9017e-07 - accuracy: 1.0000 - val_loss: 0.2866 - val_accuracy: 0.9806\n",
            "Epoch 1373/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4567e-07 - accuracy: 1.0000 - val_loss: 0.2904 - val_accuracy: 0.9807\n",
            "Epoch 1374/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1339e-07 - accuracy: 1.0000 - val_loss: 0.2930 - val_accuracy: 0.9808\n",
            "Epoch 1375/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8501e-07 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.9807\n",
            "Epoch 1376/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6908e-07 - accuracy: 1.0000 - val_loss: 0.3007 - val_accuracy: 0.9808\n",
            "Epoch 1377/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5021e-07 - accuracy: 1.0000 - val_loss: 0.3033 - val_accuracy: 0.9808\n",
            "Epoch 1378/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3552e-07 - accuracy: 1.0000 - val_loss: 0.3045 - val_accuracy: 0.9806\n",
            "Epoch 1379/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2204e-07 - accuracy: 1.0000 - val_loss: 0.3080 - val_accuracy: 0.9809\n",
            "Epoch 1380/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1019e-07 - accuracy: 1.0000 - val_loss: 0.3101 - val_accuracy: 0.9807\n",
            "Epoch 1381/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0194e-07 - accuracy: 1.0000 - val_loss: 0.3128 - val_accuracy: 0.9807\n",
            "Epoch 1382/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.3684e-08 - accuracy: 1.0000 - val_loss: 0.3151 - val_accuracy: 0.9807\n",
            "Epoch 1383/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4397e-08 - accuracy: 1.0000 - val_loss: 0.3171 - val_accuracy: 0.9809\n",
            "Epoch 1384/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8937e-08 - accuracy: 1.0000 - val_loss: 0.3181 - val_accuracy: 0.9807\n",
            "Epoch 1385/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.3880e-08 - accuracy: 1.0000 - val_loss: 0.3198 - val_accuracy: 0.9808\n",
            "Epoch 1386/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.7154e-08 - accuracy: 1.0000 - val_loss: 0.3218 - val_accuracy: 0.9807\n",
            "Epoch 1387/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.2179e-08 - accuracy: 1.0000 - val_loss: 0.3248 - val_accuracy: 0.9805\n",
            "Epoch 1388/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8945e-08 - accuracy: 1.0000 - val_loss: 0.3242 - val_accuracy: 0.9806\n",
            "Epoch 1389/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.4356e-08 - accuracy: 1.0000 - val_loss: 0.3277 - val_accuracy: 0.9807\n",
            "Epoch 1390/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.0378e-08 - accuracy: 1.0000 - val_loss: 0.3277 - val_accuracy: 0.9806\n",
            "Epoch 1391/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7344e-08 - accuracy: 1.0000 - val_loss: 0.3300 - val_accuracy: 0.9807\n",
            "Epoch 1392/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5085e-08 - accuracy: 1.0000 - val_loss: 0.3309 - val_accuracy: 0.9806\n",
            "Epoch 1393/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2261e-08 - accuracy: 1.0000 - val_loss: 0.3327 - val_accuracy: 0.9806\n",
            "Epoch 1394/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9323e-08 - accuracy: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.9805\n",
            "Epoch 1395/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8194e-08 - accuracy: 1.0000 - val_loss: 0.3349 - val_accuracy: 0.9804\n",
            "Epoch 1396/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5596e-08 - accuracy: 1.0000 - val_loss: 0.3364 - val_accuracy: 0.9803\n",
            "Epoch 1397/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2523e-08 - accuracy: 1.0000 - val_loss: 0.3364 - val_accuracy: 0.9807\n",
            "Epoch 1398/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1397e-08 - accuracy: 1.0000 - val_loss: 0.3388 - val_accuracy: 0.9803\n",
            "Epoch 1399/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9386e-08 - accuracy: 1.0000 - val_loss: 0.3397 - val_accuracy: 0.9804\n",
            "Epoch 1400/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7593e-08 - accuracy: 1.0000 - val_loss: 0.3408 - val_accuracy: 0.9805\n",
            "Epoch 1401/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5524e-08 - accuracy: 1.0000 - val_loss: 0.3411 - val_accuracy: 0.9805\n",
            "Epoch 1402/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4584e-08 - accuracy: 1.0000 - val_loss: 0.3430 - val_accuracy: 0.9805\n",
            "Epoch 1403/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3076e-08 - accuracy: 1.0000 - val_loss: 0.3456 - val_accuracy: 0.9802\n",
            "Epoch 1404/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1871e-08 - accuracy: 1.0000 - val_loss: 0.3452 - val_accuracy: 0.9805\n",
            "Epoch 1405/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0689e-08 - accuracy: 1.0000 - val_loss: 0.3467 - val_accuracy: 0.9802\n",
            "Epoch 1406/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9646e-08 - accuracy: 1.0000 - val_loss: 0.3472 - val_accuracy: 0.9803\n",
            "Epoch 1407/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8273e-08 - accuracy: 1.0000 - val_loss: 0.3481 - val_accuracy: 0.9805\n",
            "Epoch 1408/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7484e-08 - accuracy: 1.0000 - val_loss: 0.3486 - val_accuracy: 0.9804\n",
            "Epoch 1409/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6753e-08 - accuracy: 1.0000 - val_loss: 0.3500 - val_accuracy: 0.9805\n",
            "Epoch 1410/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5775e-08 - accuracy: 1.0000 - val_loss: 0.3511 - val_accuracy: 0.9805\n",
            "Epoch 1411/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4880e-08 - accuracy: 1.0000 - val_loss: 0.3527 - val_accuracy: 0.9805\n",
            "Epoch 1412/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4016e-08 - accuracy: 1.0000 - val_loss: 0.3529 - val_accuracy: 0.9805\n",
            "Epoch 1413/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3415e-08 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 0.9805\n",
            "Epoch 1414/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2798e-08 - accuracy: 1.0000 - val_loss: 0.3550 - val_accuracy: 0.9804\n",
            "Epoch 1415/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1924e-08 - accuracy: 1.0000 - val_loss: 0.3565 - val_accuracy: 0.9805\n",
            "Epoch 1416/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1388e-08 - accuracy: 1.0000 - val_loss: 0.3575 - val_accuracy: 0.9803\n",
            "Epoch 1417/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0814e-08 - accuracy: 1.0000 - val_loss: 0.3587 - val_accuracy: 0.9805\n",
            "Epoch 1418/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0096e-08 - accuracy: 1.0000 - val_loss: 0.3591 - val_accuracy: 0.9805\n",
            "Epoch 1419/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6877e-09 - accuracy: 1.0000 - val_loss: 0.3601 - val_accuracy: 0.9805\n",
            "Epoch 1420/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9963e-09 - accuracy: 1.0000 - val_loss: 0.3615 - val_accuracy: 0.9805\n",
            "Epoch 1421/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.5619e-09 - accuracy: 1.0000 - val_loss: 0.3623 - val_accuracy: 0.9805\n",
            "Epoch 1422/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1804e-09 - accuracy: 1.0000 - val_loss: 0.3632 - val_accuracy: 0.9804\n",
            "Epoch 1423/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6877e-09 - accuracy: 1.0000 - val_loss: 0.3647 - val_accuracy: 0.9805\n",
            "Epoch 1424/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2824e-09 - accuracy: 1.0000 - val_loss: 0.3651 - val_accuracy: 0.9805\n",
            "Epoch 1425/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.8691e-09 - accuracy: 1.0000 - val_loss: 0.3662 - val_accuracy: 0.9805\n",
            "Epoch 1426/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5539e-09 - accuracy: 1.0000 - val_loss: 0.3671 - val_accuracy: 0.9805\n",
            "Epoch 1427/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1353e-09 - accuracy: 1.0000 - val_loss: 0.3684 - val_accuracy: 0.9805\n",
            "Epoch 1428/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.8280e-09 - accuracy: 1.0000 - val_loss: 0.3694 - val_accuracy: 0.9803\n",
            "Epoch 1429/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5340e-09 - accuracy: 1.0000 - val_loss: 0.3704 - val_accuracy: 0.9803\n",
            "Epoch 1430/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.2796e-09 - accuracy: 1.0000 - val_loss: 0.3716 - val_accuracy: 0.9805\n",
            "Epoch 1431/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9591e-09 - accuracy: 1.0000 - val_loss: 0.3730 - val_accuracy: 0.9804\n",
            "Epoch 1432/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7074e-09 - accuracy: 1.0000 - val_loss: 0.3741 - val_accuracy: 0.9803\n",
            "Epoch 1433/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.4770e-09 - accuracy: 1.0000 - val_loss: 0.3746 - val_accuracy: 0.9803\n",
            "Epoch 1434/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.1352e-09 - accuracy: 1.0000 - val_loss: 0.3755 - val_accuracy: 0.9803\n",
            "Epoch 1435/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.9683e-09 - accuracy: 1.0000 - val_loss: 0.3770 - val_accuracy: 0.9803\n",
            "Epoch 1436/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.7697e-09 - accuracy: 1.0000 - val_loss: 0.3778 - val_accuracy: 0.9803\n",
            "Epoch 1437/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.5789e-09 - accuracy: 1.0000 - val_loss: 0.3786 - val_accuracy: 0.9803\n",
            "Epoch 1438/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3458e-09 - accuracy: 1.0000 - val_loss: 0.3791 - val_accuracy: 0.9804\n",
            "Epoch 1439/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1922e-09 - accuracy: 1.0000 - val_loss: 0.3802 - val_accuracy: 0.9803\n",
            "Epoch 1440/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9961e-09 - accuracy: 1.0000 - val_loss: 0.3814 - val_accuracy: 0.9803\n",
            "Epoch 1441/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8292e-09 - accuracy: 1.0000 - val_loss: 0.3828 - val_accuracy: 0.9803\n",
            "Epoch 1442/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6517e-09 - accuracy: 1.0000 - val_loss: 0.3840 - val_accuracy: 0.9803\n",
            "Epoch 1443/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5060e-09 - accuracy: 1.0000 - val_loss: 0.3857 - val_accuracy: 0.9802\n",
            "Epoch 1444/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3656e-09 - accuracy: 1.0000 - val_loss: 0.3869 - val_accuracy: 0.9802\n",
            "Epoch 1445/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2305e-09 - accuracy: 1.0000 - val_loss: 0.3881 - val_accuracy: 0.9801\n",
            "Epoch 1446/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1034e-09 - accuracy: 1.0000 - val_loss: 0.3893 - val_accuracy: 0.9801\n",
            "Epoch 1447/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9921e-09 - accuracy: 1.0000 - val_loss: 0.3907 - val_accuracy: 0.9801\n",
            "Epoch 1448/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9021e-09 - accuracy: 1.0000 - val_loss: 0.3924 - val_accuracy: 0.9802\n",
            "Epoch 1449/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7908e-09 - accuracy: 1.0000 - val_loss: 0.3937 - val_accuracy: 0.9803\n",
            "Epoch 1450/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7034e-09 - accuracy: 1.0000 - val_loss: 0.3950 - val_accuracy: 0.9803\n",
            "Epoch 1451/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6054e-09 - accuracy: 1.0000 - val_loss: 0.3962 - val_accuracy: 0.9803\n",
            "Epoch 1452/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5020e-09 - accuracy: 1.0000 - val_loss: 0.3975 - val_accuracy: 0.9803\n",
            "Epoch 1453/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4093e-09 - accuracy: 1.0000 - val_loss: 0.3991 - val_accuracy: 0.9803\n",
            "Epoch 1454/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3616e-09 - accuracy: 1.0000 - val_loss: 0.4004 - val_accuracy: 0.9803\n",
            "Epoch 1455/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2716e-09 - accuracy: 1.0000 - val_loss: 0.4019 - val_accuracy: 0.9804\n",
            "Epoch 1456/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2159e-09 - accuracy: 1.0000 - val_loss: 0.4033 - val_accuracy: 0.9804\n",
            "Epoch 1457/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1762e-09 - accuracy: 1.0000 - val_loss: 0.4045 - val_accuracy: 0.9804\n",
            "Epoch 1458/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0967e-09 - accuracy: 1.0000 - val_loss: 0.4058 - val_accuracy: 0.9803\n",
            "Epoch 1459/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0517e-09 - accuracy: 1.0000 - val_loss: 0.4072 - val_accuracy: 0.9804\n",
            "Epoch 1460/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0040e-09 - accuracy: 1.0000 - val_loss: 0.4085 - val_accuracy: 0.9804\n",
            "Epoch 1461/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.5632e-10 - accuracy: 1.0000 - val_loss: 0.4096 - val_accuracy: 0.9804\n",
            "Epoch 1462/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8745e-10 - accuracy: 1.0000 - val_loss: 0.4112 - val_accuracy: 0.9803\n",
            "Epoch 1463/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2122e-10 - accuracy: 1.0000 - val_loss: 0.4127 - val_accuracy: 0.9804\n",
            "Epoch 1464/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7618e-10 - accuracy: 1.0000 - val_loss: 0.4148 - val_accuracy: 0.9803\n",
            "Epoch 1465/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.3115e-10 - accuracy: 1.0000 - val_loss: 0.4169 - val_accuracy: 0.9804\n",
            "Epoch 1466/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.0731e-10 - accuracy: 1.0000 - val_loss: 0.4186 - val_accuracy: 0.9802\n",
            "Epoch 1467/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7287e-10 - accuracy: 1.0000 - val_loss: 0.4205 - val_accuracy: 0.9801\n",
            "Epoch 1468/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6227e-10 - accuracy: 1.0000 - val_loss: 0.4224 - val_accuracy: 0.9803\n",
            "Epoch 1469/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.3048e-10 - accuracy: 1.0000 - val_loss: 0.4244 - val_accuracy: 0.9802\n",
            "Epoch 1470/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 0.4258 - val_accuracy: 0.9800\n",
            "Epoch 1471/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.9075e-10 - accuracy: 1.0000 - val_loss: 0.4279 - val_accuracy: 0.9799\n",
            "Epoch 1472/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7485e-10 - accuracy: 1.0000 - val_loss: 0.4297 - val_accuracy: 0.9799\n",
            "Epoch 1473/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.5101e-10 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.9799\n",
            "Epoch 1474/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.1392e-10 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.9799\n",
            "Epoch 1475/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0598e-10 - accuracy: 1.0000 - val_loss: 0.4350 - val_accuracy: 0.9798\n",
            "Epoch 1476/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.9538e-10 - accuracy: 1.0000 - val_loss: 0.4366 - val_accuracy: 0.9797\n",
            "Epoch 1477/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9803e-10 - accuracy: 1.0000 - val_loss: 0.4383 - val_accuracy: 0.9797\n",
            "Epoch 1478/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.2915e-10 - accuracy: 1.0000 - val_loss: 0.4398 - val_accuracy: 0.9795\n",
            "Epoch 1479/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5035e-10 - accuracy: 1.0000 - val_loss: 0.4415 - val_accuracy: 0.9795\n",
            "Epoch 1480/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.2386e-10 - accuracy: 1.0000 - val_loss: 0.4439 - val_accuracy: 0.9795\n",
            "Epoch 1481/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.4240e-10 - accuracy: 1.0000 - val_loss: 0.4450 - val_accuracy: 0.9794\n",
            "Epoch 1482/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.1326e-10 - accuracy: 1.0000 - val_loss: 0.4470 - val_accuracy: 0.9794\n",
            "Epoch 1483/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0001e-10 - accuracy: 1.0000 - val_loss: 0.4487 - val_accuracy: 0.9794\n",
            "Epoch 1484/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0001e-10 - accuracy: 1.0000 - val_loss: 0.4508 - val_accuracy: 0.9793\n",
            "Epoch 1485/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.0531e-10 - accuracy: 1.0000 - val_loss: 0.4526 - val_accuracy: 0.9795\n",
            "Epoch 1486/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6822e-10 - accuracy: 1.0000 - val_loss: 0.4548 - val_accuracy: 0.9793\n",
            "Epoch 1487/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0531e-10 - accuracy: 1.0000 - val_loss: 0.4557 - val_accuracy: 0.9792\n",
            "Epoch 1488/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.5763e-10 - accuracy: 1.0000 - val_loss: 0.4574 - val_accuracy: 0.9793\n",
            "Epoch 1489/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.7617e-10 - accuracy: 1.0000 - val_loss: 0.4597 - val_accuracy: 0.9793\n",
            "Epoch 1490/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6028e-10 - accuracy: 1.0000 - val_loss: 0.4611 - val_accuracy: 0.9791\n",
            "Epoch 1491/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6822e-10 - accuracy: 1.0000 - val_loss: 0.4632 - val_accuracy: 0.9791\n",
            "Epoch 1492/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6558e-10 - accuracy: 1.0000 - val_loss: 0.4644 - val_accuracy: 0.9791\n",
            "Epoch 1493/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5233e-10 - accuracy: 1.0000 - val_loss: 0.4665 - val_accuracy: 0.9789\n",
            "Epoch 1494/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4703e-10 - accuracy: 1.0000 - val_loss: 0.4671 - val_accuracy: 0.9791\n",
            "Epoch 1495/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0730e-10 - accuracy: 1.0000 - val_loss: 0.4692 - val_accuracy: 0.9791\n",
            "Epoch 1496/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3379e-10 - accuracy: 1.0000 - val_loss: 0.4709 - val_accuracy: 0.9789\n",
            "Epoch 1497/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4173e-10 - accuracy: 1.0000 - val_loss: 0.4719 - val_accuracy: 0.9789\n",
            "Epoch 1498/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0200e-10 - accuracy: 1.0000 - val_loss: 0.4737 - val_accuracy: 0.9789\n",
            "Epoch 1499/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2054e-10 - accuracy: 1.0000 - val_loss: 0.4756 - val_accuracy: 0.9790\n",
            "Epoch 1500/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9405e-10 - accuracy: 1.0000 - val_loss: 0.4773 - val_accuracy: 0.9791\n",
            "Epoch 1501/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0730e-10 - accuracy: 1.0000 - val_loss: 0.4788 - val_accuracy: 0.9788\n",
            "Epoch 1502/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8080e-10 - accuracy: 1.0000 - val_loss: 0.4799 - val_accuracy: 0.9789\n",
            "Epoch 1503/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8610e-10 - accuracy: 1.0000 - val_loss: 0.4816 - val_accuracy: 0.9789\n",
            "Epoch 1504/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0994e-10 - accuracy: 1.0000 - val_loss: 0.4833 - val_accuracy: 0.9788\n",
            "Epoch 1505/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9670e-10 - accuracy: 1.0000 - val_loss: 0.4848 - val_accuracy: 0.9789\n",
            "Epoch 1506/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7286e-10 - accuracy: 1.0000 - val_loss: 0.4864 - val_accuracy: 0.9787\n",
            "Epoch 1507/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0994e-10 - accuracy: 1.0000 - val_loss: 0.4876 - val_accuracy: 0.9789\n",
            "Epoch 1508/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7815e-10 - accuracy: 1.0000 - val_loss: 0.4902 - val_accuracy: 0.9786\n",
            "Epoch 1509/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8610e-10 - accuracy: 1.0000 - val_loss: 0.4908 - val_accuracy: 0.9789\n",
            "Epoch 1510/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9670e-10 - accuracy: 1.0000 - val_loss: 0.4924 - val_accuracy: 0.9789\n",
            "Epoch 1511/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9935e-10 - accuracy: 1.0000 - val_loss: 0.4937 - val_accuracy: 0.9787\n",
            "Epoch 1512/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7551e-10 - accuracy: 1.0000 - val_loss: 0.4963 - val_accuracy: 0.9787\n",
            "Epoch 1513/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9935e-10 - accuracy: 1.0000 - val_loss: 0.4975 - val_accuracy: 0.9788\n",
            "Epoch 1514/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8345e-10 - accuracy: 1.0000 - val_loss: 0.4993 - val_accuracy: 0.9789\n",
            "Epoch 1515/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0200e-10 - accuracy: 1.0000 - val_loss: 0.5000 - val_accuracy: 0.9787\n",
            "Epoch 1516/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9670e-10 - accuracy: 1.0000 - val_loss: 0.5013 - val_accuracy: 0.9786\n",
            "Epoch 1517/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8875e-10 - accuracy: 1.0000 - val_loss: 0.5029 - val_accuracy: 0.9787\n",
            "Epoch 1518/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0994e-10 - accuracy: 1.0000 - val_loss: 0.5042 - val_accuracy: 0.9787\n",
            "Epoch 1519/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0730e-10 - accuracy: 1.0000 - val_loss: 0.5052 - val_accuracy: 0.9791\n",
            "Epoch 1520/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9140e-10 - accuracy: 1.0000 - val_loss: 0.5069 - val_accuracy: 0.9790\n",
            "Epoch 1521/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7021e-10 - accuracy: 1.0000 - val_loss: 0.5079 - val_accuracy: 0.9790\n",
            "Epoch 1522/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7021e-10 - accuracy: 1.0000 - val_loss: 0.5092 - val_accuracy: 0.9788\n",
            "Epoch 1523/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5696e-10 - accuracy: 1.0000 - val_loss: 0.5106 - val_accuracy: 0.9790\n",
            "Epoch 1524/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7815e-10 - accuracy: 1.0000 - val_loss: 0.5120 - val_accuracy: 0.9791\n",
            "Epoch 1525/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9935e-10 - accuracy: 1.0000 - val_loss: 0.5125 - val_accuracy: 0.9789\n",
            "Epoch 1526/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8345e-10 - accuracy: 1.0000 - val_loss: 0.5137 - val_accuracy: 0.9789\n",
            "Epoch 1527/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8610e-10 - accuracy: 1.0000 - val_loss: 0.5149 - val_accuracy: 0.9789\n",
            "Epoch 1528/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4637e-10 - accuracy: 1.0000 - val_loss: 0.5165 - val_accuracy: 0.9791\n",
            "Epoch 1529/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4637e-10 - accuracy: 1.0000 - val_loss: 0.5178 - val_accuracy: 0.9788\n",
            "Epoch 1530/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7551e-10 - accuracy: 1.0000 - val_loss: 0.5181 - val_accuracy: 0.9788\n",
            "Epoch 1531/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4107e-10 - accuracy: 1.0000 - val_loss: 0.5181 - val_accuracy: 0.9789\n",
            "Epoch 1532/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7286e-10 - accuracy: 1.0000 - val_loss: 0.5203 - val_accuracy: 0.9790\n",
            "Epoch 1533/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5696e-10 - accuracy: 1.0000 - val_loss: 0.5210 - val_accuracy: 0.9789\n",
            "Epoch 1534/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5696e-10 - accuracy: 1.0000 - val_loss: 0.5224 - val_accuracy: 0.9790\n",
            "Epoch 1535/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7021e-10 - accuracy: 1.0000 - val_loss: 0.5230 - val_accuracy: 0.9791\n",
            "Epoch 1536/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7551e-10 - accuracy: 1.0000 - val_loss: 0.5242 - val_accuracy: 0.9790\n",
            "Epoch 1537/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4372e-10 - accuracy: 1.0000 - val_loss: 0.5256 - val_accuracy: 0.9790\n",
            "Epoch 1538/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5696e-10 - accuracy: 1.0000 - val_loss: 0.5266 - val_accuracy: 0.9790\n",
            "Epoch 1539/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5431e-10 - accuracy: 1.0000 - val_loss: 0.5269 - val_accuracy: 0.9790\n",
            "Epoch 1540/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9140e-10 - accuracy: 1.0000 - val_loss: 0.5280 - val_accuracy: 0.9789\n",
            "Epoch 1541/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8610e-10 - accuracy: 1.0000 - val_loss: 0.5296 - val_accuracy: 0.9787\n",
            "Epoch 1542/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7815e-10 - accuracy: 1.0000 - val_loss: 0.5294 - val_accuracy: 0.9789\n",
            "Epoch 1543/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7286e-10 - accuracy: 1.0000 - val_loss: 0.5302 - val_accuracy: 0.9789\n",
            "Epoch 1544/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5696e-10 - accuracy: 1.0000 - val_loss: 0.5330 - val_accuracy: 0.9785\n",
            "Epoch 1545/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8610e-10 - accuracy: 1.0000 - val_loss: 0.5333 - val_accuracy: 0.9785\n",
            "Epoch 1546/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6491e-10 - accuracy: 1.0000 - val_loss: 0.5339 - val_accuracy: 0.9788\n",
            "Epoch 1547/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8610e-10 - accuracy: 1.0000 - val_loss: 0.5344 - val_accuracy: 0.9786\n",
            "Epoch 1548/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6226e-10 - accuracy: 1.0000 - val_loss: 0.5353 - val_accuracy: 0.9787\n",
            "Epoch 1549/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3908e-10 - accuracy: 1.0000 - val_loss: 0.5354 - val_accuracy: 0.9788\n",
            "Epoch 1550/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0808 - accuracy: 0.9917 - val_loss: 0.1417 - val_accuracy: 0.9769\n",
            "Epoch 1551/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.1409 - val_accuracy: 0.9773\n",
            "Epoch 1552/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5675e-04 - accuracy: 1.0000 - val_loss: 0.1440 - val_accuracy: 0.9787\n",
            "Epoch 1553/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1753e-04 - accuracy: 1.0000 - val_loss: 0.1500 - val_accuracy: 0.9789\n",
            "Epoch 1554/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8559e-05 - accuracy: 1.0000 - val_loss: 0.1629 - val_accuracy: 0.9795\n",
            "Epoch 1555/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0980e-05 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 0.9795\n",
            "Epoch 1556/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9485e-05 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9795\n",
            "Epoch 1557/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.5512e-06 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9797\n",
            "Epoch 1558/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3674e-06 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9797\n",
            "Epoch 1559/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6933e-06 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9795\n",
            "Epoch 1560/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6779e-06 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9797\n",
            "Epoch 1561/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9322e-06 - accuracy: 1.0000 - val_loss: 0.2282 - val_accuracy: 0.9796\n",
            "Epoch 1562/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4297e-06 - accuracy: 1.0000 - val_loss: 0.2326 - val_accuracy: 0.9795\n",
            "Epoch 1563/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0472e-06 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9796\n",
            "Epoch 1564/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7382e-06 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9795\n",
            "Epoch 1565/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5200e-06 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9795\n",
            "Epoch 1566/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3094e-06 - accuracy: 1.0000 - val_loss: 0.2491 - val_accuracy: 0.9794\n",
            "Epoch 1567/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1474e-06 - accuracy: 1.0000 - val_loss: 0.2523 - val_accuracy: 0.9795\n",
            "Epoch 1568/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0091e-06 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9796\n",
            "Epoch 1569/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.8142e-07 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.9797\n",
            "Epoch 1570/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8709e-07 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9797\n",
            "Epoch 1571/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.9360e-07 - accuracy: 1.0000 - val_loss: 0.2658 - val_accuracy: 0.9795\n",
            "Epoch 1572/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1604e-07 - accuracy: 1.0000 - val_loss: 0.2689 - val_accuracy: 0.9795\n",
            "Epoch 1573/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.5275e-07 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9795\n",
            "Epoch 1574/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9538e-07 - accuracy: 1.0000 - val_loss: 0.2741 - val_accuracy: 0.9795\n",
            "Epoch 1575/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.4762e-07 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9794\n",
            "Epoch 1576/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.0906e-07 - accuracy: 1.0000 - val_loss: 0.2777 - val_accuracy: 0.9794\n",
            "Epoch 1577/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6857e-07 - accuracy: 1.0000 - val_loss: 0.2807 - val_accuracy: 0.9795\n",
            "Epoch 1578/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3494e-07 - accuracy: 1.0000 - val_loss: 0.2832 - val_accuracy: 0.9794\n",
            "Epoch 1579/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0259e-07 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 0.9795\n",
            "Epoch 1580/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7719e-07 - accuracy: 1.0000 - val_loss: 0.2870 - val_accuracy: 0.9795\n",
            "Epoch 1581/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5273e-07 - accuracy: 1.0000 - val_loss: 0.2891 - val_accuracy: 0.9795\n",
            "Epoch 1582/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2905e-07 - accuracy: 1.0000 - val_loss: 0.2914 - val_accuracy: 0.9795\n",
            "Epoch 1583/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0796e-07 - accuracy: 1.0000 - val_loss: 0.2935 - val_accuracy: 0.9794\n",
            "Epoch 1584/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8953e-07 - accuracy: 1.0000 - val_loss: 0.2949 - val_accuracy: 0.9795\n",
            "Epoch 1585/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7511e-07 - accuracy: 1.0000 - val_loss: 0.2968 - val_accuracy: 0.9795\n",
            "Epoch 1586/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6017e-07 - accuracy: 1.0000 - val_loss: 0.2992 - val_accuracy: 0.9793\n",
            "Epoch 1587/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4859e-07 - accuracy: 1.0000 - val_loss: 0.3002 - val_accuracy: 0.9795\n",
            "Epoch 1588/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3622e-07 - accuracy: 1.0000 - val_loss: 0.3016 - val_accuracy: 0.9794\n",
            "Epoch 1589/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2380e-07 - accuracy: 1.0000 - val_loss: 0.3039 - val_accuracy: 0.9795\n",
            "Epoch 1590/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1509e-07 - accuracy: 1.0000 - val_loss: 0.3047 - val_accuracy: 0.9796\n",
            "Epoch 1591/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0760e-07 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 0.9797\n",
            "Epoch 1592/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7676e-08 - accuracy: 1.0000 - val_loss: 0.3081 - val_accuracy: 0.9796\n",
            "Epoch 1593/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0113e-08 - accuracy: 1.0000 - val_loss: 0.3099 - val_accuracy: 0.9796\n",
            "Epoch 1594/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4029e-08 - accuracy: 1.0000 - val_loss: 0.3111 - val_accuracy: 0.9797\n",
            "Epoch 1595/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8065e-08 - accuracy: 1.0000 - val_loss: 0.3125 - val_accuracy: 0.9796\n",
            "Epoch 1596/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1604e-08 - accuracy: 1.0000 - val_loss: 0.3135 - val_accuracy: 0.9796\n",
            "Epoch 1597/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.6404e-08 - accuracy: 1.0000 - val_loss: 0.3158 - val_accuracy: 0.9796\n",
            "Epoch 1598/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1567e-08 - accuracy: 1.0000 - val_loss: 0.3173 - val_accuracy: 0.9796\n",
            "Epoch 1599/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8171e-08 - accuracy: 1.0000 - val_loss: 0.3178 - val_accuracy: 0.9797\n",
            "Epoch 1600/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3289e-08 - accuracy: 1.0000 - val_loss: 0.3192 - val_accuracy: 0.9797\n",
            "Epoch 1601/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.8719e-08 - accuracy: 1.0000 - val_loss: 0.3210 - val_accuracy: 0.9797\n",
            "Epoch 1602/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5723e-08 - accuracy: 1.0000 - val_loss: 0.3225 - val_accuracy: 0.9797\n",
            "Epoch 1603/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2012e-08 - accuracy: 1.0000 - val_loss: 0.3240 - val_accuracy: 0.9797\n",
            "Epoch 1604/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.9445e-08 - accuracy: 1.0000 - val_loss: 0.3245 - val_accuracy: 0.9797\n",
            "Epoch 1605/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6250e-08 - accuracy: 1.0000 - val_loss: 0.3263 - val_accuracy: 0.9798\n",
            "Epoch 1606/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4322e-08 - accuracy: 1.0000 - val_loss: 0.3276 - val_accuracy: 0.9798\n",
            "Epoch 1607/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1866e-08 - accuracy: 1.0000 - val_loss: 0.3285 - val_accuracy: 0.9798\n",
            "Epoch 1608/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9463e-08 - accuracy: 1.0000 - val_loss: 0.3301 - val_accuracy: 0.9798\n",
            "Epoch 1609/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7935e-08 - accuracy: 1.0000 - val_loss: 0.3314 - val_accuracy: 0.9796\n",
            "Epoch 1610/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5548e-08 - accuracy: 1.0000 - val_loss: 0.3326 - val_accuracy: 0.9798\n",
            "Epoch 1611/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3884e-08 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9797\n",
            "Epoch 1612/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2356e-08 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.9797\n",
            "Epoch 1613/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0835e-08 - accuracy: 1.0000 - val_loss: 0.3358 - val_accuracy: 0.9796\n",
            "Epoch 1614/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9635e-08 - accuracy: 1.0000 - val_loss: 0.3368 - val_accuracy: 0.9796\n",
            "Epoch 1615/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8318e-08 - accuracy: 1.0000 - val_loss: 0.3376 - val_accuracy: 0.9798\n",
            "Epoch 1616/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7163e-08 - accuracy: 1.0000 - val_loss: 0.3388 - val_accuracy: 0.9797\n",
            "Epoch 1617/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5921e-08 - accuracy: 1.0000 - val_loss: 0.3402 - val_accuracy: 0.9798\n",
            "Epoch 1618/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4782e-08 - accuracy: 1.0000 - val_loss: 0.3405 - val_accuracy: 0.9798\n",
            "Epoch 1619/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3844e-08 - accuracy: 1.0000 - val_loss: 0.3420 - val_accuracy: 0.9798\n",
            "Epoch 1620/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3028e-08 - accuracy: 1.0000 - val_loss: 0.3431 - val_accuracy: 0.9798\n",
            "Epoch 1621/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2149e-08 - accuracy: 1.0000 - val_loss: 0.3441 - val_accuracy: 0.9799\n",
            "Epoch 1622/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1359e-08 - accuracy: 1.0000 - val_loss: 0.3447 - val_accuracy: 0.9799\n",
            "Epoch 1623/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0686e-08 - accuracy: 1.0000 - val_loss: 0.3458 - val_accuracy: 0.9798\n",
            "Epoch 1624/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.9738e-09 - accuracy: 1.0000 - val_loss: 0.3468 - val_accuracy: 0.9799\n",
            "Epoch 1625/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.3195e-09 - accuracy: 1.0000 - val_loss: 0.3479 - val_accuracy: 0.9798\n",
            "Epoch 1626/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.7367e-09 - accuracy: 1.0000 - val_loss: 0.3489 - val_accuracy: 0.9799\n",
            "Epoch 1627/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.1989e-09 - accuracy: 1.0000 - val_loss: 0.3501 - val_accuracy: 0.9797\n",
            "Epoch 1628/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.6877e-09 - accuracy: 1.0000 - val_loss: 0.3510 - val_accuracy: 0.9797\n",
            "Epoch 1629/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2002e-09 - accuracy: 1.0000 - val_loss: 0.3520 - val_accuracy: 0.9797\n",
            "Epoch 1630/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.7314e-09 - accuracy: 1.0000 - val_loss: 0.3529 - val_accuracy: 0.9797\n",
            "Epoch 1631/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3128e-09 - accuracy: 1.0000 - val_loss: 0.3538 - val_accuracy: 0.9797\n",
            "Epoch 1632/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.9340e-09 - accuracy: 1.0000 - val_loss: 0.3547 - val_accuracy: 0.9797\n",
            "Epoch 1633/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5393e-09 - accuracy: 1.0000 - val_loss: 0.3558 - val_accuracy: 0.9799\n",
            "Epoch 1634/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.2743e-09 - accuracy: 1.0000 - val_loss: 0.3565 - val_accuracy: 0.9799\n",
            "Epoch 1635/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.9326e-09 - accuracy: 1.0000 - val_loss: 0.3575 - val_accuracy: 0.9798\n",
            "Epoch 1636/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6624e-09 - accuracy: 1.0000 - val_loss: 0.3580 - val_accuracy: 0.9798\n",
            "Epoch 1637/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.3896e-09 - accuracy: 1.0000 - val_loss: 0.3590 - val_accuracy: 0.9800\n",
            "Epoch 1638/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0982e-09 - accuracy: 1.0000 - val_loss: 0.3597 - val_accuracy: 0.9800\n",
            "Epoch 1639/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8836e-09 - accuracy: 1.0000 - val_loss: 0.3607 - val_accuracy: 0.9799\n",
            "Epoch 1640/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6505e-09 - accuracy: 1.0000 - val_loss: 0.3611 - val_accuracy: 0.9800\n",
            "Epoch 1641/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.4465e-09 - accuracy: 1.0000 - val_loss: 0.3621 - val_accuracy: 0.9801\n",
            "Epoch 1642/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2134e-09 - accuracy: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.9801\n",
            "Epoch 1643/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0756e-09 - accuracy: 1.0000 - val_loss: 0.3640 - val_accuracy: 0.9800\n",
            "Epoch 1644/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8716e-09 - accuracy: 1.0000 - val_loss: 0.3649 - val_accuracy: 0.9800\n",
            "Epoch 1645/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6888e-09 - accuracy: 1.0000 - val_loss: 0.3661 - val_accuracy: 0.9801\n",
            "Epoch 1646/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5537e-09 - accuracy: 1.0000 - val_loss: 0.3670 - val_accuracy: 0.9801\n",
            "Epoch 1647/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3974e-09 - accuracy: 1.0000 - val_loss: 0.3676 - val_accuracy: 0.9801\n",
            "Epoch 1648/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2676e-09 - accuracy: 1.0000 - val_loss: 0.3687 - val_accuracy: 0.9801\n",
            "Epoch 1649/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1352e-09 - accuracy: 1.0000 - val_loss: 0.3696 - val_accuracy: 0.9801\n",
            "Epoch 1650/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0027e-09 - accuracy: 1.0000 - val_loss: 0.3708 - val_accuracy: 0.9801\n",
            "Epoch 1651/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8729e-09 - accuracy: 1.0000 - val_loss: 0.3720 - val_accuracy: 0.9801\n",
            "Epoch 1652/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7564e-09 - accuracy: 1.0000 - val_loss: 0.3731 - val_accuracy: 0.9801\n",
            "Epoch 1653/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6663e-09 - accuracy: 1.0000 - val_loss: 0.3741 - val_accuracy: 0.9802\n",
            "Epoch 1654/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5656e-09 - accuracy: 1.0000 - val_loss: 0.3753 - val_accuracy: 0.9803\n",
            "Epoch 1655/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4782e-09 - accuracy: 1.0000 - val_loss: 0.3765 - val_accuracy: 0.9803\n",
            "Epoch 1656/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3881e-09 - accuracy: 1.0000 - val_loss: 0.3775 - val_accuracy: 0.9803\n",
            "Epoch 1657/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3113e-09 - accuracy: 1.0000 - val_loss: 0.3788 - val_accuracy: 0.9803\n",
            "Epoch 1658/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1974e-09 - accuracy: 1.0000 - val_loss: 0.3803 - val_accuracy: 0.9803\n",
            "Epoch 1659/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1338e-09 - accuracy: 1.0000 - val_loss: 0.3816 - val_accuracy: 0.9802\n",
            "Epoch 1660/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0755e-09 - accuracy: 1.0000 - val_loss: 0.3830 - val_accuracy: 0.9803\n",
            "Epoch 1661/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0067e-09 - accuracy: 1.0000 - val_loss: 0.3840 - val_accuracy: 0.9803\n",
            "Epoch 1662/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4573e-10 - accuracy: 1.0000 - val_loss: 0.3855 - val_accuracy: 0.9801\n",
            "Epoch 1663/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7155e-10 - accuracy: 1.0000 - val_loss: 0.3871 - val_accuracy: 0.9803\n",
            "Epoch 1664/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1327e-10 - accuracy: 1.0000 - val_loss: 0.3888 - val_accuracy: 0.9804\n",
            "Epoch 1665/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7354e-10 - accuracy: 1.0000 - val_loss: 0.3903 - val_accuracy: 0.9803\n",
            "Epoch 1666/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3380e-10 - accuracy: 1.0000 - val_loss: 0.3917 - val_accuracy: 0.9803\n",
            "Epoch 1667/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.9141e-10 - accuracy: 1.0000 - val_loss: 0.3931 - val_accuracy: 0.9803\n",
            "Epoch 1668/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.6227e-10 - accuracy: 1.0000 - val_loss: 0.3950 - val_accuracy: 0.9802\n",
            "Epoch 1669/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0929e-10 - accuracy: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.9803\n",
            "Epoch 1670/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.9075e-10 - accuracy: 1.0000 - val_loss: 0.3986 - val_accuracy: 0.9801\n",
            "Epoch 1671/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.6161e-10 - accuracy: 1.0000 - val_loss: 0.4003 - val_accuracy: 0.9802\n",
            "Epoch 1672/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5631e-10 - accuracy: 1.0000 - val_loss: 0.4013 - val_accuracy: 0.9801\n",
            "Epoch 1673/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9273e-10 - accuracy: 1.0000 - val_loss: 0.4031 - val_accuracy: 0.9801\n",
            "Epoch 1674/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9803e-10 - accuracy: 1.0000 - val_loss: 0.4048 - val_accuracy: 0.9802\n",
            "Epoch 1675/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6359e-10 - accuracy: 1.0000 - val_loss: 0.4066 - val_accuracy: 0.9802\n",
            "Epoch 1676/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.4770e-10 - accuracy: 1.0000 - val_loss: 0.4085 - val_accuracy: 0.9801\n",
            "Epoch 1677/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4505e-10 - accuracy: 1.0000 - val_loss: 0.4098 - val_accuracy: 0.9801\n",
            "Epoch 1678/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2121e-10 - accuracy: 1.0000 - val_loss: 0.4114 - val_accuracy: 0.9800\n",
            "Epoch 1679/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8412e-10 - accuracy: 1.0000 - val_loss: 0.4131 - val_accuracy: 0.9800\n",
            "Epoch 1680/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9207e-10 - accuracy: 1.0000 - val_loss: 0.4147 - val_accuracy: 0.9801\n",
            "Epoch 1681/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.8412e-10 - accuracy: 1.0000 - val_loss: 0.4163 - val_accuracy: 0.9801\n",
            "Epoch 1682/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5763e-10 - accuracy: 1.0000 - val_loss: 0.4181 - val_accuracy: 0.9801\n",
            "Epoch 1683/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8942e-10 - accuracy: 1.0000 - val_loss: 0.4194 - val_accuracy: 0.9800\n",
            "Epoch 1684/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5498e-10 - accuracy: 1.0000 - val_loss: 0.4205 - val_accuracy: 0.9800\n",
            "Epoch 1685/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3114e-10 - accuracy: 1.0000 - val_loss: 0.4222 - val_accuracy: 0.9801\n",
            "Epoch 1686/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2054e-10 - accuracy: 1.0000 - val_loss: 0.4238 - val_accuracy: 0.9800\n",
            "Epoch 1687/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2584e-10 - accuracy: 1.0000 - val_loss: 0.4252 - val_accuracy: 0.9800\n",
            "Epoch 1688/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9670e-10 - accuracy: 1.0000 - val_loss: 0.4268 - val_accuracy: 0.9800\n",
            "Epoch 1689/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1524e-10 - accuracy: 1.0000 - val_loss: 0.4284 - val_accuracy: 0.9800\n",
            "Epoch 1690/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9935e-10 - accuracy: 1.0000 - val_loss: 0.4298 - val_accuracy: 0.9801\n",
            "Epoch 1691/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7815e-10 - accuracy: 1.0000 - val_loss: 0.4312 - val_accuracy: 0.9801\n",
            "Epoch 1692/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9140e-10 - accuracy: 1.0000 - val_loss: 0.4329 - val_accuracy: 0.9802\n",
            "Epoch 1693/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5431e-10 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.9801\n",
            "Epoch 1694/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9670e-10 - accuracy: 1.0000 - val_loss: 0.4359 - val_accuracy: 0.9802\n",
            "Epoch 1695/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8345e-10 - accuracy: 1.0000 - val_loss: 0.4371 - val_accuracy: 0.9801\n",
            "Epoch 1696/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5431e-10 - accuracy: 1.0000 - val_loss: 0.4386 - val_accuracy: 0.9802\n",
            "Epoch 1697/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9405e-10 - accuracy: 1.0000 - val_loss: 0.4397 - val_accuracy: 0.9801\n",
            "Epoch 1698/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6756e-10 - accuracy: 1.0000 - val_loss: 0.4411 - val_accuracy: 0.9801\n",
            "Epoch 1699/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7021e-10 - accuracy: 1.0000 - val_loss: 0.4428 - val_accuracy: 0.9799\n",
            "Epoch 1700/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6491e-10 - accuracy: 1.0000 - val_loss: 0.4441 - val_accuracy: 0.9801\n",
            "Epoch 1701/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4637e-10 - accuracy: 1.0000 - val_loss: 0.4456 - val_accuracy: 0.9801\n",
            "Epoch 1702/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4637e-10 - accuracy: 1.0000 - val_loss: 0.4470 - val_accuracy: 0.9801\n",
            "Epoch 1703/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4372e-10 - accuracy: 1.0000 - val_loss: 0.4485 - val_accuracy: 0.9801\n",
            "Epoch 1704/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5166e-10 - accuracy: 1.0000 - val_loss: 0.4497 - val_accuracy: 0.9801\n",
            "Epoch 1705/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4901e-10 - accuracy: 1.0000 - val_loss: 0.4512 - val_accuracy: 0.9800\n",
            "Epoch 1706/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5166e-10 - accuracy: 1.0000 - val_loss: 0.4529 - val_accuracy: 0.9801\n",
            "Epoch 1707/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6226e-10 - accuracy: 1.0000 - val_loss: 0.4538 - val_accuracy: 0.9801\n",
            "Epoch 1708/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5961e-10 - accuracy: 1.0000 - val_loss: 0.4548 - val_accuracy: 0.9800\n",
            "Epoch 1709/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1987e-10 - accuracy: 1.0000 - val_loss: 0.4562 - val_accuracy: 0.9801\n",
            "Epoch 1710/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4372e-10 - accuracy: 1.0000 - val_loss: 0.4579 - val_accuracy: 0.9800\n",
            "Epoch 1711/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5166e-10 - accuracy: 1.0000 - val_loss: 0.4591 - val_accuracy: 0.9801\n",
            "Epoch 1712/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3312e-10 - accuracy: 1.0000 - val_loss: 0.4604 - val_accuracy: 0.9801\n",
            "Epoch 1713/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2782e-10 - accuracy: 1.0000 - val_loss: 0.4618 - val_accuracy: 0.9799\n",
            "Epoch 1714/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3577e-10 - accuracy: 1.0000 - val_loss: 0.4629 - val_accuracy: 0.9801\n",
            "Epoch 1715/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3577e-10 - accuracy: 1.0000 - val_loss: 0.4645 - val_accuracy: 0.9800\n",
            "Epoch 1716/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4372e-10 - accuracy: 1.0000 - val_loss: 0.4660 - val_accuracy: 0.9799\n",
            "Epoch 1717/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6756e-10 - accuracy: 1.0000 - val_loss: 0.4668 - val_accuracy: 0.9799\n",
            "Epoch 1718/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2782e-10 - accuracy: 1.0000 - val_loss: 0.4683 - val_accuracy: 0.9799\n",
            "Epoch 1719/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4107e-10 - accuracy: 1.0000 - val_loss: 0.4700 - val_accuracy: 0.9799\n",
            "Epoch 1720/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5696e-10 - accuracy: 1.0000 - val_loss: 0.4711 - val_accuracy: 0.9797\n",
            "Epoch 1721/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3312e-10 - accuracy: 1.0000 - val_loss: 0.4719 - val_accuracy: 0.9797\n",
            "Epoch 1722/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4372e-10 - accuracy: 1.0000 - val_loss: 0.4737 - val_accuracy: 0.9797\n",
            "Epoch 1723/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3577e-10 - accuracy: 1.0000 - val_loss: 0.4749 - val_accuracy: 0.9797\n",
            "Epoch 1724/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1723e-10 - accuracy: 1.0000 - val_loss: 0.4770 - val_accuracy: 0.9797\n",
            "Epoch 1725/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5696e-10 - accuracy: 1.0000 - val_loss: 0.4777 - val_accuracy: 0.9797\n",
            "Epoch 1726/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3577e-10 - accuracy: 1.0000 - val_loss: 0.4798 - val_accuracy: 0.9797\n",
            "Epoch 1727/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5431e-10 - accuracy: 1.0000 - val_loss: 0.4804 - val_accuracy: 0.9797\n",
            "Epoch 1728/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2782e-10 - accuracy: 1.0000 - val_loss: 0.4822 - val_accuracy: 0.9796\n",
            "Epoch 1729/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2517e-10 - accuracy: 1.0000 - val_loss: 0.4834 - val_accuracy: 0.9795\n",
            "Epoch 1730/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2782e-10 - accuracy: 1.0000 - val_loss: 0.4849 - val_accuracy: 0.9794\n",
            "Epoch 1731/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4372e-10 - accuracy: 1.0000 - val_loss: 0.4864 - val_accuracy: 0.9795\n",
            "Epoch 1732/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1458e-10 - accuracy: 1.0000 - val_loss: 0.4876 - val_accuracy: 0.9793\n",
            "Epoch 1733/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3577e-10 - accuracy: 1.0000 - val_loss: 0.4890 - val_accuracy: 0.9796\n",
            "Epoch 1734/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1458e-10 - accuracy: 1.0000 - val_loss: 0.4904 - val_accuracy: 0.9795\n",
            "Epoch 1735/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3577e-10 - accuracy: 1.0000 - val_loss: 0.4914 - val_accuracy: 0.9795\n",
            "Epoch 1736/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3577e-10 - accuracy: 1.0000 - val_loss: 0.4923 - val_accuracy: 0.9793\n",
            "Epoch 1737/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1723e-10 - accuracy: 1.0000 - val_loss: 0.4936 - val_accuracy: 0.9793\n",
            "Epoch 1738/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3312e-10 - accuracy: 1.0000 - val_loss: 0.4956 - val_accuracy: 0.9795\n",
            "Epoch 1739/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3842e-10 - accuracy: 1.0000 - val_loss: 0.4964 - val_accuracy: 0.9794\n",
            "Epoch 1740/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3577e-10 - accuracy: 1.0000 - val_loss: 0.4979 - val_accuracy: 0.9794\n",
            "Epoch 1741/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4372e-10 - accuracy: 1.0000 - val_loss: 0.4993 - val_accuracy: 0.9792\n",
            "Epoch 1742/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3577e-10 - accuracy: 1.0000 - val_loss: 0.5012 - val_accuracy: 0.9793\n",
            "Epoch 1743/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6756e-10 - accuracy: 1.0000 - val_loss: 0.5021 - val_accuracy: 0.9792\n",
            "Epoch 1744/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6756e-10 - accuracy: 1.0000 - val_loss: 0.5032 - val_accuracy: 0.9792\n",
            "Epoch 1745/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3842e-10 - accuracy: 1.0000 - val_loss: 0.5049 - val_accuracy: 0.9793\n",
            "Epoch 1746/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3312e-10 - accuracy: 1.0000 - val_loss: 0.5063 - val_accuracy: 0.9793\n",
            "Epoch 1747/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8080e-10 - accuracy: 1.0000 - val_loss: 0.5068 - val_accuracy: 0.9794\n",
            "Epoch 1748/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3842e-10 - accuracy: 1.0000 - val_loss: 0.5091 - val_accuracy: 0.9792\n",
            "Epoch 1749/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4372e-10 - accuracy: 1.0000 - val_loss: 0.5100 - val_accuracy: 0.9793\n",
            "Epoch 1750/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5961e-10 - accuracy: 1.0000 - val_loss: 0.5107 - val_accuracy: 0.9793\n",
            "Epoch 1751/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7551e-10 - accuracy: 1.0000 - val_loss: 0.5118 - val_accuracy: 0.9793\n",
            "Epoch 1752/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4372e-10 - accuracy: 1.0000 - val_loss: 0.5149 - val_accuracy: 0.9792\n",
            "Epoch 1753/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5166e-10 - accuracy: 1.0000 - val_loss: 0.5156 - val_accuracy: 0.9793\n",
            "Epoch 1754/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1193e-10 - accuracy: 1.0000 - val_loss: 0.5177 - val_accuracy: 0.9791\n",
            "Epoch 1755/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4637e-10 - accuracy: 1.0000 - val_loss: 0.5180 - val_accuracy: 0.9792\n",
            "Epoch 1756/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0272 - accuracy: 0.9982 - val_loss: 1.0148 - val_accuracy: 0.9567\n",
            "Epoch 1757/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0554 - accuracy: 0.9919 - val_loss: 0.1557 - val_accuracy: 0.9782\n",
            "Epoch 1758/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.1601 - val_accuracy: 0.9790\n",
            "Epoch 1759/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3201e-04 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 0.9790\n",
            "Epoch 1760/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4205e-05 - accuracy: 1.0000 - val_loss: 0.1864 - val_accuracy: 0.9791\n",
            "Epoch 1761/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8587e-05 - accuracy: 1.0000 - val_loss: 0.1994 - val_accuracy: 0.9793\n",
            "Epoch 1762/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0701e-05 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9794\n",
            "Epoch 1763/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4602e-06 - accuracy: 1.0000 - val_loss: 0.2251 - val_accuracy: 0.9799\n",
            "Epoch 1764/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.4391e-06 - accuracy: 1.0000 - val_loss: 0.2345 - val_accuracy: 0.9796\n",
            "Epoch 1765/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1264e-06 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9799\n",
            "Epoch 1766/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3688e-06 - accuracy: 1.0000 - val_loss: 0.2471 - val_accuracy: 0.9799\n",
            "Epoch 1767/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8563e-06 - accuracy: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.9799\n",
            "Epoch 1768/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5000e-06 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.9799\n",
            "Epoch 1769/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2869e-06 - accuracy: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.9799\n",
            "Epoch 1770/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0542e-06 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9800\n",
            "Epoch 1771/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2815e-07 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9799\n",
            "Epoch 1772/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8994e-07 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9799\n",
            "Epoch 1773/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.0091e-07 - accuracy: 1.0000 - val_loss: 0.2739 - val_accuracy: 0.9799\n",
            "Epoch 1774/2000\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 6.1968e-07 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9799\n",
            "Epoch 1775/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.4942e-07 - accuracy: 1.0000 - val_loss: 0.2784 - val_accuracy: 0.9801\n",
            "Epoch 1776/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.9795e-07 - accuracy: 1.0000 - val_loss: 0.2796 - val_accuracy: 0.9801\n",
            "Epoch 1777/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5263e-07 - accuracy: 1.0000 - val_loss: 0.2821 - val_accuracy: 0.9799\n",
            "Epoch 1778/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.0986e-07 - accuracy: 1.0000 - val_loss: 0.2837 - val_accuracy: 0.9801\n",
            "Epoch 1779/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6695e-07 - accuracy: 1.0000 - val_loss: 0.2865 - val_accuracy: 0.9801\n",
            "Epoch 1780/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3125e-07 - accuracy: 1.0000 - val_loss: 0.2895 - val_accuracy: 0.9801\n",
            "Epoch 1781/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9795e-07 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.9802\n",
            "Epoch 1782/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6991e-07 - accuracy: 1.0000 - val_loss: 0.2932 - val_accuracy: 0.9803\n",
            "Epoch 1783/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4473e-07 - accuracy: 1.0000 - val_loss: 0.2950 - val_accuracy: 0.9801\n",
            "Epoch 1784/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2284e-07 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.9802\n",
            "Epoch 1785/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0568e-07 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.9802\n",
            "Epoch 1786/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8751e-07 - accuracy: 1.0000 - val_loss: 0.3001 - val_accuracy: 0.9801\n",
            "Epoch 1787/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7255e-07 - accuracy: 1.0000 - val_loss: 0.3014 - val_accuracy: 0.9802\n",
            "Epoch 1788/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5921e-07 - accuracy: 1.0000 - val_loss: 0.3030 - val_accuracy: 0.9803\n",
            "Epoch 1789/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4830e-07 - accuracy: 1.0000 - val_loss: 0.3037 - val_accuracy: 0.9804\n",
            "Epoch 1790/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3608e-07 - accuracy: 1.0000 - val_loss: 0.3058 - val_accuracy: 0.9803\n",
            "Epoch 1791/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2576e-07 - accuracy: 1.0000 - val_loss: 0.3076 - val_accuracy: 0.9801\n",
            "Epoch 1792/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1555e-07 - accuracy: 1.0000 - val_loss: 0.3090 - val_accuracy: 0.9800\n",
            "Epoch 1793/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0715e-07 - accuracy: 1.0000 - val_loss: 0.3106 - val_accuracy: 0.9801\n",
            "Epoch 1794/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0071e-07 - accuracy: 1.0000 - val_loss: 0.3121 - val_accuracy: 0.9801\n",
            "Epoch 1795/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2042e-08 - accuracy: 1.0000 - val_loss: 0.3136 - val_accuracy: 0.9801\n",
            "Epoch 1796/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3888e-08 - accuracy: 1.0000 - val_loss: 0.3147 - val_accuracy: 0.9801\n",
            "Epoch 1797/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8794e-08 - accuracy: 1.0000 - val_loss: 0.3156 - val_accuracy: 0.9800\n",
            "Epoch 1798/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3371e-08 - accuracy: 1.0000 - val_loss: 0.3173 - val_accuracy: 0.9800\n",
            "Epoch 1799/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7188e-08 - accuracy: 1.0000 - val_loss: 0.3192 - val_accuracy: 0.9800\n",
            "Epoch 1800/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.2852e-08 - accuracy: 1.0000 - val_loss: 0.3205 - val_accuracy: 0.9799\n",
            "Epoch 1801/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8115e-08 - accuracy: 1.0000 - val_loss: 0.3217 - val_accuracy: 0.9799\n",
            "Epoch 1802/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.4001e-08 - accuracy: 1.0000 - val_loss: 0.3229 - val_accuracy: 0.9799\n",
            "Epoch 1803/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.1082e-08 - accuracy: 1.0000 - val_loss: 0.3238 - val_accuracy: 0.9799\n",
            "Epoch 1804/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.6822e-08 - accuracy: 1.0000 - val_loss: 0.3252 - val_accuracy: 0.9800\n",
            "Epoch 1805/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.3956e-08 - accuracy: 1.0000 - val_loss: 0.3267 - val_accuracy: 0.9799\n",
            "Epoch 1806/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0777e-08 - accuracy: 1.0000 - val_loss: 0.3278 - val_accuracy: 0.9799\n",
            "Epoch 1807/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8459e-08 - accuracy: 1.0000 - val_loss: 0.3285 - val_accuracy: 0.9800\n",
            "Epoch 1808/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5702e-08 - accuracy: 1.0000 - val_loss: 0.3296 - val_accuracy: 0.9799\n",
            "Epoch 1809/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3201e-08 - accuracy: 1.0000 - val_loss: 0.3312 - val_accuracy: 0.9800\n",
            "Epoch 1810/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0804e-08 - accuracy: 1.0000 - val_loss: 0.3323 - val_accuracy: 0.9800\n",
            "Epoch 1811/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9034e-08 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.9800\n",
            "Epoch 1812/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7140e-08 - accuracy: 1.0000 - val_loss: 0.3348 - val_accuracy: 0.9799\n",
            "Epoch 1813/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5331e-08 - accuracy: 1.0000 - val_loss: 0.3359 - val_accuracy: 0.9800\n",
            "Epoch 1814/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3582e-08 - accuracy: 1.0000 - val_loss: 0.3370 - val_accuracy: 0.9800\n",
            "Epoch 1815/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2017e-08 - accuracy: 1.0000 - val_loss: 0.3381 - val_accuracy: 0.9799\n",
            "Epoch 1816/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0345e-08 - accuracy: 1.0000 - val_loss: 0.3395 - val_accuracy: 0.9800\n",
            "Epoch 1817/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9227e-08 - accuracy: 1.0000 - val_loss: 0.3411 - val_accuracy: 0.9799\n",
            "Epoch 1818/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8144e-08 - accuracy: 1.0000 - val_loss: 0.3417 - val_accuracy: 0.9801\n",
            "Epoch 1819/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6806e-08 - accuracy: 1.0000 - val_loss: 0.3422 - val_accuracy: 0.9800\n",
            "Epoch 1820/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5685e-08 - accuracy: 1.0000 - val_loss: 0.3433 - val_accuracy: 0.9801\n",
            "Epoch 1821/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4565e-08 - accuracy: 1.0000 - val_loss: 0.3443 - val_accuracy: 0.9801\n",
            "Epoch 1822/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3717e-08 - accuracy: 1.0000 - val_loss: 0.3454 - val_accuracy: 0.9800\n",
            "Epoch 1823/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2785e-08 - accuracy: 1.0000 - val_loss: 0.3469 - val_accuracy: 0.9801\n",
            "Epoch 1824/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2072e-08 - accuracy: 1.0000 - val_loss: 0.3479 - val_accuracy: 0.9801\n",
            "Epoch 1825/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1200e-08 - accuracy: 1.0000 - val_loss: 0.3484 - val_accuracy: 0.9801\n",
            "Epoch 1826/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0395e-08 - accuracy: 1.0000 - val_loss: 0.3500 - val_accuracy: 0.9801\n",
            "Epoch 1827/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7858e-09 - accuracy: 1.0000 - val_loss: 0.3508 - val_accuracy: 0.9800\n",
            "Epoch 1828/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.1791e-09 - accuracy: 1.0000 - val_loss: 0.3521 - val_accuracy: 0.9801\n",
            "Epoch 1829/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.5221e-09 - accuracy: 1.0000 - val_loss: 0.3529 - val_accuracy: 0.9799\n",
            "Epoch 1830/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.0374e-09 - accuracy: 1.0000 - val_loss: 0.3539 - val_accuracy: 0.9800\n",
            "Epoch 1831/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.4810e-09 - accuracy: 1.0000 - val_loss: 0.3554 - val_accuracy: 0.9801\n",
            "Epoch 1832/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.9936e-09 - accuracy: 1.0000 - val_loss: 0.3567 - val_accuracy: 0.9800\n",
            "Epoch 1833/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.5088e-09 - accuracy: 1.0000 - val_loss: 0.3575 - val_accuracy: 0.9801\n",
            "Epoch 1834/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0585e-09 - accuracy: 1.0000 - val_loss: 0.3586 - val_accuracy: 0.9801\n",
            "Epoch 1835/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.7141e-09 - accuracy: 1.0000 - val_loss: 0.3598 - val_accuracy: 0.9801\n",
            "Epoch 1836/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.2982e-09 - accuracy: 1.0000 - val_loss: 0.3612 - val_accuracy: 0.9800\n",
            "Epoch 1837/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9724e-09 - accuracy: 1.0000 - val_loss: 0.3621 - val_accuracy: 0.9801\n",
            "Epoch 1838/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6518e-09 - accuracy: 1.0000 - val_loss: 0.3637 - val_accuracy: 0.9801\n",
            "Epoch 1839/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.3763e-09 - accuracy: 1.0000 - val_loss: 0.3647 - val_accuracy: 0.9801\n",
            "Epoch 1840/2000\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 4.0478e-09 - accuracy: 1.0000 - val_loss: 0.3660 - val_accuracy: 0.9801\n",
            "Epoch 1841/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8279e-09 - accuracy: 1.0000 - val_loss: 0.3671 - val_accuracy: 0.9801\n",
            "Epoch 1842/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5763e-09 - accuracy: 1.0000 - val_loss: 0.3682 - val_accuracy: 0.9800\n",
            "Epoch 1843/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3538e-09 - accuracy: 1.0000 - val_loss: 0.3696 - val_accuracy: 0.9800\n",
            "Epoch 1844/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1127e-09 - accuracy: 1.0000 - val_loss: 0.3708 - val_accuracy: 0.9800\n",
            "Epoch 1845/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9643e-09 - accuracy: 1.0000 - val_loss: 0.3719 - val_accuracy: 0.9799\n",
            "Epoch 1846/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7180e-09 - accuracy: 1.0000 - val_loss: 0.3734 - val_accuracy: 0.9799\n",
            "Epoch 1847/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5855e-09 - accuracy: 1.0000 - val_loss: 0.3747 - val_accuracy: 0.9799\n",
            "Epoch 1848/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3895e-09 - accuracy: 1.0000 - val_loss: 0.3763 - val_accuracy: 0.9799\n",
            "Epoch 1849/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2650e-09 - accuracy: 1.0000 - val_loss: 0.3777 - val_accuracy: 0.9799\n",
            "Epoch 1850/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0928e-09 - accuracy: 1.0000 - val_loss: 0.3789 - val_accuracy: 0.9798\n",
            "Epoch 1851/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9683e-09 - accuracy: 1.0000 - val_loss: 0.3805 - val_accuracy: 0.9799\n",
            "Epoch 1852/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8544e-09 - accuracy: 1.0000 - val_loss: 0.3820 - val_accuracy: 0.9801\n",
            "Epoch 1853/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7669e-09 - accuracy: 1.0000 - val_loss: 0.3835 - val_accuracy: 0.9800\n",
            "Epoch 1854/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6265e-09 - accuracy: 1.0000 - val_loss: 0.3849 - val_accuracy: 0.9799\n",
            "Epoch 1855/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5391e-09 - accuracy: 1.0000 - val_loss: 0.3861 - val_accuracy: 0.9801\n",
            "Epoch 1856/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4570e-09 - accuracy: 1.0000 - val_loss: 0.3877 - val_accuracy: 0.9799\n",
            "Epoch 1857/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3590e-09 - accuracy: 1.0000 - val_loss: 0.3888 - val_accuracy: 0.9801\n",
            "Epoch 1858/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2557e-09 - accuracy: 1.0000 - val_loss: 0.3901 - val_accuracy: 0.9801\n",
            "Epoch 1859/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2133e-09 - accuracy: 1.0000 - val_loss: 0.3913 - val_accuracy: 0.9803\n",
            "Epoch 1860/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1365e-09 - accuracy: 1.0000 - val_loss: 0.3927 - val_accuracy: 0.9803\n",
            "Epoch 1861/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0888e-09 - accuracy: 1.0000 - val_loss: 0.3938 - val_accuracy: 0.9803\n",
            "Epoch 1862/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0358e-09 - accuracy: 1.0000 - val_loss: 0.3947 - val_accuracy: 0.9803\n",
            "Epoch 1863/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6427e-10 - accuracy: 1.0000 - val_loss: 0.3958 - val_accuracy: 0.9803\n",
            "Epoch 1864/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7685e-10 - accuracy: 1.0000 - val_loss: 0.3973 - val_accuracy: 0.9803\n",
            "Epoch 1865/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5301e-10 - accuracy: 1.0000 - val_loss: 0.3983 - val_accuracy: 0.9803\n",
            "Epoch 1866/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.1062e-10 - accuracy: 1.0000 - val_loss: 0.3993 - val_accuracy: 0.9803\n",
            "Epoch 1867/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4969e-10 - accuracy: 1.0000 - val_loss: 0.4005 - val_accuracy: 0.9803\n",
            "Epoch 1868/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.9671e-10 - accuracy: 1.0000 - val_loss: 0.4022 - val_accuracy: 0.9802\n",
            "Epoch 1869/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6227e-10 - accuracy: 1.0000 - val_loss: 0.4035 - val_accuracy: 0.9802\n",
            "Epoch 1870/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.1194e-10 - accuracy: 1.0000 - val_loss: 0.4050 - val_accuracy: 0.9802\n",
            "Epoch 1871/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5366e-10 - accuracy: 1.0000 - val_loss: 0.4071 - val_accuracy: 0.9804\n",
            "Epoch 1872/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.2452e-10 - accuracy: 1.0000 - val_loss: 0.4094 - val_accuracy: 0.9804\n",
            "Epoch 1873/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2187e-10 - accuracy: 1.0000 - val_loss: 0.4111 - val_accuracy: 0.9804\n",
            "Epoch 1874/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.6359e-10 - accuracy: 1.0000 - val_loss: 0.4135 - val_accuracy: 0.9804\n",
            "Epoch 1875/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5035e-10 - accuracy: 1.0000 - val_loss: 0.4165 - val_accuracy: 0.9805\n",
            "Epoch 1876/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3445e-10 - accuracy: 1.0000 - val_loss: 0.4187 - val_accuracy: 0.9803\n",
            "Epoch 1877/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.2650e-10 - accuracy: 1.0000 - val_loss: 0.4204 - val_accuracy: 0.9804\n",
            "Epoch 1878/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.8942e-10 - accuracy: 1.0000 - val_loss: 0.4233 - val_accuracy: 0.9804\n",
            "Epoch 1879/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8677e-10 - accuracy: 1.0000 - val_loss: 0.4256 - val_accuracy: 0.9803\n",
            "Epoch 1880/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.8942e-10 - accuracy: 1.0000 - val_loss: 0.4277 - val_accuracy: 0.9803\n",
            "Epoch 1881/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4703e-10 - accuracy: 1.0000 - val_loss: 0.4298 - val_accuracy: 0.9803\n",
            "Epoch 1882/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.4703e-10 - accuracy: 1.0000 - val_loss: 0.4320 - val_accuracy: 0.9805\n",
            "Epoch 1883/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3379e-10 - accuracy: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.9805\n",
            "Epoch 1884/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2319e-10 - accuracy: 1.0000 - val_loss: 0.4363 - val_accuracy: 0.9805\n",
            "Epoch 1885/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8875e-10 - accuracy: 1.0000 - val_loss: 0.4386 - val_accuracy: 0.9804\n",
            "Epoch 1886/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9670e-10 - accuracy: 1.0000 - val_loss: 0.4411 - val_accuracy: 0.9804\n",
            "Epoch 1887/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9670e-10 - accuracy: 1.0000 - val_loss: 0.4428 - val_accuracy: 0.9804\n",
            "Epoch 1888/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8610e-10 - accuracy: 1.0000 - val_loss: 0.4453 - val_accuracy: 0.9803\n",
            "Epoch 1889/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8080e-10 - accuracy: 1.0000 - val_loss: 0.4468 - val_accuracy: 0.9804\n",
            "Epoch 1890/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5696e-10 - accuracy: 1.0000 - val_loss: 0.4485 - val_accuracy: 0.9804\n",
            "Epoch 1891/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5431e-10 - accuracy: 1.0000 - val_loss: 0.4506 - val_accuracy: 0.9805\n",
            "Epoch 1892/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5431e-10 - accuracy: 1.0000 - val_loss: 0.4527 - val_accuracy: 0.9804\n",
            "Epoch 1893/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4901e-10 - accuracy: 1.0000 - val_loss: 0.4543 - val_accuracy: 0.9803\n",
            "Epoch 1894/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3842e-10 - accuracy: 1.0000 - val_loss: 0.4561 - val_accuracy: 0.9804\n",
            "Epoch 1895/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3047e-10 - accuracy: 1.0000 - val_loss: 0.4580 - val_accuracy: 0.9803\n",
            "Epoch 1896/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2252e-10 - accuracy: 1.0000 - val_loss: 0.4598 - val_accuracy: 0.9803\n",
            "Epoch 1897/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1193e-10 - accuracy: 1.0000 - val_loss: 0.4623 - val_accuracy: 0.9803\n",
            "Epoch 1898/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2252e-10 - accuracy: 1.0000 - val_loss: 0.4636 - val_accuracy: 0.9803\n",
            "Epoch 1899/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1723e-10 - accuracy: 1.0000 - val_loss: 0.4655 - val_accuracy: 0.9803\n",
            "Epoch 1900/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0928e-10 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9803\n",
            "Epoch 1901/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0663e-10 - accuracy: 1.0000 - val_loss: 0.4697 - val_accuracy: 0.9803\n",
            "Epoch 1902/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0663e-10 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.9803\n",
            "Epoch 1903/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1193e-10 - accuracy: 1.0000 - val_loss: 0.4733 - val_accuracy: 0.9803\n",
            "Epoch 1904/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0663e-10 - accuracy: 1.0000 - val_loss: 0.4749 - val_accuracy: 0.9802\n",
            "Epoch 1905/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9868e-10 - accuracy: 1.0000 - val_loss: 0.4770 - val_accuracy: 0.9801\n",
            "Epoch 1906/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0398e-10 - accuracy: 1.0000 - val_loss: 0.4788 - val_accuracy: 0.9802\n",
            "Epoch 1907/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9603e-10 - accuracy: 1.0000 - val_loss: 0.4803 - val_accuracy: 0.9801\n",
            "Epoch 1908/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0398e-10 - accuracy: 1.0000 - val_loss: 0.4817 - val_accuracy: 0.9801\n",
            "Epoch 1909/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9073e-10 - accuracy: 1.0000 - val_loss: 0.4835 - val_accuracy: 0.9801\n",
            "Epoch 1910/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9338e-10 - accuracy: 1.0000 - val_loss: 0.4853 - val_accuracy: 0.9801\n",
            "Epoch 1911/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9603e-10 - accuracy: 1.0000 - val_loss: 0.4868 - val_accuracy: 0.9799\n",
            "Epoch 1912/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9073e-10 - accuracy: 1.0000 - val_loss: 0.4885 - val_accuracy: 0.9799\n",
            "Epoch 1913/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8279e-10 - accuracy: 1.0000 - val_loss: 0.4898 - val_accuracy: 0.9799\n",
            "Epoch 1914/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8014e-10 - accuracy: 1.0000 - val_loss: 0.4919 - val_accuracy: 0.9798\n",
            "Epoch 1915/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8279e-10 - accuracy: 1.0000 - val_loss: 0.4935 - val_accuracy: 0.9798\n",
            "Epoch 1916/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9338e-10 - accuracy: 1.0000 - val_loss: 0.4950 - val_accuracy: 0.9798\n",
            "Epoch 1917/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7219e-10 - accuracy: 1.0000 - val_loss: 0.4967 - val_accuracy: 0.9797\n",
            "Epoch 1918/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6689e-10 - accuracy: 1.0000 - val_loss: 0.4979 - val_accuracy: 0.9799\n",
            "Epoch 1919/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6424e-10 - accuracy: 1.0000 - val_loss: 0.5001 - val_accuracy: 0.9797\n",
            "Epoch 1920/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8809e-10 - accuracy: 1.0000 - val_loss: 0.5013 - val_accuracy: 0.9796\n",
            "Epoch 1921/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8014e-10 - accuracy: 1.0000 - val_loss: 0.5020 - val_accuracy: 0.9798\n",
            "Epoch 1922/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7484e-10 - accuracy: 1.0000 - val_loss: 0.5032 - val_accuracy: 0.9798\n",
            "Epoch 1923/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5895e-10 - accuracy: 1.0000 - val_loss: 0.5051 - val_accuracy: 0.9795\n",
            "Epoch 1924/2000\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 1.6159e-10 - accuracy: 1.0000 - val_loss: 0.5065 - val_accuracy: 0.9797\n",
            "Epoch 1925/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8279e-10 - accuracy: 1.0000 - val_loss: 0.5078 - val_accuracy: 0.9795\n",
            "Epoch 1926/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7484e-10 - accuracy: 1.0000 - val_loss: 0.5091 - val_accuracy: 0.9797\n",
            "Epoch 1927/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7749e-10 - accuracy: 1.0000 - val_loss: 0.5110 - val_accuracy: 0.9795\n",
            "Epoch 1928/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6954e-10 - accuracy: 1.0000 - val_loss: 0.5123 - val_accuracy: 0.9795\n",
            "Epoch 1929/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7484e-10 - accuracy: 1.0000 - val_loss: 0.5142 - val_accuracy: 0.9793\n",
            "Epoch 1930/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8279e-10 - accuracy: 1.0000 - val_loss: 0.5153 - val_accuracy: 0.9792\n",
            "Epoch 1931/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7219e-10 - accuracy: 1.0000 - val_loss: 0.5167 - val_accuracy: 0.9793\n",
            "Epoch 1932/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7749e-10 - accuracy: 1.0000 - val_loss: 0.5172 - val_accuracy: 0.9793\n",
            "Epoch 1933/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6424e-10 - accuracy: 1.0000 - val_loss: 0.5190 - val_accuracy: 0.9794\n",
            "Epoch 1934/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7749e-10 - accuracy: 1.0000 - val_loss: 0.5206 - val_accuracy: 0.9793\n",
            "Epoch 1935/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6159e-10 - accuracy: 1.0000 - val_loss: 0.5219 - val_accuracy: 0.9794\n",
            "Epoch 1936/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6424e-10 - accuracy: 1.0000 - val_loss: 0.5236 - val_accuracy: 0.9793\n",
            "Epoch 1937/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8279e-10 - accuracy: 1.0000 - val_loss: 0.5251 - val_accuracy: 0.9793\n",
            "Epoch 1938/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8544e-10 - accuracy: 1.0000 - val_loss: 0.5264 - val_accuracy: 0.9792\n",
            "Epoch 1939/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7484e-10 - accuracy: 1.0000 - val_loss: 0.5271 - val_accuracy: 0.9793\n",
            "Epoch 1940/2000\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 1.6159e-10 - accuracy: 1.0000 - val_loss: 0.5285 - val_accuracy: 0.9793\n",
            "Epoch 1941/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9338e-10 - accuracy: 1.0000 - val_loss: 0.5296 - val_accuracy: 0.9794\n",
            "Epoch 1942/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6689e-10 - accuracy: 1.0000 - val_loss: 0.5305 - val_accuracy: 0.9793\n",
            "Epoch 1943/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5895e-10 - accuracy: 1.0000 - val_loss: 0.5320 - val_accuracy: 0.9792\n",
            "Epoch 1944/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7484e-10 - accuracy: 1.0000 - val_loss: 0.5332 - val_accuracy: 0.9793\n",
            "Epoch 1945/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5630e-10 - accuracy: 1.0000 - val_loss: 0.5345 - val_accuracy: 0.9791\n",
            "Epoch 1946/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4835e-10 - accuracy: 1.0000 - val_loss: 0.5363 - val_accuracy: 0.9792\n",
            "Epoch 1947/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8809e-10 - accuracy: 1.0000 - val_loss: 0.5375 - val_accuracy: 0.9791\n",
            "Epoch 1948/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6954e-10 - accuracy: 1.0000 - val_loss: 0.5392 - val_accuracy: 0.9791\n",
            "Epoch 1949/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8809e-10 - accuracy: 1.0000 - val_loss: 0.5402 - val_accuracy: 0.9791\n",
            "Epoch 1950/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5365e-10 - accuracy: 1.0000 - val_loss: 0.5407 - val_accuracy: 0.9792\n",
            "Epoch 1951/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0663e-10 - accuracy: 1.0000 - val_loss: 0.5430 - val_accuracy: 0.9790\n",
            "Epoch 1952/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8014e-10 - accuracy: 1.0000 - val_loss: 0.5428 - val_accuracy: 0.9791\n",
            "Epoch 1953/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7484e-10 - accuracy: 1.0000 - val_loss: 0.5439 - val_accuracy: 0.9791\n",
            "Epoch 1954/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7749e-10 - accuracy: 1.0000 - val_loss: 0.5458 - val_accuracy: 0.9793\n",
            "Epoch 1955/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6689e-10 - accuracy: 1.0000 - val_loss: 0.5466 - val_accuracy: 0.9791\n",
            "Epoch 1956/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0133e-10 - accuracy: 1.0000 - val_loss: 0.5475 - val_accuracy: 0.9792\n",
            "Epoch 1957/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5100e-10 - accuracy: 1.0000 - val_loss: 0.5475 - val_accuracy: 0.9793\n",
            "Epoch 1958/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9073e-10 - accuracy: 1.0000 - val_loss: 0.5496 - val_accuracy: 0.9792\n",
            "Epoch 1959/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7219e-10 - accuracy: 1.0000 - val_loss: 0.5515 - val_accuracy: 0.9790\n",
            "Epoch 1960/2000\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0627 - accuracy: 0.9917 - val_loss: 0.1701 - val_accuracy: 0.9767\n",
            "Epoch 1961/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.1642 - val_accuracy: 0.9793\n",
            "Epoch 1962/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.4755e-04 - accuracy: 0.9998 - val_loss: 0.1687 - val_accuracy: 0.9795\n",
            "Epoch 1963/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0346e-04 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 0.9797\n",
            "Epoch 1964/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8864e-05 - accuracy: 1.0000 - val_loss: 0.1747 - val_accuracy: 0.9798\n",
            "Epoch 1965/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7587e-05 - accuracy: 1.0000 - val_loss: 0.1767 - val_accuracy: 0.9799\n",
            "Epoch 1966/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2079e-05 - accuracy: 1.0000 - val_loss: 0.1784 - val_accuracy: 0.9799\n",
            "Epoch 1967/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8337e-05 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 0.9800\n",
            "Epoch 1968/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5541e-05 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 0.9799\n",
            "Epoch 1969/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3371e-05 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 0.9799\n",
            "Epoch 1970/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1561e-05 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9798\n",
            "Epoch 1971/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0079e-05 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9799\n",
            "Epoch 1972/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.7788e-06 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9799\n",
            "Epoch 1973/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.7234e-06 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 0.9801\n",
            "Epoch 1974/2000\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 6.7712e-06 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9801\n",
            "Epoch 1975/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.9728e-06 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9803\n",
            "Epoch 1976/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2464e-06 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9803\n",
            "Epoch 1977/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.6012e-06 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9801\n",
            "Epoch 1978/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.0092e-06 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.9801\n",
            "Epoch 1979/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.4905e-06 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.9801\n",
            "Epoch 1980/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0349e-06 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9802\n",
            "Epoch 1981/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6460e-06 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9801\n",
            "Epoch 1982/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2980e-06 - accuracy: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.9800\n",
            "Epoch 1983/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9934e-06 - accuracy: 1.0000 - val_loss: 0.2073 - val_accuracy: 0.9800\n",
            "Epoch 1984/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7356e-06 - accuracy: 1.0000 - val_loss: 0.2097 - val_accuracy: 0.9799\n",
            "Epoch 1985/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5082e-06 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9799\n",
            "Epoch 1986/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3232e-06 - accuracy: 1.0000 - val_loss: 0.2138 - val_accuracy: 0.9800\n",
            "Epoch 1987/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1614e-06 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9799\n",
            "Epoch 1988/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0249e-06 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9799\n",
            "Epoch 1989/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0151e-07 - accuracy: 1.0000 - val_loss: 0.2204 - val_accuracy: 0.9799\n",
            "Epoch 1990/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.9836e-07 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.9800\n",
            "Epoch 1991/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.0754e-07 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9800\n",
            "Epoch 1992/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2756e-07 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 0.9800\n",
            "Epoch 1993/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.5732e-07 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9801\n",
            "Epoch 1994/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.9702e-07 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 0.9801\n",
            "Epoch 1995/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.4388e-07 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9802\n",
            "Epoch 1996/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.9648e-07 - accuracy: 1.0000 - val_loss: 0.2345 - val_accuracy: 0.9802\n",
            "Epoch 1997/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.5381e-07 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9803\n",
            "Epoch 1998/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1638e-07 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 0.9803\n",
            "Epoch 1999/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8210e-07 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9803\n",
            "Epoch 2000/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5319e-07 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9803\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0605 - accuracy: 0.9951\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1814 - accuracy: 0.9828\n",
            "train accuracy :  0.9950833320617676 train loss :  0.06054401770234108\n",
            "test accuracy :  0.9828000068664551  test loss :  0.18144270777702332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf3q8f4Eb2IN"
      },
      "source": [
        "# 은닉층 2개(512/512) &  히 초깃값 (epochs = 12 / 1000 / 2000)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AporfAd2OvOB"
      },
      "source": [
        "# Usage in a Keras layer:\n",
        "initializer = tf.keras.initializers.HeNormal()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        },
        "id": "QuoQu8ccXphD",
        "outputId": "11fd7a7a-4a75-43b5-e0fb-183459c9cb1f"
      },
      "source": [
        "#은닉층 2 & 히초깃값 & epochs = 12\n",
        "model3_1 = models.Sequential([\n",
        "                            Flatten(input_shape = (28, 28)),\n",
        "                            Dense(512, activation= 'relu', kernel_initializer=initializer),\n",
        "                            Dense(512, activation= 'relu', kernel_initializer=initializer),\n",
        "                            Dense(10, activation= 'softmax', kernel_initializer=initializer)\n",
        "                            ])\n",
        "\n",
        "model3_1.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "hist3_1 = model3_1.fit(train_x, train_y, epochs = 12, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "#학습 그래프3\n",
        "plt.plot(hist3_1.history['accuracy'], 'b-')\n",
        "plt.plot(hist3_1.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train3_1 = model3_1.evaluate(train_x, train_y)\n",
        "sc_test3_1 = model3_1.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train3_1[1], \"train loss : \", sc_train3_1[0])\n",
        "print(\"test accuracy : \", sc_test3_1[1], \" test loss : \", sc_test3_1[0])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "176/176 [==============================] - 2s 7ms/step - loss: 0.2900 - accuracy: 0.9167 - val_loss: 0.1483 - val_accuracy: 0.9556\n",
            "Epoch 2/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0977 - accuracy: 0.9714 - val_loss: 0.1199 - val_accuracy: 0.9632\n",
            "Epoch 3/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0598 - accuracy: 0.9822 - val_loss: 0.0940 - val_accuracy: 0.9721\n",
            "Epoch 4/12\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0401 - accuracy: 0.9880 - val_loss: 0.0918 - val_accuracy: 0.9716\n",
            "Epoch 5/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0262 - accuracy: 0.9916 - val_loss: 0.0846 - val_accuracy: 0.9755\n",
            "Epoch 6/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 0.0975 - val_accuracy: 0.9737\n",
            "Epoch 7/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.0992 - val_accuracy: 0.9745\n",
            "Epoch 8/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0979 - val_accuracy: 0.9752\n",
            "Epoch 9/12\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.1009 - val_accuracy: 0.9756\n",
            "Epoch 10/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.0951 - val_accuracy: 0.9778\n",
            "Epoch 11/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0976 - val_accuracy: 0.9779\n",
            "Epoch 12/12\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.1314 - val_accuracy: 0.9714\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0469 - accuracy: 0.9880\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1022 - accuracy: 0.9730\n",
            "train accuracy :  0.9879666566848755 train loss :  0.04692676663398743\n",
            "test accuracy :  0.9729999899864197  test loss :  0.10215163230895996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fGSpV2Om7gt"
      },
      "source": [
        "#은닉층 2 & 히초깃값 & epochs = 120\n",
        "model3_2 = models.Sequential([\n",
        "                            Flatten(input_shape = (28, 28)),\n",
        "                            Dense(512, activation= 'relu', kernel_initializer=initializer),\n",
        "                            Dense(512, activation= 'relu', kernel_initializer=initializer),\n",
        "                            Dense(10, activation= 'softmax', kernel_initializer=initializer)\n",
        "                            ])\n",
        "\n",
        "model3_2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "hist3_2 = model3_2.fit(train_x, train_y, epochs = 120, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "#학습 그래프3\n",
        "plt.plot(hist3_2.history['accuracy'], 'b-')\n",
        "plt.plot(hist3_2.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train3_2 = model3_2.evaluate(train_x, train_y)\n",
        "sc_test3_2 = model3_2.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train3_2[1], \"train loss : \", sc_train3_2[0])\n",
        "print(\"test accuracy : \", sc_test3_2[1], \" test loss : \", sc_test3_2[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hbGowW28_2h_",
        "outputId": "1775c87a-fe4b-4bb9-bb2e-94ceadd2ccfb"
      },
      "source": [
        "#은닉층 2개 & epochs= 1000\n",
        "model3_3 = models.Sequential([\n",
        "                            Flatten(input_shape = (28, 28)),\n",
        "                            Dense(512, activation= 'relu', kernel_initializer=initializer),\n",
        "                            Dense(512, activation= 'relu', kernel_initializer=initializer),\n",
        "                            Dense(10, activation= 'softmax', kernel_initializer=initializer)\n",
        "                            ])\n",
        "\n",
        "model3_3.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "#신경망 학습 3_3\n",
        "hist3_3 = model3_3.fit(train_x, train_y, epochs = 1000, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "plt.plot(hist3_3.history['accuracy'], 'b-')\n",
        "plt.plot(hist3_3.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train3_3 = model3_3.evaluate(train_x, train_y)\n",
        "sc_test3_3 = model3_3.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train3_3[1], \"train loss : \", sc_train3_3[0])\n",
        "print(\"test accuracy : \", sc_test3_3[1], \" test loss : \", sc_test3_3[0])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "176/176 [==============================] - 2s 7ms/step - loss: 0.2894 - accuracy: 0.9146 - val_loss: 0.1496 - val_accuracy: 0.9585\n",
            "Epoch 2/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.1051 - accuracy: 0.9687 - val_loss: 0.1169 - val_accuracy: 0.9653\n",
            "Epoch 3/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0618 - accuracy: 0.9818 - val_loss: 0.0935 - val_accuracy: 0.9717\n",
            "Epoch 4/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0393 - accuracy: 0.9884 - val_loss: 0.1037 - val_accuracy: 0.9711\n",
            "Epoch 5/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0276 - accuracy: 0.9918 - val_loss: 0.0871 - val_accuracy: 0.9745\n",
            "Epoch 6/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0190 - accuracy: 0.9947 - val_loss: 0.0862 - val_accuracy: 0.9747\n",
            "Epoch 7/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.0849 - val_accuracy: 0.9769\n",
            "Epoch 8/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.1053 - val_accuracy: 0.9725\n",
            "Epoch 9/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.0913 - val_accuracy: 0.9768\n",
            "Epoch 10/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.0998 - val_accuracy: 0.9771\n",
            "Epoch 11/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.1111 - val_accuracy: 0.9759\n",
            "Epoch 12/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 0.1106 - val_accuracy: 0.9745\n",
            "Epoch 13/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0113 - accuracy: 0.9962 - val_loss: 0.1118 - val_accuracy: 0.9745\n",
            "Epoch 14/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1025 - val_accuracy: 0.9782\n",
            "Epoch 15/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.1049 - val_accuracy: 0.9776\n",
            "Epoch 16/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0122 - accuracy: 0.9965 - val_loss: 0.1092 - val_accuracy: 0.9761\n",
            "Epoch 17/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.1250 - val_accuracy: 0.9734\n",
            "Epoch 18/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.1112 - val_accuracy: 0.9778\n",
            "Epoch 19/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0982 - val_accuracy: 0.9797\n",
            "Epoch 20/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1417e-04 - accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 0.9803\n",
            "Epoch 21/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2363e-05 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9806\n",
            "Epoch 22/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3096e-05 - accuracy: 1.0000 - val_loss: 0.1026 - val_accuracy: 0.9805\n",
            "Epoch 23/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1626e-05 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9808\n",
            "Epoch 24/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3687e-05 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9807\n",
            "Epoch 25/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7648e-05 - accuracy: 1.0000 - val_loss: 0.1056 - val_accuracy: 0.9805\n",
            "Epoch 26/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3063e-05 - accuracy: 1.0000 - val_loss: 0.1069 - val_accuracy: 0.9809\n",
            "Epoch 27/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9106e-05 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 0.9812\n",
            "Epoch 28/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5880e-05 - accuracy: 1.0000 - val_loss: 0.1089 - val_accuracy: 0.9809\n",
            "Epoch 29/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3173e-05 - accuracy: 1.0000 - val_loss: 0.1095 - val_accuracy: 0.9809\n",
            "Epoch 30/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0818e-05 - accuracy: 1.0000 - val_loss: 0.1105 - val_accuracy: 0.9811\n",
            "Epoch 31/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8794e-05 - accuracy: 1.0000 - val_loss: 0.1116 - val_accuracy: 0.9811\n",
            "Epoch 32/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7002e-05 - accuracy: 1.0000 - val_loss: 0.1122 - val_accuracy: 0.9811\n",
            "Epoch 33/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5473e-05 - accuracy: 1.0000 - val_loss: 0.1131 - val_accuracy: 0.9811\n",
            "Epoch 34/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4020e-05 - accuracy: 1.0000 - val_loss: 0.1139 - val_accuracy: 0.9811\n",
            "Epoch 35/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2818e-05 - accuracy: 1.0000 - val_loss: 0.1149 - val_accuracy: 0.9811\n",
            "Epoch 36/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1654e-05 - accuracy: 1.0000 - val_loss: 0.1155 - val_accuracy: 0.9813\n",
            "Epoch 37/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0713e-05 - accuracy: 1.0000 - val_loss: 0.1165 - val_accuracy: 0.9813\n",
            "Epoch 38/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.7183e-06 - accuracy: 1.0000 - val_loss: 0.1171 - val_accuracy: 0.9814\n",
            "Epoch 39/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.9772e-06 - accuracy: 1.0000 - val_loss: 0.1183 - val_accuracy: 0.9811\n",
            "Epoch 40/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.1782e-06 - accuracy: 1.0000 - val_loss: 0.1188 - val_accuracy: 0.9813\n",
            "Epoch 41/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.5161e-06 - accuracy: 1.0000 - val_loss: 0.1198 - val_accuracy: 0.9814\n",
            "Epoch 42/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.9105e-06 - accuracy: 1.0000 - val_loss: 0.1204 - val_accuracy: 0.9815\n",
            "Epoch 43/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.3320e-06 - accuracy: 1.0000 - val_loss: 0.1210 - val_accuracy: 0.9815\n",
            "Epoch 44/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8148e-06 - accuracy: 1.0000 - val_loss: 0.1219 - val_accuracy: 0.9815\n",
            "Epoch 45/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3451e-06 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 0.9813\n",
            "Epoch 46/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.9032e-06 - accuracy: 1.0000 - val_loss: 0.1236 - val_accuracy: 0.9812\n",
            "Epoch 47/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.5373e-06 - accuracy: 1.0000 - val_loss: 0.1242 - val_accuracy: 0.9816\n",
            "Epoch 48/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.1564e-06 - accuracy: 1.0000 - val_loss: 0.1249 - val_accuracy: 0.9817\n",
            "Epoch 49/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.8157e-06 - accuracy: 1.0000 - val_loss: 0.1260 - val_accuracy: 0.9811\n",
            "Epoch 50/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.5240e-06 - accuracy: 1.0000 - val_loss: 0.1264 - val_accuracy: 0.9815\n",
            "Epoch 51/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.2470e-06 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9812\n",
            "Epoch 52/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9968e-06 - accuracy: 1.0000 - val_loss: 0.1281 - val_accuracy: 0.9815\n",
            "Epoch 53/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7281e-06 - accuracy: 1.0000 - val_loss: 0.1287 - val_accuracy: 0.9813\n",
            "Epoch 54/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5242e-06 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9815\n",
            "Epoch 55/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3147e-06 - accuracy: 1.0000 - val_loss: 0.1300 - val_accuracy: 0.9814\n",
            "Epoch 56/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1410e-06 - accuracy: 1.0000 - val_loss: 0.1312 - val_accuracy: 0.9816\n",
            "Epoch 57/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9619e-06 - accuracy: 1.0000 - val_loss: 0.1316 - val_accuracy: 0.9813\n",
            "Epoch 58/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8002e-06 - accuracy: 1.0000 - val_loss: 0.1325 - val_accuracy: 0.9815\n",
            "Epoch 59/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6620e-06 - accuracy: 1.0000 - val_loss: 0.1333 - val_accuracy: 0.9815\n",
            "Epoch 60/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5287e-06 - accuracy: 1.0000 - val_loss: 0.1338 - val_accuracy: 0.9815\n",
            "Epoch 61/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3995e-06 - accuracy: 1.0000 - val_loss: 0.1346 - val_accuracy: 0.9815\n",
            "Epoch 62/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2868e-06 - accuracy: 1.0000 - val_loss: 0.1356 - val_accuracy: 0.9815\n",
            "Epoch 63/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1876e-06 - accuracy: 1.0000 - val_loss: 0.1362 - val_accuracy: 0.9817\n",
            "Epoch 64/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0818e-06 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.9817\n",
            "Epoch 65/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0041e-06 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9817\n",
            "Epoch 66/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.1830e-07 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9814\n",
            "Epoch 67/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4484e-07 - accuracy: 1.0000 - val_loss: 0.1393 - val_accuracy: 0.9816\n",
            "Epoch 68/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.7110e-07 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.9815\n",
            "Epoch 69/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.1174e-07 - accuracy: 1.0000 - val_loss: 0.1407 - val_accuracy: 0.9817\n",
            "Epoch 70/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5699e-07 - accuracy: 1.0000 - val_loss: 0.1412 - val_accuracy: 0.9815\n",
            "Epoch 71/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.9525e-07 - accuracy: 1.0000 - val_loss: 0.1425 - val_accuracy: 0.9817\n",
            "Epoch 72/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5088e-07 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9815\n",
            "Epoch 73/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.0760e-07 - accuracy: 1.0000 - val_loss: 0.1435 - val_accuracy: 0.9816\n",
            "Epoch 74/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.6560e-07 - accuracy: 1.0000 - val_loss: 0.1446 - val_accuracy: 0.9817\n",
            "Epoch 75/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2749e-07 - accuracy: 1.0000 - val_loss: 0.1452 - val_accuracy: 0.9817\n",
            "Epoch 76/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9061e-07 - accuracy: 1.0000 - val_loss: 0.1464 - val_accuracy: 0.9815\n",
            "Epoch 77/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5982e-07 - accuracy: 1.0000 - val_loss: 0.1469 - val_accuracy: 0.9817\n",
            "Epoch 78/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2899e-07 - accuracy: 1.0000 - val_loss: 0.1474 - val_accuracy: 0.9814\n",
            "Epoch 79/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0307e-07 - accuracy: 1.0000 - val_loss: 0.1481 - val_accuracy: 0.9815\n",
            "Epoch 80/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7947e-07 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.9814\n",
            "Epoch 81/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5512e-07 - accuracy: 1.0000 - val_loss: 0.1495 - val_accuracy: 0.9815\n",
            "Epoch 82/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3271e-07 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 0.9816\n",
            "Epoch 83/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1766e-07 - accuracy: 1.0000 - val_loss: 0.1513 - val_accuracy: 0.9815\n",
            "Epoch 84/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9802e-07 - accuracy: 1.0000 - val_loss: 0.1523 - val_accuracy: 0.9816\n",
            "Epoch 85/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8156e-07 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9816\n",
            "Epoch 86/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6730e-07 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9817\n",
            "Epoch 87/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5420e-07 - accuracy: 1.0000 - val_loss: 0.1543 - val_accuracy: 0.9815\n",
            "Epoch 88/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4149e-07 - accuracy: 1.0000 - val_loss: 0.1548 - val_accuracy: 0.9816\n",
            "Epoch 89/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2960e-07 - accuracy: 1.0000 - val_loss: 0.1559 - val_accuracy: 0.9815\n",
            "Epoch 90/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1929e-07 - accuracy: 1.0000 - val_loss: 0.1567 - val_accuracy: 0.9814\n",
            "Epoch 91/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1086e-07 - accuracy: 1.0000 - val_loss: 0.1569 - val_accuracy: 0.9816\n",
            "Epoch 92/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0210e-07 - accuracy: 1.0000 - val_loss: 0.1579 - val_accuracy: 0.9817\n",
            "Epoch 93/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.3542e-08 - accuracy: 1.0000 - val_loss: 0.1584 - val_accuracy: 0.9815\n",
            "Epoch 94/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.6723e-08 - accuracy: 1.0000 - val_loss: 0.1594 - val_accuracy: 0.9817\n",
            "Epoch 95/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.9438e-08 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 0.9817\n",
            "Epoch 96/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3740e-08 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9815\n",
            "Epoch 97/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7343e-08 - accuracy: 1.0000 - val_loss: 0.1617 - val_accuracy: 0.9816\n",
            "Epoch 98/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.2455e-08 - accuracy: 1.0000 - val_loss: 0.1623 - val_accuracy: 0.9817\n",
            "Epoch 99/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7867e-08 - accuracy: 1.0000 - val_loss: 0.1627 - val_accuracy: 0.9818\n",
            "Epoch 100/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3226e-08 - accuracy: 1.0000 - val_loss: 0.1637 - val_accuracy: 0.9816\n",
            "Epoch 101/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.9376e-08 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 0.9817\n",
            "Epoch 102/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.5631e-08 - accuracy: 1.0000 - val_loss: 0.1649 - val_accuracy: 0.9817\n",
            "Epoch 103/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.2550e-08 - accuracy: 1.0000 - val_loss: 0.1657 - val_accuracy: 0.9817\n",
            "Epoch 104/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9429e-08 - accuracy: 1.0000 - val_loss: 0.1664 - val_accuracy: 0.9816\n",
            "Epoch 105/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6399e-08 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9817\n",
            "Epoch 106/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3699e-08 - accuracy: 1.0000 - val_loss: 0.1680 - val_accuracy: 0.9813\n",
            "Epoch 107/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1720e-08 - accuracy: 1.0000 - val_loss: 0.1684 - val_accuracy: 0.9817\n",
            "Epoch 108/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9190e-08 - accuracy: 1.0000 - val_loss: 0.1690 - val_accuracy: 0.9817\n",
            "Epoch 109/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7002e-08 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 0.9815\n",
            "Epoch 110/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5283e-08 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 0.9817\n",
            "Epoch 111/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3511e-08 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9814\n",
            "Epoch 112/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1823e-08 - accuracy: 1.0000 - val_loss: 0.1715 - val_accuracy: 0.9814\n",
            "Epoch 113/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0560e-08 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 0.9813\n",
            "Epoch 114/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9079e-08 - accuracy: 1.0000 - val_loss: 0.1727 - val_accuracy: 0.9812\n",
            "Epoch 115/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7847e-08 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.9813\n",
            "Epoch 116/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6544e-08 - accuracy: 1.0000 - val_loss: 0.1744 - val_accuracy: 0.9811\n",
            "Epoch 117/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5606e-08 - accuracy: 1.0000 - val_loss: 0.1744 - val_accuracy: 0.9815\n",
            "Epoch 118/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4623e-08 - accuracy: 1.0000 - val_loss: 0.1750 - val_accuracy: 0.9813\n",
            "Epoch 119/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3669e-08 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 0.9813\n",
            "Epoch 120/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2925e-08 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 0.9813\n",
            "Epoch 121/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1945e-08 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.9814\n",
            "Epoch 122/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1230e-08 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 0.9814\n",
            "Epoch 123/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0700e-08 - accuracy: 1.0000 - val_loss: 0.1773 - val_accuracy: 0.9814\n",
            "Epoch 124/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0037e-08 - accuracy: 1.0000 - val_loss: 0.1778 - val_accuracy: 0.9813\n",
            "Epoch 125/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.4520e-09 - accuracy: 1.0000 - val_loss: 0.1784 - val_accuracy: 0.9814\n",
            "Epoch 126/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9460e-09 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.9813\n",
            "Epoch 127/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.3844e-09 - accuracy: 1.0000 - val_loss: 0.1794 - val_accuracy: 0.9815\n",
            "Epoch 128/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9393e-09 - accuracy: 1.0000 - val_loss: 0.1799 - val_accuracy: 0.9815\n",
            "Epoch 129/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4519e-09 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 0.9813\n",
            "Epoch 130/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.1340e-09 - accuracy: 1.0000 - val_loss: 0.1807 - val_accuracy: 0.9813\n",
            "Epoch 131/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.7234e-09 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 0.9813\n",
            "Epoch 132/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3737e-09 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 0.9815\n",
            "Epoch 133/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0770e-09 - accuracy: 1.0000 - val_loss: 0.1821 - val_accuracy: 0.9813\n",
            "Epoch 134/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.7883e-09 - accuracy: 1.0000 - val_loss: 0.1821 - val_accuracy: 0.9812\n",
            "Epoch 135/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.4942e-09 - accuracy: 1.0000 - val_loss: 0.1825 - val_accuracy: 0.9814\n",
            "Epoch 136/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2055e-09 - accuracy: 1.0000 - val_loss: 0.1827 - val_accuracy: 0.9813\n",
            "Epoch 137/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.9379e-09 - accuracy: 1.0000 - val_loss: 0.1830 - val_accuracy: 0.9811\n",
            "Epoch 138/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.7339e-09 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 0.9814\n",
            "Epoch 139/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.5194e-09 - accuracy: 1.0000 - val_loss: 0.1837 - val_accuracy: 0.9813\n",
            "Epoch 140/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.2624e-09 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.9813\n",
            "Epoch 141/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.0876e-09 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9813\n",
            "Epoch 142/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9577e-09 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.9813\n",
            "Epoch 143/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8412e-09 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.9813\n",
            "Epoch 144/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6425e-09 - accuracy: 1.0000 - val_loss: 0.1853 - val_accuracy: 0.9812\n",
            "Epoch 145/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4624e-09 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9813\n",
            "Epoch 146/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3670e-09 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9813\n",
            "Epoch 147/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2187e-09 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9811\n",
            "Epoch 148/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1206e-09 - accuracy: 1.0000 - val_loss: 0.1864 - val_accuracy: 0.9813\n",
            "Epoch 149/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9935e-09 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 0.9811\n",
            "Epoch 150/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8928e-09 - accuracy: 1.0000 - val_loss: 0.1866 - val_accuracy: 0.9813\n",
            "Epoch 151/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7445e-09 - accuracy: 1.0000 - val_loss: 0.1866 - val_accuracy: 0.9811\n",
            "Epoch 152/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6994e-09 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9813\n",
            "Epoch 153/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6094e-09 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9812\n",
            "Epoch 154/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4875e-09 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9813\n",
            "Epoch 155/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4637e-09 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9813\n",
            "Epoch 156/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3921e-09 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 0.9813\n",
            "Epoch 157/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3365e-09 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 0.9813\n",
            "Epoch 158/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2888e-09 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 0.9813\n",
            "Epoch 159/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1484e-09 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9813\n",
            "Epoch 160/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1378e-09 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9814\n",
            "Epoch 161/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1007e-09 - accuracy: 1.0000 - val_loss: 0.1885 - val_accuracy: 0.9813\n",
            "Epoch 162/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0822e-09 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9813\n",
            "Epoch 163/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9868e-09 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9813\n",
            "Epoch 164/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9497e-09 - accuracy: 1.0000 - val_loss: 0.1892 - val_accuracy: 0.9813\n",
            "Epoch 165/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8941e-09 - accuracy: 1.0000 - val_loss: 0.1892 - val_accuracy: 0.9814\n",
            "Epoch 166/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9153e-09 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9813\n",
            "Epoch 167/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8756e-09 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.9813\n",
            "Epoch 168/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8623e-09 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 0.9813\n",
            "Epoch 169/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8517e-09 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 0.9813\n",
            "Epoch 170/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8279e-09 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9814\n",
            "Epoch 171/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8014e-09 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9815\n",
            "Epoch 172/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7961e-09 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9815\n",
            "Epoch 173/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7352e-09 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9815\n",
            "Epoch 174/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7405e-09 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9814\n",
            "Epoch 175/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7246e-09 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9815\n",
            "Epoch 176/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7405e-09 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9815\n",
            "Epoch 177/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7113e-09 - accuracy: 1.0000 - val_loss: 0.1922 - val_accuracy: 0.9813\n",
            "Epoch 178/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6663e-09 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9814\n",
            "Epoch 179/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7166e-09 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 0.9813\n",
            "Epoch 180/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7669e-09 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 0.9812\n",
            "Epoch 181/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7140e-09 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9813\n",
            "Epoch 182/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6769e-09 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9811\n",
            "Epoch 183/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6451e-09 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9812\n",
            "Epoch 184/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6583e-09 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 0.9812\n",
            "Epoch 185/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6795e-09 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9812\n",
            "Epoch 186/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6689e-09 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9812\n",
            "Epoch 187/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7166e-09 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9812\n",
            "Epoch 188/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6742e-09 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.9811\n",
            "Epoch 189/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6822e-09 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9813\n",
            "Epoch 190/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6742e-09 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9812\n",
            "Epoch 191/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6822e-09 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.9813\n",
            "Epoch 192/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6663e-09 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9812\n",
            "Epoch 193/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6477e-09 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.9813\n",
            "Epoch 194/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6822e-09 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.9813\n",
            "Epoch 195/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6769e-09 - accuracy: 1.0000 - val_loss: 0.1971 - val_accuracy: 0.9812\n",
            "Epoch 196/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6954e-09 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9811\n",
            "Epoch 197/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7299e-09 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9812\n",
            "Epoch 198/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6981e-09 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9811\n",
            "Epoch 199/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7034e-09 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.9811\n",
            "Epoch 200/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7219e-09 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9812\n",
            "Epoch 201/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7246e-09 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9812\n",
            "Epoch 202/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7405e-09 - accuracy: 1.0000 - val_loss: 0.1994 - val_accuracy: 0.9813\n",
            "Epoch 203/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6822e-09 - accuracy: 1.0000 - val_loss: 0.1996 - val_accuracy: 0.9811\n",
            "Epoch 204/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6689e-09 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9813\n",
            "Epoch 205/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7352e-09 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9813\n",
            "Epoch 206/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7246e-09 - accuracy: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.9813\n",
            "Epoch 207/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7219e-09 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9813\n",
            "Epoch 208/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7352e-09 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9814\n",
            "Epoch 209/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7299e-09 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9812\n",
            "Epoch 210/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7564e-09 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9813\n",
            "Epoch 211/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7484e-09 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.9813\n",
            "Epoch 212/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7855e-09 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 0.9812\n",
            "Epoch 213/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7961e-09 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9813\n",
            "Epoch 214/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8040e-09 - accuracy: 1.0000 - val_loss: 0.2038 - val_accuracy: 0.9813\n",
            "Epoch 215/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7775e-09 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9813\n",
            "Epoch 216/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7987e-09 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 0.9813\n",
            "Epoch 217/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8279e-09 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 0.9813\n",
            "Epoch 218/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8544e-09 - accuracy: 1.0000 - val_loss: 0.2052 - val_accuracy: 0.9813\n",
            "Epoch 219/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8252e-09 - accuracy: 1.0000 - val_loss: 0.2054 - val_accuracy: 0.9813\n",
            "Epoch 220/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8411e-09 - accuracy: 1.0000 - val_loss: 0.2065 - val_accuracy: 0.9811\n",
            "Epoch 221/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8544e-09 - accuracy: 1.0000 - val_loss: 0.2065 - val_accuracy: 0.9813\n",
            "Epoch 222/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8809e-09 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 0.9813\n",
            "Epoch 223/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8252e-09 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9813\n",
            "Epoch 224/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8862e-09 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9812\n",
            "Epoch 225/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8703e-09 - accuracy: 1.0000 - val_loss: 0.2083 - val_accuracy: 0.9813\n",
            "Epoch 226/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9232e-09 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.9813\n",
            "Epoch 227/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9365e-09 - accuracy: 1.0000 - val_loss: 0.2087 - val_accuracy: 0.9812\n",
            "Epoch 228/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9100e-09 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9812\n",
            "Epoch 229/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8915e-09 - accuracy: 1.0000 - val_loss: 0.2089 - val_accuracy: 0.9813\n",
            "Epoch 230/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9312e-09 - accuracy: 1.0000 - val_loss: 0.2104 - val_accuracy: 0.9813\n",
            "Epoch 231/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9418e-09 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9813\n",
            "Epoch 232/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9259e-09 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9812\n",
            "Epoch 233/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9630e-09 - accuracy: 1.0000 - val_loss: 0.2117 - val_accuracy: 0.9812\n",
            "Epoch 234/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9656e-09 - accuracy: 1.0000 - val_loss: 0.2119 - val_accuracy: 0.9811\n",
            "Epoch 235/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9550e-09 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 0.9812\n",
            "Epoch 236/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9948e-09 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 0.9811\n",
            "Epoch 237/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0372e-09 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9813\n",
            "Epoch 238/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0054e-09 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9812\n",
            "Epoch 239/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0345e-09 - accuracy: 1.0000 - val_loss: 0.2133 - val_accuracy: 0.9812\n",
            "Epoch 240/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0292e-09 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9812\n",
            "Epoch 241/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0292e-09 - accuracy: 1.0000 - val_loss: 0.2148 - val_accuracy: 0.9811\n",
            "Epoch 242/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0478e-09 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9811\n",
            "Epoch 243/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1034e-09 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9811\n",
            "Epoch 244/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0663e-09 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9811\n",
            "Epoch 245/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0954e-09 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9809\n",
            "Epoch 246/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1166e-09 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 0.9809\n",
            "Epoch 247/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1352e-09 - accuracy: 1.0000 - val_loss: 0.2166 - val_accuracy: 0.9810\n",
            "Epoch 248/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1140e-09 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9811\n",
            "Epoch 249/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1829e-09 - accuracy: 1.0000 - val_loss: 0.2179 - val_accuracy: 0.9811\n",
            "Epoch 250/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1617e-09 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9809\n",
            "Epoch 251/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2120e-09 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9811\n",
            "Epoch 252/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1855e-09 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9810\n",
            "Epoch 253/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1855e-09 - accuracy: 1.0000 - val_loss: 0.2189 - val_accuracy: 0.9807\n",
            "Epoch 254/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2040e-09 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 0.9810\n",
            "Epoch 255/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2332e-09 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9809\n",
            "Epoch 256/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1987e-09 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9807\n",
            "Epoch 257/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2650e-09 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9809\n",
            "Epoch 258/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2623e-09 - accuracy: 1.0000 - val_loss: 0.2210 - val_accuracy: 0.9809\n",
            "Epoch 259/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2941e-09 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 0.9808\n",
            "Epoch 260/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3127e-09 - accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 0.9808\n",
            "Epoch 261/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3233e-09 - accuracy: 1.0000 - val_loss: 0.2221 - val_accuracy: 0.9808\n",
            "Epoch 262/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3630e-09 - accuracy: 1.0000 - val_loss: 0.2214 - val_accuracy: 0.9805\n",
            "Epoch 263/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3339e-09 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 0.9806\n",
            "Epoch 264/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3312e-09 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9806\n",
            "Epoch 265/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3312e-09 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.9805\n",
            "Epoch 266/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4398e-09 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 0.9807\n",
            "Epoch 267/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3577e-09 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9809\n",
            "Epoch 268/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4637e-09 - accuracy: 1.0000 - val_loss: 0.2251 - val_accuracy: 0.9807\n",
            "Epoch 269/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5007e-09 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9807\n",
            "Epoch 270/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4451e-09 - accuracy: 1.0000 - val_loss: 0.2258 - val_accuracy: 0.9806\n",
            "Epoch 271/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5352e-09 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9805\n",
            "Epoch 272/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4875e-09 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9806\n",
            "Epoch 273/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5166e-09 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9805\n",
            "Epoch 274/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5802e-09 - accuracy: 1.0000 - val_loss: 0.2268 - val_accuracy: 0.9804\n",
            "Epoch 275/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5299e-09 - accuracy: 1.0000 - val_loss: 0.2274 - val_accuracy: 0.9804\n",
            "Epoch 276/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5723e-09 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9803\n",
            "Epoch 277/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6358e-09 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9804\n",
            "Epoch 278/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5484e-09 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.9802\n",
            "Epoch 279/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5696e-09 - accuracy: 1.0000 - val_loss: 0.2302 - val_accuracy: 0.9801\n",
            "Epoch 280/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7365e-09 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9801\n",
            "Epoch 281/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6491e-09 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 0.9803\n",
            "Epoch 282/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7127e-09 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9803\n",
            "Epoch 283/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6994e-09 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.9801\n",
            "Epoch 284/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7339e-09 - accuracy: 1.0000 - val_loss: 0.2323 - val_accuracy: 0.9803\n",
            "Epoch 285/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7657e-09 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9801\n",
            "Epoch 286/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6835e-09 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.9800\n",
            "Epoch 287/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7789e-09 - accuracy: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9800\n",
            "Epoch 288/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8637e-09 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9798\n",
            "Epoch 289/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7339e-09 - accuracy: 1.0000 - val_loss: 0.2346 - val_accuracy: 0.9803\n",
            "Epoch 290/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8107e-09 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9798\n",
            "Epoch 291/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9776e-09 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9801\n",
            "Epoch 292/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9352e-09 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.9798\n",
            "Epoch 293/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8637e-09 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9799\n",
            "Epoch 294/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8584e-09 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9797\n",
            "Epoch 295/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7291e-08 - accuracy: 1.0000 - val_loss: 0.4245 - val_accuracy: 0.9687\n",
            "Epoch 296/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.1798 - accuracy: 0.9843 - val_loss: 0.1344 - val_accuracy: 0.9759\n",
            "Epoch 297/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.1290 - val_accuracy: 0.9775\n",
            "Epoch 298/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.4323e-04 - accuracy: 0.9999 - val_loss: 0.1222 - val_accuracy: 0.9786\n",
            "Epoch 299/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6535e-04 - accuracy: 1.0000 - val_loss: 0.1223 - val_accuracy: 0.9792\n",
            "Epoch 300/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0845e-04 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9793\n",
            "Epoch 301/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4173e-05 - accuracy: 1.0000 - val_loss: 0.1238 - val_accuracy: 0.9793\n",
            "Epoch 302/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.0363e-05 - accuracy: 1.0000 - val_loss: 0.1245 - val_accuracy: 0.9793\n",
            "Epoch 303/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0353e-05 - accuracy: 1.0000 - val_loss: 0.1255 - val_accuracy: 0.9792\n",
            "Epoch 304/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2658e-05 - accuracy: 1.0000 - val_loss: 0.1263 - val_accuracy: 0.9792\n",
            "Epoch 305/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5967e-05 - accuracy: 1.0000 - val_loss: 0.1270 - val_accuracy: 0.9793\n",
            "Epoch 306/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0593e-05 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9793\n",
            "Epoch 307/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.5968e-05 - accuracy: 1.0000 - val_loss: 0.1287 - val_accuracy: 0.9793\n",
            "Epoch 308/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1954e-05 - accuracy: 1.0000 - val_loss: 0.1292 - val_accuracy: 0.9797\n",
            "Epoch 309/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8632e-05 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 0.9794\n",
            "Epoch 310/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5584e-05 - accuracy: 1.0000 - val_loss: 0.1310 - val_accuracy: 0.9798\n",
            "Epoch 311/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2882e-05 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 0.9795\n",
            "Epoch 312/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0406e-05 - accuracy: 1.0000 - val_loss: 0.1328 - val_accuracy: 0.9796\n",
            "Epoch 313/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8270e-05 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.9797\n",
            "Epoch 314/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6405e-05 - accuracy: 1.0000 - val_loss: 0.1349 - val_accuracy: 0.9799\n",
            "Epoch 315/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4712e-05 - accuracy: 1.0000 - val_loss: 0.1357 - val_accuracy: 0.9798\n",
            "Epoch 316/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3164e-05 - accuracy: 1.0000 - val_loss: 0.1367 - val_accuracy: 0.9799\n",
            "Epoch 317/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1779e-05 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9800\n",
            "Epoch 318/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0573e-05 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9800\n",
            "Epoch 319/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.5343e-06 - accuracy: 1.0000 - val_loss: 0.1395 - val_accuracy: 0.9801\n",
            "Epoch 320/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.5634e-06 - accuracy: 1.0000 - val_loss: 0.1403 - val_accuracy: 0.9801\n",
            "Epoch 321/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7581e-06 - accuracy: 1.0000 - val_loss: 0.1413 - val_accuracy: 0.9801\n",
            "Epoch 322/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0279e-06 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9802\n",
            "Epoch 323/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3486e-06 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9801\n",
            "Epoch 324/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7727e-06 - accuracy: 1.0000 - val_loss: 0.1444 - val_accuracy: 0.9801\n",
            "Epoch 325/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.2258e-06 - accuracy: 1.0000 - val_loss: 0.1445 - val_accuracy: 0.9803\n",
            "Epoch 326/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.7759e-06 - accuracy: 1.0000 - val_loss: 0.1459 - val_accuracy: 0.9801\n",
            "Epoch 327/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3433e-06 - accuracy: 1.0000 - val_loss: 0.1468 - val_accuracy: 0.9803\n",
            "Epoch 328/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9494e-06 - accuracy: 1.0000 - val_loss: 0.1480 - val_accuracy: 0.9803\n",
            "Epoch 329/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.5843e-06 - accuracy: 1.0000 - val_loss: 0.1493 - val_accuracy: 0.9801\n",
            "Epoch 330/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2726e-06 - accuracy: 1.0000 - val_loss: 0.1498 - val_accuracy: 0.9801\n",
            "Epoch 331/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9820e-06 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 0.9801\n",
            "Epoch 332/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7153e-06 - accuracy: 1.0000 - val_loss: 0.1521 - val_accuracy: 0.9801\n",
            "Epoch 333/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4761e-06 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9802\n",
            "Epoch 334/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2633e-06 - accuracy: 1.0000 - val_loss: 0.1539 - val_accuracy: 0.9801\n",
            "Epoch 335/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0623e-06 - accuracy: 1.0000 - val_loss: 0.1546 - val_accuracy: 0.9802\n",
            "Epoch 336/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8847e-06 - accuracy: 1.0000 - val_loss: 0.1556 - val_accuracy: 0.9800\n",
            "Epoch 337/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7203e-06 - accuracy: 1.0000 - val_loss: 0.1565 - val_accuracy: 0.9800\n",
            "Epoch 338/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5770e-06 - accuracy: 1.0000 - val_loss: 0.1572 - val_accuracy: 0.9802\n",
            "Epoch 339/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4425e-06 - accuracy: 1.0000 - val_loss: 0.1580 - val_accuracy: 0.9801\n",
            "Epoch 340/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3185e-06 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9801\n",
            "Epoch 341/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2069e-06 - accuracy: 1.0000 - val_loss: 0.1606 - val_accuracy: 0.9801\n",
            "Epoch 342/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1035e-06 - accuracy: 1.0000 - val_loss: 0.1613 - val_accuracy: 0.9801\n",
            "Epoch 343/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0075e-06 - accuracy: 1.0000 - val_loss: 0.1622 - val_accuracy: 0.9801\n",
            "Epoch 344/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2063e-07 - accuracy: 1.0000 - val_loss: 0.1631 - val_accuracy: 0.9802\n",
            "Epoch 345/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4340e-07 - accuracy: 1.0000 - val_loss: 0.1646 - val_accuracy: 0.9801\n",
            "Epoch 346/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7339e-07 - accuracy: 1.0000 - val_loss: 0.1653 - val_accuracy: 0.9800\n",
            "Epoch 347/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0542e-07 - accuracy: 1.0000 - val_loss: 0.1661 - val_accuracy: 0.9799\n",
            "Epoch 348/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4863e-07 - accuracy: 1.0000 - val_loss: 0.1672 - val_accuracy: 0.9801\n",
            "Epoch 349/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.9281e-07 - accuracy: 1.0000 - val_loss: 0.1682 - val_accuracy: 0.9799\n",
            "Epoch 350/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.4331e-07 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 0.9799\n",
            "Epoch 351/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9962e-07 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 0.9798\n",
            "Epoch 352/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.5541e-07 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 0.9799\n",
            "Epoch 353/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1789e-07 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 0.9801\n",
            "Epoch 354/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.8375e-07 - accuracy: 1.0000 - val_loss: 0.1730 - val_accuracy: 0.9798\n",
            "Epoch 355/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5237e-07 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 0.9798\n",
            "Epoch 356/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2378e-07 - accuracy: 1.0000 - val_loss: 0.1745 - val_accuracy: 0.9800\n",
            "Epoch 357/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9741e-07 - accuracy: 1.0000 - val_loss: 0.1754 - val_accuracy: 0.9799\n",
            "Epoch 358/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7306e-07 - accuracy: 1.0000 - val_loss: 0.1760 - val_accuracy: 0.9799\n",
            "Epoch 359/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.5090e-07 - accuracy: 1.0000 - val_loss: 0.1773 - val_accuracy: 0.9797\n",
            "Epoch 360/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3066e-07 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 0.9798\n",
            "Epoch 361/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1228e-07 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 0.9798\n",
            "Epoch 362/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9526e-07 - accuracy: 1.0000 - val_loss: 0.1799 - val_accuracy: 0.9797\n",
            "Epoch 363/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7980e-07 - accuracy: 1.0000 - val_loss: 0.1805 - val_accuracy: 0.9798\n",
            "Epoch 364/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6546e-07 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9795\n",
            "Epoch 365/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5251e-07 - accuracy: 1.0000 - val_loss: 0.1824 - val_accuracy: 0.9795\n",
            "Epoch 366/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4030e-07 - accuracy: 1.0000 - val_loss: 0.1831 - val_accuracy: 0.9796\n",
            "Epoch 367/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2941e-07 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.9797\n",
            "Epoch 368/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1972e-07 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9798\n",
            "Epoch 369/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0983e-07 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9798\n",
            "Epoch 370/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0112e-07 - accuracy: 1.0000 - val_loss: 0.1864 - val_accuracy: 0.9798\n",
            "Epoch 371/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3428e-08 - accuracy: 1.0000 - val_loss: 0.1873 - val_accuracy: 0.9797\n",
            "Epoch 372/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6413e-08 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9798\n",
            "Epoch 373/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9491e-08 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 0.9798\n",
            "Epoch 374/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3494e-08 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9798\n",
            "Epoch 375/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7963e-08 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 0.9799\n",
            "Epoch 376/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2985e-08 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9799\n",
            "Epoch 377/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7920e-08 - accuracy: 1.0000 - val_loss: 0.1919 - val_accuracy: 0.9799\n",
            "Epoch 378/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3668e-08 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 0.9799\n",
            "Epoch 379/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9586e-08 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9799\n",
            "Epoch 380/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5943e-08 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9799\n",
            "Epoch 381/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.2383e-08 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9799\n",
            "Epoch 382/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.9355e-08 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9800\n",
            "Epoch 383/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6489e-08 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.9800\n",
            "Epoch 384/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3776e-08 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9799\n",
            "Epoch 385/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1413e-08 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9798\n",
            "Epoch 386/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9132e-08 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.9801\n",
            "Epoch 387/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7121e-08 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9799\n",
            "Epoch 388/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5331e-08 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9799\n",
            "Epoch 389/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3532e-08 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.9799\n",
            "Epoch 390/1000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1874e-08 - accuracy: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.9799\n",
            "Epoch 391/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0284e-08 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9799\n",
            "Epoch 392/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8880e-08 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9801\n",
            "Epoch 393/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7616e-08 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9801\n",
            "Epoch 394/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6438e-08 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9801\n",
            "Epoch 395/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5412e-08 - accuracy: 1.0000 - val_loss: 0.2038 - val_accuracy: 0.9800\n",
            "Epoch 396/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4374e-08 - accuracy: 1.0000 - val_loss: 0.2051 - val_accuracy: 0.9802\n",
            "Epoch 397/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3402e-08 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 0.9803\n",
            "Epoch 398/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2541e-08 - accuracy: 1.0000 - val_loss: 0.2062 - val_accuracy: 0.9803\n",
            "Epoch 399/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1645e-08 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9805\n",
            "Epoch 400/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1012e-08 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9805\n",
            "Epoch 401/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0302e-08 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9805\n",
            "Epoch 402/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5897e-09 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9805\n",
            "Epoch 403/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0414e-09 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.9804\n",
            "Epoch 404/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5062e-09 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9805\n",
            "Epoch 405/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.0188e-09 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 0.9807\n",
            "Epoch 406/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.4969e-09 - accuracy: 1.0000 - val_loss: 0.2112 - val_accuracy: 0.9807\n",
            "Epoch 407/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.0996e-09 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9805\n",
            "Epoch 408/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.6333e-09 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 0.9807\n",
            "Epoch 409/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.2545e-09 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9805\n",
            "Epoch 410/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.8651e-09 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9805\n",
            "Epoch 411/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.5446e-09 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9805\n",
            "Epoch 412/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1949e-09 - accuracy: 1.0000 - val_loss: 0.2148 - val_accuracy: 0.9804\n",
            "Epoch 413/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9379e-09 - accuracy: 1.0000 - val_loss: 0.2155 - val_accuracy: 0.9804\n",
            "Epoch 414/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.7021e-09 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9804\n",
            "Epoch 415/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4213e-09 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9805\n",
            "Epoch 416/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2333e-09 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9803\n",
            "Epoch 417/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.0001e-09 - accuracy: 1.0000 - val_loss: 0.2175 - val_accuracy: 0.9803\n",
            "Epoch 418/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7379e-09 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9803\n",
            "Epoch 419/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5975e-09 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 0.9803\n",
            "Epoch 420/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3908e-09 - accuracy: 1.0000 - val_loss: 0.2195 - val_accuracy: 0.9803\n",
            "Epoch 421/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2822e-09 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9804\n",
            "Epoch 422/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0782e-09 - accuracy: 1.0000 - val_loss: 0.2204 - val_accuracy: 0.9804\n",
            "Epoch 423/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9696e-09 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9805\n",
            "Epoch 424/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8266e-09 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9804\n",
            "Epoch 425/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6941e-09 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9804\n",
            "Epoch 426/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5352e-09 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9803\n",
            "Epoch 427/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4531e-09 - accuracy: 1.0000 - val_loss: 0.2233 - val_accuracy: 0.9803\n",
            "Epoch 428/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3153e-09 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9803\n",
            "Epoch 429/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2199e-09 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9803\n",
            "Epoch 430/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1458e-09 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.9803\n",
            "Epoch 431/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0345e-09 - accuracy: 1.0000 - val_loss: 0.2258 - val_accuracy: 0.9803\n",
            "Epoch 432/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9842e-09 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 0.9804\n",
            "Epoch 433/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9073e-09 - accuracy: 1.0000 - val_loss: 0.2274 - val_accuracy: 0.9805\n",
            "Epoch 434/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8517e-09 - accuracy: 1.0000 - val_loss: 0.2277 - val_accuracy: 0.9803\n",
            "Epoch 435/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7802e-09 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9803\n",
            "Epoch 436/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7908e-09 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9803\n",
            "Epoch 437/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7219e-09 - accuracy: 1.0000 - val_loss: 0.2298 - val_accuracy: 0.9803\n",
            "Epoch 438/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6716e-09 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 0.9804\n",
            "Epoch 439/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6318e-09 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9804\n",
            "Epoch 440/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6027e-09 - accuracy: 1.0000 - val_loss: 0.2318 - val_accuracy: 0.9803\n",
            "Epoch 441/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5259e-09 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9803\n",
            "Epoch 442/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5179e-09 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.9802\n",
            "Epoch 443/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4861e-09 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.9803\n",
            "Epoch 444/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4597e-09 - accuracy: 1.0000 - val_loss: 0.2344 - val_accuracy: 0.9802\n",
            "Epoch 445/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4252e-09 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9802\n",
            "Epoch 446/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4067e-09 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9801\n",
            "Epoch 447/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4199e-09 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9800\n",
            "Epoch 448/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3510e-09 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9799\n",
            "Epoch 449/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3616e-09 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9801\n",
            "Epoch 450/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3590e-09 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9800\n",
            "Epoch 451/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3537e-09 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9801\n",
            "Epoch 452/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3034e-09 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9800\n",
            "Epoch 453/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2822e-09 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 0.9799\n",
            "Epoch 454/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3060e-09 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9799\n",
            "Epoch 455/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3007e-09 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 0.9799\n",
            "Epoch 456/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3245e-09 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9799\n",
            "Epoch 457/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2822e-09 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9799\n",
            "Epoch 458/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3378e-09 - accuracy: 1.0000 - val_loss: 0.2428 - val_accuracy: 0.9799\n",
            "Epoch 459/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2901e-09 - accuracy: 1.0000 - val_loss: 0.2435 - val_accuracy: 0.9799\n",
            "Epoch 460/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2424e-09 - accuracy: 1.0000 - val_loss: 0.2442 - val_accuracy: 0.9799\n",
            "Epoch 461/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2345e-09 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9799\n",
            "Epoch 462/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2504e-09 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.9799\n",
            "Epoch 463/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2742e-09 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9798\n",
            "Epoch 464/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2663e-09 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9799\n",
            "Epoch 465/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2212e-09 - accuracy: 1.0000 - val_loss: 0.2470 - val_accuracy: 0.9799\n",
            "Epoch 466/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2769e-09 - accuracy: 1.0000 - val_loss: 0.2474 - val_accuracy: 0.9799\n",
            "Epoch 467/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2159e-09 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9799\n",
            "Epoch 468/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2159e-09 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.9799\n",
            "Epoch 469/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2133e-09 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9799\n",
            "Epoch 470/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2186e-09 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.9798\n",
            "Epoch 471/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2610e-09 - accuracy: 1.0000 - val_loss: 0.2496 - val_accuracy: 0.9801\n",
            "Epoch 472/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2504e-09 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9799\n",
            "Epoch 473/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2530e-09 - accuracy: 1.0000 - val_loss: 0.2511 - val_accuracy: 0.9799\n",
            "Epoch 474/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2742e-09 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9799\n",
            "Epoch 475/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2583e-09 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.9799\n",
            "Epoch 476/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2212e-09 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.9799\n",
            "Epoch 477/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2742e-09 - accuracy: 1.0000 - val_loss: 0.2529 - val_accuracy: 0.9800\n",
            "Epoch 478/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2689e-09 - accuracy: 1.0000 - val_loss: 0.2535 - val_accuracy: 0.9799\n",
            "Epoch 479/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2398e-09 - accuracy: 1.0000 - val_loss: 0.2545 - val_accuracy: 0.9799\n",
            "Epoch 480/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3590e-09 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.9800\n",
            "Epoch 481/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3298e-09 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.9799\n",
            "Epoch 482/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3140e-09 - accuracy: 1.0000 - val_loss: 0.2554 - val_accuracy: 0.9799\n",
            "Epoch 483/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3060e-09 - accuracy: 1.0000 - val_loss: 0.2554 - val_accuracy: 0.9800\n",
            "Epoch 484/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2875e-09 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9798\n",
            "Epoch 485/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2901e-09 - accuracy: 1.0000 - val_loss: 0.2571 - val_accuracy: 0.9799\n",
            "Epoch 486/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3431e-09 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.9801\n",
            "Epoch 487/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3563e-09 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.9799\n",
            "Epoch 488/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3325e-09 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9799\n",
            "Epoch 489/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3457e-09 - accuracy: 1.0000 - val_loss: 0.2589 - val_accuracy: 0.9799\n",
            "Epoch 490/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3828e-09 - accuracy: 1.0000 - val_loss: 0.2593 - val_accuracy: 0.9800\n",
            "Epoch 491/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3696e-09 - accuracy: 1.0000 - val_loss: 0.2603 - val_accuracy: 0.9797\n",
            "Epoch 492/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3669e-09 - accuracy: 1.0000 - val_loss: 0.2603 - val_accuracy: 0.9798\n",
            "Epoch 493/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3802e-09 - accuracy: 1.0000 - val_loss: 0.2609 - val_accuracy: 0.9799\n",
            "Epoch 494/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3484e-09 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.9798\n",
            "Epoch 495/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3749e-09 - accuracy: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.9799\n",
            "Epoch 496/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3881e-09 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.9797\n",
            "Epoch 497/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3881e-09 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9797\n",
            "Epoch 498/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4014e-09 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9798\n",
            "Epoch 499/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3855e-09 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9799\n",
            "Epoch 500/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3749e-09 - accuracy: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.9795\n",
            "Epoch 501/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4305e-09 - accuracy: 1.0000 - val_loss: 0.2644 - val_accuracy: 0.9797\n",
            "Epoch 502/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4332e-09 - accuracy: 1.0000 - val_loss: 0.2647 - val_accuracy: 0.9796\n",
            "Epoch 503/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4570e-09 - accuracy: 1.0000 - val_loss: 0.2655 - val_accuracy: 0.9795\n",
            "Epoch 504/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3881e-09 - accuracy: 1.0000 - val_loss: 0.2655 - val_accuracy: 0.9799\n",
            "Epoch 505/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4146e-09 - accuracy: 1.0000 - val_loss: 0.2658 - val_accuracy: 0.9796\n",
            "Epoch 506/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4835e-09 - accuracy: 1.0000 - val_loss: 0.2662 - val_accuracy: 0.9797\n",
            "Epoch 507/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4199e-09 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9797\n",
            "Epoch 508/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4358e-09 - accuracy: 1.0000 - val_loss: 0.2672 - val_accuracy: 0.9796\n",
            "Epoch 509/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4491e-09 - accuracy: 1.0000 - val_loss: 0.2677 - val_accuracy: 0.9795\n",
            "Epoch 510/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4252e-09 - accuracy: 1.0000 - val_loss: 0.2677 - val_accuracy: 0.9795\n",
            "Epoch 511/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4544e-09 - accuracy: 1.0000 - val_loss: 0.2683 - val_accuracy: 0.9796\n",
            "Epoch 512/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5259e-09 - accuracy: 1.0000 - val_loss: 0.2693 - val_accuracy: 0.9794\n",
            "Epoch 513/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5232e-09 - accuracy: 1.0000 - val_loss: 0.2694 - val_accuracy: 0.9795\n",
            "Epoch 514/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5259e-09 - accuracy: 1.0000 - val_loss: 0.2703 - val_accuracy: 0.9791\n",
            "Epoch 515/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4967e-09 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.9794\n",
            "Epoch 516/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5391e-09 - accuracy: 1.0000 - val_loss: 0.2707 - val_accuracy: 0.9793\n",
            "Epoch 517/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4967e-09 - accuracy: 1.0000 - val_loss: 0.2711 - val_accuracy: 0.9794\n",
            "Epoch 518/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4994e-09 - accuracy: 1.0000 - val_loss: 0.2716 - val_accuracy: 0.9793\n",
            "Epoch 519/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5736e-09 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.9792\n",
            "Epoch 520/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5020e-09 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9793\n",
            "Epoch 521/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5179e-09 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9794\n",
            "Epoch 522/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5047e-09 - accuracy: 1.0000 - val_loss: 0.2739 - val_accuracy: 0.9791\n",
            "Epoch 523/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5391e-09 - accuracy: 1.0000 - val_loss: 0.2751 - val_accuracy: 0.9791\n",
            "Epoch 524/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6239e-09 - accuracy: 1.0000 - val_loss: 0.2746 - val_accuracy: 0.9793\n",
            "Epoch 525/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5656e-09 - accuracy: 1.0000 - val_loss: 0.2745 - val_accuracy: 0.9793\n",
            "Epoch 526/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6054e-09 - accuracy: 1.0000 - val_loss: 0.2749 - val_accuracy: 0.9795\n",
            "Epoch 527/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5232e-09 - accuracy: 1.0000 - val_loss: 0.2753 - val_accuracy: 0.9794\n",
            "Epoch 528/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5709e-09 - accuracy: 1.0000 - val_loss: 0.2756 - val_accuracy: 0.9795\n",
            "Epoch 529/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6504e-09 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9795\n",
            "Epoch 530/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6133e-09 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9791\n",
            "Epoch 531/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6345e-09 - accuracy: 1.0000 - val_loss: 0.2773 - val_accuracy: 0.9795\n",
            "Epoch 532/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6822e-09 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.9794\n",
            "Epoch 533/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6265e-09 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9792\n",
            "Epoch 534/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6054e-09 - accuracy: 1.0000 - val_loss: 0.2794 - val_accuracy: 0.9792\n",
            "Epoch 535/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6954e-09 - accuracy: 1.0000 - val_loss: 0.2790 - val_accuracy: 0.9793\n",
            "Epoch 536/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6239e-09 - accuracy: 1.0000 - val_loss: 0.2791 - val_accuracy: 0.9795\n",
            "Epoch 537/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6477e-09 - accuracy: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.9795\n",
            "Epoch 538/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6742e-09 - accuracy: 1.0000 - val_loss: 0.2801 - val_accuracy: 0.9795\n",
            "Epoch 539/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7193e-09 - accuracy: 1.0000 - val_loss: 0.2802 - val_accuracy: 0.9795\n",
            "Epoch 540/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6186e-09 - accuracy: 1.0000 - val_loss: 0.2816 - val_accuracy: 0.9789\n",
            "Epoch 541/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5789e-09 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9790\n",
            "Epoch 542/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7908e-09 - accuracy: 1.0000 - val_loss: 0.2819 - val_accuracy: 0.9793\n",
            "Epoch 543/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7352e-09 - accuracy: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.9792\n",
            "Epoch 544/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7325e-09 - accuracy: 1.0000 - val_loss: 0.2840 - val_accuracy: 0.9786\n",
            "Epoch 545/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7828e-09 - accuracy: 1.0000 - val_loss: 0.2828 - val_accuracy: 0.9791\n",
            "Epoch 546/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8199e-09 - accuracy: 1.0000 - val_loss: 0.2837 - val_accuracy: 0.9789\n",
            "Epoch 547/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7511e-09 - accuracy: 1.0000 - val_loss: 0.2837 - val_accuracy: 0.9791\n",
            "Epoch 548/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8146e-09 - accuracy: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.9791\n",
            "Epoch 549/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8252e-09 - accuracy: 1.0000 - val_loss: 0.2851 - val_accuracy: 0.9789\n",
            "Epoch 550/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7775e-09 - accuracy: 1.0000 - val_loss: 0.2867 - val_accuracy: 0.9788\n",
            "Epoch 551/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8411e-09 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.9791\n",
            "Epoch 552/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6769e-09 - accuracy: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.9789\n",
            "Epoch 553/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8650e-09 - accuracy: 1.0000 - val_loss: 0.2862 - val_accuracy: 0.9789\n",
            "Epoch 554/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8332e-09 - accuracy: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.9791\n",
            "Epoch 555/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7961e-09 - accuracy: 1.0000 - val_loss: 0.2873 - val_accuracy: 0.9789\n",
            "Epoch 556/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0742e-09 - accuracy: 1.0000 - val_loss: 0.2893 - val_accuracy: 0.9790\n",
            "Epoch 557/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.2210 - accuracy: 0.9860 - val_loss: 0.2680 - val_accuracy: 0.9721\n",
            "Epoch 558/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0185 - accuracy: 0.9955 - val_loss: 0.2282 - val_accuracy: 0.9766\n",
            "Epoch 559/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.2350 - val_accuracy: 0.9765\n",
            "Epoch 560/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.2151 - val_accuracy: 0.9785\n",
            "Epoch 561/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.8085e-04 - accuracy: 0.9999 - val_loss: 0.2122 - val_accuracy: 0.9786\n",
            "Epoch 562/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9881e-04 - accuracy: 0.9998 - val_loss: 0.2110 - val_accuracy: 0.9783\n",
            "Epoch 563/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8573e-04 - accuracy: 0.9998 - val_loss: 0.2184 - val_accuracy: 0.9785\n",
            "Epoch 564/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1784e-05 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9787\n",
            "Epoch 565/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4904e-05 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9789\n",
            "Epoch 566/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1264e-05 - accuracy: 1.0000 - val_loss: 0.2106 - val_accuracy: 0.9788\n",
            "Epoch 567/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6248e-06 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 0.9786\n",
            "Epoch 568/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.4206e-06 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.9787\n",
            "Epoch 569/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5423e-06 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9787\n",
            "Epoch 570/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8251e-06 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9787\n",
            "Epoch 571/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2229e-06 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9787\n",
            "Epoch 572/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7102e-06 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9787\n",
            "Epoch 573/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2461e-06 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9789\n",
            "Epoch 574/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.8565e-06 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.9788\n",
            "Epoch 575/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5128e-06 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 0.9788\n",
            "Epoch 576/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1790e-06 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 0.9787\n",
            "Epoch 577/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8990e-06 - accuracy: 1.0000 - val_loss: 0.2104 - val_accuracy: 0.9787\n",
            "Epoch 578/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6444e-06 - accuracy: 1.0000 - val_loss: 0.2106 - val_accuracy: 0.9789\n",
            "Epoch 579/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3951e-06 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9789\n",
            "Epoch 580/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1696e-06 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9788\n",
            "Epoch 581/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9686e-06 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9788\n",
            "Epoch 582/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7737e-06 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9788\n",
            "Epoch 583/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5953e-06 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9787\n",
            "Epoch 584/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4295e-06 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9787\n",
            "Epoch 585/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2709e-06 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9789\n",
            "Epoch 586/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1238e-06 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 0.9787\n",
            "Epoch 587/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9834e-06 - accuracy: 1.0000 - val_loss: 0.2125 - val_accuracy: 0.9787\n",
            "Epoch 588/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8653e-06 - accuracy: 1.0000 - val_loss: 0.2128 - val_accuracy: 0.9786\n",
            "Epoch 589/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7351e-06 - accuracy: 1.0000 - val_loss: 0.2131 - val_accuracy: 0.9787\n",
            "Epoch 590/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6121e-06 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9785\n",
            "Epoch 591/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5080e-06 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9785\n",
            "Epoch 592/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4029e-06 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9786\n",
            "Epoch 593/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3069e-06 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.9785\n",
            "Epoch 594/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2178e-06 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9784\n",
            "Epoch 595/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1306e-06 - accuracy: 1.0000 - val_loss: 0.2149 - val_accuracy: 0.9783\n",
            "Epoch 596/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0575e-06 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9784\n",
            "Epoch 597/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.8520e-07 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 0.9784\n",
            "Epoch 598/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.1762e-07 - accuracy: 1.0000 - val_loss: 0.2158 - val_accuracy: 0.9784\n",
            "Epoch 599/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.5635e-07 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9784\n",
            "Epoch 600/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0152e-07 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9783\n",
            "Epoch 601/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.4318e-07 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9784\n",
            "Epoch 602/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.9464e-07 - accuracy: 1.0000 - val_loss: 0.2173 - val_accuracy: 0.9786\n",
            "Epoch 603/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.4710e-07 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9787\n",
            "Epoch 604/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0275e-07 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9787\n",
            "Epoch 605/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.6221e-07 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9787\n",
            "Epoch 606/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2317e-07 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 0.9789\n",
            "Epoch 607/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.8687e-07 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9789\n",
            "Epoch 608/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5398e-07 - accuracy: 1.0000 - val_loss: 0.2194 - val_accuracy: 0.9788\n",
            "Epoch 609/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2286e-07 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9789\n",
            "Epoch 610/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9354e-07 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9789\n",
            "Epoch 611/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6453e-07 - accuracy: 1.0000 - val_loss: 0.2205 - val_accuracy: 0.9789\n",
            "Epoch 612/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3986e-07 - accuracy: 1.0000 - val_loss: 0.2209 - val_accuracy: 0.9788\n",
            "Epoch 613/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1597e-07 - accuracy: 1.0000 - val_loss: 0.2214 - val_accuracy: 0.9787\n",
            "Epoch 614/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9373e-07 - accuracy: 1.0000 - val_loss: 0.2216 - val_accuracy: 0.9787\n",
            "Epoch 615/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7334e-07 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9786\n",
            "Epoch 616/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5406e-07 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.9788\n",
            "Epoch 617/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3577e-07 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9788\n",
            "Epoch 618/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1934e-07 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9789\n",
            "Epoch 619/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0409e-07 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9788\n",
            "Epoch 620/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8950e-07 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 0.9787\n",
            "Epoch 621/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7612e-07 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9789\n",
            "Epoch 622/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6357e-07 - accuracy: 1.0000 - val_loss: 0.2247 - val_accuracy: 0.9789\n",
            "Epoch 623/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5213e-07 - accuracy: 1.0000 - val_loss: 0.2252 - val_accuracy: 0.9789\n",
            "Epoch 624/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4107e-07 - accuracy: 1.0000 - val_loss: 0.2255 - val_accuracy: 0.9788\n",
            "Epoch 625/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3131e-07 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9789\n",
            "Epoch 626/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2199e-07 - accuracy: 1.0000 - val_loss: 0.2265 - val_accuracy: 0.9789\n",
            "Epoch 627/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1400e-07 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9789\n",
            "Epoch 628/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0552e-07 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9787\n",
            "Epoch 629/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.7833e-08 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9787\n",
            "Epoch 630/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.1388e-08 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9787\n",
            "Epoch 631/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4766e-08 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9787\n",
            "Epoch 632/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.8869e-08 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.9786\n",
            "Epoch 633/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3112e-08 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.9785\n",
            "Epoch 634/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7928e-08 - accuracy: 1.0000 - val_loss: 0.2302 - val_accuracy: 0.9785\n",
            "Epoch 635/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3395e-08 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.9786\n",
            "Epoch 636/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8820e-08 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9786\n",
            "Epoch 637/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.4789e-08 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.9785\n",
            "Epoch 638/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.1006e-08 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9785\n",
            "Epoch 639/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.7485e-08 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9785\n",
            "Epoch 640/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4184e-08 - accuracy: 1.0000 - val_loss: 0.2331 - val_accuracy: 0.9785\n",
            "Epoch 641/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0984e-08 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.9785\n",
            "Epoch 642/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8269e-08 - accuracy: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9785\n",
            "Epoch 643/1000\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 3.5614e-08 - accuracy: 1.0000 - val_loss: 0.2345 - val_accuracy: 0.9785\n",
            "Epoch 644/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3061e-08 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9785\n",
            "Epoch 645/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0896e-08 - accuracy: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.9787\n",
            "Epoch 646/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8690e-08 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9787\n",
            "Epoch 647/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6761e-08 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9787\n",
            "Epoch 648/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4933e-08 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9786\n",
            "Epoch 649/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3180e-08 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9786\n",
            "Epoch 650/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1545e-08 - accuracy: 1.0000 - val_loss: 0.2384 - val_accuracy: 0.9786\n",
            "Epoch 651/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0085e-08 - accuracy: 1.0000 - val_loss: 0.2388 - val_accuracy: 0.9786\n",
            "Epoch 652/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8668e-08 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9789\n",
            "Epoch 653/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7473e-08 - accuracy: 1.0000 - val_loss: 0.2398 - val_accuracy: 0.9787\n",
            "Epoch 654/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6271e-08 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9787\n",
            "Epoch 655/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5124e-08 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9789\n",
            "Epoch 656/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4051e-08 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9789\n",
            "Epoch 657/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3097e-08 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9789\n",
            "Epoch 658/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2231e-08 - accuracy: 1.0000 - val_loss: 0.2429 - val_accuracy: 0.9790\n",
            "Epoch 659/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1415e-08 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9790\n",
            "Epoch 660/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0636e-08 - accuracy: 1.0000 - val_loss: 0.2442 - val_accuracy: 0.9790\n",
            "Epoch 661/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.9103e-09 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9789\n",
            "Epoch 662/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3301e-09 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9789\n",
            "Epoch 663/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7632e-09 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9789\n",
            "Epoch 664/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1221e-09 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9790\n",
            "Epoch 665/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5923e-09 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.9791\n",
            "Epoch 666/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1102e-09 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.9791\n",
            "Epoch 667/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6916e-09 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 0.9790\n",
            "Epoch 668/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2466e-09 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9791\n",
            "Epoch 669/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8307e-09 - accuracy: 1.0000 - val_loss: 0.2507 - val_accuracy: 0.9790\n",
            "Epoch 670/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.4677e-09 - accuracy: 1.0000 - val_loss: 0.2516 - val_accuracy: 0.9791\n",
            "Epoch 671/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.1551e-09 - accuracy: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.9791\n",
            "Epoch 672/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.8531e-09 - accuracy: 1.0000 - val_loss: 0.2533 - val_accuracy: 0.9790\n",
            "Epoch 673/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5405e-09 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.9792\n",
            "Epoch 674/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.2359e-09 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.9791\n",
            "Epoch 675/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1061e-09 - accuracy: 1.0000 - val_loss: 0.2558 - val_accuracy: 0.9792\n",
            "Epoch 676/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7935e-09 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.9790\n",
            "Epoch 677/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6107e-09 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.9789\n",
            "Epoch 678/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3749e-09 - accuracy: 1.0000 - val_loss: 0.2589 - val_accuracy: 0.9789\n",
            "Epoch 679/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1922e-09 - accuracy: 1.0000 - val_loss: 0.2598 - val_accuracy: 0.9789\n",
            "Epoch 680/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0650e-09 - accuracy: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.9790\n",
            "Epoch 681/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8822e-09 - accuracy: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.9789\n",
            "Epoch 682/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7577e-09 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.9789\n",
            "Epoch 683/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5776e-09 - accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 0.9789\n",
            "Epoch 684/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4875e-09 - accuracy: 1.0000 - val_loss: 0.2644 - val_accuracy: 0.9789\n",
            "Epoch 685/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3312e-09 - accuracy: 1.0000 - val_loss: 0.2655 - val_accuracy: 0.9790\n",
            "Epoch 686/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2888e-09 - accuracy: 1.0000 - val_loss: 0.2663 - val_accuracy: 0.9789\n",
            "Epoch 687/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1484e-09 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9791\n",
            "Epoch 688/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1087e-09 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.9789\n",
            "Epoch 689/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9656e-09 - accuracy: 1.0000 - val_loss: 0.2694 - val_accuracy: 0.9791\n",
            "Epoch 690/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9524e-09 - accuracy: 1.0000 - val_loss: 0.2702 - val_accuracy: 0.9789\n",
            "Epoch 691/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8676e-09 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.9790\n",
            "Epoch 692/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7987e-09 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9790\n",
            "Epoch 693/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7060e-09 - accuracy: 1.0000 - val_loss: 0.2737 - val_accuracy: 0.9791\n",
            "Epoch 694/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7113e-09 - accuracy: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.9791\n",
            "Epoch 695/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6159e-09 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9791\n",
            "Epoch 696/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6027e-09 - accuracy: 1.0000 - val_loss: 0.2767 - val_accuracy: 0.9791\n",
            "Epoch 697/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5444e-09 - accuracy: 1.0000 - val_loss: 0.2775 - val_accuracy: 0.9792\n",
            "Epoch 698/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5073e-09 - accuracy: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.9791\n",
            "Epoch 699/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4835e-09 - accuracy: 1.0000 - val_loss: 0.2794 - val_accuracy: 0.9790\n",
            "Epoch 700/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4464e-09 - accuracy: 1.0000 - val_loss: 0.2804 - val_accuracy: 0.9791\n",
            "Epoch 701/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4411e-09 - accuracy: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.9790\n",
            "Epoch 702/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4120e-09 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9791\n",
            "Epoch 703/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3722e-09 - accuracy: 1.0000 - val_loss: 0.2831 - val_accuracy: 0.9791\n",
            "Epoch 704/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3510e-09 - accuracy: 1.0000 - val_loss: 0.2843 - val_accuracy: 0.9791\n",
            "Epoch 705/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3404e-09 - accuracy: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.9791\n",
            "Epoch 706/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3537e-09 - accuracy: 1.0000 - val_loss: 0.2858 - val_accuracy: 0.9789\n",
            "Epoch 707/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3616e-09 - accuracy: 1.0000 - val_loss: 0.2870 - val_accuracy: 0.9791\n",
            "Epoch 708/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3060e-09 - accuracy: 1.0000 - val_loss: 0.2881 - val_accuracy: 0.9791\n",
            "Epoch 709/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2981e-09 - accuracy: 1.0000 - val_loss: 0.2890 - val_accuracy: 0.9790\n",
            "Epoch 710/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3034e-09 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.9791\n",
            "Epoch 711/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2610e-09 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.9792\n",
            "Epoch 712/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2689e-09 - accuracy: 1.0000 - val_loss: 0.2914 - val_accuracy: 0.9790\n",
            "Epoch 713/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2106e-09 - accuracy: 1.0000 - val_loss: 0.2923 - val_accuracy: 0.9791\n",
            "Epoch 714/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2212e-09 - accuracy: 1.0000 - val_loss: 0.2931 - val_accuracy: 0.9792\n",
            "Epoch 715/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2318e-09 - accuracy: 1.0000 - val_loss: 0.2935 - val_accuracy: 0.9789\n",
            "Epoch 716/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2053e-09 - accuracy: 1.0000 - val_loss: 0.2949 - val_accuracy: 0.9790\n",
            "Epoch 717/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2239e-09 - accuracy: 1.0000 - val_loss: 0.2960 - val_accuracy: 0.9791\n",
            "Epoch 718/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2371e-09 - accuracy: 1.0000 - val_loss: 0.2965 - val_accuracy: 0.9791\n",
            "Epoch 719/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2239e-09 - accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.9792\n",
            "Epoch 720/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2186e-09 - accuracy: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.9793\n",
            "Epoch 721/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2027e-09 - accuracy: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.9791\n",
            "Epoch 722/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1947e-09 - accuracy: 1.0000 - val_loss: 0.3001 - val_accuracy: 0.9791\n",
            "Epoch 723/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2159e-09 - accuracy: 1.0000 - val_loss: 0.3001 - val_accuracy: 0.9791\n",
            "Epoch 724/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2345e-09 - accuracy: 1.0000 - val_loss: 0.3016 - val_accuracy: 0.9791\n",
            "Epoch 725/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1868e-09 - accuracy: 1.0000 - val_loss: 0.3018 - val_accuracy: 0.9789\n",
            "Epoch 726/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2292e-09 - accuracy: 1.0000 - val_loss: 0.3030 - val_accuracy: 0.9790\n",
            "Epoch 727/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1815e-09 - accuracy: 1.0000 - val_loss: 0.3041 - val_accuracy: 0.9791\n",
            "Epoch 728/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2212e-09 - accuracy: 1.0000 - val_loss: 0.3040 - val_accuracy: 0.9790\n",
            "Epoch 729/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1947e-09 - accuracy: 1.0000 - val_loss: 0.3054 - val_accuracy: 0.9790\n",
            "Epoch 730/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2822e-09 - accuracy: 1.0000 - val_loss: 0.3063 - val_accuracy: 0.9791\n",
            "Epoch 731/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1974e-09 - accuracy: 1.0000 - val_loss: 0.3065 - val_accuracy: 0.9790\n",
            "Epoch 732/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2080e-09 - accuracy: 1.0000 - val_loss: 0.3071 - val_accuracy: 0.9789\n",
            "Epoch 733/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2557e-09 - accuracy: 1.0000 - val_loss: 0.3075 - val_accuracy: 0.9789\n",
            "Epoch 734/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1788e-09 - accuracy: 1.0000 - val_loss: 0.3088 - val_accuracy: 0.9790\n",
            "Epoch 735/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2265e-09 - accuracy: 1.0000 - val_loss: 0.3097 - val_accuracy: 0.9791\n",
            "Epoch 736/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2159e-09 - accuracy: 1.0000 - val_loss: 0.3104 - val_accuracy: 0.9790\n",
            "Epoch 737/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2106e-09 - accuracy: 1.0000 - val_loss: 0.3108 - val_accuracy: 0.9789\n",
            "Epoch 738/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1921e-09 - accuracy: 1.0000 - val_loss: 0.3114 - val_accuracy: 0.9789\n",
            "Epoch 739/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2186e-09 - accuracy: 1.0000 - val_loss: 0.3124 - val_accuracy: 0.9789\n",
            "Epoch 740/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2583e-09 - accuracy: 1.0000 - val_loss: 0.3128 - val_accuracy: 0.9790\n",
            "Epoch 741/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2398e-09 - accuracy: 1.0000 - val_loss: 0.3143 - val_accuracy: 0.9789\n",
            "Epoch 742/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2398e-09 - accuracy: 1.0000 - val_loss: 0.3144 - val_accuracy: 0.9788\n",
            "Epoch 743/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2000e-09 - accuracy: 1.0000 - val_loss: 0.3160 - val_accuracy: 0.9787\n",
            "Epoch 744/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1894e-09 - accuracy: 1.0000 - val_loss: 0.3158 - val_accuracy: 0.9787\n",
            "Epoch 745/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2292e-09 - accuracy: 1.0000 - val_loss: 0.3171 - val_accuracy: 0.9787\n",
            "Epoch 746/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2875e-09 - accuracy: 1.0000 - val_loss: 0.3182 - val_accuracy: 0.9787\n",
            "Epoch 747/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2212e-09 - accuracy: 1.0000 - val_loss: 0.3182 - val_accuracy: 0.9788\n",
            "Epoch 748/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2292e-09 - accuracy: 1.0000 - val_loss: 0.3191 - val_accuracy: 0.9787\n",
            "Epoch 749/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2769e-09 - accuracy: 1.0000 - val_loss: 0.3195 - val_accuracy: 0.9785\n",
            "Epoch 750/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2345e-09 - accuracy: 1.0000 - val_loss: 0.3199 - val_accuracy: 0.9787\n",
            "Epoch 751/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2875e-09 - accuracy: 1.0000 - val_loss: 0.3213 - val_accuracy: 0.9785\n",
            "Epoch 752/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2663e-09 - accuracy: 1.0000 - val_loss: 0.3222 - val_accuracy: 0.9787\n",
            "Epoch 753/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3378e-09 - accuracy: 1.0000 - val_loss: 0.3220 - val_accuracy: 0.9785\n",
            "Epoch 754/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2451e-09 - accuracy: 1.0000 - val_loss: 0.3236 - val_accuracy: 0.9786\n",
            "Epoch 755/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3219e-09 - accuracy: 1.0000 - val_loss: 0.3233 - val_accuracy: 0.9786\n",
            "Epoch 756/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2981e-09 - accuracy: 1.0000 - val_loss: 0.3228 - val_accuracy: 0.9786\n",
            "Epoch 757/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2530e-09 - accuracy: 1.0000 - val_loss: 0.3255 - val_accuracy: 0.9785\n",
            "Epoch 758/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2663e-09 - accuracy: 1.0000 - val_loss: 0.3256 - val_accuracy: 0.9785\n",
            "Epoch 759/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3404e-09 - accuracy: 1.0000 - val_loss: 0.3251 - val_accuracy: 0.9785\n",
            "Epoch 760/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3351e-09 - accuracy: 1.0000 - val_loss: 0.3255 - val_accuracy: 0.9785\n",
            "Epoch 761/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4173e-09 - accuracy: 1.0000 - val_loss: 0.3256 - val_accuracy: 0.9786\n",
            "Epoch 762/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1868e-09 - accuracy: 1.0000 - val_loss: 0.3264 - val_accuracy: 0.9783\n",
            "Epoch 763/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3643e-09 - accuracy: 1.0000 - val_loss: 0.3276 - val_accuracy: 0.9785\n",
            "Epoch 764/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3087e-09 - accuracy: 1.0000 - val_loss: 0.3274 - val_accuracy: 0.9783\n",
            "Epoch 765/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4093e-09 - accuracy: 1.0000 - val_loss: 0.3296 - val_accuracy: 0.9788\n",
            "Epoch 766/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.1055 - accuracy: 0.9905 - val_loss: 0.3856 - val_accuracy: 0.9677\n",
            "Epoch 767/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0315 - accuracy: 0.9933 - val_loss: 0.2210 - val_accuracy: 0.9739\n",
            "Epoch 768/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.2200 - val_accuracy: 0.9769\n",
            "Epoch 769/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.2170 - val_accuracy: 0.9763\n",
            "Epoch 770/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.0143e-04 - accuracy: 0.9999 - val_loss: 0.2057 - val_accuracy: 0.9782\n",
            "Epoch 771/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8863e-05 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9789\n",
            "Epoch 772/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7477e-05 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9791\n",
            "Epoch 773/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3861e-05 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9791\n",
            "Epoch 774/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1733e-05 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9791\n",
            "Epoch 775/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0251e-05 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9791\n",
            "Epoch 776/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.0699e-06 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9790\n",
            "Epoch 777/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1015e-06 - accuracy: 1.0000 - val_loss: 0.2025 - val_accuracy: 0.9791\n",
            "Epoch 778/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.3003e-06 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9791\n",
            "Epoch 779/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6168e-06 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9792\n",
            "Epoch 780/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.9568e-06 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9791\n",
            "Epoch 781/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.4468e-06 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 0.9793\n",
            "Epoch 782/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9347e-06 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9793\n",
            "Epoch 783/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5149e-06 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9791\n",
            "Epoch 784/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0916e-06 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9793\n",
            "Epoch 785/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7425e-06 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.9794\n",
            "Epoch 786/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4136e-06 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 0.9794\n",
            "Epoch 787/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1056e-06 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9795\n",
            "Epoch 788/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7913e-06 - accuracy: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.9795\n",
            "Epoch 789/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4538e-06 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9795\n",
            "Epoch 790/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1409e-06 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9793\n",
            "Epoch 791/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7464e-06 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9793\n",
            "Epoch 792/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3684e-06 - accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 0.9791\n",
            "Epoch 793/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0633e-06 - accuracy: 1.0000 - val_loss: 0.2264 - val_accuracy: 0.9787\n",
            "Epoch 794/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1533e-07 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9789\n",
            "Epoch 795/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.9540e-07 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 0.9785\n",
            "Epoch 796/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0029e-07 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9787\n",
            "Epoch 797/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.0369e-07 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9785\n",
            "Epoch 798/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5182e-07 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9783\n",
            "Epoch 799/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.9471e-07 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.9785\n",
            "Epoch 800/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6861e-07 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.9790\n",
            "Epoch 801/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4443e-07 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.9788\n",
            "Epoch 802/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9314e-07 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.9787\n",
            "Epoch 803/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7301e-07 - accuracy: 1.0000 - val_loss: 0.2537 - val_accuracy: 0.9786\n",
            "Epoch 804/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4737e-07 - accuracy: 1.0000 - val_loss: 0.2556 - val_accuracy: 0.9787\n",
            "Epoch 805/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3415e-07 - accuracy: 1.0000 - val_loss: 0.2556 - val_accuracy: 0.9787\n",
            "Epoch 806/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1538e-07 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9786\n",
            "Epoch 807/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9639e-07 - accuracy: 1.0000 - val_loss: 0.2588 - val_accuracy: 0.9788\n",
            "Epoch 808/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8150e-07 - accuracy: 1.0000 - val_loss: 0.2610 - val_accuracy: 0.9784\n",
            "Epoch 809/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7287e-07 - accuracy: 1.0000 - val_loss: 0.2608 - val_accuracy: 0.9786\n",
            "Epoch 810/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5739e-07 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.9785\n",
            "Epoch 811/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4518e-07 - accuracy: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.9783\n",
            "Epoch 812/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3672e-07 - accuracy: 1.0000 - val_loss: 0.2645 - val_accuracy: 0.9783\n",
            "Epoch 813/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2774e-07 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.9781\n",
            "Epoch 814/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1865e-07 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9785\n",
            "Epoch 815/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0894e-07 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9784\n",
            "Epoch 816/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0108e-07 - accuracy: 1.0000 - val_loss: 0.2673 - val_accuracy: 0.9785\n",
            "Epoch 817/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7671e-08 - accuracy: 1.0000 - val_loss: 0.2702 - val_accuracy: 0.9781\n",
            "Epoch 818/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0813e-08 - accuracy: 1.0000 - val_loss: 0.2698 - val_accuracy: 0.9787\n",
            "Epoch 819/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.4914e-08 - accuracy: 1.0000 - val_loss: 0.2711 - val_accuracy: 0.9784\n",
            "Epoch 820/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.9584e-08 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9785\n",
            "Epoch 821/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5785e-08 - accuracy: 1.0000 - val_loss: 0.2730 - val_accuracy: 0.9783\n",
            "Epoch 822/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1687e-08 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9785\n",
            "Epoch 823/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7477e-08 - accuracy: 1.0000 - val_loss: 0.2745 - val_accuracy: 0.9783\n",
            "Epoch 824/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.1650e-08 - accuracy: 1.0000 - val_loss: 0.2747 - val_accuracy: 0.9784\n",
            "Epoch 825/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7355e-08 - accuracy: 1.0000 - val_loss: 0.2751 - val_accuracy: 0.9785\n",
            "Epoch 826/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.4161e-08 - accuracy: 1.0000 - val_loss: 0.2761 - val_accuracy: 0.9785\n",
            "Epoch 827/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1686e-08 - accuracy: 1.0000 - val_loss: 0.2769 - val_accuracy: 0.9783\n",
            "Epoch 828/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.8749e-08 - accuracy: 1.0000 - val_loss: 0.2778 - val_accuracy: 0.9781\n",
            "Epoch 829/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4786e-08 - accuracy: 1.0000 - val_loss: 0.2775 - val_accuracy: 0.9786\n",
            "Epoch 830/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.1877e-08 - accuracy: 1.0000 - val_loss: 0.2800 - val_accuracy: 0.9781\n",
            "Epoch 831/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.9530e-08 - accuracy: 1.0000 - val_loss: 0.2788 - val_accuracy: 0.9785\n",
            "Epoch 832/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6981e-08 - accuracy: 1.0000 - val_loss: 0.2819 - val_accuracy: 0.9781\n",
            "Epoch 833/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.4730e-08 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9781\n",
            "Epoch 834/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2597e-08 - accuracy: 1.0000 - val_loss: 0.2830 - val_accuracy: 0.9781\n",
            "Epoch 835/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0404e-08 - accuracy: 1.0000 - val_loss: 0.2836 - val_accuracy: 0.9782\n",
            "Epoch 836/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8674e-08 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 0.9782\n",
            "Epoch 837/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7010e-08 - accuracy: 1.0000 - val_loss: 0.2843 - val_accuracy: 0.9783\n",
            "Epoch 838/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4928e-08 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.9783\n",
            "Epoch 839/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3341e-08 - accuracy: 1.0000 - val_loss: 0.2863 - val_accuracy: 0.9781\n",
            "Epoch 840/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2242e-08 - accuracy: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.9781\n",
            "Epoch 841/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0711e-08 - accuracy: 1.0000 - val_loss: 0.2869 - val_accuracy: 0.9783\n",
            "Epoch 842/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9627e-08 - accuracy: 1.0000 - val_loss: 0.2881 - val_accuracy: 0.9781\n",
            "Epoch 843/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8016e-08 - accuracy: 1.0000 - val_loss: 0.2892 - val_accuracy: 0.9782\n",
            "Epoch 844/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7105e-08 - accuracy: 1.0000 - val_loss: 0.2890 - val_accuracy: 0.9783\n",
            "Epoch 845/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5940e-08 - accuracy: 1.0000 - val_loss: 0.2897 - val_accuracy: 0.9783\n",
            "Epoch 846/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4994e-08 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.9783\n",
            "Epoch 847/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4083e-08 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.9781\n",
            "Epoch 848/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3102e-08 - accuracy: 1.0000 - val_loss: 0.2925 - val_accuracy: 0.9781\n",
            "Epoch 849/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2133e-08 - accuracy: 1.0000 - val_loss: 0.2923 - val_accuracy: 0.9788\n",
            "Epoch 850/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1539e-08 - accuracy: 1.0000 - val_loss: 0.2937 - val_accuracy: 0.9784\n",
            "Epoch 851/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0893e-08 - accuracy: 1.0000 - val_loss: 0.2943 - val_accuracy: 0.9783\n",
            "Epoch 852/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0075e-08 - accuracy: 1.0000 - val_loss: 0.2953 - val_accuracy: 0.9785\n",
            "Epoch 853/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5341e-09 - accuracy: 1.0000 - val_loss: 0.2956 - val_accuracy: 0.9784\n",
            "Epoch 854/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9327e-09 - accuracy: 1.0000 - val_loss: 0.2968 - val_accuracy: 0.9784\n",
            "Epoch 855/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.3420e-09 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.9785\n",
            "Epoch 856/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8970e-09 - accuracy: 1.0000 - val_loss: 0.2978 - val_accuracy: 0.9783\n",
            "Epoch 857/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2400e-09 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 0.9787\n",
            "Epoch 858/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.8823e-09 - accuracy: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.9788\n",
            "Epoch 859/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5141e-09 - accuracy: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.9788\n",
            "Epoch 860/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0850e-09 - accuracy: 1.0000 - val_loss: 0.3006 - val_accuracy: 0.9787\n",
            "Epoch 861/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7114e-09 - accuracy: 1.0000 - val_loss: 0.3018 - val_accuracy: 0.9786\n",
            "Epoch 862/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3856e-09 - accuracy: 1.0000 - val_loss: 0.3022 - val_accuracy: 0.9787\n",
            "Epoch 863/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.0280e-09 - accuracy: 1.0000 - val_loss: 0.3028 - val_accuracy: 0.9787\n",
            "Epoch 864/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7207e-09 - accuracy: 1.0000 - val_loss: 0.3031 - val_accuracy: 0.9789\n",
            "Epoch 865/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.4531e-09 - accuracy: 1.0000 - val_loss: 0.3046 - val_accuracy: 0.9787\n",
            "Epoch 866/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1511e-09 - accuracy: 1.0000 - val_loss: 0.3050 - val_accuracy: 0.9789\n",
            "Epoch 867/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9313e-09 - accuracy: 1.0000 - val_loss: 0.3059 - val_accuracy: 0.9788\n",
            "Epoch 868/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6849e-09 - accuracy: 1.0000 - val_loss: 0.3069 - val_accuracy: 0.9788\n",
            "Epoch 869/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4544e-09 - accuracy: 1.0000 - val_loss: 0.3079 - val_accuracy: 0.9788\n",
            "Epoch 870/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2663e-09 - accuracy: 1.0000 - val_loss: 0.3082 - val_accuracy: 0.9787\n",
            "Epoch 871/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0465e-09 - accuracy: 1.0000 - val_loss: 0.3090 - val_accuracy: 0.9787\n",
            "Epoch 872/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8902e-09 - accuracy: 1.0000 - val_loss: 0.3100 - val_accuracy: 0.9786\n",
            "Epoch 873/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7153e-09 - accuracy: 1.0000 - val_loss: 0.3110 - val_accuracy: 0.9788\n",
            "Epoch 874/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5537e-09 - accuracy: 1.0000 - val_loss: 0.3121 - val_accuracy: 0.9787\n",
            "Epoch 875/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4266e-09 - accuracy: 1.0000 - val_loss: 0.3131 - val_accuracy: 0.9787\n",
            "Epoch 876/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2676e-09 - accuracy: 1.0000 - val_loss: 0.3134 - val_accuracy: 0.9787\n",
            "Epoch 877/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1325e-09 - accuracy: 1.0000 - val_loss: 0.3147 - val_accuracy: 0.9789\n",
            "Epoch 878/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0239e-09 - accuracy: 1.0000 - val_loss: 0.3152 - val_accuracy: 0.9787\n",
            "Epoch 879/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9630e-09 - accuracy: 1.0000 - val_loss: 0.3161 - val_accuracy: 0.9788\n",
            "Epoch 880/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8252e-09 - accuracy: 1.0000 - val_loss: 0.3168 - val_accuracy: 0.9789\n",
            "Epoch 881/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7484e-09 - accuracy: 1.0000 - val_loss: 0.3179 - val_accuracy: 0.9788\n",
            "Epoch 882/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6636e-09 - accuracy: 1.0000 - val_loss: 0.3188 - val_accuracy: 0.9785\n",
            "Epoch 883/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5789e-09 - accuracy: 1.0000 - val_loss: 0.3195 - val_accuracy: 0.9786\n",
            "Epoch 884/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4623e-09 - accuracy: 1.0000 - val_loss: 0.3207 - val_accuracy: 0.9787\n",
            "Epoch 885/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4332e-09 - accuracy: 1.0000 - val_loss: 0.3212 - val_accuracy: 0.9788\n",
            "Epoch 886/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3351e-09 - accuracy: 1.0000 - val_loss: 0.3227 - val_accuracy: 0.9787\n",
            "Epoch 887/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3060e-09 - accuracy: 1.0000 - val_loss: 0.3230 - val_accuracy: 0.9787\n",
            "Epoch 888/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2106e-09 - accuracy: 1.0000 - val_loss: 0.3243 - val_accuracy: 0.9787\n",
            "Epoch 889/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1974e-09 - accuracy: 1.0000 - val_loss: 0.3248 - val_accuracy: 0.9787\n",
            "Epoch 890/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1206e-09 - accuracy: 1.0000 - val_loss: 0.3256 - val_accuracy: 0.9785\n",
            "Epoch 891/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0543e-09 - accuracy: 1.0000 - val_loss: 0.3266 - val_accuracy: 0.9785\n",
            "Epoch 892/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0093e-09 - accuracy: 1.0000 - val_loss: 0.3272 - val_accuracy: 0.9784\n",
            "Epoch 893/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.8017e-10 - accuracy: 1.0000 - val_loss: 0.3288 - val_accuracy: 0.9787\n",
            "Epoch 894/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.0334e-10 - accuracy: 1.0000 - val_loss: 0.3295 - val_accuracy: 0.9785\n",
            "Epoch 895/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.2189e-10 - accuracy: 1.0000 - val_loss: 0.3304 - val_accuracy: 0.9785\n",
            "Epoch 896/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9804e-10 - accuracy: 1.0000 - val_loss: 0.3317 - val_accuracy: 0.9787\n",
            "Epoch 897/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3182e-10 - accuracy: 1.0000 - val_loss: 0.3323 - val_accuracy: 0.9784\n",
            "Epoch 898/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.3976e-10 - accuracy: 1.0000 - val_loss: 0.3338 - val_accuracy: 0.9783\n",
            "Epoch 899/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2122e-10 - accuracy: 1.0000 - val_loss: 0.3346 - val_accuracy: 0.9786\n",
            "Epoch 900/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.0268e-10 - accuracy: 1.0000 - val_loss: 0.3350 - val_accuracy: 0.9786\n",
            "Epoch 901/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.4175e-10 - accuracy: 1.0000 - val_loss: 0.3363 - val_accuracy: 0.9785\n",
            "Epoch 902/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.2585e-10 - accuracy: 1.0000 - val_loss: 0.3376 - val_accuracy: 0.9785\n",
            "Epoch 903/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5764e-10 - accuracy: 1.0000 - val_loss: 0.3384 - val_accuracy: 0.9786\n",
            "Epoch 904/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5499e-10 - accuracy: 1.0000 - val_loss: 0.3394 - val_accuracy: 0.9786\n",
            "Epoch 905/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8082e-10 - accuracy: 1.0000 - val_loss: 0.3400 - val_accuracy: 0.9784\n",
            "Epoch 906/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1261e-10 - accuracy: 1.0000 - val_loss: 0.3416 - val_accuracy: 0.9787\n",
            "Epoch 907/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2055e-10 - accuracy: 1.0000 - val_loss: 0.3417 - val_accuracy: 0.9787\n",
            "Epoch 908/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6492e-10 - accuracy: 1.0000 - val_loss: 0.3427 - val_accuracy: 0.9786\n",
            "Epoch 909/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.8612e-10 - accuracy: 1.0000 - val_loss: 0.3436 - val_accuracy: 0.9784\n",
            "Epoch 910/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.4903e-10 - accuracy: 1.0000 - val_loss: 0.3448 - val_accuracy: 0.9788\n",
            "Epoch 911/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5433e-10 - accuracy: 1.0000 - val_loss: 0.3451 - val_accuracy: 0.9784\n",
            "Epoch 912/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8876e-10 - accuracy: 1.0000 - val_loss: 0.3460 - val_accuracy: 0.9783\n",
            "Epoch 913/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.6227e-10 - accuracy: 1.0000 - val_loss: 0.3476 - val_accuracy: 0.9786\n",
            "Epoch 914/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.5168e-10 - accuracy: 1.0000 - val_loss: 0.3482 - val_accuracy: 0.9784\n",
            "Epoch 915/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.3843e-10 - accuracy: 1.0000 - val_loss: 0.3489 - val_accuracy: 0.9784\n",
            "Epoch 916/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.5698e-10 - accuracy: 1.0000 - val_loss: 0.3490 - val_accuracy: 0.9785\n",
            "Epoch 917/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4903e-10 - accuracy: 1.0000 - val_loss: 0.3508 - val_accuracy: 0.9785\n",
            "Epoch 918/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.7287e-10 - accuracy: 1.0000 - val_loss: 0.3515 - val_accuracy: 0.9783\n",
            "Epoch 919/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1194e-10 - accuracy: 1.0000 - val_loss: 0.3516 - val_accuracy: 0.9787\n",
            "Epoch 920/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.0929e-10 - accuracy: 1.0000 - val_loss: 0.3524 - val_accuracy: 0.9787\n",
            "Epoch 921/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.1724e-10 - accuracy: 1.0000 - val_loss: 0.3538 - val_accuracy: 0.9784\n",
            "Epoch 922/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1724e-10 - accuracy: 1.0000 - val_loss: 0.3544 - val_accuracy: 0.9784\n",
            "Epoch 923/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 0.3546 - val_accuracy: 0.9783\n",
            "Epoch 924/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.0664e-10 - accuracy: 1.0000 - val_loss: 0.3552 - val_accuracy: 0.9785\n",
            "Epoch 925/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.6161e-10 - accuracy: 1.0000 - val_loss: 0.3566 - val_accuracy: 0.9786\n",
            "Epoch 926/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.4903e-10 - accuracy: 1.0000 - val_loss: 0.3567 - val_accuracy: 0.9783\n",
            "Epoch 927/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.9340e-10 - accuracy: 1.0000 - val_loss: 0.3584 - val_accuracy: 0.9784\n",
            "Epoch 928/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0399e-10 - accuracy: 1.0000 - val_loss: 0.3583 - val_accuracy: 0.9781\n",
            "Epoch 929/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.9870e-10 - accuracy: 1.0000 - val_loss: 0.3581 - val_accuracy: 0.9782\n",
            "Epoch 930/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1459e-10 - accuracy: 1.0000 - val_loss: 0.3601 - val_accuracy: 0.9781\n",
            "Epoch 931/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2254e-10 - accuracy: 1.0000 - val_loss: 0.3596 - val_accuracy: 0.9781\n",
            "Epoch 932/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.1724e-10 - accuracy: 1.0000 - val_loss: 0.3608 - val_accuracy: 0.9780\n",
            "Epoch 933/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3048e-10 - accuracy: 1.0000 - val_loss: 0.3618 - val_accuracy: 0.9780\n",
            "Epoch 934/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.9141e-10 - accuracy: 1.0000 - val_loss: 0.3624 - val_accuracy: 0.9780\n",
            "Epoch 935/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.8280e-10 - accuracy: 1.0000 - val_loss: 0.3625 - val_accuracy: 0.9780\n",
            "Epoch 936/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8810e-10 - accuracy: 1.0000 - val_loss: 0.3639 - val_accuracy: 0.9781\n",
            "Epoch 937/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0664e-10 - accuracy: 1.0000 - val_loss: 0.3642 - val_accuracy: 0.9781\n",
            "Epoch 938/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8280e-10 - accuracy: 1.0000 - val_loss: 0.3656 - val_accuracy: 0.9779\n",
            "Epoch 939/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4175e-10 - accuracy: 1.0000 - val_loss: 0.3649 - val_accuracy: 0.9780\n",
            "Epoch 940/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.8015e-10 - accuracy: 1.0000 - val_loss: 0.3639 - val_accuracy: 0.9781\n",
            "Epoch 941/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0947 - accuracy: 0.9944 - val_loss: 0.8928 - val_accuracy: 0.9527\n",
            "Epoch 942/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0644 - accuracy: 0.9914 - val_loss: 0.1992 - val_accuracy: 0.9768\n",
            "Epoch 943/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.2033 - val_accuracy: 0.9769\n",
            "Epoch 944/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.1923 - val_accuracy: 0.9776\n",
            "Epoch 945/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1134e-04 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9779\n",
            "Epoch 946/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9287e-05 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9779\n",
            "Epoch 947/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1189e-05 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9780\n",
            "Epoch 948/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7653e-05 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9783\n",
            "Epoch 949/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5027e-05 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9782\n",
            "Epoch 950/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2938e-05 - accuracy: 1.0000 - val_loss: 0.1922 - val_accuracy: 0.9783\n",
            "Epoch 951/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1313e-05 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9785\n",
            "Epoch 952/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.8486e-06 - accuracy: 1.0000 - val_loss: 0.1954 - val_accuracy: 0.9785\n",
            "Epoch 953/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.5242e-06 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9784\n",
            "Epoch 954/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7597e-06 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9787\n",
            "Epoch 955/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.8946e-06 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9785\n",
            "Epoch 956/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2364e-06 - accuracy: 1.0000 - val_loss: 0.2205 - val_accuracy: 0.9785\n",
            "Epoch 957/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3891e-06 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.9782\n",
            "Epoch 958/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8488e-06 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9787\n",
            "Epoch 959/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4773e-06 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9787\n",
            "Epoch 960/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2240e-06 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9783\n",
            "Epoch 961/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0346e-06 - accuracy: 1.0000 - val_loss: 0.2429 - val_accuracy: 0.9787\n",
            "Epoch 962/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2272e-07 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.9788\n",
            "Epoch 963/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.0147e-07 - accuracy: 1.0000 - val_loss: 0.2482 - val_accuracy: 0.9789\n",
            "Epoch 964/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.4023e-07 - accuracy: 1.0000 - val_loss: 0.2505 - val_accuracy: 0.9789\n",
            "Epoch 965/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4041e-07 - accuracy: 1.0000 - val_loss: 0.2523 - val_accuracy: 0.9786\n",
            "Epoch 966/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.8342e-07 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.9789\n",
            "Epoch 967/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2177e-07 - accuracy: 1.0000 - val_loss: 0.2556 - val_accuracy: 0.9787\n",
            "Epoch 968/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.6970e-07 - accuracy: 1.0000 - val_loss: 0.2585 - val_accuracy: 0.9788\n",
            "Epoch 969/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4145e-07 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9789\n",
            "Epoch 970/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.9977e-07 - accuracy: 1.0000 - val_loss: 0.2627 - val_accuracy: 0.9789\n",
            "Epoch 971/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6287e-07 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9789\n",
            "Epoch 972/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3651e-07 - accuracy: 1.0000 - val_loss: 0.2647 - val_accuracy: 0.9789\n",
            "Epoch 973/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2125e-07 - accuracy: 1.0000 - val_loss: 0.2672 - val_accuracy: 0.9789\n",
            "Epoch 974/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9068e-07 - accuracy: 1.0000 - val_loss: 0.2683 - val_accuracy: 0.9789\n",
            "Epoch 975/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6911e-07 - accuracy: 1.0000 - val_loss: 0.2700 - val_accuracy: 0.9791\n",
            "Epoch 976/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4798e-07 - accuracy: 1.0000 - val_loss: 0.2712 - val_accuracy: 0.9789\n",
            "Epoch 977/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3551e-07 - accuracy: 1.0000 - val_loss: 0.2726 - val_accuracy: 0.9791\n",
            "Epoch 978/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1395e-07 - accuracy: 1.0000 - val_loss: 0.2732 - val_accuracy: 0.9789\n",
            "Epoch 979/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9854e-07 - accuracy: 1.0000 - val_loss: 0.2744 - val_accuracy: 0.9790\n",
            "Epoch 980/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9118e-07 - accuracy: 1.0000 - val_loss: 0.2771 - val_accuracy: 0.9790\n",
            "Epoch 981/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7834e-07 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.9789\n",
            "Epoch 982/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6441e-07 - accuracy: 1.0000 - val_loss: 0.2778 - val_accuracy: 0.9792\n",
            "Epoch 983/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5499e-07 - accuracy: 1.0000 - val_loss: 0.2786 - val_accuracy: 0.9791\n",
            "Epoch 984/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4436e-07 - accuracy: 1.0000 - val_loss: 0.2803 - val_accuracy: 0.9787\n",
            "Epoch 985/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3498e-07 - accuracy: 1.0000 - val_loss: 0.2811 - val_accuracy: 0.9791\n",
            "Epoch 986/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2854e-07 - accuracy: 1.0000 - val_loss: 0.2806 - val_accuracy: 0.9790\n",
            "Epoch 987/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1976e-07 - accuracy: 1.0000 - val_loss: 0.2833 - val_accuracy: 0.9791\n",
            "Epoch 988/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1241e-07 - accuracy: 1.0000 - val_loss: 0.2848 - val_accuracy: 0.9789\n",
            "Epoch 989/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0543e-07 - accuracy: 1.0000 - val_loss: 0.2841 - val_accuracy: 0.9789\n",
            "Epoch 990/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0121e-07 - accuracy: 1.0000 - val_loss: 0.2855 - val_accuracy: 0.9789\n",
            "Epoch 991/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9282e-08 - accuracy: 1.0000 - val_loss: 0.2869 - val_accuracy: 0.9789\n",
            "Epoch 992/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4627e-08 - accuracy: 1.0000 - val_loss: 0.2876 - val_accuracy: 0.9793\n",
            "Epoch 993/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.1139e-08 - accuracy: 1.0000 - val_loss: 0.2878 - val_accuracy: 0.9793\n",
            "Epoch 994/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3435e-08 - accuracy: 1.0000 - val_loss: 0.2891 - val_accuracy: 0.9789\n",
            "Epoch 995/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.9189e-08 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9789\n",
            "Epoch 996/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5581e-08 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.9791\n",
            "Epoch 997/1000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.1973e-08 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.9792\n",
            "Epoch 998/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.6558e-08 - accuracy: 1.0000 - val_loss: 0.2935 - val_accuracy: 0.9791\n",
            "Epoch 999/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.4150e-08 - accuracy: 1.0000 - val_loss: 0.2938 - val_accuracy: 0.9789\n",
            "Epoch 1000/1000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1252e-08 - accuracy: 1.0000 - val_loss: 0.2943 - val_accuracy: 0.9793\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0736 - accuracy: 0.9948\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2230 - accuracy: 0.9814\n",
            "train accuracy :  0.9948166608810425 train loss :  0.07356633991003036\n",
            "test accuracy :  0.9814000129699707  test loss :  0.22297894954681396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgTm-dXEPjVg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3683c868-2592-4dfb-e11a-f236babcea04"
      },
      "source": [
        "#은닉층 1개 & epochs = 2000\n",
        "model3_4 = models.Sequential([\n",
        "                            Flatten(input_shape = (28, 28)),\n",
        "                            Dense(512, activation= 'relu', kernel_initializer=initializer),\n",
        "                            Dense(512, activation= 'relu', kernel_initializer=initializer),\n",
        "                            Dense(10, activation= 'softmax', kernel_initializer=initializer)\n",
        "                            ])\n",
        "\n",
        "model3_4.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "#신경망 학습 3_4\n",
        "hist3_4 = model3_4.fit(train_x, train_y, epochs = 2000, batch_size = 256, validation_split = 0.25)\n",
        "\n",
        "plt.plot(hist3_4.history['accuracy'], 'b-')\n",
        "plt.plot(hist3_4.history['val_accuracy'], 'r--')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.ylim([0.94, 1.005])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sc_train3_4 = model3_4.evaluate(train_x, train_y)\n",
        "sc_test3_4 = model3_4.evaluate(test_x, test_y)\n",
        "print(\"train accuracy : \", sc_train3_4[1], \"train loss : \", sc_train3_4[0])\n",
        "print(\"test accuracy : \", sc_test3_4[1], \" test loss : \", sc_test3_4[0])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "176/176 [==============================] - 2s 7ms/step - loss: 0.2888 - accuracy: 0.9161 - val_loss: 0.1511 - val_accuracy: 0.9538\n",
            "Epoch 2/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.1011 - accuracy: 0.9700 - val_loss: 0.1185 - val_accuracy: 0.9650\n",
            "Epoch 3/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0633 - accuracy: 0.9811 - val_loss: 0.0946 - val_accuracy: 0.9722\n",
            "Epoch 4/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0408 - accuracy: 0.9875 - val_loss: 0.0870 - val_accuracy: 0.9731\n",
            "Epoch 5/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0262 - accuracy: 0.9926 - val_loss: 0.0975 - val_accuracy: 0.9728\n",
            "Epoch 6/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0166 - accuracy: 0.9954 - val_loss: 0.0908 - val_accuracy: 0.9749\n",
            "Epoch 7/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0144 - accuracy: 0.9956 - val_loss: 0.0967 - val_accuracy: 0.9765\n",
            "Epoch 8/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.1127 - val_accuracy: 0.9718\n",
            "Epoch 9/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.9978 - val_loss: 0.1158 - val_accuracy: 0.9728\n",
            "Epoch 10/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.1210 - val_accuracy: 0.9721\n",
            "Epoch 11/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.1030 - val_accuracy: 0.9762\n",
            "Epoch 12/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.0960 - val_accuracy: 0.9773\n",
            "Epoch 13/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.1092 - val_accuracy: 0.9753\n",
            "Epoch 14/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.1134 - val_accuracy: 0.9761\n",
            "Epoch 15/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.1048 - val_accuracy: 0.9791\n",
            "Epoch 16/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.1022 - val_accuracy: 0.9787\n",
            "Epoch 17/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.1214 - val_accuracy: 0.9763\n",
            "Epoch 18/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.1309 - val_accuracy: 0.9749\n",
            "Epoch 19/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.1421 - val_accuracy: 0.9703\n",
            "Epoch 20/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.1286 - val_accuracy: 0.9739\n",
            "Epoch 21/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.1193 - val_accuracy: 0.9771\n",
            "Epoch 22/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.1119 - val_accuracy: 0.9768\n",
            "Epoch 23/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.1106 - val_accuracy: 0.9793\n",
            "Epoch 24/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.1060 - val_accuracy: 0.9800\n",
            "Epoch 25/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.3936e-04 - accuracy: 0.9998 - val_loss: 0.1102 - val_accuracy: 0.9807\n",
            "Epoch 26/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1275e-04 - accuracy: 0.9999 - val_loss: 0.1076 - val_accuracy: 0.9809\n",
            "Epoch 27/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3207e-05 - accuracy: 1.0000 - val_loss: 0.1079 - val_accuracy: 0.9809\n",
            "Epoch 28/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.7205e-05 - accuracy: 1.0000 - val_loss: 0.1087 - val_accuracy: 0.9809\n",
            "Epoch 29/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.0614e-05 - accuracy: 1.0000 - val_loss: 0.1095 - val_accuracy: 0.9808\n",
            "Epoch 30/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6000e-05 - accuracy: 1.0000 - val_loss: 0.1103 - val_accuracy: 0.9811\n",
            "Epoch 31/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2516e-05 - accuracy: 1.0000 - val_loss: 0.1107 - val_accuracy: 0.9811\n",
            "Epoch 32/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9773e-05 - accuracy: 1.0000 - val_loss: 0.1114 - val_accuracy: 0.9814\n",
            "Epoch 33/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7481e-05 - accuracy: 1.0000 - val_loss: 0.1121 - val_accuracy: 0.9815\n",
            "Epoch 34/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5587e-05 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9815\n",
            "Epoch 35/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3961e-05 - accuracy: 1.0000 - val_loss: 0.1135 - val_accuracy: 0.9815\n",
            "Epoch 36/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2580e-05 - accuracy: 1.0000 - val_loss: 0.1143 - val_accuracy: 0.9815\n",
            "Epoch 37/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1345e-05 - accuracy: 1.0000 - val_loss: 0.1150 - val_accuracy: 0.9815\n",
            "Epoch 38/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0270e-05 - accuracy: 1.0000 - val_loss: 0.1156 - val_accuracy: 0.9814\n",
            "Epoch 39/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.3137e-06 - accuracy: 1.0000 - val_loss: 0.1164 - val_accuracy: 0.9815\n",
            "Epoch 40/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.4738e-06 - accuracy: 1.0000 - val_loss: 0.1171 - val_accuracy: 0.9813\n",
            "Epoch 41/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7255e-06 - accuracy: 1.0000 - val_loss: 0.1177 - val_accuracy: 0.9813\n",
            "Epoch 42/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.0380e-06 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 0.9811\n",
            "Epoch 43/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4353e-06 - accuracy: 1.0000 - val_loss: 0.1192 - val_accuracy: 0.9812\n",
            "Epoch 44/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.8774e-06 - accuracy: 1.0000 - val_loss: 0.1199 - val_accuracy: 0.9813\n",
            "Epoch 45/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3784e-06 - accuracy: 1.0000 - val_loss: 0.1206 - val_accuracy: 0.9813\n",
            "Epoch 46/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9309e-06 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 0.9813\n",
            "Epoch 47/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.5229e-06 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9813\n",
            "Epoch 48/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.1455e-06 - accuracy: 1.0000 - val_loss: 0.1228 - val_accuracy: 0.9813\n",
            "Epoch 49/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.8022e-06 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 0.9813\n",
            "Epoch 50/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.5000e-06 - accuracy: 1.0000 - val_loss: 0.1242 - val_accuracy: 0.9812\n",
            "Epoch 51/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2192e-06 - accuracy: 1.0000 - val_loss: 0.1249 - val_accuracy: 0.9812\n",
            "Epoch 52/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9577e-06 - accuracy: 1.0000 - val_loss: 0.1256 - val_accuracy: 0.9812\n",
            "Epoch 53/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7191e-06 - accuracy: 1.0000 - val_loss: 0.1264 - val_accuracy: 0.9813\n",
            "Epoch 54/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4997e-06 - accuracy: 1.0000 - val_loss: 0.1271 - val_accuracy: 0.9813\n",
            "Epoch 55/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3003e-06 - accuracy: 1.0000 - val_loss: 0.1278 - val_accuracy: 0.9811\n",
            "Epoch 56/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1145e-06 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 0.9811\n",
            "Epoch 57/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9454e-06 - accuracy: 1.0000 - val_loss: 0.1294 - val_accuracy: 0.9813\n",
            "Epoch 58/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7900e-06 - accuracy: 1.0000 - val_loss: 0.1299 - val_accuracy: 0.9813\n",
            "Epoch 59/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6480e-06 - accuracy: 1.0000 - val_loss: 0.1307 - val_accuracy: 0.9814\n",
            "Epoch 60/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5125e-06 - accuracy: 1.0000 - val_loss: 0.1315 - val_accuracy: 0.9815\n",
            "Epoch 61/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3928e-06 - accuracy: 1.0000 - val_loss: 0.1324 - val_accuracy: 0.9813\n",
            "Epoch 62/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2812e-06 - accuracy: 1.0000 - val_loss: 0.1331 - val_accuracy: 0.9812\n",
            "Epoch 63/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1760e-06 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.9814\n",
            "Epoch 64/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0875e-06 - accuracy: 1.0000 - val_loss: 0.1343 - val_accuracy: 0.9813\n",
            "Epoch 65/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0006e-06 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.9812\n",
            "Epoch 66/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1909e-07 - accuracy: 1.0000 - val_loss: 0.1360 - val_accuracy: 0.9813\n",
            "Epoch 67/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 8.4936e-07 - accuracy: 1.0000 - val_loss: 0.1367 - val_accuracy: 0.9813\n",
            "Epoch 68/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8220e-07 - accuracy: 1.0000 - val_loss: 0.1375 - val_accuracy: 0.9814\n",
            "Epoch 69/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.1788e-07 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9813\n",
            "Epoch 70/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.6157e-07 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9812\n",
            "Epoch 71/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0914e-07 - accuracy: 1.0000 - val_loss: 0.1398 - val_accuracy: 0.9813\n",
            "Epoch 72/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5819e-07 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 0.9815\n",
            "Epoch 73/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.1531e-07 - accuracy: 1.0000 - val_loss: 0.1412 - val_accuracy: 0.9813\n",
            "Epoch 74/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.7510e-07 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.9814\n",
            "Epoch 75/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.3572e-07 - accuracy: 1.0000 - val_loss: 0.1425 - val_accuracy: 0.9813\n",
            "Epoch 76/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.0297e-07 - accuracy: 1.0000 - val_loss: 0.1431 - val_accuracy: 0.9815\n",
            "Epoch 77/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.7066e-07 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9813\n",
            "Epoch 78/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.4159e-07 - accuracy: 1.0000 - val_loss: 0.1444 - val_accuracy: 0.9814\n",
            "Epoch 79/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1376e-07 - accuracy: 1.0000 - val_loss: 0.1454 - val_accuracy: 0.9813\n",
            "Epoch 80/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8724e-07 - accuracy: 1.0000 - val_loss: 0.1465 - val_accuracy: 0.9815\n",
            "Epoch 81/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6757e-07 - accuracy: 1.0000 - val_loss: 0.1468 - val_accuracy: 0.9813\n",
            "Epoch 82/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4382e-07 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 0.9813\n",
            "Epoch 83/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2629e-07 - accuracy: 1.0000 - val_loss: 0.1481 - val_accuracy: 0.9814\n",
            "Epoch 84/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0770e-07 - accuracy: 1.0000 - val_loss: 0.1490 - val_accuracy: 0.9813\n",
            "Epoch 85/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9116e-07 - accuracy: 1.0000 - val_loss: 0.1498 - val_accuracy: 0.9815\n",
            "Epoch 86/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7693e-07 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 0.9812\n",
            "Epoch 87/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6277e-07 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9813\n",
            "Epoch 88/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4976e-07 - accuracy: 1.0000 - val_loss: 0.1518 - val_accuracy: 0.9813\n",
            "Epoch 89/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3855e-07 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9812\n",
            "Epoch 90/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2681e-07 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9812\n",
            "Epoch 91/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1730e-07 - accuracy: 1.0000 - val_loss: 0.1539 - val_accuracy: 0.9811\n",
            "Epoch 92/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0823e-07 - accuracy: 1.0000 - val_loss: 0.1548 - val_accuracy: 0.9814\n",
            "Epoch 93/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.9836e-08 - accuracy: 1.0000 - val_loss: 0.1554 - val_accuracy: 0.9814\n",
            "Epoch 94/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.1995e-08 - accuracy: 1.0000 - val_loss: 0.1561 - val_accuracy: 0.9815\n",
            "Epoch 95/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5195e-08 - accuracy: 1.0000 - val_loss: 0.1567 - val_accuracy: 0.9814\n",
            "Epoch 96/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8230e-08 - accuracy: 1.0000 - val_loss: 0.1575 - val_accuracy: 0.9814\n",
            "Epoch 97/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.2699e-08 - accuracy: 1.0000 - val_loss: 0.1581 - val_accuracy: 0.9815\n",
            "Epoch 98/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.6622e-08 - accuracy: 1.0000 - val_loss: 0.1593 - val_accuracy: 0.9813\n",
            "Epoch 99/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2132e-08 - accuracy: 1.0000 - val_loss: 0.1597 - val_accuracy: 0.9815\n",
            "Epoch 100/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7093e-08 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9815\n",
            "Epoch 101/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3003e-08 - accuracy: 1.0000 - val_loss: 0.1616 - val_accuracy: 0.9813\n",
            "Epoch 102/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.8992e-08 - accuracy: 1.0000 - val_loss: 0.1617 - val_accuracy: 0.9814\n",
            "Epoch 103/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.5228e-08 - accuracy: 1.0000 - val_loss: 0.1623 - val_accuracy: 0.9815\n",
            "Epoch 104/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.2113e-08 - accuracy: 1.0000 - val_loss: 0.1628 - val_accuracy: 0.9815\n",
            "Epoch 105/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9289e-08 - accuracy: 1.0000 - val_loss: 0.1635 - val_accuracy: 0.9815\n",
            "Epoch 106/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6404e-08 - accuracy: 1.0000 - val_loss: 0.1644 - val_accuracy: 0.9814\n",
            "Epoch 107/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3506e-08 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9814\n",
            "Epoch 108/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1167e-08 - accuracy: 1.0000 - val_loss: 0.1656 - val_accuracy: 0.9813\n",
            "Epoch 109/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9198e-08 - accuracy: 1.0000 - val_loss: 0.1664 - val_accuracy: 0.9815\n",
            "Epoch 110/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.7055e-08 - accuracy: 1.0000 - val_loss: 0.1670 - val_accuracy: 0.9816\n",
            "Epoch 111/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5029e-08 - accuracy: 1.0000 - val_loss: 0.1674 - val_accuracy: 0.9813\n",
            "Epoch 112/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3360e-08 - accuracy: 1.0000 - val_loss: 0.1678 - val_accuracy: 0.9814\n",
            "Epoch 113/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.1839e-08 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9816\n",
            "Epoch 114/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.0345e-08 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9816\n",
            "Epoch 115/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8949e-08 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 0.9817\n",
            "Epoch 116/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7635e-08 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 0.9817\n",
            "Epoch 117/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6496e-08 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 0.9815\n",
            "Epoch 118/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5333e-08 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 0.9815\n",
            "Epoch 119/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4435e-08 - accuracy: 1.0000 - val_loss: 0.1719 - val_accuracy: 0.9815\n",
            "Epoch 120/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3537e-08 - accuracy: 1.0000 - val_loss: 0.1728 - val_accuracy: 0.9814\n",
            "Epoch 121/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2795e-08 - accuracy: 1.0000 - val_loss: 0.1729 - val_accuracy: 0.9817\n",
            "Epoch 122/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1852e-08 - accuracy: 1.0000 - val_loss: 0.1737 - val_accuracy: 0.9815\n",
            "Epoch 123/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1121e-08 - accuracy: 1.0000 - val_loss: 0.1737 - val_accuracy: 0.9817\n",
            "Epoch 124/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.0567e-08 - accuracy: 1.0000 - val_loss: 0.1743 - val_accuracy: 0.9817\n",
            "Epoch 125/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.8970e-09 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 0.9815\n",
            "Epoch 126/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2771e-09 - accuracy: 1.0000 - val_loss: 0.1754 - val_accuracy: 0.9817\n",
            "Epoch 127/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6890e-09 - accuracy: 1.0000 - val_loss: 0.1758 - val_accuracy: 0.9817\n",
            "Epoch 128/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2360e-09 - accuracy: 1.0000 - val_loss: 0.1761 - val_accuracy: 0.9817\n",
            "Epoch 129/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.8281e-09 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.9816\n",
            "Epoch 130/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 7.3512e-09 - accuracy: 1.0000 - val_loss: 0.1771 - val_accuracy: 0.9817\n",
            "Epoch 131/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8956e-09 - accuracy: 1.0000 - val_loss: 0.1776 - val_accuracy: 0.9819\n",
            "Epoch 132/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5433e-09 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9817\n",
            "Epoch 133/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2015e-09 - accuracy: 1.0000 - val_loss: 0.1783 - val_accuracy: 0.9817\n",
            "Epoch 134/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8598e-09 - accuracy: 1.0000 - val_loss: 0.1785 - val_accuracy: 0.9818\n",
            "Epoch 135/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.5790e-09 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.9819\n",
            "Epoch 136/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 5.3273e-09 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9819\n",
            "Epoch 137/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.9909e-09 - accuracy: 1.0000 - val_loss: 0.1796 - val_accuracy: 0.9818\n",
            "Epoch 138/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7763e-09 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 0.9817\n",
            "Epoch 139/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.5538e-09 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 0.9819\n",
            "Epoch 140/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.3604e-09 - accuracy: 1.0000 - val_loss: 0.1808 - val_accuracy: 0.9818\n",
            "Epoch 141/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1829e-09 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9816\n",
            "Epoch 142/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.9869e-09 - accuracy: 1.0000 - val_loss: 0.1813 - val_accuracy: 0.9817\n",
            "Epoch 143/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.8359e-09 - accuracy: 1.0000 - val_loss: 0.1813 - val_accuracy: 0.9816\n",
            "Epoch 144/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.6531e-09 - accuracy: 1.0000 - val_loss: 0.1817 - val_accuracy: 0.9818\n",
            "Epoch 145/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4544e-09 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9819\n",
            "Epoch 146/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.3644e-09 - accuracy: 1.0000 - val_loss: 0.1823 - val_accuracy: 0.9818\n",
            "Epoch 147/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.2028e-09 - accuracy: 1.0000 - val_loss: 0.1827 - val_accuracy: 0.9818\n",
            "Epoch 148/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.1047e-09 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 0.9818\n",
            "Epoch 149/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.9802e-09 - accuracy: 1.0000 - val_loss: 0.1830 - val_accuracy: 0.9818\n",
            "Epoch 150/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.8345e-09 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 0.9818\n",
            "Epoch 151/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7630e-09 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9819\n",
            "Epoch 152/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.6067e-09 - accuracy: 1.0000 - val_loss: 0.1837 - val_accuracy: 0.9817\n",
            "Epoch 153/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5643e-09 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.9818\n",
            "Epoch 154/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4478e-09 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.9819\n",
            "Epoch 155/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3524e-09 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9817\n",
            "Epoch 156/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2729e-09 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 0.9817\n",
            "Epoch 157/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.2305e-09 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.9818\n",
            "Epoch 158/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0981e-09 - accuracy: 1.0000 - val_loss: 0.1846 - val_accuracy: 0.9819\n",
            "Epoch 159/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0345e-09 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 0.9819\n",
            "Epoch 160/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.9842e-09 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 0.9819\n",
            "Epoch 161/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8994e-09 - accuracy: 1.0000 - val_loss: 0.1853 - val_accuracy: 0.9819\n",
            "Epoch 162/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8994e-09 - accuracy: 1.0000 - val_loss: 0.1853 - val_accuracy: 0.9819\n",
            "Epoch 163/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8438e-09 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9819\n",
            "Epoch 164/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7431e-09 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9818\n",
            "Epoch 165/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7193e-09 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9819\n",
            "Epoch 166/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6928e-09 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9818\n",
            "Epoch 167/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6530e-09 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9819\n",
            "Epoch 168/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6212e-09 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9819\n",
            "Epoch 169/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6424e-09 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9818\n",
            "Epoch 170/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5444e-09 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9820\n",
            "Epoch 171/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5391e-09 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9819\n",
            "Epoch 172/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4755e-09 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9819\n",
            "Epoch 173/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4808e-09 - accuracy: 1.0000 - val_loss: 0.1866 - val_accuracy: 0.9819\n",
            "Epoch 174/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4597e-09 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9819\n",
            "Epoch 175/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4411e-09 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9819\n",
            "Epoch 176/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3775e-09 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9819\n",
            "Epoch 177/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3563e-09 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9819\n",
            "Epoch 178/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3590e-09 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9819\n",
            "Epoch 179/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3140e-09 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9819\n",
            "Epoch 180/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3378e-09 - accuracy: 1.0000 - val_loss: 0.1873 - val_accuracy: 0.9818\n",
            "Epoch 181/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2424e-09 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 0.9819\n",
            "Epoch 182/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3113e-09 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9819\n",
            "Epoch 183/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2875e-09 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.9819\n",
            "Epoch 184/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2610e-09 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9818\n",
            "Epoch 185/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2212e-09 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9818\n",
            "Epoch 186/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2265e-09 - accuracy: 1.0000 - val_loss: 0.1885 - val_accuracy: 0.9819\n",
            "Epoch 187/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2239e-09 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9819\n",
            "Epoch 188/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1841e-09 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 0.9819\n",
            "Epoch 189/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1735e-09 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9819\n",
            "Epoch 190/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2133e-09 - accuracy: 1.0000 - val_loss: 0.1892 - val_accuracy: 0.9819\n",
            "Epoch 191/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1947e-09 - accuracy: 1.0000 - val_loss: 0.1895 - val_accuracy: 0.9819\n",
            "Epoch 192/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1683e-09 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9819\n",
            "Epoch 193/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1709e-09 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.9818\n",
            "Epoch 194/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1868e-09 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9819\n",
            "Epoch 195/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1418e-09 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9819\n",
            "Epoch 196/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1762e-09 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9819\n",
            "Epoch 197/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1577e-09 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9818\n",
            "Epoch 198/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1577e-09 - accuracy: 1.0000 - val_loss: 0.1907 - val_accuracy: 0.9819\n",
            "Epoch 199/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1921e-09 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9818\n",
            "Epoch 200/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1577e-09 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9819\n",
            "Epoch 201/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1577e-09 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9819\n",
            "Epoch 202/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1418e-09 - accuracy: 1.0000 - val_loss: 0.1916 - val_accuracy: 0.9819\n",
            "Epoch 203/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1550e-09 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9819\n",
            "Epoch 204/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1603e-09 - accuracy: 1.0000 - val_loss: 0.1922 - val_accuracy: 0.9819\n",
            "Epoch 205/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1497e-09 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 0.9819\n",
            "Epoch 206/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1391e-09 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9819\n",
            "Epoch 207/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1735e-09 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9819\n",
            "Epoch 208/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1762e-09 - accuracy: 1.0000 - val_loss: 0.1931 - val_accuracy: 0.9819\n",
            "Epoch 209/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1603e-09 - accuracy: 1.0000 - val_loss: 0.1935 - val_accuracy: 0.9819\n",
            "Epoch 210/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1206e-09 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9819\n",
            "Epoch 211/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1497e-09 - accuracy: 1.0000 - val_loss: 0.1939 - val_accuracy: 0.9819\n",
            "Epoch 212/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1153e-09 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9819\n",
            "Epoch 213/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1312e-09 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9819\n",
            "Epoch 214/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1497e-09 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9818\n",
            "Epoch 215/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1338e-09 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.9819\n",
            "Epoch 216/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1312e-09 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9819\n",
            "Epoch 217/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1921e-09 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9819\n",
            "Epoch 218/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1683e-09 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9817\n",
            "Epoch 219/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1285e-09 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9819\n",
            "Epoch 220/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2080e-09 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.9817\n",
            "Epoch 221/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1841e-09 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.9818\n",
            "Epoch 222/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1577e-09 - accuracy: 1.0000 - val_loss: 0.1969 - val_accuracy: 0.9817\n",
            "Epoch 223/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1788e-09 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 0.9818\n",
            "Epoch 224/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1603e-09 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9817\n",
            "Epoch 225/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1735e-09 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9817\n",
            "Epoch 226/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1815e-09 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9817\n",
            "Epoch 227/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1868e-09 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9816\n",
            "Epoch 228/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1497e-09 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.9817\n",
            "Epoch 229/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2053e-09 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9817\n",
            "Epoch 230/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2000e-09 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9817\n",
            "Epoch 231/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2239e-09 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 0.9817\n",
            "Epoch 232/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1709e-09 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9817\n",
            "Epoch 233/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2265e-09 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9816\n",
            "Epoch 234/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2292e-09 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9817\n",
            "Epoch 235/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2133e-09 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9816\n",
            "Epoch 236/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2265e-09 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9816\n",
            "Epoch 237/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2424e-09 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9817\n",
            "Epoch 238/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2239e-09 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9816\n",
            "Epoch 239/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1974e-09 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9817\n",
            "Epoch 240/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2318e-09 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9814\n",
            "Epoch 241/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2504e-09 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9815\n",
            "Epoch 242/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2504e-09 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9816\n",
            "Epoch 243/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2822e-09 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9814\n",
            "Epoch 244/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2345e-09 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9814\n",
            "Epoch 245/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2848e-09 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9813\n",
            "Epoch 246/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2636e-09 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9815\n",
            "Epoch 247/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2583e-09 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9815\n",
            "Epoch 248/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3140e-09 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9815\n",
            "Epoch 249/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3087e-09 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 0.9815\n",
            "Epoch 250/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2742e-09 - accuracy: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.9815\n",
            "Epoch 251/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3087e-09 - accuracy: 1.0000 - val_loss: 0.2051 - val_accuracy: 0.9813\n",
            "Epoch 252/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.2928e-09 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.9815\n",
            "Epoch 253/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3272e-09 - accuracy: 1.0000 - val_loss: 0.2060 - val_accuracy: 0.9815\n",
            "Epoch 254/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3087e-09 - accuracy: 1.0000 - val_loss: 0.2065 - val_accuracy: 0.9814\n",
            "Epoch 255/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3298e-09 - accuracy: 1.0000 - val_loss: 0.2066 - val_accuracy: 0.9815\n",
            "Epoch 256/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3431e-09 - accuracy: 1.0000 - val_loss: 0.2070 - val_accuracy: 0.9813\n",
            "Epoch 257/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3484e-09 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9814\n",
            "Epoch 258/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3669e-09 - accuracy: 1.0000 - val_loss: 0.2073 - val_accuracy: 0.9813\n",
            "Epoch 259/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3616e-09 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9814\n",
            "Epoch 260/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3298e-09 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.9812\n",
            "Epoch 261/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3828e-09 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9813\n",
            "Epoch 262/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3802e-09 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 0.9813\n",
            "Epoch 263/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.3616e-09 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9812\n",
            "Epoch 264/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4093e-09 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9811\n",
            "Epoch 265/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4464e-09 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9813\n",
            "Epoch 266/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4358e-09 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 0.9813\n",
            "Epoch 267/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4173e-09 - accuracy: 1.0000 - val_loss: 0.2104 - val_accuracy: 0.9813\n",
            "Epoch 268/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4305e-09 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9813\n",
            "Epoch 269/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4570e-09 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9813\n",
            "Epoch 270/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4755e-09 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9811\n",
            "Epoch 271/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.4888e-09 - accuracy: 1.0000 - val_loss: 0.2119 - val_accuracy: 0.9812\n",
            "Epoch 272/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4332e-09 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9812\n",
            "Epoch 273/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4861e-09 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 0.9812\n",
            "Epoch 274/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4835e-09 - accuracy: 1.0000 - val_loss: 0.2131 - val_accuracy: 0.9812\n",
            "Epoch 275/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5179e-09 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.9811\n",
            "Epoch 276/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5073e-09 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9813\n",
            "Epoch 277/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5232e-09 - accuracy: 1.0000 - val_loss: 0.2136 - val_accuracy: 0.9812\n",
            "Epoch 278/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5285e-09 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9810\n",
            "Epoch 279/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4941e-09 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.9811\n",
            "Epoch 280/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5497e-09 - accuracy: 1.0000 - val_loss: 0.2149 - val_accuracy: 0.9810\n",
            "Epoch 281/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5656e-09 - accuracy: 1.0000 - val_loss: 0.2151 - val_accuracy: 0.9810\n",
            "Epoch 282/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5338e-09 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 0.9811\n",
            "Epoch 283/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5736e-09 - accuracy: 1.0000 - val_loss: 0.2158 - val_accuracy: 0.9811\n",
            "Epoch 284/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5895e-09 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9810\n",
            "Epoch 285/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5709e-09 - accuracy: 1.0000 - val_loss: 0.2163 - val_accuracy: 0.9811\n",
            "Epoch 286/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6001e-09 - accuracy: 1.0000 - val_loss: 0.2166 - val_accuracy: 0.9809\n",
            "Epoch 287/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5895e-09 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9809\n",
            "Epoch 288/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6054e-09 - accuracy: 1.0000 - val_loss: 0.2170 - val_accuracy: 0.9808\n",
            "Epoch 289/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6265e-09 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9810\n",
            "Epoch 290/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.5895e-09 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9809\n",
            "Epoch 291/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6186e-09 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 0.9808\n",
            "Epoch 292/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6133e-09 - accuracy: 1.0000 - val_loss: 0.2194 - val_accuracy: 0.9809\n",
            "Epoch 293/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6795e-09 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9810\n",
            "Epoch 294/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6901e-09 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9808\n",
            "Epoch 295/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6981e-09 - accuracy: 1.0000 - val_loss: 0.2195 - val_accuracy: 0.9810\n",
            "Epoch 296/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6716e-09 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9808\n",
            "Epoch 297/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6636e-09 - accuracy: 1.0000 - val_loss: 0.2206 - val_accuracy: 0.9809\n",
            "Epoch 298/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7246e-09 - accuracy: 1.0000 - val_loss: 0.2210 - val_accuracy: 0.9809\n",
            "Epoch 299/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.6928e-09 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9809\n",
            "Epoch 300/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7113e-09 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9807\n",
            "Epoch 301/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.7590e-09 - accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 0.9807\n",
            "Epoch 302/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7431e-09 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.9805\n",
            "Epoch 303/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7881e-09 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9806\n",
            "Epoch 304/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7961e-09 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9808\n",
            "Epoch 305/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8067e-09 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 0.9808\n",
            "Epoch 306/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7749e-09 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.9806\n",
            "Epoch 307/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8544e-09 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9807\n",
            "Epoch 308/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8729e-09 - accuracy: 1.0000 - val_loss: 0.2245 - val_accuracy: 0.9805\n",
            "Epoch 309/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8862e-09 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.9807\n",
            "Epoch 310/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9021e-09 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9807\n",
            "Epoch 311/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9153e-09 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.9805\n",
            "Epoch 312/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.8915e-09 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9804\n",
            "Epoch 313/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8941e-09 - accuracy: 1.0000 - val_loss: 0.2260 - val_accuracy: 0.9805\n",
            "Epoch 314/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9312e-09 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 0.9803\n",
            "Epoch 315/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9391e-09 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9804\n",
            "Epoch 316/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9736e-09 - accuracy: 1.0000 - val_loss: 0.2276 - val_accuracy: 0.9805\n",
            "Epoch 317/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9815e-09 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 0.9805\n",
            "Epoch 318/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0107e-09 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.9805\n",
            "Epoch 319/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0345e-09 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9801\n",
            "Epoch 320/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0292e-09 - accuracy: 1.0000 - val_loss: 0.2289 - val_accuracy: 0.9804\n",
            "Epoch 321/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0398e-09 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9803\n",
            "Epoch 322/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0530e-09 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 0.9803\n",
            "Epoch 323/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0292e-09 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 0.9805\n",
            "Epoch 324/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0875e-09 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9804\n",
            "Epoch 325/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0928e-09 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9803\n",
            "Epoch 326/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0478e-09 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9804\n",
            "Epoch 327/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1087e-09 - accuracy: 1.0000 - val_loss: 0.2326 - val_accuracy: 0.9801\n",
            "Epoch 328/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0107e-09 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9800\n",
            "Epoch 329/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1193e-09 - accuracy: 1.0000 - val_loss: 0.2324 - val_accuracy: 0.9800\n",
            "Epoch 330/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1511e-09 - accuracy: 1.0000 - val_loss: 0.2323 - val_accuracy: 0.9799\n",
            "Epoch 331/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1802e-09 - accuracy: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.9801\n",
            "Epoch 332/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1378e-09 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9803\n",
            "Epoch 333/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2279e-09 - accuracy: 1.0000 - val_loss: 0.2333 - val_accuracy: 0.9802\n",
            "Epoch 334/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2756e-09 - accuracy: 1.0000 - val_loss: 0.2341 - val_accuracy: 0.9800\n",
            "Epoch 335/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1829e-09 - accuracy: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.9799\n",
            "Epoch 336/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2862e-09 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9801\n",
            "Epoch 337/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3206e-09 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.9799\n",
            "Epoch 338/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2650e-09 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 0.9800\n",
            "Epoch 339/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3709e-09 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9801\n",
            "Epoch 340/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3047e-09 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9802\n",
            "Epoch 341/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5723e-09 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.9801\n",
            "Epoch 342/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3842e-09 - accuracy: 1.0000 - val_loss: 0.2388 - val_accuracy: 0.9799\n",
            "Epoch 343/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3444e-09 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.9799\n",
            "Epoch 344/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3948e-09 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9801\n",
            "Epoch 345/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.3233e-09 - accuracy: 1.0000 - val_loss: 0.2395 - val_accuracy: 0.9796\n",
            "Epoch 346/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4292e-09 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9797\n",
            "Epoch 347/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5246e-09 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.9798\n",
            "Epoch 348/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4875e-09 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9797\n",
            "Epoch 349/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5087e-09 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9798\n",
            "Epoch 350/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5325e-09 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 0.9797\n",
            "Epoch 351/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5590e-09 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9797\n",
            "Epoch 352/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4584e-09 - accuracy: 1.0000 - val_loss: 0.2437 - val_accuracy: 0.9795\n",
            "Epoch 353/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6915e-09 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9795\n",
            "Epoch 354/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7259e-09 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9794\n",
            "Epoch 355/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.2731 - accuracy: 0.9869 - val_loss: 0.4477 - val_accuracy: 0.9489\n",
            "Epoch 356/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0304 - accuracy: 0.9932 - val_loss: 0.1772 - val_accuracy: 0.9738\n",
            "Epoch 357/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.1624 - val_accuracy: 0.9760\n",
            "Epoch 358/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5597e-04 - accuracy: 1.0000 - val_loss: 0.1610 - val_accuracy: 0.9767\n",
            "Epoch 359/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2396e-04 - accuracy: 1.0000 - val_loss: 0.1597 - val_accuracy: 0.9768\n",
            "Epoch 360/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2551e-05 - accuracy: 1.0000 - val_loss: 0.1598 - val_accuracy: 0.9770\n",
            "Epoch 361/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6701e-05 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9769\n",
            "Epoch 362/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 6.5313e-05 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 0.9771\n",
            "Epoch 363/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.6827e-05 - accuracy: 1.0000 - val_loss: 0.1607 - val_accuracy: 0.9773\n",
            "Epoch 364/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0086e-05 - accuracy: 1.0000 - val_loss: 0.1612 - val_accuracy: 0.9772\n",
            "Epoch 365/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 4.4463e-05 - accuracy: 1.0000 - val_loss: 0.1615 - val_accuracy: 0.9776\n",
            "Epoch 366/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.9804e-05 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.9775\n",
            "Epoch 367/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 3.5529e-05 - accuracy: 1.0000 - val_loss: 0.1623 - val_accuracy: 0.9775\n",
            "Epoch 368/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1990e-05 - accuracy: 1.0000 - val_loss: 0.1625 - val_accuracy: 0.9776\n",
            "Epoch 369/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8818e-05 - accuracy: 1.0000 - val_loss: 0.1630 - val_accuracy: 0.9777\n",
            "Epoch 370/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5887e-05 - accuracy: 1.0000 - val_loss: 0.1634 - val_accuracy: 0.9779\n",
            "Epoch 371/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3288e-05 - accuracy: 1.0000 - val_loss: 0.1638 - val_accuracy: 0.9780\n",
            "Epoch 372/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0978e-05 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 0.9780\n",
            "Epoch 373/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9017e-05 - accuracy: 1.0000 - val_loss: 0.1648 - val_accuracy: 0.9780\n",
            "Epoch 374/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7002e-05 - accuracy: 1.0000 - val_loss: 0.1655 - val_accuracy: 0.9783\n",
            "Epoch 375/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5359e-05 - accuracy: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9781\n",
            "Epoch 376/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3832e-05 - accuracy: 1.0000 - val_loss: 0.1665 - val_accuracy: 0.9780\n",
            "Epoch 377/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2403e-05 - accuracy: 1.0000 - val_loss: 0.1670 - val_accuracy: 0.9779\n",
            "Epoch 378/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1181e-05 - accuracy: 1.0000 - val_loss: 0.1677 - val_accuracy: 0.9783\n",
            "Epoch 379/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0036e-05 - accuracy: 1.0000 - val_loss: 0.1690 - val_accuracy: 0.9781\n",
            "Epoch 380/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 9.0317e-06 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 0.9784\n",
            "Epoch 381/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1446e-06 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 0.9787\n",
            "Epoch 382/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3436e-06 - accuracy: 1.0000 - val_loss: 0.1703 - val_accuracy: 0.9785\n",
            "Epoch 383/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6631e-06 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 0.9785\n",
            "Epoch 384/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0037e-06 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 0.9788\n",
            "Epoch 385/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.4463e-06 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 0.9787\n",
            "Epoch 386/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9376e-06 - accuracy: 1.0000 - val_loss: 0.1726 - val_accuracy: 0.9785\n",
            "Epoch 387/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4882e-06 - accuracy: 1.0000 - val_loss: 0.1735 - val_accuracy: 0.9787\n",
            "Epoch 388/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.0694e-06 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 0.9787\n",
            "Epoch 389/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7211e-06 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9788\n",
            "Epoch 390/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3779e-06 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 0.9788\n",
            "Epoch 391/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0828e-06 - accuracy: 1.0000 - val_loss: 0.1761 - val_accuracy: 0.9788\n",
            "Epoch 392/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8113e-06 - accuracy: 1.0000 - val_loss: 0.1770 - val_accuracy: 0.9788\n",
            "Epoch 393/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5719e-06 - accuracy: 1.0000 - val_loss: 0.1776 - val_accuracy: 0.9787\n",
            "Epoch 394/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3525e-06 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 0.9787\n",
            "Epoch 395/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1430e-06 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9788\n",
            "Epoch 396/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9631e-06 - accuracy: 1.0000 - val_loss: 0.1794 - val_accuracy: 0.9787\n",
            "Epoch 397/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7954e-06 - accuracy: 1.0000 - val_loss: 0.1804 - val_accuracy: 0.9789\n",
            "Epoch 398/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6398e-06 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 0.9789\n",
            "Epoch 399/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5003e-06 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 0.9789\n",
            "Epoch 400/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3748e-06 - accuracy: 1.0000 - val_loss: 0.1825 - val_accuracy: 0.9789\n",
            "Epoch 401/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2607e-06 - accuracy: 1.0000 - val_loss: 0.1825 - val_accuracy: 0.9788\n",
            "Epoch 402/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1528e-06 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 0.9790\n",
            "Epoch 403/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0570e-06 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9789\n",
            "Epoch 404/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.6650e-07 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9789\n",
            "Epoch 405/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.8645e-07 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9789\n",
            "Epoch 406/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1092e-07 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9790\n",
            "Epoch 407/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3960e-07 - accuracy: 1.0000 - val_loss: 0.1866 - val_accuracy: 0.9791\n",
            "Epoch 408/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7989e-07 - accuracy: 1.0000 - val_loss: 0.1873 - val_accuracy: 0.9791\n",
            "Epoch 409/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2334e-07 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9792\n",
            "Epoch 410/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.7353e-07 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.9793\n",
            "Epoch 411/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2605e-07 - accuracy: 1.0000 - val_loss: 0.1895 - val_accuracy: 0.9794\n",
            "Epoch 412/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.8298e-07 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9791\n",
            "Epoch 413/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4468e-07 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9791\n",
            "Epoch 414/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0565e-07 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9791\n",
            "Epoch 415/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7472e-07 - accuracy: 1.0000 - val_loss: 0.1920 - val_accuracy: 0.9791\n",
            "Epoch 416/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4309e-07 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9793\n",
            "Epoch 417/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1544e-07 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9791\n",
            "Epoch 418/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9099e-07 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 0.9792\n",
            "Epoch 419/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6747e-07 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9791\n",
            "Epoch 420/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 2.4556e-07 - accuracy: 1.0000 - val_loss: 0.1958 - val_accuracy: 0.9790\n",
            "Epoch 421/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2664e-07 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9791\n",
            "Epoch 422/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0848e-07 - accuracy: 1.0000 - val_loss: 0.1971 - val_accuracy: 0.9791\n",
            "Epoch 423/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9203e-07 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9791\n",
            "Epoch 424/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7638e-07 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 0.9791\n",
            "Epoch 425/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6221e-07 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9793\n",
            "Epoch 426/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5006e-07 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9793\n",
            "Epoch 427/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3790e-07 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9792\n",
            "Epoch 428/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2726e-07 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9792\n",
            "Epoch 429/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1748e-07 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9791\n",
            "Epoch 430/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0827e-07 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9792\n",
            "Epoch 431/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0001e-07 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9791\n",
            "Epoch 432/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.2456e-08 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9792\n",
            "Epoch 433/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5250e-08 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9791\n",
            "Epoch 434/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.9009e-08 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9791\n",
            "Epoch 435/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.2980e-08 - accuracy: 1.0000 - val_loss: 0.2053 - val_accuracy: 0.9791\n",
            "Epoch 436/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.7345e-08 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9791\n",
            "Epoch 437/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2540e-08 - accuracy: 1.0000 - val_loss: 0.2066 - val_accuracy: 0.9791\n",
            "Epoch 438/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.7575e-08 - accuracy: 1.0000 - val_loss: 0.2073 - val_accuracy: 0.9791\n",
            "Epoch 439/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3501e-08 - accuracy: 1.0000 - val_loss: 0.2078 - val_accuracy: 0.9791\n",
            "Epoch 440/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9538e-08 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9790\n",
            "Epoch 441/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5760e-08 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9790\n",
            "Epoch 442/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2489e-08 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9791\n",
            "Epoch 443/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9424e-08 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 0.9791\n",
            "Epoch 444/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6634e-08 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9791\n",
            "Epoch 445/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3922e-08 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9792\n",
            "Epoch 446/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1593e-08 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9791\n",
            "Epoch 447/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9312e-08 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9792\n",
            "Epoch 448/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7214e-08 - accuracy: 1.0000 - val_loss: 0.2133 - val_accuracy: 0.9792\n",
            "Epoch 449/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5468e-08 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.9794\n",
            "Epoch 450/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3648e-08 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9793\n",
            "Epoch 451/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2040e-08 - accuracy: 1.0000 - val_loss: 0.2151 - val_accuracy: 0.9793\n",
            "Epoch 452/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0480e-08 - accuracy: 1.0000 - val_loss: 0.2158 - val_accuracy: 0.9793\n",
            "Epoch 453/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9145e-08 - accuracy: 1.0000 - val_loss: 0.2165 - val_accuracy: 0.9795\n",
            "Epoch 454/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7863e-08 - accuracy: 1.0000 - val_loss: 0.2170 - val_accuracy: 0.9795\n",
            "Epoch 455/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6578e-08 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9795\n",
            "Epoch 456/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5537e-08 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9795\n",
            "Epoch 457/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4411e-08 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 0.9796\n",
            "Epoch 458/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3571e-08 - accuracy: 1.0000 - val_loss: 0.2191 - val_accuracy: 0.9798\n",
            "Epoch 459/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2589e-08 - accuracy: 1.0000 - val_loss: 0.2195 - val_accuracy: 0.9797\n",
            "Epoch 460/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1823e-08 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 0.9797\n",
            "Epoch 461/2000\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1.1039e-08 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9797\n",
            "Epoch 462/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0347e-08 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9798\n",
            "Epoch 463/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7222e-09 - accuracy: 1.0000 - val_loss: 0.2216 - val_accuracy: 0.9798\n",
            "Epoch 464/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.1420e-09 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9797\n",
            "Epoch 465/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6122e-09 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9797\n",
            "Epoch 466/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.0400e-09 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9798\n",
            "Epoch 467/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5287e-09 - accuracy: 1.0000 - val_loss: 0.2240 - val_accuracy: 0.9797\n",
            "Epoch 468/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.0492e-09 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9797\n",
            "Epoch 469/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.5618e-09 - accuracy: 1.0000 - val_loss: 0.2249 - val_accuracy: 0.9797\n",
            "Epoch 470/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2068e-09 - accuracy: 1.0000 - val_loss: 0.2257 - val_accuracy: 0.9797\n",
            "Epoch 471/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.8730e-09 - accuracy: 1.0000 - val_loss: 0.2258 - val_accuracy: 0.9796\n",
            "Epoch 472/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5737e-09 - accuracy: 1.0000 - val_loss: 0.2264 - val_accuracy: 0.9797\n",
            "Epoch 473/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1922e-09 - accuracy: 1.0000 - val_loss: 0.2270 - val_accuracy: 0.9797\n",
            "Epoch 474/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9459e-09 - accuracy: 1.0000 - val_loss: 0.2276 - val_accuracy: 0.9797\n",
            "Epoch 475/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5776e-09 - accuracy: 1.0000 - val_loss: 0.2282 - val_accuracy: 0.9796\n",
            "Epoch 476/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3392e-09 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9797\n",
            "Epoch 477/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1087e-09 - accuracy: 1.0000 - val_loss: 0.2290 - val_accuracy: 0.9797\n",
            "Epoch 478/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8889e-09 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 0.9796\n",
            "Epoch 479/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6452e-09 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 0.9798\n",
            "Epoch 480/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5153e-09 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9798\n",
            "Epoch 481/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2796e-09 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.9797\n",
            "Epoch 482/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0835e-09 - accuracy: 1.0000 - val_loss: 0.2323 - val_accuracy: 0.9798\n",
            "Epoch 483/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9352e-09 - accuracy: 1.0000 - val_loss: 0.2327 - val_accuracy: 0.9799\n",
            "Epoch 484/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7710e-09 - accuracy: 1.0000 - val_loss: 0.2332 - val_accuracy: 0.9797\n",
            "Epoch 485/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6491e-09 - accuracy: 1.0000 - val_loss: 0.2337 - val_accuracy: 0.9799\n",
            "Epoch 486/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5007e-09 - accuracy: 1.0000 - val_loss: 0.2345 - val_accuracy: 0.9799\n",
            "Epoch 487/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4133e-09 - accuracy: 1.0000 - val_loss: 0.2350 - val_accuracy: 0.9799\n",
            "Epoch 488/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2358e-09 - accuracy: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.9799\n",
            "Epoch 489/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1961e-09 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9799\n",
            "Epoch 490/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0239e-09 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9799\n",
            "Epoch 491/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9577e-09 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 0.9799\n",
            "Epoch 492/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8729e-09 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.9799\n",
            "Epoch 493/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8040e-09 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9799\n",
            "Epoch 494/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7352e-09 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.9798\n",
            "Epoch 495/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6477e-09 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9799\n",
            "Epoch 496/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5921e-09 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9797\n",
            "Epoch 497/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5206e-09 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9795\n",
            "Epoch 498/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4597e-09 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9797\n",
            "Epoch 499/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3934e-09 - accuracy: 1.0000 - val_loss: 0.2428 - val_accuracy: 0.9795\n",
            "Epoch 500/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3325e-09 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9796\n",
            "Epoch 501/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3431e-09 - accuracy: 1.0000 - val_loss: 0.2441 - val_accuracy: 0.9796\n",
            "Epoch 502/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2371e-09 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9797\n",
            "Epoch 503/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2398e-09 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9796\n",
            "Epoch 504/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2159e-09 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9795\n",
            "Epoch 505/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1550e-09 - accuracy: 1.0000 - val_loss: 0.2465 - val_accuracy: 0.9794\n",
            "Epoch 506/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1259e-09 - accuracy: 1.0000 - val_loss: 0.2474 - val_accuracy: 0.9795\n",
            "Epoch 507/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1047e-09 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9797\n",
            "Epoch 508/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0596e-09 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9794\n",
            "Epoch 509/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0835e-09 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9794\n",
            "Epoch 510/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0517e-09 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9794\n",
            "Epoch 511/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0278e-09 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9794\n",
            "Epoch 512/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0305e-09 - accuracy: 1.0000 - val_loss: 0.2511 - val_accuracy: 0.9794\n",
            "Epoch 513/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.9606e-10 - accuracy: 1.0000 - val_loss: 0.2520 - val_accuracy: 0.9795\n",
            "Epoch 514/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7222e-10 - accuracy: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.9795\n",
            "Epoch 515/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5897e-10 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.9794\n",
            "Epoch 516/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5103e-10 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.9793\n",
            "Epoch 517/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6957e-10 - accuracy: 1.0000 - val_loss: 0.2545 - val_accuracy: 0.9793\n",
            "Epoch 518/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3513e-10 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9792\n",
            "Epoch 519/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2983e-10 - accuracy: 1.0000 - val_loss: 0.2560 - val_accuracy: 0.9791\n",
            "Epoch 520/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3513e-10 - accuracy: 1.0000 - val_loss: 0.2560 - val_accuracy: 0.9795\n",
            "Epoch 521/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.4573e-10 - accuracy: 1.0000 - val_loss: 0.2570 - val_accuracy: 0.9792\n",
            "Epoch 522/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1924e-10 - accuracy: 1.0000 - val_loss: 0.2577 - val_accuracy: 0.9791\n",
            "Epoch 523/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.0864e-10 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9792\n",
            "Epoch 524/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0864e-10 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.9793\n",
            "Epoch 525/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.3248e-10 - accuracy: 1.0000 - val_loss: 0.2593 - val_accuracy: 0.9791\n",
            "Epoch 526/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.2983e-10 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.9791\n",
            "Epoch 527/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.9275e-10 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9793\n",
            "Epoch 528/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8745e-10 - accuracy: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.9792\n",
            "Epoch 529/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.7685e-10 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.9793\n",
            "Epoch 530/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9010e-10 - accuracy: 1.0000 - val_loss: 0.2622 - val_accuracy: 0.9793\n",
            "Epoch 531/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1659e-10 - accuracy: 1.0000 - val_loss: 0.2630 - val_accuracy: 0.9793\n",
            "Epoch 532/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6890e-10 - accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 0.9791\n",
            "Epoch 533/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.7420e-10 - accuracy: 1.0000 - val_loss: 0.2641 - val_accuracy: 0.9792\n",
            "Epoch 534/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.5831e-10 - accuracy: 1.0000 - val_loss: 0.2646 - val_accuracy: 0.9792\n",
            "Epoch 535/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6096e-10 - accuracy: 1.0000 - val_loss: 0.2651 - val_accuracy: 0.9791\n",
            "Epoch 536/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.5301e-10 - accuracy: 1.0000 - val_loss: 0.2656 - val_accuracy: 0.9791\n",
            "Epoch 537/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4506e-10 - accuracy: 1.0000 - val_loss: 0.2661 - val_accuracy: 0.9792\n",
            "Epoch 538/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8480e-10 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9793\n",
            "Epoch 539/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.6625e-10 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9793\n",
            "Epoch 540/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.8480e-10 - accuracy: 1.0000 - val_loss: 0.2677 - val_accuracy: 0.9793\n",
            "Epoch 541/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6625e-10 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.9792\n",
            "Epoch 542/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8480e-10 - accuracy: 1.0000 - val_loss: 0.2688 - val_accuracy: 0.9792\n",
            "Epoch 543/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.7950e-10 - accuracy: 1.0000 - val_loss: 0.2694 - val_accuracy: 0.9793\n",
            "Epoch 544/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.0864e-10 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.9792\n",
            "Epoch 545/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.7950e-10 - accuracy: 1.0000 - val_loss: 0.2702 - val_accuracy: 0.9794\n",
            "Epoch 546/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.1129e-10 - accuracy: 1.0000 - val_loss: 0.2711 - val_accuracy: 0.9793\n",
            "Epoch 547/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8215e-10 - accuracy: 1.0000 - val_loss: 0.2714 - val_accuracy: 0.9793\n",
            "Epoch 548/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9539e-10 - accuracy: 1.0000 - val_loss: 0.2715 - val_accuracy: 0.9793\n",
            "Epoch 549/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.8745e-10 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9795\n",
            "Epoch 550/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0334e-10 - accuracy: 1.0000 - val_loss: 0.2725 - val_accuracy: 0.9794\n",
            "Epoch 551/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6890e-10 - accuracy: 1.0000 - val_loss: 0.2729 - val_accuracy: 0.9794\n",
            "Epoch 552/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5367e-10 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9794\n",
            "Epoch 553/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.2718e-10 - accuracy: 1.0000 - val_loss: 0.2741 - val_accuracy: 0.9795\n",
            "Epoch 554/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2453e-10 - accuracy: 1.0000 - val_loss: 0.2744 - val_accuracy: 0.9795\n",
            "Epoch 555/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.4308e-10 - accuracy: 1.0000 - val_loss: 0.2749 - val_accuracy: 0.9794\n",
            "Epoch 556/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2453e-10 - accuracy: 1.0000 - val_loss: 0.2759 - val_accuracy: 0.9794\n",
            "Epoch 557/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7222e-10 - accuracy: 1.0000 - val_loss: 0.2766 - val_accuracy: 0.9795\n",
            "Epoch 558/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5632e-10 - accuracy: 1.0000 - val_loss: 0.2766 - val_accuracy: 0.9794\n",
            "Epoch 559/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0599e-10 - accuracy: 1.0000 - val_loss: 0.2775 - val_accuracy: 0.9795\n",
            "Epoch 560/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.7487e-10 - accuracy: 1.0000 - val_loss: 0.2778 - val_accuracy: 0.9794\n",
            "Epoch 561/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.2983e-10 - accuracy: 1.0000 - val_loss: 0.2784 - val_accuracy: 0.9794\n",
            "Epoch 562/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.8281e-10 - accuracy: 1.0000 - val_loss: 0.2797 - val_accuracy: 0.9795\n",
            "Epoch 563/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9871e-10 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9795\n",
            "Epoch 564/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0596e-09 - accuracy: 1.0000 - val_loss: 0.2801 - val_accuracy: 0.9796\n",
            "Epoch 565/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0173e-09 - accuracy: 1.0000 - val_loss: 0.2807 - val_accuracy: 0.9797\n",
            "Epoch 566/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0226e-09 - accuracy: 1.0000 - val_loss: 0.2811 - val_accuracy: 0.9795\n",
            "Epoch 567/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0093e-09 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9796\n",
            "Epoch 568/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0384e-09 - accuracy: 1.0000 - val_loss: 0.2823 - val_accuracy: 0.9793\n",
            "Epoch 569/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0517e-09 - accuracy: 1.0000 - val_loss: 0.2832 - val_accuracy: 0.9793\n",
            "Epoch 570/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0331e-09 - accuracy: 1.0000 - val_loss: 0.2837 - val_accuracy: 0.9795\n",
            "Epoch 571/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0464e-09 - accuracy: 1.0000 - val_loss: 0.2846 - val_accuracy: 0.9794\n",
            "Epoch 572/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0358e-09 - accuracy: 1.0000 - val_loss: 0.2851 - val_accuracy: 0.9795\n",
            "Epoch 573/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0729e-09 - accuracy: 1.0000 - val_loss: 0.2854 - val_accuracy: 0.9794\n",
            "Epoch 574/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0914e-09 - accuracy: 1.0000 - val_loss: 0.2861 - val_accuracy: 0.9793\n",
            "Epoch 575/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0570e-09 - accuracy: 1.0000 - val_loss: 0.2870 - val_accuracy: 0.9792\n",
            "Epoch 576/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1206e-09 - accuracy: 1.0000 - val_loss: 0.2868 - val_accuracy: 0.9792\n",
            "Epoch 577/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1259e-09 - accuracy: 1.0000 - val_loss: 0.2875 - val_accuracy: 0.9792\n",
            "Epoch 578/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0994e-09 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.9793\n",
            "Epoch 579/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1312e-09 - accuracy: 1.0000 - val_loss: 0.2883 - val_accuracy: 0.9793\n",
            "Epoch 580/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1206e-09 - accuracy: 1.0000 - val_loss: 0.2894 - val_accuracy: 0.9793\n",
            "Epoch 581/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1100e-09 - accuracy: 1.0000 - val_loss: 0.2897 - val_accuracy: 0.9794\n",
            "Epoch 582/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1100e-09 - accuracy: 1.0000 - val_loss: 0.2905 - val_accuracy: 0.9795\n",
            "Epoch 583/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1126e-09 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.9793\n",
            "Epoch 584/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1656e-09 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.9795\n",
            "Epoch 585/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1232e-09 - accuracy: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.9793\n",
            "Epoch 586/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1338e-09 - accuracy: 1.0000 - val_loss: 0.2921 - val_accuracy: 0.9790\n",
            "Epoch 587/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2292e-09 - accuracy: 1.0000 - val_loss: 0.2926 - val_accuracy: 0.9796\n",
            "Epoch 588/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2000e-09 - accuracy: 1.0000 - val_loss: 0.2924 - val_accuracy: 0.9793\n",
            "Epoch 589/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1868e-09 - accuracy: 1.0000 - val_loss: 0.2936 - val_accuracy: 0.9793\n",
            "Epoch 590/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1656e-09 - accuracy: 1.0000 - val_loss: 0.2937 - val_accuracy: 0.9794\n",
            "Epoch 591/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1762e-09 - accuracy: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.9794\n",
            "Epoch 592/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2371e-09 - accuracy: 1.0000 - val_loss: 0.2950 - val_accuracy: 0.9794\n",
            "Epoch 593/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2265e-09 - accuracy: 1.0000 - val_loss: 0.2949 - val_accuracy: 0.9793\n",
            "Epoch 594/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2239e-09 - accuracy: 1.0000 - val_loss: 0.2964 - val_accuracy: 0.9794\n",
            "Epoch 595/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2106e-09 - accuracy: 1.0000 - val_loss: 0.2962 - val_accuracy: 0.9792\n",
            "Epoch 596/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2292e-09 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.9793\n",
            "Epoch 597/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2080e-09 - accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.9794\n",
            "Epoch 598/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1788e-09 - accuracy: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.9794\n",
            "Epoch 599/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2716e-09 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.9794\n",
            "Epoch 600/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2212e-09 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.9793\n",
            "Epoch 601/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2053e-09 - accuracy: 1.0000 - val_loss: 0.2992 - val_accuracy: 0.9792\n",
            "Epoch 602/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1974e-09 - accuracy: 1.0000 - val_loss: 0.3001 - val_accuracy: 0.9791\n",
            "Epoch 603/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2848e-09 - accuracy: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.9792\n",
            "Epoch 604/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2504e-09 - accuracy: 1.0000 - val_loss: 0.3003 - val_accuracy: 0.9792\n",
            "Epoch 605/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2345e-09 - accuracy: 1.0000 - val_loss: 0.3010 - val_accuracy: 0.9790\n",
            "Epoch 606/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2822e-09 - accuracy: 1.0000 - val_loss: 0.3026 - val_accuracy: 0.9791\n",
            "Epoch 607/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3034e-09 - accuracy: 1.0000 - val_loss: 0.3032 - val_accuracy: 0.9792\n",
            "Epoch 608/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2159e-09 - accuracy: 1.0000 - val_loss: 0.3027 - val_accuracy: 0.9793\n",
            "Epoch 609/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2636e-09 - accuracy: 1.0000 - val_loss: 0.3050 - val_accuracy: 0.9791\n",
            "Epoch 610/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3934e-09 - accuracy: 1.0000 - val_loss: 0.3019 - val_accuracy: 0.9794\n",
            "Epoch 611/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2663e-09 - accuracy: 1.0000 - val_loss: 0.3053 - val_accuracy: 0.9789\n",
            "Epoch 612/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3140e-09 - accuracy: 1.0000 - val_loss: 0.3054 - val_accuracy: 0.9790\n",
            "Epoch 613/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2901e-09 - accuracy: 1.0000 - val_loss: 0.3048 - val_accuracy: 0.9787\n",
            "Epoch 614/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3245e-09 - accuracy: 1.0000 - val_loss: 0.3065 - val_accuracy: 0.9791\n",
            "Epoch 615/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2875e-09 - accuracy: 1.0000 - val_loss: 0.3064 - val_accuracy: 0.9791\n",
            "Epoch 616/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3431e-09 - accuracy: 1.0000 - val_loss: 0.3070 - val_accuracy: 0.9789\n",
            "Epoch 617/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2663e-09 - accuracy: 1.0000 - val_loss: 0.3076 - val_accuracy: 0.9790\n",
            "Epoch 618/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3060e-09 - accuracy: 1.0000 - val_loss: 0.3075 - val_accuracy: 0.9789\n",
            "Epoch 619/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2822e-09 - accuracy: 1.0000 - val_loss: 0.3077 - val_accuracy: 0.9791\n",
            "Epoch 620/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3272e-09 - accuracy: 1.0000 - val_loss: 0.3105 - val_accuracy: 0.9789\n",
            "Epoch 621/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4279e-09 - accuracy: 1.0000 - val_loss: 0.3097 - val_accuracy: 0.9787\n",
            "Epoch 622/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3431e-09 - accuracy: 1.0000 - val_loss: 0.3105 - val_accuracy: 0.9787\n",
            "Epoch 623/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3908e-09 - accuracy: 1.0000 - val_loss: 0.3091 - val_accuracy: 0.9791\n",
            "Epoch 624/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7060e-09 - accuracy: 1.0000 - val_loss: 0.3093 - val_accuracy: 0.9789\n",
            "Epoch 625/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.1490 - accuracy: 0.9876 - val_loss: 0.2682 - val_accuracy: 0.9719\n",
            "Epoch 626/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0134 - accuracy: 0.9965 - val_loss: 0.2237 - val_accuracy: 0.9753\n",
            "Epoch 627/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.2068 - val_accuracy: 0.9780\n",
            "Epoch 628/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0713e-04 - accuracy: 0.9997 - val_loss: 0.2052 - val_accuracy: 0.9781\n",
            "Epoch 629/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9666e-04 - accuracy: 0.9999 - val_loss: 0.2054 - val_accuracy: 0.9783\n",
            "Epoch 630/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5760e-04 - accuracy: 0.9999 - val_loss: 0.2087 - val_accuracy: 0.9780\n",
            "Epoch 631/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9456e-05 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9776\n",
            "Epoch 632/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2249e-05 - accuracy: 1.0000 - val_loss: 0.2054 - val_accuracy: 0.9778\n",
            "Epoch 633/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0216e-05 - accuracy: 1.0000 - val_loss: 0.2052 - val_accuracy: 0.9778\n",
            "Epoch 634/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9343e-06 - accuracy: 1.0000 - val_loss: 0.2052 - val_accuracy: 0.9779\n",
            "Epoch 635/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9832e-06 - accuracy: 1.0000 - val_loss: 0.2052 - val_accuracy: 0.9779\n",
            "Epoch 636/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1969e-06 - accuracy: 1.0000 - val_loss: 0.2052 - val_accuracy: 0.9780\n",
            "Epoch 637/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.5397e-06 - accuracy: 1.0000 - val_loss: 0.2053 - val_accuracy: 0.9780\n",
            "Epoch 638/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.9496e-06 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 0.9781\n",
            "Epoch 639/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.4484e-06 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.9781\n",
            "Epoch 640/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9999e-06 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9782\n",
            "Epoch 641/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.6173e-06 - accuracy: 1.0000 - val_loss: 0.2060 - val_accuracy: 0.9783\n",
            "Epoch 642/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2752e-06 - accuracy: 1.0000 - val_loss: 0.2062 - val_accuracy: 0.9784\n",
            "Epoch 643/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9553e-06 - accuracy: 1.0000 - val_loss: 0.2064 - val_accuracy: 0.9784\n",
            "Epoch 644/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6620e-06 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9785\n",
            "Epoch 645/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3869e-06 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 0.9784\n",
            "Epoch 646/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1346e-06 - accuracy: 1.0000 - val_loss: 0.2071 - val_accuracy: 0.9785\n",
            "Epoch 647/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8990e-06 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9787\n",
            "Epoch 648/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6933e-06 - accuracy: 1.0000 - val_loss: 0.2077 - val_accuracy: 0.9787\n",
            "Epoch 649/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5016e-06 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9789\n",
            "Epoch 650/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3276e-06 - accuracy: 1.0000 - val_loss: 0.2082 - val_accuracy: 0.9789\n",
            "Epoch 651/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1671e-06 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9790\n",
            "Epoch 652/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0154e-06 - accuracy: 1.0000 - val_loss: 0.2087 - val_accuracy: 0.9790\n",
            "Epoch 653/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8814e-06 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9790\n",
            "Epoch 654/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7552e-06 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.9791\n",
            "Epoch 655/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6362e-06 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9789\n",
            "Epoch 656/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5272e-06 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9789\n",
            "Epoch 657/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4257e-06 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 0.9789\n",
            "Epoch 658/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3287e-06 - accuracy: 1.0000 - val_loss: 0.2104 - val_accuracy: 0.9789\n",
            "Epoch 659/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2399e-06 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9790\n",
            "Epoch 660/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1563e-06 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9790\n",
            "Epoch 661/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0788e-06 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9790\n",
            "Epoch 662/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0064e-06 - accuracy: 1.0000 - val_loss: 0.2117 - val_accuracy: 0.9790\n",
            "Epoch 663/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3908e-07 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9790\n",
            "Epoch 664/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7530e-07 - accuracy: 1.0000 - val_loss: 0.2125 - val_accuracy: 0.9790\n",
            "Epoch 665/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.1642e-07 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9791\n",
            "Epoch 666/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.5999e-07 - accuracy: 1.0000 - val_loss: 0.2133 - val_accuracy: 0.9790\n",
            "Epoch 667/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.0870e-07 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9791\n",
            "Epoch 668/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6019e-07 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9791\n",
            "Epoch 669/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1368e-07 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9791\n",
            "Epoch 670/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.7321e-07 - accuracy: 1.0000 - val_loss: 0.2149 - val_accuracy: 0.9791\n",
            "Epoch 671/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.3400e-07 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9791\n",
            "Epoch 672/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.9633e-07 - accuracy: 1.0000 - val_loss: 0.2158 - val_accuracy: 0.9791\n",
            "Epoch 673/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6325e-07 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9793\n",
            "Epoch 674/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3152e-07 - accuracy: 1.0000 - val_loss: 0.2166 - val_accuracy: 0.9793\n",
            "Epoch 675/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0116e-07 - accuracy: 1.0000 - val_loss: 0.2170 - val_accuracy: 0.9793\n",
            "Epoch 676/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.7371e-07 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9792\n",
            "Epoch 677/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4759e-07 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9791\n",
            "Epoch 678/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2369e-07 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9791\n",
            "Epoch 679/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0128e-07 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9791\n",
            "Epoch 680/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8013e-07 - accuracy: 1.0000 - val_loss: 0.2191 - val_accuracy: 0.9792\n",
            "Epoch 681/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6053e-07 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9791\n",
            "Epoch 682/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4230e-07 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9791\n",
            "Epoch 683/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2493e-07 - accuracy: 1.0000 - val_loss: 0.2206 - val_accuracy: 0.9792\n",
            "Epoch 684/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0879e-07 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9791\n",
            "Epoch 685/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9391e-07 - accuracy: 1.0000 - val_loss: 0.2216 - val_accuracy: 0.9791\n",
            "Epoch 686/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8055e-07 - accuracy: 1.0000 - val_loss: 0.2221 - val_accuracy: 0.9791\n",
            "Epoch 687/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6746e-07 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.9791\n",
            "Epoch 688/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5547e-07 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9791\n",
            "Epoch 689/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4423e-07 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9790\n",
            "Epoch 690/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3377e-07 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 0.9790\n",
            "Epoch 691/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2432e-07 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9791\n",
            "Epoch 692/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1533e-07 - accuracy: 1.0000 - val_loss: 0.2249 - val_accuracy: 0.9791\n",
            "Epoch 693/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0704e-07 - accuracy: 1.0000 - val_loss: 0.2255 - val_accuracy: 0.9791\n",
            "Epoch 694/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.9264e-08 - accuracy: 1.0000 - val_loss: 0.2260 - val_accuracy: 0.9791\n",
            "Epoch 695/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2141e-08 - accuracy: 1.0000 - val_loss: 0.2265 - val_accuracy: 0.9791\n",
            "Epoch 696/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5460e-08 - accuracy: 1.0000 - val_loss: 0.2270 - val_accuracy: 0.9791\n",
            "Epoch 697/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9242e-08 - accuracy: 1.0000 - val_loss: 0.2276 - val_accuracy: 0.9791\n",
            "Epoch 698/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3443e-08 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 0.9791\n",
            "Epoch 699/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.7984e-08 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.9793\n",
            "Epoch 700/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3051e-08 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.9793\n",
            "Epoch 701/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8399e-08 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.9793\n",
            "Epoch 702/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.4208e-08 - accuracy: 1.0000 - val_loss: 0.2302 - val_accuracy: 0.9794\n",
            "Epoch 703/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0431e-08 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.9793\n",
            "Epoch 704/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6775e-08 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.9793\n",
            "Epoch 705/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3310e-08 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9793\n",
            "Epoch 706/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0285e-08 - accuracy: 1.0000 - val_loss: 0.2323 - val_accuracy: 0.9793\n",
            "Epoch 707/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7289e-08 - accuracy: 1.0000 - val_loss: 0.2329 - val_accuracy: 0.9793\n",
            "Epoch 708/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4565e-08 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.9793\n",
            "Epoch 709/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2110e-08 - accuracy: 1.0000 - val_loss: 0.2339 - val_accuracy: 0.9793\n",
            "Epoch 710/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9876e-08 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9795\n",
            "Epoch 711/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7696e-08 - accuracy: 1.0000 - val_loss: 0.2350 - val_accuracy: 0.9795\n",
            "Epoch 712/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5723e-08 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9795\n",
            "Epoch 713/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3929e-08 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9794\n",
            "Epoch 714/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2152e-08 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9794\n",
            "Epoch 715/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0565e-08 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9793\n",
            "Epoch 716/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9140e-08 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.9793\n",
            "Epoch 717/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7736e-08 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.9794\n",
            "Epoch 718/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6525e-08 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9793\n",
            "Epoch 719/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5333e-08 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.9793\n",
            "Epoch 720/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4313e-08 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.9794\n",
            "Epoch 721/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3304e-08 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9795\n",
            "Epoch 722/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2414e-08 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 0.9794\n",
            "Epoch 723/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1471e-08 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9794\n",
            "Epoch 724/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0676e-08 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9794\n",
            "Epoch 725/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0029e-08 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9794\n",
            "Epoch 726/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.2904e-09 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9794\n",
            "Epoch 727/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.6466e-09 - accuracy: 1.0000 - val_loss: 0.2442 - val_accuracy: 0.9794\n",
            "Epoch 728/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0559e-09 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9794\n",
            "Epoch 729/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.5208e-09 - accuracy: 1.0000 - val_loss: 0.2452 - val_accuracy: 0.9793\n",
            "Epoch 730/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.0201e-09 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9793\n",
            "Epoch 731/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5777e-09 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9794\n",
            "Epoch 732/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0744e-09 - accuracy: 1.0000 - val_loss: 0.2470 - val_accuracy: 0.9795\n",
            "Epoch 733/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7167e-09 - accuracy: 1.0000 - val_loss: 0.2478 - val_accuracy: 0.9794\n",
            "Epoch 734/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.3247e-09 - accuracy: 1.0000 - val_loss: 0.2486 - val_accuracy: 0.9794\n",
            "Epoch 735/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.0280e-09 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9795\n",
            "Epoch 736/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6280e-09 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9795\n",
            "Epoch 737/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3392e-09 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9795\n",
            "Epoch 738/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0558e-09 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.9796\n",
            "Epoch 739/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8200e-09 - accuracy: 1.0000 - val_loss: 0.2520 - val_accuracy: 0.9796\n",
            "Epoch 740/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6001e-09 - accuracy: 1.0000 - val_loss: 0.2528 - val_accuracy: 0.9796\n",
            "Epoch 741/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3988e-09 - accuracy: 1.0000 - val_loss: 0.2535 - val_accuracy: 0.9797\n",
            "Epoch 742/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1842e-09 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.9795\n",
            "Epoch 743/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9776e-09 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.9797\n",
            "Epoch 744/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8080e-09 - accuracy: 1.0000 - val_loss: 0.2557 - val_accuracy: 0.9796\n",
            "Epoch 745/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6200e-09 - accuracy: 1.0000 - val_loss: 0.2565 - val_accuracy: 0.9796\n",
            "Epoch 746/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4451e-09 - accuracy: 1.0000 - val_loss: 0.2575 - val_accuracy: 0.9797\n",
            "Epoch 747/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3339e-09 - accuracy: 1.0000 - val_loss: 0.2582 - val_accuracy: 0.9797\n",
            "Epoch 748/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1961e-09 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.9796\n",
            "Epoch 749/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0345e-09 - accuracy: 1.0000 - val_loss: 0.2598 - val_accuracy: 0.9796\n",
            "Epoch 750/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9338e-09 - accuracy: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.9796\n",
            "Epoch 751/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8093e-09 - accuracy: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.9798\n",
            "Epoch 752/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6822e-09 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.9797\n",
            "Epoch 753/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6001e-09 - accuracy: 1.0000 - val_loss: 0.2636 - val_accuracy: 0.9797\n",
            "Epoch 754/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5047e-09 - accuracy: 1.0000 - val_loss: 0.2647 - val_accuracy: 0.9798\n",
            "Epoch 755/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4729e-09 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.9798\n",
            "Epoch 756/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3908e-09 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.9798\n",
            "Epoch 757/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3140e-09 - accuracy: 1.0000 - val_loss: 0.2677 - val_accuracy: 0.9797\n",
            "Epoch 758/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2504e-09 - accuracy: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.9797\n",
            "Epoch 759/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2159e-09 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.9797\n",
            "Epoch 760/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1762e-09 - accuracy: 1.0000 - val_loss: 0.2708 - val_accuracy: 0.9796\n",
            "Epoch 761/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1206e-09 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.9794\n",
            "Epoch 762/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0967e-09 - accuracy: 1.0000 - val_loss: 0.2730 - val_accuracy: 0.9796\n",
            "Epoch 763/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0649e-09 - accuracy: 1.0000 - val_loss: 0.2743 - val_accuracy: 0.9795\n",
            "Epoch 764/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0464e-09 - accuracy: 1.0000 - val_loss: 0.2749 - val_accuracy: 0.9795\n",
            "Epoch 765/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.8811e-10 - accuracy: 1.0000 - val_loss: 0.2763 - val_accuracy: 0.9795\n",
            "Epoch 766/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6692e-10 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.9795\n",
            "Epoch 767/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6162e-10 - accuracy: 1.0000 - val_loss: 0.2780 - val_accuracy: 0.9795\n",
            "Epoch 768/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.1924e-10 - accuracy: 1.0000 - val_loss: 0.2790 - val_accuracy: 0.9795\n",
            "Epoch 769/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0069e-10 - accuracy: 1.0000 - val_loss: 0.2802 - val_accuracy: 0.9795\n",
            "Epoch 770/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.4771e-10 - accuracy: 1.0000 - val_loss: 0.2811 - val_accuracy: 0.9795\n",
            "Epoch 771/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5301e-10 - accuracy: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.9795\n",
            "Epoch 772/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1857e-10 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.9795\n",
            "Epoch 773/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.3182e-10 - accuracy: 1.0000 - val_loss: 0.2836 - val_accuracy: 0.9795\n",
            "Epoch 774/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.9473e-10 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 0.9796\n",
            "Epoch 775/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8943e-10 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.9795\n",
            "Epoch 776/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8943e-10 - accuracy: 1.0000 - val_loss: 0.2861 - val_accuracy: 0.9796\n",
            "Epoch 777/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.7089e-10 - accuracy: 1.0000 - val_loss: 0.2869 - val_accuracy: 0.9797\n",
            "Epoch 778/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.5499e-10 - accuracy: 1.0000 - val_loss: 0.2876 - val_accuracy: 0.9797\n",
            "Epoch 779/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.4175e-10 - accuracy: 1.0000 - val_loss: 0.2884 - val_accuracy: 0.9797\n",
            "Epoch 780/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3645e-10 - accuracy: 1.0000 - val_loss: 0.2893 - val_accuracy: 0.9797\n",
            "Epoch 781/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.4440e-10 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.9796\n",
            "Epoch 782/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4440e-10 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.9796\n",
            "Epoch 783/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1526e-10 - accuracy: 1.0000 - val_loss: 0.2911 - val_accuracy: 0.9799\n",
            "Epoch 784/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.2585e-10 - accuracy: 1.0000 - val_loss: 0.2925 - val_accuracy: 0.9793\n",
            "Epoch 785/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2320e-10 - accuracy: 1.0000 - val_loss: 0.2932 - val_accuracy: 0.9795\n",
            "Epoch 786/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.0201e-10 - accuracy: 1.0000 - val_loss: 0.2936 - val_accuracy: 0.9795\n",
            "Epoch 787/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.9406e-10 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.9795\n",
            "Epoch 788/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.9141e-10 - accuracy: 1.0000 - val_loss: 0.2952 - val_accuracy: 0.9795\n",
            "Epoch 789/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.9936e-10 - accuracy: 1.0000 - val_loss: 0.2958 - val_accuracy: 0.9795\n",
            "Epoch 790/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.1261e-10 - accuracy: 1.0000 - val_loss: 0.2963 - val_accuracy: 0.9795\n",
            "Epoch 791/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.6757e-10 - accuracy: 1.0000 - val_loss: 0.2970 - val_accuracy: 0.9798\n",
            "Epoch 792/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.9936e-10 - accuracy: 1.0000 - val_loss: 0.2976 - val_accuracy: 0.9797\n",
            "Epoch 793/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8876e-10 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.9797\n",
            "Epoch 794/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7817e-10 - accuracy: 1.0000 - val_loss: 0.2987 - val_accuracy: 0.9798\n",
            "Epoch 795/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8082e-10 - accuracy: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.9797\n",
            "Epoch 796/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.6492e-10 - accuracy: 1.0000 - val_loss: 0.3002 - val_accuracy: 0.9797\n",
            "Epoch 797/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.5433e-10 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.9796\n",
            "Epoch 798/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7817e-10 - accuracy: 1.0000 - val_loss: 0.3014 - val_accuracy: 0.9795\n",
            "Epoch 799/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5962e-10 - accuracy: 1.0000 - val_loss: 0.3024 - val_accuracy: 0.9795\n",
            "Epoch 800/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8347e-10 - accuracy: 1.0000 - val_loss: 0.3027 - val_accuracy: 0.9795\n",
            "Epoch 801/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.2784e-10 - accuracy: 1.0000 - val_loss: 0.3033 - val_accuracy: 0.9796\n",
            "Epoch 802/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6757e-10 - accuracy: 1.0000 - val_loss: 0.3041 - val_accuracy: 0.9796\n",
            "Epoch 803/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.0201e-10 - accuracy: 1.0000 - val_loss: 0.3046 - val_accuracy: 0.9796\n",
            "Epoch 804/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7552e-10 - accuracy: 1.0000 - val_loss: 0.3054 - val_accuracy: 0.9796\n",
            "Epoch 805/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5698e-10 - accuracy: 1.0000 - val_loss: 0.3060 - val_accuracy: 0.9795\n",
            "Epoch 806/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8347e-10 - accuracy: 1.0000 - val_loss: 0.3068 - val_accuracy: 0.9795\n",
            "Epoch 807/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.7022e-10 - accuracy: 1.0000 - val_loss: 0.3077 - val_accuracy: 0.9793\n",
            "Epoch 808/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.9936e-10 - accuracy: 1.0000 - val_loss: 0.3077 - val_accuracy: 0.9795\n",
            "Epoch 809/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8876e-10 - accuracy: 1.0000 - val_loss: 0.3083 - val_accuracy: 0.9794\n",
            "Epoch 810/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8347e-10 - accuracy: 1.0000 - val_loss: 0.3090 - val_accuracy: 0.9795\n",
            "Epoch 811/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7022e-10 - accuracy: 1.0000 - val_loss: 0.3095 - val_accuracy: 0.9793\n",
            "Epoch 812/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8876e-10 - accuracy: 1.0000 - val_loss: 0.3106 - val_accuracy: 0.9793\n",
            "Epoch 813/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.9141e-10 - accuracy: 1.0000 - val_loss: 0.3107 - val_accuracy: 0.9793\n",
            "Epoch 814/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.9671e-10 - accuracy: 1.0000 - val_loss: 0.3115 - val_accuracy: 0.9792\n",
            "Epoch 815/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.0731e-10 - accuracy: 1.0000 - val_loss: 0.3118 - val_accuracy: 0.9790\n",
            "Epoch 816/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.0731e-10 - accuracy: 1.0000 - val_loss: 0.3124 - val_accuracy: 0.9791\n",
            "Epoch 817/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.9406e-10 - accuracy: 1.0000 - val_loss: 0.3131 - val_accuracy: 0.9790\n",
            "Epoch 818/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7817e-10 - accuracy: 1.0000 - val_loss: 0.3143 - val_accuracy: 0.9792\n",
            "Epoch 819/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3645e-10 - accuracy: 1.0000 - val_loss: 0.3148 - val_accuracy: 0.9791\n",
            "Epoch 820/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.9671e-10 - accuracy: 1.0000 - val_loss: 0.3154 - val_accuracy: 0.9793\n",
            "Epoch 821/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.5764e-10 - accuracy: 1.0000 - val_loss: 0.3154 - val_accuracy: 0.9789\n",
            "Epoch 822/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.9936e-10 - accuracy: 1.0000 - val_loss: 0.3165 - val_accuracy: 0.9792\n",
            "Epoch 823/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3380e-10 - accuracy: 1.0000 - val_loss: 0.3168 - val_accuracy: 0.9791\n",
            "Epoch 824/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.3910e-10 - accuracy: 1.0000 - val_loss: 0.3179 - val_accuracy: 0.9789\n",
            "Epoch 825/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.4440e-10 - accuracy: 1.0000 - val_loss: 0.3177 - val_accuracy: 0.9790\n",
            "Epoch 826/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.4704e-10 - accuracy: 1.0000 - val_loss: 0.3191 - val_accuracy: 0.9789\n",
            "Epoch 827/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.2585e-10 - accuracy: 1.0000 - val_loss: 0.3188 - val_accuracy: 0.9791\n",
            "Epoch 828/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.1526e-10 - accuracy: 1.0000 - val_loss: 0.3209 - val_accuracy: 0.9791\n",
            "Epoch 829/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4969e-10 - accuracy: 1.0000 - val_loss: 0.3201 - val_accuracy: 0.9788\n",
            "Epoch 830/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3910e-10 - accuracy: 1.0000 - val_loss: 0.3225 - val_accuracy: 0.9791\n",
            "Epoch 831/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3910e-10 - accuracy: 1.0000 - val_loss: 0.3222 - val_accuracy: 0.9788\n",
            "Epoch 832/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3115e-10 - accuracy: 1.0000 - val_loss: 0.3223 - val_accuracy: 0.9789\n",
            "Epoch 833/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3645e-10 - accuracy: 1.0000 - val_loss: 0.3235 - val_accuracy: 0.9788\n",
            "Epoch 834/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.9208e-10 - accuracy: 1.0000 - val_loss: 0.3236 - val_accuracy: 0.9789\n",
            "Epoch 835/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3910e-10 - accuracy: 1.0000 - val_loss: 0.3241 - val_accuracy: 0.9791\n",
            "Epoch 836/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.8413e-10 - accuracy: 1.0000 - val_loss: 0.3251 - val_accuracy: 0.9790\n",
            "Epoch 837/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.6559e-10 - accuracy: 1.0000 - val_loss: 0.3249 - val_accuracy: 0.9788\n",
            "Epoch 838/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.8413e-10 - accuracy: 1.0000 - val_loss: 0.3268 - val_accuracy: 0.9789\n",
            "Epoch 839/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7089e-10 - accuracy: 1.0000 - val_loss: 0.3266 - val_accuracy: 0.9789\n",
            "Epoch 840/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.5764e-10 - accuracy: 1.0000 - val_loss: 0.3274 - val_accuracy: 0.9789\n",
            "Epoch 841/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.4175e-10 - accuracy: 1.0000 - val_loss: 0.3278 - val_accuracy: 0.9789\n",
            "Epoch 842/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8678e-10 - accuracy: 1.0000 - val_loss: 0.3293 - val_accuracy: 0.9788\n",
            "Epoch 843/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5234e-10 - accuracy: 1.0000 - val_loss: 0.3289 - val_accuracy: 0.9787\n",
            "Epoch 844/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0268e-10 - accuracy: 1.0000 - val_loss: 0.3299 - val_accuracy: 0.9788\n",
            "Epoch 845/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.1327e-10 - accuracy: 1.0000 - val_loss: 0.3304 - val_accuracy: 0.9789\n",
            "Epoch 846/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1857e-10 - accuracy: 1.0000 - val_loss: 0.3308 - val_accuracy: 0.9787\n",
            "Epoch 847/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5036e-10 - accuracy: 1.0000 - val_loss: 0.3308 - val_accuracy: 0.9786\n",
            "Epoch 848/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.1857e-10 - accuracy: 1.0000 - val_loss: 0.3319 - val_accuracy: 0.9787\n",
            "Epoch 849/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5499e-10 - accuracy: 1.0000 - val_loss: 0.3336 - val_accuracy: 0.9787\n",
            "Epoch 850/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.1592e-10 - accuracy: 1.0000 - val_loss: 0.3333 - val_accuracy: 0.9786\n",
            "Epoch 851/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2917e-10 - accuracy: 1.0000 - val_loss: 0.3348 - val_accuracy: 0.9789\n",
            "Epoch 852/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6559e-10 - accuracy: 1.0000 - val_loss: 0.3353 - val_accuracy: 0.9786\n",
            "Epoch 853/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8678e-10 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9787\n",
            "Epoch 854/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3115e-10 - accuracy: 1.0000 - val_loss: 0.3356 - val_accuracy: 0.9787\n",
            "Epoch 855/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6029e-10 - accuracy: 1.0000 - val_loss: 0.3358 - val_accuracy: 0.9789\n",
            "Epoch 856/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0268e-10 - accuracy: 1.0000 - val_loss: 0.3375 - val_accuracy: 0.9788\n",
            "Epoch 857/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8943e-10 - accuracy: 1.0000 - val_loss: 0.3370 - val_accuracy: 0.9787\n",
            "Epoch 858/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.2652e-10 - accuracy: 1.0000 - val_loss: 0.3386 - val_accuracy: 0.9787\n",
            "Epoch 859/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.6559e-10 - accuracy: 1.0000 - val_loss: 0.3384 - val_accuracy: 0.9785\n",
            "Epoch 860/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1241 - accuracy: 0.9897 - val_loss: 0.3156 - val_accuracy: 0.9741\n",
            "Epoch 861/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0219 - accuracy: 0.9956 - val_loss: 0.2404 - val_accuracy: 0.9765\n",
            "Epoch 862/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.2264 - val_accuracy: 0.9785\n",
            "Epoch 863/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.2227 - val_accuracy: 0.9785\n",
            "Epoch 864/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6422e-04 - accuracy: 0.9998 - val_loss: 0.2265 - val_accuracy: 0.9791\n",
            "Epoch 865/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.4869e-04 - accuracy: 0.9998 - val_loss: 0.2266 - val_accuracy: 0.9791\n",
            "Epoch 866/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0050e-04 - accuracy: 1.0000 - val_loss: 0.2221 - val_accuracy: 0.9795\n",
            "Epoch 867/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2230e-05 - accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 0.9795\n",
            "Epoch 868/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8616e-06 - accuracy: 1.0000 - val_loss: 0.2216 - val_accuracy: 0.9794\n",
            "Epoch 869/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5531e-06 - accuracy: 1.0000 - val_loss: 0.2216 - val_accuracy: 0.9795\n",
            "Epoch 870/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.7130e-06 - accuracy: 1.0000 - val_loss: 0.2216 - val_accuracy: 0.9794\n",
            "Epoch 871/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0900e-06 - accuracy: 1.0000 - val_loss: 0.2216 - val_accuracy: 0.9794\n",
            "Epoch 872/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5790e-06 - accuracy: 1.0000 - val_loss: 0.2216 - val_accuracy: 0.9793\n",
            "Epoch 873/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.1772e-06 - accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 0.9793\n",
            "Epoch 874/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8190e-06 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9793\n",
            "Epoch 875/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.4987e-06 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9793\n",
            "Epoch 876/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2185e-06 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 0.9794\n",
            "Epoch 877/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9747e-06 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 0.9793\n",
            "Epoch 878/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7540e-06 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9794\n",
            "Epoch 879/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5491e-06 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9794\n",
            "Epoch 880/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3616e-06 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.9794\n",
            "Epoch 881/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1873e-06 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.9795\n",
            "Epoch 882/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0345e-06 - accuracy: 1.0000 - val_loss: 0.2226 - val_accuracy: 0.9795\n",
            "Epoch 883/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8887e-06 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9795\n",
            "Epoch 884/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7593e-06 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9796\n",
            "Epoch 885/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6356e-06 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 0.9796\n",
            "Epoch 886/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5241e-06 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9795\n",
            "Epoch 887/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4185e-06 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9796\n",
            "Epoch 888/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3233e-06 - accuracy: 1.0000 - val_loss: 0.2233 - val_accuracy: 0.9796\n",
            "Epoch 889/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2300e-06 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9797\n",
            "Epoch 890/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1432e-06 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9797\n",
            "Epoch 891/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0701e-06 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9797\n",
            "Epoch 892/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.9220e-07 - accuracy: 1.0000 - val_loss: 0.2239 - val_accuracy: 0.9798\n",
            "Epoch 893/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2592e-07 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 0.9798\n",
            "Epoch 894/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6094e-07 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9798\n",
            "Epoch 895/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0156e-07 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9800\n",
            "Epoch 896/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.4742e-07 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9799\n",
            "Epoch 897/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.9488e-07 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9799\n",
            "Epoch 898/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4675e-07 - accuracy: 1.0000 - val_loss: 0.2249 - val_accuracy: 0.9799\n",
            "Epoch 899/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0143e-07 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9798\n",
            "Epoch 900/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.6015e-07 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9799\n",
            "Epoch 901/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.2205e-07 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9797\n",
            "Epoch 902/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.8353e-07 - accuracy: 1.0000 - val_loss: 0.2257 - val_accuracy: 0.9798\n",
            "Epoch 903/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5171e-07 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9799\n",
            "Epoch 904/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2008e-07 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9798\n",
            "Epoch 905/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9183e-07 - accuracy: 1.0000 - val_loss: 0.2263 - val_accuracy: 0.9798\n",
            "Epoch 906/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6534e-07 - accuracy: 1.0000 - val_loss: 0.2265 - val_accuracy: 0.9798\n",
            "Epoch 907/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3985e-07 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 0.9797\n",
            "Epoch 908/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1701e-07 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9797\n",
            "Epoch 909/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9513e-07 - accuracy: 1.0000 - val_loss: 0.2274 - val_accuracy: 0.9797\n",
            "Epoch 910/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7419e-07 - accuracy: 1.0000 - val_loss: 0.2274 - val_accuracy: 0.9797\n",
            "Epoch 911/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5563e-07 - accuracy: 1.0000 - val_loss: 0.2278 - val_accuracy: 0.9797\n",
            "Epoch 912/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3800e-07 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 0.9797\n",
            "Epoch 913/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2148e-07 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9797\n",
            "Epoch 914/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0622e-07 - accuracy: 1.0000 - val_loss: 0.2289 - val_accuracy: 0.9797\n",
            "Epoch 915/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9216e-07 - accuracy: 1.0000 - val_loss: 0.2290 - val_accuracy: 0.9796\n",
            "Epoch 916/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7927e-07 - accuracy: 1.0000 - val_loss: 0.2294 - val_accuracy: 0.9796\n",
            "Epoch 917/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6653e-07 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.9797\n",
            "Epoch 918/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5518e-07 - accuracy: 1.0000 - val_loss: 0.2301 - val_accuracy: 0.9797\n",
            "Epoch 919/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4428e-07 - accuracy: 1.0000 - val_loss: 0.2303 - val_accuracy: 0.9797\n",
            "Epoch 920/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3419e-07 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 0.9797\n",
            "Epoch 921/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2509e-07 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9797\n",
            "Epoch 922/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1631e-07 - accuracy: 1.0000 - val_loss: 0.2315 - val_accuracy: 0.9797\n",
            "Epoch 923/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0815e-07 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.9797\n",
            "Epoch 924/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0057e-07 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9797\n",
            "Epoch 925/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3590e-08 - accuracy: 1.0000 - val_loss: 0.2327 - val_accuracy: 0.9797\n",
            "Epoch 926/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7038e-08 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.9797\n",
            "Epoch 927/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.0985e-08 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.9798\n",
            "Epoch 928/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5247e-08 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9797\n",
            "Epoch 929/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.9939e-08 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9798\n",
            "Epoch 930/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.5054e-08 - accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 0.9798\n",
            "Epoch 931/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0420e-08 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9797\n",
            "Epoch 932/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.6320e-08 - accuracy: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.9797\n",
            "Epoch 933/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.2259e-08 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 0.9798\n",
            "Epoch 934/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.8523e-08 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9798\n",
            "Epoch 935/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5143e-08 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9797\n",
            "Epoch 936/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1975e-08 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9797\n",
            "Epoch 937/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8928e-08 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.9797\n",
            "Epoch 938/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6314e-08 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.9798\n",
            "Epoch 939/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3734e-08 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9798\n",
            "Epoch 940/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1416e-08 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9798\n",
            "Epoch 941/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9156e-08 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9798\n",
            "Epoch 942/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7074e-08 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9798\n",
            "Epoch 943/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5172e-08 - accuracy: 1.0000 - val_loss: 0.2407 - val_accuracy: 0.9799\n",
            "Epoch 944/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3418e-08 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9799\n",
            "Epoch 945/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1754e-08 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9799\n",
            "Epoch 946/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0258e-08 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9799\n",
            "Epoch 947/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8854e-08 - accuracy: 1.0000 - val_loss: 0.2427 - val_accuracy: 0.9799\n",
            "Epoch 948/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7577e-08 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9799\n",
            "Epoch 949/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6334e-08 - accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 0.9799\n",
            "Epoch 950/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5259e-08 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9799\n",
            "Epoch 951/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4199e-08 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9799\n",
            "Epoch 952/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3222e-08 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.9800\n",
            "Epoch 953/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2339e-08 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9801\n",
            "Epoch 954/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1457e-08 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9801\n",
            "Epoch 955/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0628e-08 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9801\n",
            "Epoch 956/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9023e-09 - accuracy: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.9802\n",
            "Epoch 957/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2665e-09 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9802\n",
            "Epoch 958/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6308e-09 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9802\n",
            "Epoch 959/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.0321e-09 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 0.9802\n",
            "Epoch 960/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.4969e-09 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.9802\n",
            "Epoch 961/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.9910e-09 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9802\n",
            "Epoch 962/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5327e-09 - accuracy: 1.0000 - val_loss: 0.2510 - val_accuracy: 0.9802\n",
            "Epoch 963/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.0770e-09 - accuracy: 1.0000 - val_loss: 0.2516 - val_accuracy: 0.9802\n",
            "Epoch 964/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.6558e-09 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.9802\n",
            "Epoch 965/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3114e-09 - accuracy: 1.0000 - val_loss: 0.2529 - val_accuracy: 0.9802\n",
            "Epoch 966/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.9538e-09 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.9802\n",
            "Epoch 967/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6068e-09 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.9801\n",
            "Epoch 968/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.3127e-09 - accuracy: 1.0000 - val_loss: 0.2548 - val_accuracy: 0.9802\n",
            "Epoch 969/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0611e-09 - accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 0.9802\n",
            "Epoch 970/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7564e-09 - accuracy: 1.0000 - val_loss: 0.2562 - val_accuracy: 0.9802\n",
            "Epoch 971/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5418e-09 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.9803\n",
            "Epoch 972/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2769e-09 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.9803\n",
            "Epoch 973/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0756e-09 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9802\n",
            "Epoch 974/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8610e-09 - accuracy: 1.0000 - val_loss: 0.2591 - val_accuracy: 0.9803\n",
            "Epoch 975/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7153e-09 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.9803\n",
            "Epoch 976/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5299e-09 - accuracy: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.9803\n",
            "Epoch 977/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3418e-09 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.9803\n",
            "Epoch 978/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2279e-09 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.9803\n",
            "Epoch 979/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0716e-09 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9802\n",
            "Epoch 980/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9603e-09 - accuracy: 1.0000 - val_loss: 0.2639 - val_accuracy: 0.9802\n",
            "Epoch 981/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8146e-09 - accuracy: 1.0000 - val_loss: 0.2648 - val_accuracy: 0.9803\n",
            "Epoch 982/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7246e-09 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.9802\n",
            "Epoch 983/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6186e-09 - accuracy: 1.0000 - val_loss: 0.2665 - val_accuracy: 0.9801\n",
            "Epoch 984/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5577e-09 - accuracy: 1.0000 - val_loss: 0.2674 - val_accuracy: 0.9801\n",
            "Epoch 985/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4305e-09 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9802\n",
            "Epoch 986/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3855e-09 - accuracy: 1.0000 - val_loss: 0.2689 - val_accuracy: 0.9803\n",
            "Epoch 987/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2954e-09 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.9803\n",
            "Epoch 988/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2186e-09 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9802\n",
            "Epoch 989/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1735e-09 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.9803\n",
            "Epoch 990/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1020e-09 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9803\n",
            "Epoch 991/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0173e-09 - accuracy: 1.0000 - val_loss: 0.2731 - val_accuracy: 0.9804\n",
            "Epoch 992/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.5632e-10 - accuracy: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.9805\n",
            "Epoch 993/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.3778e-10 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9805\n",
            "Epoch 994/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7685e-10 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9805\n",
            "Epoch 995/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5831e-10 - accuracy: 1.0000 - val_loss: 0.2773 - val_accuracy: 0.9804\n",
            "Epoch 996/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.0532e-10 - accuracy: 1.0000 - val_loss: 0.2784 - val_accuracy: 0.9803\n",
            "Epoch 997/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7618e-10 - accuracy: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.9803\n",
            "Epoch 998/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.2850e-10 - accuracy: 1.0000 - val_loss: 0.2805 - val_accuracy: 0.9803\n",
            "Epoch 999/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3645e-10 - accuracy: 1.0000 - val_loss: 0.2815 - val_accuracy: 0.9804\n",
            "Epoch 1000/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7552e-10 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.9804\n",
            "Epoch 1001/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.7287e-10 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 0.9803\n",
            "Epoch 1002/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6227e-10 - accuracy: 1.0000 - val_loss: 0.2846 - val_accuracy: 0.9803\n",
            "Epoch 1003/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3048e-10 - accuracy: 1.0000 - val_loss: 0.2854 - val_accuracy: 0.9802\n",
            "Epoch 1004/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3048e-10 - accuracy: 1.0000 - val_loss: 0.2862 - val_accuracy: 0.9802\n",
            "Epoch 1005/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.8545e-10 - accuracy: 1.0000 - val_loss: 0.2872 - val_accuracy: 0.9802\n",
            "Epoch 1006/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8280e-10 - accuracy: 1.0000 - val_loss: 0.2882 - val_accuracy: 0.9802\n",
            "Epoch 1007/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7485e-10 - accuracy: 1.0000 - val_loss: 0.2891 - val_accuracy: 0.9802\n",
            "Epoch 1008/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.4571e-10 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9802\n",
            "Epoch 1009/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7750e-10 - accuracy: 1.0000 - val_loss: 0.2911 - val_accuracy: 0.9802\n",
            "Epoch 1010/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.5101e-10 - accuracy: 1.0000 - val_loss: 0.2920 - val_accuracy: 0.9802\n",
            "Epoch 1011/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2717e-10 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.9801\n",
            "Epoch 1012/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.1922e-10 - accuracy: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.9801\n",
            "Epoch 1013/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2717e-10 - accuracy: 1.0000 - val_loss: 0.2943 - val_accuracy: 0.9801\n",
            "Epoch 1014/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3247e-10 - accuracy: 1.0000 - val_loss: 0.2950 - val_accuracy: 0.9801\n",
            "Epoch 1015/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1392e-10 - accuracy: 1.0000 - val_loss: 0.2957 - val_accuracy: 0.9801\n",
            "Epoch 1016/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.0863e-10 - accuracy: 1.0000 - val_loss: 0.2968 - val_accuracy: 0.9800\n",
            "Epoch 1017/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9538e-10 - accuracy: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.9800\n",
            "Epoch 1018/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.8743e-10 - accuracy: 1.0000 - val_loss: 0.2979 - val_accuracy: 0.9801\n",
            "Epoch 1019/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9273e-10 - accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 0.9799\n",
            "Epoch 1020/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.8743e-10 - accuracy: 1.0000 - val_loss: 0.2995 - val_accuracy: 0.9800\n",
            "Epoch 1021/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.7154e-10 - accuracy: 1.0000 - val_loss: 0.3004 - val_accuracy: 0.9801\n",
            "Epoch 1022/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5829e-10 - accuracy: 1.0000 - val_loss: 0.3009 - val_accuracy: 0.9799\n",
            "Epoch 1023/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6094e-10 - accuracy: 1.0000 - val_loss: 0.3015 - val_accuracy: 0.9799\n",
            "Epoch 1024/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5300e-10 - accuracy: 1.0000 - val_loss: 0.3023 - val_accuracy: 0.9799\n",
            "Epoch 1025/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6889e-10 - accuracy: 1.0000 - val_loss: 0.3032 - val_accuracy: 0.9799\n",
            "Epoch 1026/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4240e-10 - accuracy: 1.0000 - val_loss: 0.3038 - val_accuracy: 0.9799\n",
            "Epoch 1027/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4240e-10 - accuracy: 1.0000 - val_loss: 0.3048 - val_accuracy: 0.9799\n",
            "Epoch 1028/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5035e-10 - accuracy: 1.0000 - val_loss: 0.3051 - val_accuracy: 0.9799\n",
            "Epoch 1029/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2915e-10 - accuracy: 1.0000 - val_loss: 0.3060 - val_accuracy: 0.9799\n",
            "Epoch 1030/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2650e-10 - accuracy: 1.0000 - val_loss: 0.3072 - val_accuracy: 0.9799\n",
            "Epoch 1031/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6094e-10 - accuracy: 1.0000 - val_loss: 0.3077 - val_accuracy: 0.9798\n",
            "Epoch 1032/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4240e-10 - accuracy: 1.0000 - val_loss: 0.3083 - val_accuracy: 0.9799\n",
            "Epoch 1033/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6359e-10 - accuracy: 1.0000 - val_loss: 0.3090 - val_accuracy: 0.9798\n",
            "Epoch 1034/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3180e-10 - accuracy: 1.0000 - val_loss: 0.3097 - val_accuracy: 0.9798\n",
            "Epoch 1035/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3710e-10 - accuracy: 1.0000 - val_loss: 0.3104 - val_accuracy: 0.9797\n",
            "Epoch 1036/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2650e-10 - accuracy: 1.0000 - val_loss: 0.3110 - val_accuracy: 0.9797\n",
            "Epoch 1037/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5564e-10 - accuracy: 1.0000 - val_loss: 0.3120 - val_accuracy: 0.9796\n",
            "Epoch 1038/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5829e-10 - accuracy: 1.0000 - val_loss: 0.3124 - val_accuracy: 0.9793\n",
            "Epoch 1039/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5829e-10 - accuracy: 1.0000 - val_loss: 0.3127 - val_accuracy: 0.9794\n",
            "Epoch 1040/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1326e-10 - accuracy: 1.0000 - val_loss: 0.3137 - val_accuracy: 0.9793\n",
            "Epoch 1041/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.6359e-10 - accuracy: 1.0000 - val_loss: 0.3146 - val_accuracy: 0.9794\n",
            "Epoch 1042/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5300e-10 - accuracy: 1.0000 - val_loss: 0.3147 - val_accuracy: 0.9794\n",
            "Epoch 1043/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2121e-10 - accuracy: 1.0000 - val_loss: 0.3157 - val_accuracy: 0.9793\n",
            "Epoch 1044/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.3180e-10 - accuracy: 1.0000 - val_loss: 0.3164 - val_accuracy: 0.9795\n",
            "Epoch 1045/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2650e-10 - accuracy: 1.0000 - val_loss: 0.3173 - val_accuracy: 0.9795\n",
            "Epoch 1046/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.1326e-10 - accuracy: 1.0000 - val_loss: 0.3179 - val_accuracy: 0.9796\n",
            "Epoch 1047/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.7684e-10 - accuracy: 1.0000 - val_loss: 0.3183 - val_accuracy: 0.9795\n",
            "Epoch 1048/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.3710e-10 - accuracy: 1.0000 - val_loss: 0.3192 - val_accuracy: 0.9794\n",
            "Epoch 1049/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9736e-10 - accuracy: 1.0000 - val_loss: 0.3197 - val_accuracy: 0.9793\n",
            "Epoch 1050/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.3445e-10 - accuracy: 1.0000 - val_loss: 0.3204 - val_accuracy: 0.9793\n",
            "Epoch 1051/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3710e-10 - accuracy: 1.0000 - val_loss: 0.3212 - val_accuracy: 0.9791\n",
            "Epoch 1052/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2386e-10 - accuracy: 1.0000 - val_loss: 0.3221 - val_accuracy: 0.9792\n",
            "Epoch 1053/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5300e-10 - accuracy: 1.0000 - val_loss: 0.3220 - val_accuracy: 0.9790\n",
            "Epoch 1054/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5035e-10 - accuracy: 1.0000 - val_loss: 0.3229 - val_accuracy: 0.9791\n",
            "Epoch 1055/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.4505e-10 - accuracy: 1.0000 - val_loss: 0.3238 - val_accuracy: 0.9791\n",
            "Epoch 1056/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5035e-10 - accuracy: 1.0000 - val_loss: 0.3244 - val_accuracy: 0.9791\n",
            "Epoch 1057/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2915e-10 - accuracy: 1.0000 - val_loss: 0.3249 - val_accuracy: 0.9792\n",
            "Epoch 1058/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7684e-10 - accuracy: 1.0000 - val_loss: 0.3258 - val_accuracy: 0.9794\n",
            "Epoch 1059/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.6094e-10 - accuracy: 1.0000 - val_loss: 0.3257 - val_accuracy: 0.9792\n",
            "Epoch 1060/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.3180e-10 - accuracy: 1.0000 - val_loss: 0.3266 - val_accuracy: 0.9793\n",
            "Epoch 1061/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5035e-10 - accuracy: 1.0000 - val_loss: 0.3278 - val_accuracy: 0.9794\n",
            "Epoch 1062/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5564e-10 - accuracy: 1.0000 - val_loss: 0.3289 - val_accuracy: 0.9795\n",
            "Epoch 1063/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5564e-10 - accuracy: 1.0000 - val_loss: 0.3285 - val_accuracy: 0.9793\n",
            "Epoch 1064/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5035e-10 - accuracy: 1.0000 - val_loss: 0.3296 - val_accuracy: 0.9793\n",
            "Epoch 1065/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.6359e-10 - accuracy: 1.0000 - val_loss: 0.3299 - val_accuracy: 0.9793\n",
            "Epoch 1066/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7154e-10 - accuracy: 1.0000 - val_loss: 0.3307 - val_accuracy: 0.9793\n",
            "Epoch 1067/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.4505e-10 - accuracy: 1.0000 - val_loss: 0.3318 - val_accuracy: 0.9793\n",
            "Epoch 1068/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6094e-10 - accuracy: 1.0000 - val_loss: 0.3325 - val_accuracy: 0.9793\n",
            "Epoch 1069/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.4240e-10 - accuracy: 1.0000 - val_loss: 0.3326 - val_accuracy: 0.9791\n",
            "Epoch 1070/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5300e-10 - accuracy: 1.0000 - val_loss: 0.3331 - val_accuracy: 0.9791\n",
            "Epoch 1071/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9008e-10 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.9791\n",
            "Epoch 1072/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.6624e-10 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9791\n",
            "Epoch 1073/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6889e-10 - accuracy: 1.0000 - val_loss: 0.3353 - val_accuracy: 0.9791\n",
            "Epoch 1074/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.7684e-10 - accuracy: 1.0000 - val_loss: 0.3354 - val_accuracy: 0.9790\n",
            "Epoch 1075/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5564e-10 - accuracy: 1.0000 - val_loss: 0.3368 - val_accuracy: 0.9791\n",
            "Epoch 1076/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6359e-10 - accuracy: 1.0000 - val_loss: 0.3373 - val_accuracy: 0.9791\n",
            "Epoch 1077/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.8214e-10 - accuracy: 1.0000 - val_loss: 0.3374 - val_accuracy: 0.9791\n",
            "Epoch 1078/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.9538e-10 - accuracy: 1.0000 - val_loss: 0.3388 - val_accuracy: 0.9791\n",
            "Epoch 1079/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7949e-10 - accuracy: 1.0000 - val_loss: 0.3397 - val_accuracy: 0.9791\n",
            "Epoch 1080/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0598e-10 - accuracy: 1.0000 - val_loss: 0.3399 - val_accuracy: 0.9790\n",
            "Epoch 1081/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.9538e-10 - accuracy: 1.0000 - val_loss: 0.3400 - val_accuracy: 0.9790\n",
            "Epoch 1082/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.7419e-10 - accuracy: 1.0000 - val_loss: 0.3410 - val_accuracy: 0.9790\n",
            "Epoch 1083/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1128e-10 - accuracy: 1.0000 - val_loss: 0.3415 - val_accuracy: 0.9791\n",
            "Epoch 1084/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0333e-10 - accuracy: 1.0000 - val_loss: 0.3419 - val_accuracy: 0.9789\n",
            "Epoch 1085/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6094e-10 - accuracy: 1.0000 - val_loss: 0.3428 - val_accuracy: 0.9789\n",
            "Epoch 1086/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1128e-10 - accuracy: 1.0000 - val_loss: 0.3434 - val_accuracy: 0.9789\n",
            "Epoch 1087/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.7419e-10 - accuracy: 1.0000 - val_loss: 0.3449 - val_accuracy: 0.9788\n",
            "Epoch 1088/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.8478e-10 - accuracy: 1.0000 - val_loss: 0.3451 - val_accuracy: 0.9789\n",
            "Epoch 1089/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.4306e-10 - accuracy: 1.0000 - val_loss: 0.3455 - val_accuracy: 0.9788\n",
            "Epoch 1090/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.9538e-10 - accuracy: 1.0000 - val_loss: 0.3474 - val_accuracy: 0.9787\n",
            "Epoch 1091/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1128e-10 - accuracy: 1.0000 - val_loss: 0.3471 - val_accuracy: 0.9787\n",
            "Epoch 1092/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.3247e-10 - accuracy: 1.0000 - val_loss: 0.3472 - val_accuracy: 0.9786\n",
            "Epoch 1093/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7419e-10 - accuracy: 1.0000 - val_loss: 0.3480 - val_accuracy: 0.9787\n",
            "Epoch 1094/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.7949e-10 - accuracy: 1.0000 - val_loss: 0.3497 - val_accuracy: 0.9787\n",
            "Epoch 1095/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.2187e-10 - accuracy: 1.0000 - val_loss: 0.3516 - val_accuracy: 0.9788\n",
            "Epoch 1096/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.1392e-10 - accuracy: 1.0000 - val_loss: 0.3505 - val_accuracy: 0.9786\n",
            "Epoch 1097/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7949e-10 - accuracy: 1.0000 - val_loss: 0.3514 - val_accuracy: 0.9788\n",
            "Epoch 1098/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.8743e-10 - accuracy: 1.0000 - val_loss: 0.3521 - val_accuracy: 0.9787\n",
            "Epoch 1099/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9008e-10 - accuracy: 1.0000 - val_loss: 0.3522 - val_accuracy: 0.9787\n",
            "Epoch 1100/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.5300e-10 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 0.9786\n",
            "Epoch 1101/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2187e-10 - accuracy: 1.0000 - val_loss: 0.3535 - val_accuracy: 0.9785\n",
            "Epoch 1102/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.9273e-10 - accuracy: 1.0000 - val_loss: 0.3558 - val_accuracy: 0.9787\n",
            "Epoch 1103/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.3247e-10 - accuracy: 1.0000 - val_loss: 0.3546 - val_accuracy: 0.9787\n",
            "Epoch 1104/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7750e-10 - accuracy: 1.0000 - val_loss: 0.3584 - val_accuracy: 0.9785\n",
            "Epoch 1105/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.1194e-10 - accuracy: 1.0000 - val_loss: 0.3568 - val_accuracy: 0.9784\n",
            "Epoch 1106/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.4836e-10 - accuracy: 1.0000 - val_loss: 0.3571 - val_accuracy: 0.9786\n",
            "Epoch 1107/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2982e-10 - accuracy: 1.0000 - val_loss: 0.3579 - val_accuracy: 0.9787\n",
            "Epoch 1108/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3247e-10 - accuracy: 1.0000 - val_loss: 0.3579 - val_accuracy: 0.9787\n",
            "Epoch 1109/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5366e-10 - accuracy: 1.0000 - val_loss: 0.3598 - val_accuracy: 0.9787\n",
            "Epoch 1110/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.2254e-10 - accuracy: 1.0000 - val_loss: 0.3610 - val_accuracy: 0.9785\n",
            "Epoch 1111/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.1922e-10 - accuracy: 1.0000 - val_loss: 0.3604 - val_accuracy: 0.9785\n",
            "Epoch 1112/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.2717e-10 - accuracy: 1.0000 - val_loss: 0.3613 - val_accuracy: 0.9787\n",
            "Epoch 1113/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5101e-10 - accuracy: 1.0000 - val_loss: 0.3615 - val_accuracy: 0.9785\n",
            "Epoch 1114/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2982e-10 - accuracy: 1.0000 - val_loss: 0.3625 - val_accuracy: 0.9786\n",
            "Epoch 1115/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.8015e-10 - accuracy: 1.0000 - val_loss: 0.3635 - val_accuracy: 0.9783\n",
            "Epoch 1116/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5101e-10 - accuracy: 1.0000 - val_loss: 0.3626 - val_accuracy: 0.9787\n",
            "Epoch 1117/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7220e-10 - accuracy: 1.0000 - val_loss: 0.3634 - val_accuracy: 0.9788\n",
            "Epoch 1118/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8413e-10 - accuracy: 1.0000 - val_loss: 0.3615 - val_accuracy: 0.9784\n",
            "Epoch 1119/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.1906 - accuracy: 0.9868 - val_loss: 0.3025 - val_accuracy: 0.9759\n",
            "Epoch 1120/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 0.2829 - val_accuracy: 0.9767\n",
            "Epoch 1121/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.2766 - val_accuracy: 0.9776\n",
            "Epoch 1122/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.2668 - val_accuracy: 0.9786\n",
            "Epoch 1123/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.0775e-04 - accuracy: 0.9998 - val_loss: 0.2569 - val_accuracy: 0.9795\n",
            "Epoch 1124/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7827e-04 - accuracy: 0.9998 - val_loss: 0.2676 - val_accuracy: 0.9789\n",
            "Epoch 1125/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.2628 - val_accuracy: 0.9779\n",
            "Epoch 1126/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.2711 - val_accuracy: 0.9773\n",
            "Epoch 1127/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.2585 - val_accuracy: 0.9779\n",
            "Epoch 1128/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8028e-04 - accuracy: 1.0000 - val_loss: 0.2395 - val_accuracy: 0.9774\n",
            "Epoch 1129/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2658e-04 - accuracy: 0.9999 - val_loss: 0.2378 - val_accuracy: 0.9787\n",
            "Epoch 1130/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.8614e-06 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9787\n",
            "Epoch 1131/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5760e-06 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9788\n",
            "Epoch 1132/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9580e-06 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9790\n",
            "Epoch 1133/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5684e-06 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9790\n",
            "Epoch 1134/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2737e-06 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9791\n",
            "Epoch 1135/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0467e-06 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9791\n",
            "Epoch 1136/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8564e-06 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9791\n",
            "Epoch 1137/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6961e-06 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9791\n",
            "Epoch 1138/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5576e-06 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9792\n",
            "Epoch 1139/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4346e-06 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9792\n",
            "Epoch 1140/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3280e-06 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9792\n",
            "Epoch 1141/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2313e-06 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9792\n",
            "Epoch 1142/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1435e-06 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9792\n",
            "Epoch 1143/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0649e-06 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9792\n",
            "Epoch 1144/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9186e-07 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9792\n",
            "Epoch 1145/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2514e-07 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9794\n",
            "Epoch 1146/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6495e-07 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.9794\n",
            "Epoch 1147/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0852e-07 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.9794\n",
            "Epoch 1148/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.5647e-07 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9794\n",
            "Epoch 1149/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.0741e-07 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9794\n",
            "Epoch 1150/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6262e-07 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9794\n",
            "Epoch 1151/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2033e-07 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9795\n",
            "Epoch 1152/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.8147e-07 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9795\n",
            "Epoch 1153/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.4434e-07 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9795\n",
            "Epoch 1154/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1056e-07 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9795\n",
            "Epoch 1155/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7894e-07 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9794\n",
            "Epoch 1156/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4911e-07 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9794\n",
            "Epoch 1157/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.2110e-07 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9795\n",
            "Epoch 1158/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9489e-07 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9795\n",
            "Epoch 1159/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7036e-07 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9795\n",
            "Epoch 1160/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4676e-07 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9796\n",
            "Epoch 1161/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2502e-07 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9795\n",
            "Epoch 1162/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0451e-07 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9796\n",
            "Epoch 1163/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8527e-07 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9795\n",
            "Epoch 1164/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6767e-07 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9796\n",
            "Epoch 1165/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5091e-07 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9797\n",
            "Epoch 1166/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3525e-07 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9797\n",
            "Epoch 1167/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2038e-07 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9797\n",
            "Epoch 1168/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0675e-07 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9798\n",
            "Epoch 1169/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9390e-07 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9799\n",
            "Epoch 1170/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8172e-07 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 0.9799\n",
            "Epoch 1171/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7026e-07 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9799\n",
            "Epoch 1172/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5963e-07 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9798\n",
            "Epoch 1173/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4973e-07 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.9799\n",
            "Epoch 1174/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4007e-07 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9799\n",
            "Epoch 1175/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3127e-07 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9800\n",
            "Epoch 1176/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2288e-07 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 0.9800\n",
            "Epoch 1177/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1509e-07 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.9801\n",
            "Epoch 1178/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0789e-07 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9800\n",
            "Epoch 1179/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0090e-07 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9799\n",
            "Epoch 1180/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4384e-08 - accuracy: 1.0000 - val_loss: 0.2388 - val_accuracy: 0.9799\n",
            "Epoch 1181/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.8252e-08 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9799\n",
            "Epoch 1182/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.2450e-08 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9799\n",
            "Epoch 1183/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6903e-08 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9799\n",
            "Epoch 1184/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.1917e-08 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.9799\n",
            "Epoch 1185/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.7189e-08 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9799\n",
            "Epoch 1186/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.2746e-08 - accuracy: 1.0000 - val_loss: 0.2398 - val_accuracy: 0.9799\n",
            "Epoch 1187/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.8524e-08 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9799\n",
            "Epoch 1188/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.4661e-08 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9799\n",
            "Epoch 1189/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1008e-08 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9799\n",
            "Epoch 1190/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.7670e-08 - accuracy: 1.0000 - val_loss: 0.2407 - val_accuracy: 0.9798\n",
            "Epoch 1191/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.4457e-08 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9799\n",
            "Epoch 1192/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1352e-08 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 0.9799\n",
            "Epoch 1193/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8674e-08 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 0.9799\n",
            "Epoch 1194/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6062e-08 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9798\n",
            "Epoch 1195/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3628e-08 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9797\n",
            "Epoch 1196/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1341e-08 - accuracy: 1.0000 - val_loss: 0.2421 - val_accuracy: 0.9797\n",
            "Epoch 1197/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9204e-08 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9798\n",
            "Epoch 1198/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7206e-08 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.9798\n",
            "Epoch 1199/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5418e-08 - accuracy: 1.0000 - val_loss: 0.2428 - val_accuracy: 0.9797\n",
            "Epoch 1200/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3643e-08 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9797\n",
            "Epoch 1201/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1995e-08 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9797\n",
            "Epoch 1202/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0578e-08 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9797\n",
            "Epoch 1203/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9145e-08 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9797\n",
            "Epoch 1204/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7810e-08 - accuracy: 1.0000 - val_loss: 0.2443 - val_accuracy: 0.9797\n",
            "Epoch 1205/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6647e-08 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9797\n",
            "Epoch 1206/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5518e-08 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9798\n",
            "Epoch 1207/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4488e-08 - accuracy: 1.0000 - val_loss: 0.2452 - val_accuracy: 0.9798\n",
            "Epoch 1208/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3508e-08 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9797\n",
            "Epoch 1209/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2567e-08 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 0.9797\n",
            "Epoch 1210/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1770e-08 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9798\n",
            "Epoch 1211/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0914e-08 - accuracy: 1.0000 - val_loss: 0.2465 - val_accuracy: 0.9798\n",
            "Epoch 1212/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0247e-08 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9798\n",
            "Epoch 1213/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5394e-09 - accuracy: 1.0000 - val_loss: 0.2473 - val_accuracy: 0.9799\n",
            "Epoch 1214/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.8771e-09 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.9799\n",
            "Epoch 1215/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2996e-09 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9799\n",
            "Epoch 1216/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.7539e-09 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.9799\n",
            "Epoch 1217/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2002e-09 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.9799\n",
            "Epoch 1218/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.6492e-09 - accuracy: 1.0000 - val_loss: 0.2491 - val_accuracy: 0.9799\n",
            "Epoch 1219/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2360e-09 - accuracy: 1.0000 - val_loss: 0.2496 - val_accuracy: 0.9800\n",
            "Epoch 1220/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.8439e-09 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9801\n",
            "Epoch 1221/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.4439e-09 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9801\n",
            "Epoch 1222/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0810e-09 - accuracy: 1.0000 - val_loss: 0.2509 - val_accuracy: 0.9801\n",
            "Epoch 1223/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7445e-09 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9801\n",
            "Epoch 1224/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.4266e-09 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.9800\n",
            "Epoch 1225/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1379e-09 - accuracy: 1.0000 - val_loss: 0.2523 - val_accuracy: 0.9799\n",
            "Epoch 1226/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.8889e-09 - accuracy: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.9799\n",
            "Epoch 1227/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.5842e-09 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.9799\n",
            "Epoch 1228/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3617e-09 - accuracy: 1.0000 - val_loss: 0.2538 - val_accuracy: 0.9799\n",
            "Epoch 1229/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1816e-09 - accuracy: 1.0000 - val_loss: 0.2543 - val_accuracy: 0.9799\n",
            "Epoch 1230/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9617e-09 - accuracy: 1.0000 - val_loss: 0.2548 - val_accuracy: 0.9798\n",
            "Epoch 1231/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7868e-09 - accuracy: 1.0000 - val_loss: 0.2554 - val_accuracy: 0.9798\n",
            "Epoch 1232/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6041e-09 - accuracy: 1.0000 - val_loss: 0.2560 - val_accuracy: 0.9798\n",
            "Epoch 1233/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4425e-09 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9798\n",
            "Epoch 1234/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2994e-09 - accuracy: 1.0000 - val_loss: 0.2572 - val_accuracy: 0.9798\n",
            "Epoch 1235/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1590e-09 - accuracy: 1.0000 - val_loss: 0.2578 - val_accuracy: 0.9798\n",
            "Epoch 1236/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0239e-09 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9798\n",
            "Epoch 1237/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9153e-09 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.9797\n",
            "Epoch 1238/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7643e-09 - accuracy: 1.0000 - val_loss: 0.2598 - val_accuracy: 0.9798\n",
            "Epoch 1239/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6477e-09 - accuracy: 1.0000 - val_loss: 0.2604 - val_accuracy: 0.9798\n",
            "Epoch 1240/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5497e-09 - accuracy: 1.0000 - val_loss: 0.2612 - val_accuracy: 0.9797\n",
            "Epoch 1241/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4782e-09 - accuracy: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.9798\n",
            "Epoch 1242/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3881e-09 - accuracy: 1.0000 - val_loss: 0.2627 - val_accuracy: 0.9798\n",
            "Epoch 1243/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2981e-09 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9798\n",
            "Epoch 1244/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1974e-09 - accuracy: 1.0000 - val_loss: 0.2641 - val_accuracy: 0.9797\n",
            "Epoch 1245/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1232e-09 - accuracy: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.9797\n",
            "Epoch 1246/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0411e-09 - accuracy: 1.0000 - val_loss: 0.2660 - val_accuracy: 0.9797\n",
            "Epoch 1247/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.8546e-10 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.9797\n",
            "Epoch 1248/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.0334e-10 - accuracy: 1.0000 - val_loss: 0.2678 - val_accuracy: 0.9797\n",
            "Epoch 1249/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.5301e-10 - accuracy: 1.0000 - val_loss: 0.2688 - val_accuracy: 0.9797\n",
            "Epoch 1250/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0797e-10 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.9797\n",
            "Epoch 1251/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.7089e-10 - accuracy: 1.0000 - val_loss: 0.2708 - val_accuracy: 0.9797\n",
            "Epoch 1252/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.4440e-10 - accuracy: 1.0000 - val_loss: 0.2716 - val_accuracy: 0.9797\n",
            "Epoch 1253/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.9936e-10 - accuracy: 1.0000 - val_loss: 0.2726 - val_accuracy: 0.9797\n",
            "Epoch 1254/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8876e-10 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.9796\n",
            "Epoch 1255/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.4638e-10 - accuracy: 1.0000 - val_loss: 0.2745 - val_accuracy: 0.9799\n",
            "Epoch 1256/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.0929e-10 - accuracy: 1.0000 - val_loss: 0.2756 - val_accuracy: 0.9799\n",
            "Epoch 1257/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7750e-10 - accuracy: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.9800\n",
            "Epoch 1258/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.7220e-10 - accuracy: 1.0000 - val_loss: 0.2777 - val_accuracy: 0.9800\n",
            "Epoch 1259/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.5366e-10 - accuracy: 1.0000 - val_loss: 0.2788 - val_accuracy: 0.9800\n",
            "Epoch 1260/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.3512e-10 - accuracy: 1.0000 - val_loss: 0.2799 - val_accuracy: 0.9800\n",
            "Epoch 1261/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.3777e-10 - accuracy: 1.0000 - val_loss: 0.2808 - val_accuracy: 0.9800\n",
            "Epoch 1262/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.0598e-10 - accuracy: 1.0000 - val_loss: 0.2818 - val_accuracy: 0.9801\n",
            "Epoch 1263/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.8743e-10 - accuracy: 1.0000 - val_loss: 0.2827 - val_accuracy: 0.9801\n",
            "Epoch 1264/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5564e-10 - accuracy: 1.0000 - val_loss: 0.2837 - val_accuracy: 0.9801\n",
            "Epoch 1265/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.6624e-10 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.9801\n",
            "Epoch 1266/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4505e-10 - accuracy: 1.0000 - val_loss: 0.2855 - val_accuracy: 0.9800\n",
            "Epoch 1267/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.2915e-10 - accuracy: 1.0000 - val_loss: 0.2865 - val_accuracy: 0.9799\n",
            "Epoch 1268/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.1856e-10 - accuracy: 1.0000 - val_loss: 0.2876 - val_accuracy: 0.9799\n",
            "Epoch 1269/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0531e-10 - accuracy: 1.0000 - val_loss: 0.2882 - val_accuracy: 0.9799\n",
            "Epoch 1270/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0266e-10 - accuracy: 1.0000 - val_loss: 0.2892 - val_accuracy: 0.9797\n",
            "Epoch 1271/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.7882e-10 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9797\n",
            "Epoch 1272/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6558e-10 - accuracy: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.9795\n",
            "Epoch 1273/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.7617e-10 - accuracy: 1.0000 - val_loss: 0.2921 - val_accuracy: 0.9795\n",
            "Epoch 1274/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6822e-10 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.9795\n",
            "Epoch 1275/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3114e-10 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.9794\n",
            "Epoch 1276/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.4438e-10 - accuracy: 1.0000 - val_loss: 0.2949 - val_accuracy: 0.9794\n",
            "Epoch 1277/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6293e-10 - accuracy: 1.0000 - val_loss: 0.2957 - val_accuracy: 0.9793\n",
            "Epoch 1278/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2319e-10 - accuracy: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.9793\n",
            "Epoch 1279/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2584e-10 - accuracy: 1.0000 - val_loss: 0.2976 - val_accuracy: 0.9793\n",
            "Epoch 1280/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2319e-10 - accuracy: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.9792\n",
            "Epoch 1281/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0465e-10 - accuracy: 1.0000 - val_loss: 0.2994 - val_accuracy: 0.9793\n",
            "Epoch 1282/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2319e-10 - accuracy: 1.0000 - val_loss: 0.3005 - val_accuracy: 0.9793\n",
            "Epoch 1283/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9935e-10 - accuracy: 1.0000 - val_loss: 0.3015 - val_accuracy: 0.9793\n",
            "Epoch 1284/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9935e-10 - accuracy: 1.0000 - val_loss: 0.3023 - val_accuracy: 0.9794\n",
            "Epoch 1285/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0200e-10 - accuracy: 1.0000 - val_loss: 0.3035 - val_accuracy: 0.9793\n",
            "Epoch 1286/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0465e-10 - accuracy: 1.0000 - val_loss: 0.3042 - val_accuracy: 0.9794\n",
            "Epoch 1287/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8610e-10 - accuracy: 1.0000 - val_loss: 0.3047 - val_accuracy: 0.9795\n",
            "Epoch 1288/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7551e-10 - accuracy: 1.0000 - val_loss: 0.3058 - val_accuracy: 0.9794\n",
            "Epoch 1289/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7815e-10 - accuracy: 1.0000 - val_loss: 0.3071 - val_accuracy: 0.9794\n",
            "Epoch 1290/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8610e-10 - accuracy: 1.0000 - val_loss: 0.3075 - val_accuracy: 0.9793\n",
            "Epoch 1291/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7286e-10 - accuracy: 1.0000 - val_loss: 0.3088 - val_accuracy: 0.9792\n",
            "Epoch 1292/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9935e-10 - accuracy: 1.0000 - val_loss: 0.3096 - val_accuracy: 0.9791\n",
            "Epoch 1293/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0200e-10 - accuracy: 1.0000 - val_loss: 0.3103 - val_accuracy: 0.9792\n",
            "Epoch 1294/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7815e-10 - accuracy: 1.0000 - val_loss: 0.3111 - val_accuracy: 0.9792\n",
            "Epoch 1295/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7021e-10 - accuracy: 1.0000 - val_loss: 0.3120 - val_accuracy: 0.9791\n",
            "Epoch 1296/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7815e-10 - accuracy: 1.0000 - val_loss: 0.3126 - val_accuracy: 0.9791\n",
            "Epoch 1297/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7551e-10 - accuracy: 1.0000 - val_loss: 0.3131 - val_accuracy: 0.9793\n",
            "Epoch 1298/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8610e-10 - accuracy: 1.0000 - val_loss: 0.3144 - val_accuracy: 0.9791\n",
            "Epoch 1299/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6226e-10 - accuracy: 1.0000 - val_loss: 0.3156 - val_accuracy: 0.9790\n",
            "Epoch 1300/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9405e-10 - accuracy: 1.0000 - val_loss: 0.3161 - val_accuracy: 0.9793\n",
            "Epoch 1301/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8875e-10 - accuracy: 1.0000 - val_loss: 0.3169 - val_accuracy: 0.9792\n",
            "Epoch 1302/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8345e-10 - accuracy: 1.0000 - val_loss: 0.3180 - val_accuracy: 0.9790\n",
            "Epoch 1303/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8080e-10 - accuracy: 1.0000 - val_loss: 0.3190 - val_accuracy: 0.9791\n",
            "Epoch 1304/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5961e-10 - accuracy: 1.0000 - val_loss: 0.3200 - val_accuracy: 0.9789\n",
            "Epoch 1305/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8345e-10 - accuracy: 1.0000 - val_loss: 0.3207 - val_accuracy: 0.9790\n",
            "Epoch 1306/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6226e-10 - accuracy: 1.0000 - val_loss: 0.3222 - val_accuracy: 0.9789\n",
            "Epoch 1307/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9405e-10 - accuracy: 1.0000 - val_loss: 0.3229 - val_accuracy: 0.9788\n",
            "Epoch 1308/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8345e-10 - accuracy: 1.0000 - val_loss: 0.3230 - val_accuracy: 0.9789\n",
            "Epoch 1309/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7286e-10 - accuracy: 1.0000 - val_loss: 0.3245 - val_accuracy: 0.9788\n",
            "Epoch 1310/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6756e-10 - accuracy: 1.0000 - val_loss: 0.3255 - val_accuracy: 0.9791\n",
            "Epoch 1311/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1524e-10 - accuracy: 1.0000 - val_loss: 0.3259 - val_accuracy: 0.9790\n",
            "Epoch 1312/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9405e-10 - accuracy: 1.0000 - val_loss: 0.3263 - val_accuracy: 0.9789\n",
            "Epoch 1313/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0465e-10 - accuracy: 1.0000 - val_loss: 0.3274 - val_accuracy: 0.9791\n",
            "Epoch 1314/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7815e-10 - accuracy: 1.0000 - val_loss: 0.3284 - val_accuracy: 0.9789\n",
            "Epoch 1315/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8080e-10 - accuracy: 1.0000 - val_loss: 0.3280 - val_accuracy: 0.9789\n",
            "Epoch 1316/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9140e-10 - accuracy: 1.0000 - val_loss: 0.3288 - val_accuracy: 0.9788\n",
            "Epoch 1317/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9405e-10 - accuracy: 1.0000 - val_loss: 0.3305 - val_accuracy: 0.9788\n",
            "Epoch 1318/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8080e-10 - accuracy: 1.0000 - val_loss: 0.3317 - val_accuracy: 0.9789\n",
            "Epoch 1319/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0200e-10 - accuracy: 1.0000 - val_loss: 0.3318 - val_accuracy: 0.9790\n",
            "Epoch 1320/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9670e-10 - accuracy: 1.0000 - val_loss: 0.3326 - val_accuracy: 0.9790\n",
            "Epoch 1321/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9405e-10 - accuracy: 1.0000 - val_loss: 0.3331 - val_accuracy: 0.9790\n",
            "Epoch 1322/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9670e-10 - accuracy: 1.0000 - val_loss: 0.3346 - val_accuracy: 0.9787\n",
            "Epoch 1323/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0465e-10 - accuracy: 1.0000 - val_loss: 0.3348 - val_accuracy: 0.9787\n",
            "Epoch 1324/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8345e-10 - accuracy: 1.0000 - val_loss: 0.3356 - val_accuracy: 0.9791\n",
            "Epoch 1325/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9935e-10 - accuracy: 1.0000 - val_loss: 0.3364 - val_accuracy: 0.9789\n",
            "Epoch 1326/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0465e-10 - accuracy: 1.0000 - val_loss: 0.3369 - val_accuracy: 0.9787\n",
            "Epoch 1327/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8080e-10 - accuracy: 1.0000 - val_loss: 0.3387 - val_accuracy: 0.9787\n",
            "Epoch 1328/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1789e-10 - accuracy: 1.0000 - val_loss: 0.3385 - val_accuracy: 0.9789\n",
            "Epoch 1329/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9140e-10 - accuracy: 1.0000 - val_loss: 0.3394 - val_accuracy: 0.9789\n",
            "Epoch 1330/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9935e-10 - accuracy: 1.0000 - val_loss: 0.3409 - val_accuracy: 0.9788\n",
            "Epoch 1331/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9405e-10 - accuracy: 1.0000 - val_loss: 0.3412 - val_accuracy: 0.9789\n",
            "Epoch 1332/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0994e-10 - accuracy: 1.0000 - val_loss: 0.3418 - val_accuracy: 0.9788\n",
            "Epoch 1333/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1789e-10 - accuracy: 1.0000 - val_loss: 0.3436 - val_accuracy: 0.9788\n",
            "Epoch 1334/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0994e-10 - accuracy: 1.0000 - val_loss: 0.3430 - val_accuracy: 0.9789\n",
            "Epoch 1335/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0730e-10 - accuracy: 1.0000 - val_loss: 0.3435 - val_accuracy: 0.9791\n",
            "Epoch 1336/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3644e-10 - accuracy: 1.0000 - val_loss: 0.3438 - val_accuracy: 0.9790\n",
            "Epoch 1337/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4173e-10 - accuracy: 1.0000 - val_loss: 0.3462 - val_accuracy: 0.9788\n",
            "Epoch 1338/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9670e-10 - accuracy: 1.0000 - val_loss: 0.3452 - val_accuracy: 0.9789\n",
            "Epoch 1339/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2584e-10 - accuracy: 1.0000 - val_loss: 0.3465 - val_accuracy: 0.9789\n",
            "Epoch 1340/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2054e-10 - accuracy: 1.0000 - val_loss: 0.3480 - val_accuracy: 0.9789\n",
            "Epoch 1341/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2849e-10 - accuracy: 1.0000 - val_loss: 0.3482 - val_accuracy: 0.9789\n",
            "Epoch 1342/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2054e-10 - accuracy: 1.0000 - val_loss: 0.3493 - val_accuracy: 0.9787\n",
            "Epoch 1343/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1259e-10 - accuracy: 1.0000 - val_loss: 0.3509 - val_accuracy: 0.9791\n",
            "Epoch 1344/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2584e-10 - accuracy: 1.0000 - val_loss: 0.3508 - val_accuracy: 0.9788\n",
            "Epoch 1345/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0465e-10 - accuracy: 1.0000 - val_loss: 0.3514 - val_accuracy: 0.9788\n",
            "Epoch 1346/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2584e-10 - accuracy: 1.0000 - val_loss: 0.3523 - val_accuracy: 0.9789\n",
            "Epoch 1347/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3114e-10 - accuracy: 1.0000 - val_loss: 0.3527 - val_accuracy: 0.9791\n",
            "Epoch 1348/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2319e-10 - accuracy: 1.0000 - val_loss: 0.3531 - val_accuracy: 0.9789\n",
            "Epoch 1349/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9935e-10 - accuracy: 1.0000 - val_loss: 0.3537 - val_accuracy: 0.9789\n",
            "Epoch 1350/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2319e-10 - accuracy: 1.0000 - val_loss: 0.3546 - val_accuracy: 0.9788\n",
            "Epoch 1351/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5233e-10 - accuracy: 1.0000 - val_loss: 0.3549 - val_accuracy: 0.9790\n",
            "Epoch 1352/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9140e-10 - accuracy: 1.0000 - val_loss: 0.3571 - val_accuracy: 0.9789\n",
            "Epoch 1353/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.4968e-10 - accuracy: 1.0000 - val_loss: 0.3557 - val_accuracy: 0.9789\n",
            "Epoch 1354/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.7419e-10 - accuracy: 1.0000 - val_loss: 0.3557 - val_accuracy: 0.9789\n",
            "Epoch 1355/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0169 - accuracy: 0.9986 - val_loss: 0.7445 - val_accuracy: 0.9621\n",
            "Epoch 1356/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0883 - accuracy: 0.9894 - val_loss: 0.2880 - val_accuracy: 0.9748\n",
            "Epoch 1357/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.2596 - val_accuracy: 0.9777\n",
            "Epoch 1358/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.2512 - val_accuracy: 0.9779\n",
            "Epoch 1359/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1446e-04 - accuracy: 0.9998 - val_loss: 0.2579 - val_accuracy: 0.9777\n",
            "Epoch 1360/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6917e-04 - accuracy: 0.9999 - val_loss: 0.2440 - val_accuracy: 0.9783\n",
            "Epoch 1361/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9079e-05 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.9784\n",
            "Epoch 1362/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1524e-05 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9782\n",
            "Epoch 1363/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4621e-06 - accuracy: 1.0000 - val_loss: 0.2407 - val_accuracy: 0.9783\n",
            "Epoch 1364/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7743e-06 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9783\n",
            "Epoch 1365/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3073e-06 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.9783\n",
            "Epoch 1366/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9634e-06 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9784\n",
            "Epoch 1367/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6740e-06 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9784\n",
            "Epoch 1368/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4383e-06 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 0.9785\n",
            "Epoch 1369/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2455e-06 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 0.9784\n",
            "Epoch 1370/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0687e-06 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9785\n",
            "Epoch 1371/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9127e-06 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9786\n",
            "Epoch 1372/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7757e-06 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9786\n",
            "Epoch 1373/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6490e-06 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9786\n",
            "Epoch 1374/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5350e-06 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9785\n",
            "Epoch 1375/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4285e-06 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9784\n",
            "Epoch 1376/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3309e-06 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9785\n",
            "Epoch 1377/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2424e-06 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9784\n",
            "Epoch 1378/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1616e-06 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 0.9784\n",
            "Epoch 1379/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0874e-06 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 0.9785\n",
            "Epoch 1380/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0190e-06 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9785\n",
            "Epoch 1381/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.5447e-07 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9785\n",
            "Epoch 1382/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.9585e-07 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.9786\n",
            "Epoch 1383/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.4037e-07 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9786\n",
            "Epoch 1384/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8825e-07 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9786\n",
            "Epoch 1385/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.4019e-07 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9786\n",
            "Epoch 1386/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.9502e-07 - accuracy: 1.0000 - val_loss: 0.2406 - val_accuracy: 0.9787\n",
            "Epoch 1387/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.5238e-07 - accuracy: 1.0000 - val_loss: 0.2407 - val_accuracy: 0.9786\n",
            "Epoch 1388/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1284e-07 - accuracy: 1.0000 - val_loss: 0.2407 - val_accuracy: 0.9787\n",
            "Epoch 1389/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.7472e-07 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9787\n",
            "Epoch 1390/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3925e-07 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9787\n",
            "Epoch 1391/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0594e-07 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9786\n",
            "Epoch 1392/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.7404e-07 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 0.9786\n",
            "Epoch 1393/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4413e-07 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 0.9786\n",
            "Epoch 1394/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.1655e-07 - accuracy: 1.0000 - val_loss: 0.2415 - val_accuracy: 0.9786\n",
            "Epoch 1395/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8972e-07 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9786\n",
            "Epoch 1396/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6531e-07 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9786\n",
            "Epoch 1397/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4208e-07 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9786\n",
            "Epoch 1398/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2106e-07 - accuracy: 1.0000 - val_loss: 0.2420 - val_accuracy: 0.9785\n",
            "Epoch 1399/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0062e-07 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9785\n",
            "Epoch 1400/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8163e-07 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9785\n",
            "Epoch 1401/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6373e-07 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 0.9784\n",
            "Epoch 1402/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4737e-07 - accuracy: 1.0000 - val_loss: 0.2427 - val_accuracy: 0.9785\n",
            "Epoch 1403/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3183e-07 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9785\n",
            "Epoch 1404/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1723e-07 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9785\n",
            "Epoch 1405/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0337e-07 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9785\n",
            "Epoch 1406/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9032e-07 - accuracy: 1.0000 - val_loss: 0.2435 - val_accuracy: 0.9785\n",
            "Epoch 1407/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7810e-07 - accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 0.9786\n",
            "Epoch 1408/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6653e-07 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9785\n",
            "Epoch 1409/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5586e-07 - accuracy: 1.0000 - val_loss: 0.2442 - val_accuracy: 0.9785\n",
            "Epoch 1410/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4571e-07 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9785\n",
            "Epoch 1411/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3612e-07 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9785\n",
            "Epoch 1412/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2722e-07 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9785\n",
            "Epoch 1413/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1865e-07 - accuracy: 1.0000 - val_loss: 0.2452 - val_accuracy: 0.9786\n",
            "Epoch 1414/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1074e-07 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9787\n",
            "Epoch 1415/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0346e-07 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9785\n",
            "Epoch 1416/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.6628e-08 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9785\n",
            "Epoch 1417/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.0204e-08 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9786\n",
            "Epoch 1418/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.3923e-08 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.9787\n",
            "Epoch 1419/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8278e-08 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9787\n",
            "Epoch 1420/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.2932e-08 - accuracy: 1.0000 - val_loss: 0.2472 - val_accuracy: 0.9786\n",
            "Epoch 1421/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.8023e-08 - accuracy: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.9787\n",
            "Epoch 1422/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3424e-08 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.9787\n",
            "Epoch 1423/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.9085e-08 - accuracy: 1.0000 - val_loss: 0.2482 - val_accuracy: 0.9787\n",
            "Epoch 1424/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.5085e-08 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9787\n",
            "Epoch 1425/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1289e-08 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9788\n",
            "Epoch 1426/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7747e-08 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.9788\n",
            "Epoch 1427/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.4499e-08 - accuracy: 1.0000 - val_loss: 0.2496 - val_accuracy: 0.9788\n",
            "Epoch 1428/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1379e-08 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9789\n",
            "Epoch 1429/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.8621e-08 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9789\n",
            "Epoch 1430/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5903e-08 - accuracy: 1.0000 - val_loss: 0.2508 - val_accuracy: 0.9790\n",
            "Epoch 1431/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3408e-08 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.9791\n",
            "Epoch 1432/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1124e-08 - accuracy: 1.0000 - val_loss: 0.2516 - val_accuracy: 0.9791\n",
            "Epoch 1433/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8941e-08 - accuracy: 1.0000 - val_loss: 0.2520 - val_accuracy: 0.9791\n",
            "Epoch 1434/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6955e-08 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9791\n",
            "Epoch 1435/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5095e-08 - accuracy: 1.0000 - val_loss: 0.2529 - val_accuracy: 0.9792\n",
            "Epoch 1436/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3389e-08 - accuracy: 1.0000 - val_loss: 0.2533 - val_accuracy: 0.9793\n",
            "Epoch 1437/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.1768e-08 - accuracy: 1.0000 - val_loss: 0.2537 - val_accuracy: 0.9791\n",
            "Epoch 1438/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0295e-08 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.9793\n",
            "Epoch 1439/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8872e-08 - accuracy: 1.0000 - val_loss: 0.2545 - val_accuracy: 0.9792\n",
            "Epoch 1440/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7579e-08 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.9791\n",
            "Epoch 1441/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6390e-08 - accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 0.9791\n",
            "Epoch 1442/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5232e-08 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.9792\n",
            "Epoch 1443/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4239e-08 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9791\n",
            "Epoch 1444/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3256e-08 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.9792\n",
            "Epoch 1445/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2347e-08 - accuracy: 1.0000 - val_loss: 0.2574 - val_accuracy: 0.9792\n",
            "Epoch 1446/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1484e-08 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.9791\n",
            "Epoch 1447/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0724e-08 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9793\n",
            "Epoch 1448/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9977e-09 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.9794\n",
            "Epoch 1449/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.3354e-09 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.9794\n",
            "Epoch 1450/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7208e-09 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.9793\n",
            "Epoch 1451/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.1619e-09 - accuracy: 1.0000 - val_loss: 0.2604 - val_accuracy: 0.9793\n",
            "Epoch 1452/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.6267e-09 - accuracy: 1.0000 - val_loss: 0.2610 - val_accuracy: 0.9793\n",
            "Epoch 1453/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.0969e-09 - accuracy: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.9793\n",
            "Epoch 1454/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6148e-09 - accuracy: 1.0000 - val_loss: 0.2621 - val_accuracy: 0.9793\n",
            "Epoch 1455/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.1750e-09 - accuracy: 1.0000 - val_loss: 0.2627 - val_accuracy: 0.9795\n",
            "Epoch 1456/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7512e-09 - accuracy: 1.0000 - val_loss: 0.2633 - val_accuracy: 0.9794\n",
            "Epoch 1457/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.4200e-09 - accuracy: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.9794\n",
            "Epoch 1458/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0598e-09 - accuracy: 1.0000 - val_loss: 0.2643 - val_accuracy: 0.9793\n",
            "Epoch 1459/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7551e-09 - accuracy: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.9794\n",
            "Epoch 1460/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4346e-09 - accuracy: 1.0000 - val_loss: 0.2655 - val_accuracy: 0.9794\n",
            "Epoch 1461/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1723e-09 - accuracy: 1.0000 - val_loss: 0.2662 - val_accuracy: 0.9794\n",
            "Epoch 1462/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9207e-09 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.9795\n",
            "Epoch 1463/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6425e-09 - accuracy: 1.0000 - val_loss: 0.2674 - val_accuracy: 0.9795\n",
            "Epoch 1464/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4279e-09 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.9794\n",
            "Epoch 1465/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2213e-09 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.9795\n",
            "Epoch 1466/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0253e-09 - accuracy: 1.0000 - val_loss: 0.2692 - val_accuracy: 0.9795\n",
            "Epoch 1467/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8239e-09 - accuracy: 1.0000 - val_loss: 0.2698 - val_accuracy: 0.9795\n",
            "Epoch 1468/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6491e-09 - accuracy: 1.0000 - val_loss: 0.2704 - val_accuracy: 0.9795\n",
            "Epoch 1469/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4875e-09 - accuracy: 1.0000 - val_loss: 0.2711 - val_accuracy: 0.9794\n",
            "Epoch 1470/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3047e-09 - accuracy: 1.0000 - val_loss: 0.2719 - val_accuracy: 0.9795\n",
            "Epoch 1471/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1405e-09 - accuracy: 1.0000 - val_loss: 0.2728 - val_accuracy: 0.9793\n",
            "Epoch 1472/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0319e-09 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9794\n",
            "Epoch 1473/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9179e-09 - accuracy: 1.0000 - val_loss: 0.2744 - val_accuracy: 0.9794\n",
            "Epoch 1474/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8067e-09 - accuracy: 1.0000 - val_loss: 0.2752 - val_accuracy: 0.9794\n",
            "Epoch 1475/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6716e-09 - accuracy: 1.0000 - val_loss: 0.2760 - val_accuracy: 0.9794\n",
            "Epoch 1476/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6054e-09 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.9793\n",
            "Epoch 1477/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5100e-09 - accuracy: 1.0000 - val_loss: 0.2777 - val_accuracy: 0.9793\n",
            "Epoch 1478/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4199e-09 - accuracy: 1.0000 - val_loss: 0.2786 - val_accuracy: 0.9793\n",
            "Epoch 1479/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3404e-09 - accuracy: 1.0000 - val_loss: 0.2794 - val_accuracy: 0.9793\n",
            "Epoch 1480/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2451e-09 - accuracy: 1.0000 - val_loss: 0.2804 - val_accuracy: 0.9793\n",
            "Epoch 1481/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1868e-09 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9792\n",
            "Epoch 1482/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1073e-09 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.9791\n",
            "Epoch 1483/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0623e-09 - accuracy: 1.0000 - val_loss: 0.2833 - val_accuracy: 0.9793\n",
            "Epoch 1484/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.7222e-10 - accuracy: 1.0000 - val_loss: 0.2843 - val_accuracy: 0.9791\n",
            "Epoch 1485/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.3778e-10 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.9791\n",
            "Epoch 1486/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.8215e-10 - accuracy: 1.0000 - val_loss: 0.2865 - val_accuracy: 0.9791\n",
            "Epoch 1487/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.4506e-10 - accuracy: 1.0000 - val_loss: 0.2874 - val_accuracy: 0.9791\n",
            "Epoch 1488/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8943e-10 - accuracy: 1.0000 - val_loss: 0.2886 - val_accuracy: 0.9791\n",
            "Epoch 1489/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.8148e-10 - accuracy: 1.0000 - val_loss: 0.2894 - val_accuracy: 0.9793\n",
            "Epoch 1490/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.3380e-10 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.9793\n",
            "Epoch 1491/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.9141e-10 - accuracy: 1.0000 - val_loss: 0.2916 - val_accuracy: 0.9793\n",
            "Epoch 1492/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.8082e-10 - accuracy: 1.0000 - val_loss: 0.2925 - val_accuracy: 0.9793\n",
            "Epoch 1493/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.2519e-10 - accuracy: 1.0000 - val_loss: 0.2936 - val_accuracy: 0.9793\n",
            "Epoch 1494/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.2519e-10 - accuracy: 1.0000 - val_loss: 0.2947 - val_accuracy: 0.9793\n",
            "Epoch 1495/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.7750e-10 - accuracy: 1.0000 - val_loss: 0.2957 - val_accuracy: 0.9794\n",
            "Epoch 1496/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.4571e-10 - accuracy: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.9794\n",
            "Epoch 1497/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2717e-10 - accuracy: 1.0000 - val_loss: 0.2980 - val_accuracy: 0.9795\n",
            "Epoch 1498/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.1392e-10 - accuracy: 1.0000 - val_loss: 0.2991 - val_accuracy: 0.9794\n",
            "Epoch 1499/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0068e-10 - accuracy: 1.0000 - val_loss: 0.3003 - val_accuracy: 0.9794\n",
            "Epoch 1500/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6094e-10 - accuracy: 1.0000 - val_loss: 0.3016 - val_accuracy: 0.9793\n",
            "Epoch 1501/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.9008e-10 - accuracy: 1.0000 - val_loss: 0.3027 - val_accuracy: 0.9792\n",
            "Epoch 1502/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2650e-10 - accuracy: 1.0000 - val_loss: 0.3040 - val_accuracy: 0.9792\n",
            "Epoch 1503/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5564e-10 - accuracy: 1.0000 - val_loss: 0.3050 - val_accuracy: 0.9793\n",
            "Epoch 1504/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3180e-10 - accuracy: 1.0000 - val_loss: 0.3062 - val_accuracy: 0.9792\n",
            "Epoch 1505/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.2386e-10 - accuracy: 1.0000 - val_loss: 0.3071 - val_accuracy: 0.9792\n",
            "Epoch 1506/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0266e-10 - accuracy: 1.0000 - val_loss: 0.3081 - val_accuracy: 0.9794\n",
            "Epoch 1507/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1591e-10 - accuracy: 1.0000 - val_loss: 0.3092 - val_accuracy: 0.9793\n",
            "Epoch 1508/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.0796e-10 - accuracy: 1.0000 - val_loss: 0.3102 - val_accuracy: 0.9794\n",
            "Epoch 1509/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8147e-10 - accuracy: 1.0000 - val_loss: 0.3113 - val_accuracy: 0.9794\n",
            "Epoch 1510/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8412e-10 - accuracy: 1.0000 - val_loss: 0.3124 - val_accuracy: 0.9794\n",
            "Epoch 1511/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6028e-10 - accuracy: 1.0000 - val_loss: 0.3138 - val_accuracy: 0.9793\n",
            "Epoch 1512/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9736e-10 - accuracy: 1.0000 - val_loss: 0.3146 - val_accuracy: 0.9794\n",
            "Epoch 1513/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6293e-10 - accuracy: 1.0000 - val_loss: 0.3159 - val_accuracy: 0.9793\n",
            "Epoch 1514/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.8147e-10 - accuracy: 1.0000 - val_loss: 0.3168 - val_accuracy: 0.9792\n",
            "Epoch 1515/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.8677e-10 - accuracy: 1.0000 - val_loss: 0.3179 - val_accuracy: 0.9791\n",
            "Epoch 1516/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6558e-10 - accuracy: 1.0000 - val_loss: 0.3191 - val_accuracy: 0.9791\n",
            "Epoch 1517/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5498e-10 - accuracy: 1.0000 - val_loss: 0.3199 - val_accuracy: 0.9791\n",
            "Epoch 1518/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.7087e-10 - accuracy: 1.0000 - val_loss: 0.3211 - val_accuracy: 0.9791\n",
            "Epoch 1519/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4968e-10 - accuracy: 1.0000 - val_loss: 0.3218 - val_accuracy: 0.9791\n",
            "Epoch 1520/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1789e-10 - accuracy: 1.0000 - val_loss: 0.3229 - val_accuracy: 0.9791\n",
            "Epoch 1521/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5498e-10 - accuracy: 1.0000 - val_loss: 0.3240 - val_accuracy: 0.9791\n",
            "Epoch 1522/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2584e-10 - accuracy: 1.0000 - val_loss: 0.3248 - val_accuracy: 0.9791\n",
            "Epoch 1523/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3644e-10 - accuracy: 1.0000 - val_loss: 0.3258 - val_accuracy: 0.9791\n",
            "Epoch 1524/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3644e-10 - accuracy: 1.0000 - val_loss: 0.3264 - val_accuracy: 0.9791\n",
            "Epoch 1525/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1524e-10 - accuracy: 1.0000 - val_loss: 0.3276 - val_accuracy: 0.9791\n",
            "Epoch 1526/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1789e-10 - accuracy: 1.0000 - val_loss: 0.3288 - val_accuracy: 0.9791\n",
            "Epoch 1527/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2054e-10 - accuracy: 1.0000 - val_loss: 0.3297 - val_accuracy: 0.9791\n",
            "Epoch 1528/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2054e-10 - accuracy: 1.0000 - val_loss: 0.3306 - val_accuracy: 0.9791\n",
            "Epoch 1529/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1524e-10 - accuracy: 1.0000 - val_loss: 0.3317 - val_accuracy: 0.9790\n",
            "Epoch 1530/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2849e-10 - accuracy: 1.0000 - val_loss: 0.3324 - val_accuracy: 0.9792\n",
            "Epoch 1531/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9935e-10 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.9791\n",
            "Epoch 1532/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1789e-10 - accuracy: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.9791\n",
            "Epoch 1533/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0200e-10 - accuracy: 1.0000 - val_loss: 0.3353 - val_accuracy: 0.9790\n",
            "Epoch 1534/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8875e-10 - accuracy: 1.0000 - val_loss: 0.3366 - val_accuracy: 0.9791\n",
            "Epoch 1535/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0730e-10 - accuracy: 1.0000 - val_loss: 0.3375 - val_accuracy: 0.9792\n",
            "Epoch 1536/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8875e-10 - accuracy: 1.0000 - val_loss: 0.3383 - val_accuracy: 0.9791\n",
            "Epoch 1537/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0200e-10 - accuracy: 1.0000 - val_loss: 0.3392 - val_accuracy: 0.9791\n",
            "Epoch 1538/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7815e-10 - accuracy: 1.0000 - val_loss: 0.3404 - val_accuracy: 0.9791\n",
            "Epoch 1539/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8080e-10 - accuracy: 1.0000 - val_loss: 0.3420 - val_accuracy: 0.9791\n",
            "Epoch 1540/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0730e-10 - accuracy: 1.0000 - val_loss: 0.3426 - val_accuracy: 0.9791\n",
            "Epoch 1541/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8610e-10 - accuracy: 1.0000 - val_loss: 0.3436 - val_accuracy: 0.9790\n",
            "Epoch 1542/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9405e-10 - accuracy: 1.0000 - val_loss: 0.3447 - val_accuracy: 0.9789\n",
            "Epoch 1543/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8610e-10 - accuracy: 1.0000 - val_loss: 0.3457 - val_accuracy: 0.9791\n",
            "Epoch 1544/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0994e-10 - accuracy: 1.0000 - val_loss: 0.3465 - val_accuracy: 0.9789\n",
            "Epoch 1545/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0200e-10 - accuracy: 1.0000 - val_loss: 0.3472 - val_accuracy: 0.9789\n",
            "Epoch 1546/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8345e-10 - accuracy: 1.0000 - val_loss: 0.3486 - val_accuracy: 0.9789\n",
            "Epoch 1547/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8345e-10 - accuracy: 1.0000 - val_loss: 0.3497 - val_accuracy: 0.9791\n",
            "Epoch 1548/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0465e-10 - accuracy: 1.0000 - val_loss: 0.3507 - val_accuracy: 0.9789\n",
            "Epoch 1549/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9670e-10 - accuracy: 1.0000 - val_loss: 0.3513 - val_accuracy: 0.9789\n",
            "Epoch 1550/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9935e-10 - accuracy: 1.0000 - val_loss: 0.3521 - val_accuracy: 0.9789\n",
            "Epoch 1551/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8610e-10 - accuracy: 1.0000 - val_loss: 0.3527 - val_accuracy: 0.9789\n",
            "Epoch 1552/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8875e-10 - accuracy: 1.0000 - val_loss: 0.3541 - val_accuracy: 0.9789\n",
            "Epoch 1553/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9670e-10 - accuracy: 1.0000 - val_loss: 0.3553 - val_accuracy: 0.9789\n",
            "Epoch 1554/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8610e-10 - accuracy: 1.0000 - val_loss: 0.3560 - val_accuracy: 0.9789\n",
            "Epoch 1555/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0465e-10 - accuracy: 1.0000 - val_loss: 0.3567 - val_accuracy: 0.9788\n",
            "Epoch 1556/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5696e-10 - accuracy: 1.0000 - val_loss: 0.3579 - val_accuracy: 0.9789\n",
            "Epoch 1557/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9935e-10 - accuracy: 1.0000 - val_loss: 0.3587 - val_accuracy: 0.9790\n",
            "Epoch 1558/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7021e-10 - accuracy: 1.0000 - val_loss: 0.3593 - val_accuracy: 0.9791\n",
            "Epoch 1559/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8080e-10 - accuracy: 1.0000 - val_loss: 0.3604 - val_accuracy: 0.9789\n",
            "Epoch 1560/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7286e-10 - accuracy: 1.0000 - val_loss: 0.3609 - val_accuracy: 0.9789\n",
            "Epoch 1561/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8875e-10 - accuracy: 1.0000 - val_loss: 0.3621 - val_accuracy: 0.9791\n",
            "Epoch 1562/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7551e-10 - accuracy: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.9790\n",
            "Epoch 1563/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9405e-10 - accuracy: 1.0000 - val_loss: 0.3636 - val_accuracy: 0.9791\n",
            "Epoch 1564/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9405e-10 - accuracy: 1.0000 - val_loss: 0.3649 - val_accuracy: 0.9790\n",
            "Epoch 1565/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0200e-10 - accuracy: 1.0000 - val_loss: 0.3653 - val_accuracy: 0.9791\n",
            "Epoch 1566/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7286e-10 - accuracy: 1.0000 - val_loss: 0.3664 - val_accuracy: 0.9790\n",
            "Epoch 1567/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5961e-10 - accuracy: 1.0000 - val_loss: 0.3673 - val_accuracy: 0.9790\n",
            "Epoch 1568/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7286e-10 - accuracy: 1.0000 - val_loss: 0.3686 - val_accuracy: 0.9790\n",
            "Epoch 1569/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7286e-10 - accuracy: 1.0000 - val_loss: 0.3696 - val_accuracy: 0.9789\n",
            "Epoch 1570/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1789e-10 - accuracy: 1.0000 - val_loss: 0.3701 - val_accuracy: 0.9790\n",
            "Epoch 1571/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7021e-10 - accuracy: 1.0000 - val_loss: 0.3712 - val_accuracy: 0.9790\n",
            "Epoch 1572/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7815e-10 - accuracy: 1.0000 - val_loss: 0.3725 - val_accuracy: 0.9791\n",
            "Epoch 1573/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9670e-10 - accuracy: 1.0000 - val_loss: 0.3731 - val_accuracy: 0.9789\n",
            "Epoch 1574/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9670e-10 - accuracy: 1.0000 - val_loss: 0.3741 - val_accuracy: 0.9790\n",
            "Epoch 1575/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8080e-10 - accuracy: 1.0000 - val_loss: 0.3743 - val_accuracy: 0.9789\n",
            "Epoch 1576/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6491e-10 - accuracy: 1.0000 - val_loss: 0.3757 - val_accuracy: 0.9790\n",
            "Epoch 1577/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0730e-10 - accuracy: 1.0000 - val_loss: 0.3762 - val_accuracy: 0.9792\n",
            "Epoch 1578/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0465e-10 - accuracy: 1.0000 - val_loss: 0.3769 - val_accuracy: 0.9789\n",
            "Epoch 1579/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7286e-10 - accuracy: 1.0000 - val_loss: 0.3779 - val_accuracy: 0.9791\n",
            "Epoch 1580/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1789e-10 - accuracy: 1.0000 - val_loss: 0.3789 - val_accuracy: 0.9791\n",
            "Epoch 1581/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7551e-10 - accuracy: 1.0000 - val_loss: 0.3797 - val_accuracy: 0.9790\n",
            "Epoch 1582/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9405e-10 - accuracy: 1.0000 - val_loss: 0.3807 - val_accuracy: 0.9791\n",
            "Epoch 1583/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6756e-10 - accuracy: 1.0000 - val_loss: 0.3812 - val_accuracy: 0.9792\n",
            "Epoch 1584/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9670e-10 - accuracy: 1.0000 - val_loss: 0.3816 - val_accuracy: 0.9793\n",
            "Epoch 1585/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6491e-10 - accuracy: 1.0000 - val_loss: 0.3834 - val_accuracy: 0.9792\n",
            "Epoch 1586/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0730e-10 - accuracy: 1.0000 - val_loss: 0.3839 - val_accuracy: 0.9791\n",
            "Epoch 1587/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8875e-10 - accuracy: 1.0000 - val_loss: 0.3844 - val_accuracy: 0.9792\n",
            "Epoch 1588/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6226e-10 - accuracy: 1.0000 - val_loss: 0.3862 - val_accuracy: 0.9792\n",
            "Epoch 1589/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8875e-10 - accuracy: 1.0000 - val_loss: 0.3869 - val_accuracy: 0.9791\n",
            "Epoch 1590/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7551e-10 - accuracy: 1.0000 - val_loss: 0.3874 - val_accuracy: 0.9791\n",
            "Epoch 1591/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7286e-10 - accuracy: 1.0000 - val_loss: 0.3888 - val_accuracy: 0.9790\n",
            "Epoch 1592/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7815e-10 - accuracy: 1.0000 - val_loss: 0.3897 - val_accuracy: 0.9792\n",
            "Epoch 1593/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8080e-10 - accuracy: 1.0000 - val_loss: 0.3907 - val_accuracy: 0.9792\n",
            "Epoch 1594/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9140e-10 - accuracy: 1.0000 - val_loss: 0.3918 - val_accuracy: 0.9791\n",
            "Epoch 1595/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9670e-10 - accuracy: 1.0000 - val_loss: 0.3914 - val_accuracy: 0.9792\n",
            "Epoch 1596/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3379e-10 - accuracy: 1.0000 - val_loss: 0.3929 - val_accuracy: 0.9792\n",
            "Epoch 1597/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7815e-10 - accuracy: 1.0000 - val_loss: 0.3945 - val_accuracy: 0.9792\n",
            "Epoch 1598/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6756e-10 - accuracy: 1.0000 - val_loss: 0.3947 - val_accuracy: 0.9791\n",
            "Epoch 1599/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2319e-10 - accuracy: 1.0000 - val_loss: 0.3957 - val_accuracy: 0.9791\n",
            "Epoch 1600/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.5498e-10 - accuracy: 1.0000 - val_loss: 0.3969 - val_accuracy: 0.9792\n",
            "Epoch 1601/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0813 - accuracy: 0.9945 - val_loss: 0.5294 - val_accuracy: 0.9657\n",
            "Epoch 1602/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0345 - accuracy: 0.9941 - val_loss: 0.2809 - val_accuracy: 0.9760\n",
            "Epoch 1603/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.2660 - val_accuracy: 0.9772\n",
            "Epoch 1604/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.2689 - val_accuracy: 0.9769\n",
            "Epoch 1605/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.4775e-04 - accuracy: 0.9998 - val_loss: 0.2490 - val_accuracy: 0.9783\n",
            "Epoch 1606/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.8799e-05 - accuracy: 1.0000 - val_loss: 0.2468 - val_accuracy: 0.9790\n",
            "Epoch 1607/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2093e-06 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.9791\n",
            "Epoch 1608/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.8794e-06 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.9791\n",
            "Epoch 1609/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.0866e-06 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.9791\n",
            "Epoch 1610/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.5181e-06 - accuracy: 1.0000 - val_loss: 0.2465 - val_accuracy: 0.9793\n",
            "Epoch 1611/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0884e-06 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9793\n",
            "Epoch 1612/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7489e-06 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9793\n",
            "Epoch 1613/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4656e-06 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9793\n",
            "Epoch 1614/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2186e-06 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9793\n",
            "Epoch 1615/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0121e-06 - accuracy: 1.0000 - val_loss: 0.2461 - val_accuracy: 0.9793\n",
            "Epoch 1616/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8251e-06 - accuracy: 1.0000 - val_loss: 0.2461 - val_accuracy: 0.9793\n",
            "Epoch 1617/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6691e-06 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9793\n",
            "Epoch 1618/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5241e-06 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9793\n",
            "Epoch 1619/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3966e-06 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9794\n",
            "Epoch 1620/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2854e-06 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9794\n",
            "Epoch 1621/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1866e-06 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 0.9795\n",
            "Epoch 1622/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0987e-06 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9795\n",
            "Epoch 1623/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0164e-06 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9795\n",
            "Epoch 1624/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.4299e-07 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9795\n",
            "Epoch 1625/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7536e-07 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9795\n",
            "Epoch 1626/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.1534e-07 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9795\n",
            "Epoch 1627/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.5859e-07 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9796\n",
            "Epoch 1628/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.0560e-07 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9796\n",
            "Epoch 1629/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.5849e-07 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9797\n",
            "Epoch 1630/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.1409e-07 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9797\n",
            "Epoch 1631/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.7457e-07 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9797\n",
            "Epoch 1632/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.3662e-07 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9797\n",
            "Epoch 1633/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.0156e-07 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9797\n",
            "Epoch 1634/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.7036e-07 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9797\n",
            "Epoch 1635/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.3949e-07 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9797\n",
            "Epoch 1636/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.0904e-07 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9797\n",
            "Epoch 1637/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8134e-07 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9797\n",
            "Epoch 1638/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5603e-07 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 0.9797\n",
            "Epoch 1639/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3247e-07 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 0.9797\n",
            "Epoch 1640/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1069e-07 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9797\n",
            "Epoch 1641/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9062e-07 - accuracy: 1.0000 - val_loss: 0.2461 - val_accuracy: 0.9798\n",
            "Epoch 1642/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7183e-07 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9798\n",
            "Epoch 1643/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5366e-07 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9797\n",
            "Epoch 1644/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3768e-07 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9797\n",
            "Epoch 1645/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2226e-07 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.9797\n",
            "Epoch 1646/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0801e-07 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.9797\n",
            "Epoch 1647/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9480e-07 - accuracy: 1.0000 - val_loss: 0.2468 - val_accuracy: 0.9799\n",
            "Epoch 1648/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8238e-07 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9799\n",
            "Epoch 1649/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7090e-07 - accuracy: 1.0000 - val_loss: 0.2471 - val_accuracy: 0.9799\n",
            "Epoch 1650/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5986e-07 - accuracy: 1.0000 - val_loss: 0.2472 - val_accuracy: 0.9797\n",
            "Epoch 1651/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4962e-07 - accuracy: 1.0000 - val_loss: 0.2474 - val_accuracy: 0.9797\n",
            "Epoch 1652/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4023e-07 - accuracy: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.9798\n",
            "Epoch 1653/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3144e-07 - accuracy: 1.0000 - val_loss: 0.2477 - val_accuracy: 0.9798\n",
            "Epoch 1654/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2312e-07 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.9799\n",
            "Epoch 1655/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1508e-07 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9799\n",
            "Epoch 1656/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0774e-07 - accuracy: 1.0000 - val_loss: 0.2482 - val_accuracy: 0.9799\n",
            "Epoch 1657/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0079e-07 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.9799\n",
            "Epoch 1658/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4257e-08 - accuracy: 1.0000 - val_loss: 0.2486 - val_accuracy: 0.9799\n",
            "Epoch 1659/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.8167e-08 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9800\n",
            "Epoch 1660/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.2609e-08 - accuracy: 1.0000 - val_loss: 0.2491 - val_accuracy: 0.9801\n",
            "Epoch 1661/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.7417e-08 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.9801\n",
            "Epoch 1662/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.2434e-08 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9802\n",
            "Epoch 1663/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.7809e-08 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9802\n",
            "Epoch 1664/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.3517e-08 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9802\n",
            "Epoch 1665/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.9517e-08 - accuracy: 1.0000 - val_loss: 0.2503 - val_accuracy: 0.9803\n",
            "Epoch 1666/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5652e-08 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9803\n",
            "Epoch 1667/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.2020e-08 - accuracy: 1.0000 - val_loss: 0.2509 - val_accuracy: 0.9803\n",
            "Epoch 1668/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.8635e-08 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.9804\n",
            "Epoch 1669/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5432e-08 - accuracy: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.9805\n",
            "Epoch 1670/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2544e-08 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.9805\n",
            "Epoch 1671/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9678e-08 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.9805\n",
            "Epoch 1672/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.7161e-08 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9804\n",
            "Epoch 1673/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4730e-08 - accuracy: 1.0000 - val_loss: 0.2528 - val_accuracy: 0.9804\n",
            "Epoch 1674/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2414e-08 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.9804\n",
            "Epoch 1675/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0322e-08 - accuracy: 1.0000 - val_loss: 0.2535 - val_accuracy: 0.9804\n",
            "Epoch 1676/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8279e-08 - accuracy: 1.0000 - val_loss: 0.2539 - val_accuracy: 0.9803\n",
            "Epoch 1677/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6478e-08 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.9803\n",
            "Epoch 1678/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4679e-08 - accuracy: 1.0000 - val_loss: 0.2545 - val_accuracy: 0.9803\n",
            "Epoch 1679/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3082e-08 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.9803\n",
            "Epoch 1680/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1474e-08 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9803\n",
            "Epoch 1681/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.0099e-08 - accuracy: 1.0000 - val_loss: 0.2557 - val_accuracy: 0.9804\n",
            "Epoch 1682/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8679e-08 - accuracy: 1.0000 - val_loss: 0.2562 - val_accuracy: 0.9803\n",
            "Epoch 1683/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7415e-08 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9803\n",
            "Epoch 1684/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6234e-08 - accuracy: 1.0000 - val_loss: 0.2570 - val_accuracy: 0.9803\n",
            "Epoch 1685/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5105e-08 - accuracy: 1.0000 - val_loss: 0.2575 - val_accuracy: 0.9804\n",
            "Epoch 1686/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4059e-08 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.9804\n",
            "Epoch 1687/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3137e-08 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9803\n",
            "Epoch 1688/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2297e-08 - accuracy: 1.0000 - val_loss: 0.2589 - val_accuracy: 0.9804\n",
            "Epoch 1689/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1407e-08 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.9804\n",
            "Epoch 1690/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0681e-08 - accuracy: 1.0000 - val_loss: 0.2598 - val_accuracy: 0.9803\n",
            "Epoch 1691/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.9341e-09 - accuracy: 1.0000 - val_loss: 0.2603 - val_accuracy: 0.9804\n",
            "Epoch 1692/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.2877e-09 - accuracy: 1.0000 - val_loss: 0.2609 - val_accuracy: 0.9805\n",
            "Epoch 1693/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.6122e-09 - accuracy: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.9805\n",
            "Epoch 1694/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.0956e-09 - accuracy: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.9805\n",
            "Epoch 1695/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.5446e-09 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.9805\n",
            "Epoch 1696/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.0598e-09 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9807\n",
            "Epoch 1697/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.6095e-09 - accuracy: 1.0000 - val_loss: 0.2633 - val_accuracy: 0.9806\n",
            "Epoch 1698/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.1433e-09 - accuracy: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.9806\n",
            "Epoch 1699/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.7777e-09 - accuracy: 1.0000 - val_loss: 0.2643 - val_accuracy: 0.9807\n",
            "Epoch 1700/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3883e-09 - accuracy: 1.0000 - val_loss: 0.2649 - val_accuracy: 0.9807\n",
            "Epoch 1701/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.0121e-09 - accuracy: 1.0000 - val_loss: 0.2655 - val_accuracy: 0.9806\n",
            "Epoch 1702/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.7127e-09 - accuracy: 1.0000 - val_loss: 0.2660 - val_accuracy: 0.9806\n",
            "Epoch 1703/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4028e-09 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9806\n",
            "Epoch 1704/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.0876e-09 - accuracy: 1.0000 - val_loss: 0.2673 - val_accuracy: 0.9806\n",
            "Epoch 1705/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.8253e-09 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.9806\n",
            "Epoch 1706/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5551e-09 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.9806\n",
            "Epoch 1707/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3352e-09 - accuracy: 1.0000 - val_loss: 0.2693 - val_accuracy: 0.9806\n",
            "Epoch 1708/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1392e-09 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.9806\n",
            "Epoch 1709/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9087e-09 - accuracy: 1.0000 - val_loss: 0.2706 - val_accuracy: 0.9806\n",
            "Epoch 1710/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7206e-09 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.9806\n",
            "Epoch 1711/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5590e-09 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.9806\n",
            "Epoch 1712/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4239e-09 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9806\n",
            "Epoch 1713/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2782e-09 - accuracy: 1.0000 - val_loss: 0.2734 - val_accuracy: 0.9806\n",
            "Epoch 1714/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1484e-09 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9806\n",
            "Epoch 1715/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0107e-09 - accuracy: 1.0000 - val_loss: 0.2748 - val_accuracy: 0.9807\n",
            "Epoch 1716/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8888e-09 - accuracy: 1.0000 - val_loss: 0.2755 - val_accuracy: 0.9806\n",
            "Epoch 1717/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7696e-09 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9806\n",
            "Epoch 1718/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6477e-09 - accuracy: 1.0000 - val_loss: 0.2769 - val_accuracy: 0.9805\n",
            "Epoch 1719/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5762e-09 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.9805\n",
            "Epoch 1720/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4623e-09 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9803\n",
            "Epoch 1721/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4014e-09 - accuracy: 1.0000 - val_loss: 0.2790 - val_accuracy: 0.9805\n",
            "Epoch 1722/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3166e-09 - accuracy: 1.0000 - val_loss: 0.2798 - val_accuracy: 0.9805\n",
            "Epoch 1723/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2424e-09 - accuracy: 1.0000 - val_loss: 0.2806 - val_accuracy: 0.9805\n",
            "Epoch 1724/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1683e-09 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9805\n",
            "Epoch 1725/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1073e-09 - accuracy: 1.0000 - val_loss: 0.2821 - val_accuracy: 0.9805\n",
            "Epoch 1726/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0596e-09 - accuracy: 1.0000 - val_loss: 0.2830 - val_accuracy: 0.9805\n",
            "Epoch 1727/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0278e-09 - accuracy: 1.0000 - val_loss: 0.2837 - val_accuracy: 0.9805\n",
            "Epoch 1728/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.3248e-10 - accuracy: 1.0000 - val_loss: 0.2845 - val_accuracy: 0.9805\n",
            "Epoch 1729/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.0599e-10 - accuracy: 1.0000 - val_loss: 0.2854 - val_accuracy: 0.9803\n",
            "Epoch 1730/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7420e-10 - accuracy: 1.0000 - val_loss: 0.2862 - val_accuracy: 0.9803\n",
            "Epoch 1731/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.1857e-10 - accuracy: 1.0000 - val_loss: 0.2871 - val_accuracy: 0.9803\n",
            "Epoch 1732/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.9473e-10 - accuracy: 1.0000 - val_loss: 0.2879 - val_accuracy: 0.9803\n",
            "Epoch 1733/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.1790e-10 - accuracy: 1.0000 - val_loss: 0.2891 - val_accuracy: 0.9803\n",
            "Epoch 1734/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.4175e-10 - accuracy: 1.0000 - val_loss: 0.2899 - val_accuracy: 0.9803\n",
            "Epoch 1735/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.8612e-10 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9803\n",
            "Epoch 1736/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3843e-10 - accuracy: 1.0000 - val_loss: 0.2919 - val_accuracy: 0.9802\n",
            "Epoch 1737/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.3313e-10 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.9802\n",
            "Epoch 1738/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 0.2937 - val_accuracy: 0.9802\n",
            "Epoch 1739/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.9340e-10 - accuracy: 1.0000 - val_loss: 0.2946 - val_accuracy: 0.9802\n",
            "Epoch 1740/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.5631e-10 - accuracy: 1.0000 - val_loss: 0.2956 - val_accuracy: 0.9802\n",
            "Epoch 1741/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.3512e-10 - accuracy: 1.0000 - val_loss: 0.2964 - val_accuracy: 0.9802\n",
            "Epoch 1742/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1922e-10 - accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.9802\n",
            "Epoch 1743/2000\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 4.9538e-10 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.9801\n",
            "Epoch 1744/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.6889e-10 - accuracy: 1.0000 - val_loss: 0.2992 - val_accuracy: 0.9803\n",
            "Epoch 1745/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.7419e-10 - accuracy: 1.0000 - val_loss: 0.3002 - val_accuracy: 0.9803\n",
            "Epoch 1746/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.6094e-10 - accuracy: 1.0000 - val_loss: 0.3012 - val_accuracy: 0.9803\n",
            "Epoch 1747/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6094e-10 - accuracy: 1.0000 - val_loss: 0.3021 - val_accuracy: 0.9803\n",
            "Epoch 1748/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.3710e-10 - accuracy: 1.0000 - val_loss: 0.3031 - val_accuracy: 0.9801\n",
            "Epoch 1749/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.6624e-10 - accuracy: 1.0000 - val_loss: 0.3041 - val_accuracy: 0.9801\n",
            "Epoch 1750/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.4505e-10 - accuracy: 1.0000 - val_loss: 0.3048 - val_accuracy: 0.9803\n",
            "Epoch 1751/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2650e-10 - accuracy: 1.0000 - val_loss: 0.3056 - val_accuracy: 0.9803\n",
            "Epoch 1752/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2650e-10 - accuracy: 1.0000 - val_loss: 0.3066 - val_accuracy: 0.9803\n",
            "Epoch 1753/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.4240e-10 - accuracy: 1.0000 - val_loss: 0.3072 - val_accuracy: 0.9804\n",
            "Epoch 1754/2000\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 4.1061e-10 - accuracy: 1.0000 - val_loss: 0.3080 - val_accuracy: 0.9804\n",
            "Epoch 1755/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.1591e-10 - accuracy: 1.0000 - val_loss: 0.3088 - val_accuracy: 0.9804\n",
            "Epoch 1756/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.0266e-10 - accuracy: 1.0000 - val_loss: 0.3097 - val_accuracy: 0.9804\n",
            "Epoch 1757/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.1326e-10 - accuracy: 1.0000 - val_loss: 0.3102 - val_accuracy: 0.9804\n",
            "Epoch 1758/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8412e-10 - accuracy: 1.0000 - val_loss: 0.3111 - val_accuracy: 0.9802\n",
            "Epoch 1759/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.8677e-10 - accuracy: 1.0000 - val_loss: 0.3119 - val_accuracy: 0.9802\n",
            "Epoch 1760/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.8677e-10 - accuracy: 1.0000 - val_loss: 0.3127 - val_accuracy: 0.9803\n",
            "Epoch 1761/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8412e-10 - accuracy: 1.0000 - val_loss: 0.3135 - val_accuracy: 0.9803\n",
            "Epoch 1762/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7882e-10 - accuracy: 1.0000 - val_loss: 0.3143 - val_accuracy: 0.9804\n",
            "Epoch 1763/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.7617e-10 - accuracy: 1.0000 - val_loss: 0.3150 - val_accuracy: 0.9803\n",
            "Epoch 1764/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.8412e-10 - accuracy: 1.0000 - val_loss: 0.3156 - val_accuracy: 0.9805\n",
            "Epoch 1765/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6293e-10 - accuracy: 1.0000 - val_loss: 0.3165 - val_accuracy: 0.9804\n",
            "Epoch 1766/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4173e-10 - accuracy: 1.0000 - val_loss: 0.3175 - val_accuracy: 0.9805\n",
            "Epoch 1767/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.6028e-10 - accuracy: 1.0000 - val_loss: 0.3184 - val_accuracy: 0.9804\n",
            "Epoch 1768/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.5498e-10 - accuracy: 1.0000 - val_loss: 0.3190 - val_accuracy: 0.9803\n",
            "Epoch 1769/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.6293e-10 - accuracy: 1.0000 - val_loss: 0.3197 - val_accuracy: 0.9803\n",
            "Epoch 1770/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5498e-10 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 0.9803\n",
            "Epoch 1771/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3908e-10 - accuracy: 1.0000 - val_loss: 0.3210 - val_accuracy: 0.9803\n",
            "Epoch 1772/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3644e-10 - accuracy: 1.0000 - val_loss: 0.3219 - val_accuracy: 0.9803\n",
            "Epoch 1773/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1789e-10 - accuracy: 1.0000 - val_loss: 0.3226 - val_accuracy: 0.9801\n",
            "Epoch 1774/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3114e-10 - accuracy: 1.0000 - val_loss: 0.3232 - val_accuracy: 0.9802\n",
            "Epoch 1775/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1789e-10 - accuracy: 1.0000 - val_loss: 0.3241 - val_accuracy: 0.9802\n",
            "Epoch 1776/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1524e-10 - accuracy: 1.0000 - val_loss: 0.3249 - val_accuracy: 0.9802\n",
            "Epoch 1777/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2054e-10 - accuracy: 1.0000 - val_loss: 0.3255 - val_accuracy: 0.9802\n",
            "Epoch 1778/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0465e-10 - accuracy: 1.0000 - val_loss: 0.3264 - val_accuracy: 0.9801\n",
            "Epoch 1779/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2319e-10 - accuracy: 1.0000 - val_loss: 0.3270 - val_accuracy: 0.9802\n",
            "Epoch 1780/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2054e-10 - accuracy: 1.0000 - val_loss: 0.3277 - val_accuracy: 0.9802\n",
            "Epoch 1781/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1259e-10 - accuracy: 1.0000 - val_loss: 0.3283 - val_accuracy: 0.9803\n",
            "Epoch 1782/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7551e-10 - accuracy: 1.0000 - val_loss: 0.3294 - val_accuracy: 0.9801\n",
            "Epoch 1783/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.3379e-10 - accuracy: 1.0000 - val_loss: 0.3298 - val_accuracy: 0.9801\n",
            "Epoch 1784/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1259e-10 - accuracy: 1.0000 - val_loss: 0.3307 - val_accuracy: 0.9800\n",
            "Epoch 1785/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0730e-10 - accuracy: 1.0000 - val_loss: 0.3313 - val_accuracy: 0.9800\n",
            "Epoch 1786/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9140e-10 - accuracy: 1.0000 - val_loss: 0.3321 - val_accuracy: 0.9799\n",
            "Epoch 1787/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2054e-10 - accuracy: 1.0000 - val_loss: 0.3328 - val_accuracy: 0.9799\n",
            "Epoch 1788/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9140e-10 - accuracy: 1.0000 - val_loss: 0.3334 - val_accuracy: 0.9799\n",
            "Epoch 1789/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9140e-10 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9799\n",
            "Epoch 1790/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9935e-10 - accuracy: 1.0000 - val_loss: 0.3349 - val_accuracy: 0.9799\n",
            "Epoch 1791/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.1789e-10 - accuracy: 1.0000 - val_loss: 0.3355 - val_accuracy: 0.9799\n",
            "Epoch 1792/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9670e-10 - accuracy: 1.0000 - val_loss: 0.3362 - val_accuracy: 0.9799\n",
            "Epoch 1793/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.1259e-10 - accuracy: 1.0000 - val_loss: 0.3370 - val_accuracy: 0.9799\n",
            "Epoch 1794/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9405e-10 - accuracy: 1.0000 - val_loss: 0.3376 - val_accuracy: 0.9799\n",
            "Epoch 1795/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0465e-10 - accuracy: 1.0000 - val_loss: 0.3384 - val_accuracy: 0.9799\n",
            "Epoch 1796/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9140e-10 - accuracy: 1.0000 - val_loss: 0.3388 - val_accuracy: 0.9798\n",
            "Epoch 1797/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8610e-10 - accuracy: 1.0000 - val_loss: 0.3396 - val_accuracy: 0.9798\n",
            "Epoch 1798/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7551e-10 - accuracy: 1.0000 - val_loss: 0.3404 - val_accuracy: 0.9798\n",
            "Epoch 1799/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9140e-10 - accuracy: 1.0000 - val_loss: 0.3412 - val_accuracy: 0.9799\n",
            "Epoch 1800/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8080e-10 - accuracy: 1.0000 - val_loss: 0.3423 - val_accuracy: 0.9797\n",
            "Epoch 1801/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9670e-10 - accuracy: 1.0000 - val_loss: 0.3426 - val_accuracy: 0.9799\n",
            "Epoch 1802/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9140e-10 - accuracy: 1.0000 - val_loss: 0.3436 - val_accuracy: 0.9798\n",
            "Epoch 1803/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8875e-10 - accuracy: 1.0000 - val_loss: 0.3447 - val_accuracy: 0.9797\n",
            "Epoch 1804/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8345e-10 - accuracy: 1.0000 - val_loss: 0.3453 - val_accuracy: 0.9797\n",
            "Epoch 1805/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8080e-10 - accuracy: 1.0000 - val_loss: 0.3464 - val_accuracy: 0.9795\n",
            "Epoch 1806/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0994e-10 - accuracy: 1.0000 - val_loss: 0.3470 - val_accuracy: 0.9795\n",
            "Epoch 1807/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9140e-10 - accuracy: 1.0000 - val_loss: 0.3478 - val_accuracy: 0.9795\n",
            "Epoch 1808/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8875e-10 - accuracy: 1.0000 - val_loss: 0.3486 - val_accuracy: 0.9795\n",
            "Epoch 1809/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8080e-10 - accuracy: 1.0000 - val_loss: 0.3496 - val_accuracy: 0.9795\n",
            "Epoch 1810/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8875e-10 - accuracy: 1.0000 - val_loss: 0.3504 - val_accuracy: 0.9796\n",
            "Epoch 1811/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8080e-10 - accuracy: 1.0000 - val_loss: 0.3512 - val_accuracy: 0.9795\n",
            "Epoch 1812/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8345e-10 - accuracy: 1.0000 - val_loss: 0.3523 - val_accuracy: 0.9797\n",
            "Epoch 1813/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.9140e-10 - accuracy: 1.0000 - val_loss: 0.3529 - val_accuracy: 0.9797\n",
            "Epoch 1814/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8345e-10 - accuracy: 1.0000 - val_loss: 0.3537 - val_accuracy: 0.9796\n",
            "Epoch 1815/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8080e-10 - accuracy: 1.0000 - val_loss: 0.3546 - val_accuracy: 0.9797\n",
            "Epoch 1816/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7551e-10 - accuracy: 1.0000 - val_loss: 0.3552 - val_accuracy: 0.9797\n",
            "Epoch 1817/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7286e-10 - accuracy: 1.0000 - val_loss: 0.3559 - val_accuracy: 0.9797\n",
            "Epoch 1818/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8345e-10 - accuracy: 1.0000 - val_loss: 0.3567 - val_accuracy: 0.9797\n",
            "Epoch 1819/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3577e-10 - accuracy: 1.0000 - val_loss: 0.3577 - val_accuracy: 0.9797\n",
            "Epoch 1820/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7021e-10 - accuracy: 1.0000 - val_loss: 0.3579 - val_accuracy: 0.9797\n",
            "Epoch 1821/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7021e-10 - accuracy: 1.0000 - val_loss: 0.3592 - val_accuracy: 0.9797\n",
            "Epoch 1822/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6491e-10 - accuracy: 1.0000 - val_loss: 0.3596 - val_accuracy: 0.9796\n",
            "Epoch 1823/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4637e-10 - accuracy: 1.0000 - val_loss: 0.3607 - val_accuracy: 0.9797\n",
            "Epoch 1824/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5166e-10 - accuracy: 1.0000 - val_loss: 0.3612 - val_accuracy: 0.9795\n",
            "Epoch 1825/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0200e-10 - accuracy: 1.0000 - val_loss: 0.3626 - val_accuracy: 0.9797\n",
            "Epoch 1826/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6491e-10 - accuracy: 1.0000 - val_loss: 0.3629 - val_accuracy: 0.9795\n",
            "Epoch 1827/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5166e-10 - accuracy: 1.0000 - val_loss: 0.3639 - val_accuracy: 0.9795\n",
            "Epoch 1828/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6226e-10 - accuracy: 1.0000 - val_loss: 0.3643 - val_accuracy: 0.9794\n",
            "Epoch 1829/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7021e-10 - accuracy: 1.0000 - val_loss: 0.3653 - val_accuracy: 0.9794\n",
            "Epoch 1830/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7021e-10 - accuracy: 1.0000 - val_loss: 0.3665 - val_accuracy: 0.9795\n",
            "Epoch 1831/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6756e-10 - accuracy: 1.0000 - val_loss: 0.3673 - val_accuracy: 0.9795\n",
            "Epoch 1832/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7551e-10 - accuracy: 1.0000 - val_loss: 0.3681 - val_accuracy: 0.9795\n",
            "Epoch 1833/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7551e-10 - accuracy: 1.0000 - val_loss: 0.3688 - val_accuracy: 0.9795\n",
            "Epoch 1834/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6756e-10 - accuracy: 1.0000 - val_loss: 0.3696 - val_accuracy: 0.9795\n",
            "Epoch 1835/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9405e-10 - accuracy: 1.0000 - val_loss: 0.3704 - val_accuracy: 0.9796\n",
            "Epoch 1836/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9140e-10 - accuracy: 1.0000 - val_loss: 0.3715 - val_accuracy: 0.9796\n",
            "Epoch 1837/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7286e-10 - accuracy: 1.0000 - val_loss: 0.3717 - val_accuracy: 0.9793\n",
            "Epoch 1838/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7021e-10 - accuracy: 1.0000 - val_loss: 0.3727 - val_accuracy: 0.9793\n",
            "Epoch 1839/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6226e-10 - accuracy: 1.0000 - val_loss: 0.3737 - val_accuracy: 0.9794\n",
            "Epoch 1840/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.7551e-10 - accuracy: 1.0000 - val_loss: 0.3748 - val_accuracy: 0.9795\n",
            "Epoch 1841/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5166e-10 - accuracy: 1.0000 - val_loss: 0.3751 - val_accuracy: 0.9793\n",
            "Epoch 1842/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5961e-10 - accuracy: 1.0000 - val_loss: 0.3760 - val_accuracy: 0.9793\n",
            "Epoch 1843/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4901e-10 - accuracy: 1.0000 - val_loss: 0.3769 - val_accuracy: 0.9793\n",
            "Epoch 1844/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7021e-10 - accuracy: 1.0000 - val_loss: 0.3780 - val_accuracy: 0.9793\n",
            "Epoch 1845/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5961e-10 - accuracy: 1.0000 - val_loss: 0.3790 - val_accuracy: 0.9793\n",
            "Epoch 1846/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4107e-10 - accuracy: 1.0000 - val_loss: 0.3801 - val_accuracy: 0.9792\n",
            "Epoch 1847/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8875e-10 - accuracy: 1.0000 - val_loss: 0.3806 - val_accuracy: 0.9793\n",
            "Epoch 1848/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6491e-10 - accuracy: 1.0000 - val_loss: 0.3818 - val_accuracy: 0.9791\n",
            "Epoch 1849/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4637e-10 - accuracy: 1.0000 - val_loss: 0.3821 - val_accuracy: 0.9792\n",
            "Epoch 1850/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2782e-10 - accuracy: 1.0000 - val_loss: 0.3827 - val_accuracy: 0.9792\n",
            "Epoch 1851/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6491e-10 - accuracy: 1.0000 - val_loss: 0.3839 - val_accuracy: 0.9793\n",
            "Epoch 1852/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5696e-10 - accuracy: 1.0000 - val_loss: 0.3846 - val_accuracy: 0.9791\n",
            "Epoch 1853/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5696e-10 - accuracy: 1.0000 - val_loss: 0.3849 - val_accuracy: 0.9791\n",
            "Epoch 1854/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5431e-10 - accuracy: 1.0000 - val_loss: 0.3860 - val_accuracy: 0.9793\n",
            "Epoch 1855/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5696e-10 - accuracy: 1.0000 - val_loss: 0.3870 - val_accuracy: 0.9791\n",
            "Epoch 1856/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8080e-10 - accuracy: 1.0000 - val_loss: 0.3877 - val_accuracy: 0.9789\n",
            "Epoch 1857/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7021e-10 - accuracy: 1.0000 - val_loss: 0.3881 - val_accuracy: 0.9791\n",
            "Epoch 1858/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5166e-10 - accuracy: 1.0000 - val_loss: 0.3894 - val_accuracy: 0.9790\n",
            "Epoch 1859/2000\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 2.7286e-10 - accuracy: 1.0000 - val_loss: 0.3892 - val_accuracy: 0.9791\n",
            "Epoch 1860/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6491e-10 - accuracy: 1.0000 - val_loss: 0.3905 - val_accuracy: 0.9790\n",
            "Epoch 1861/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7551e-10 - accuracy: 1.0000 - val_loss: 0.3916 - val_accuracy: 0.9790\n",
            "Epoch 1862/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5961e-10 - accuracy: 1.0000 - val_loss: 0.3919 - val_accuracy: 0.9789\n",
            "Epoch 1863/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4107e-10 - accuracy: 1.0000 - val_loss: 0.3925 - val_accuracy: 0.9791\n",
            "Epoch 1864/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3047e-10 - accuracy: 1.0000 - val_loss: 0.3938 - val_accuracy: 0.9789\n",
            "Epoch 1865/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.4901e-10 - accuracy: 1.0000 - val_loss: 0.3941 - val_accuracy: 0.9789\n",
            "Epoch 1866/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8080e-10 - accuracy: 1.0000 - val_loss: 0.3943 - val_accuracy: 0.9791\n",
            "Epoch 1867/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.8345e-10 - accuracy: 1.0000 - val_loss: 0.3953 - val_accuracy: 0.9789\n",
            "Epoch 1868/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.5961e-10 - accuracy: 1.0000 - val_loss: 0.3957 - val_accuracy: 0.9789\n",
            "Epoch 1869/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6226e-10 - accuracy: 1.0000 - val_loss: 0.3967 - val_accuracy: 0.9789\n",
            "Epoch 1870/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0581 - accuracy: 0.9956 - val_loss: 0.5676 - val_accuracy: 0.9663\n",
            "Epoch 1871/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0455 - accuracy: 0.9943 - val_loss: 0.3148 - val_accuracy: 0.9753\n",
            "Epoch 1872/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.2705 - val_accuracy: 0.9770\n",
            "Epoch 1873/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.2992e-04 - accuracy: 0.9998 - val_loss: 0.2746 - val_accuracy: 0.9780\n",
            "Epoch 1874/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.2801e-04 - accuracy: 0.9999 - val_loss: 0.2642 - val_accuracy: 0.9786\n",
            "Epoch 1875/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9678e-05 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.9793\n",
            "Epoch 1876/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3289e-04 - accuracy: 1.0000 - val_loss: 0.2585 - val_accuracy: 0.9792\n",
            "Epoch 1877/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.0857e-06 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.9793\n",
            "Epoch 1878/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.6643e-06 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.9795\n",
            "Epoch 1879/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1849e-06 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.9795\n",
            "Epoch 1880/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9310e-06 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9795\n",
            "Epoch 1881/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6971e-06 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.9796\n",
            "Epoch 1882/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.5473e-06 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9796\n",
            "Epoch 1883/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4083e-06 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9795\n",
            "Epoch 1884/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2940e-06 - accuracy: 1.0000 - val_loss: 0.2588 - val_accuracy: 0.9795\n",
            "Epoch 1885/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1759e-06 - accuracy: 1.0000 - val_loss: 0.2589 - val_accuracy: 0.9795\n",
            "Epoch 1886/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0801e-06 - accuracy: 1.0000 - val_loss: 0.2591 - val_accuracy: 0.9795\n",
            "Epoch 1887/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.9147e-07 - accuracy: 1.0000 - val_loss: 0.2593 - val_accuracy: 0.9795\n",
            "Epoch 1888/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.0972e-07 - accuracy: 1.0000 - val_loss: 0.2593 - val_accuracy: 0.9795\n",
            "Epoch 1889/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.4057e-07 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.9795\n",
            "Epoch 1890/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.7702e-07 - accuracy: 1.0000 - val_loss: 0.2596 - val_accuracy: 0.9793\n",
            "Epoch 1891/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.2132e-07 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.9791\n",
            "Epoch 1892/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.7504e-07 - accuracy: 1.0000 - val_loss: 0.2602 - val_accuracy: 0.9790\n",
            "Epoch 1893/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2602e-07 - accuracy: 1.0000 - val_loss: 0.2603 - val_accuracy: 0.9791\n",
            "Epoch 1894/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.8406e-07 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.9791\n",
            "Epoch 1895/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.4515e-07 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9790\n",
            "Epoch 1896/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.0778e-07 - accuracy: 1.0000 - val_loss: 0.2610 - val_accuracy: 0.9789\n",
            "Epoch 1897/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.7472e-07 - accuracy: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.9789\n",
            "Epoch 1898/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4265e-07 - accuracy: 1.0000 - val_loss: 0.2616 - val_accuracy: 0.9788\n",
            "Epoch 1899/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.1274e-07 - accuracy: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.9788\n",
            "Epoch 1900/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.8365e-07 - accuracy: 1.0000 - val_loss: 0.2622 - val_accuracy: 0.9787\n",
            "Epoch 1901/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.5819e-07 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9788\n",
            "Epoch 1902/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.3331e-07 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9789\n",
            "Epoch 1903/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.0726e-07 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9789\n",
            "Epoch 1904/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.8629e-07 - accuracy: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.9788\n",
            "Epoch 1905/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.6502e-07 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9789\n",
            "Epoch 1906/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.4640e-07 - accuracy: 1.0000 - val_loss: 0.2649 - val_accuracy: 0.9787\n",
            "Epoch 1907/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3025e-07 - accuracy: 1.0000 - val_loss: 0.2653 - val_accuracy: 0.9788\n",
            "Epoch 1908/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1276e-07 - accuracy: 1.0000 - val_loss: 0.2660 - val_accuracy: 0.9788\n",
            "Epoch 1909/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9887e-07 - accuracy: 1.0000 - val_loss: 0.2662 - val_accuracy: 0.9789\n",
            "Epoch 1910/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.8383e-07 - accuracy: 1.0000 - val_loss: 0.2674 - val_accuracy: 0.9788\n",
            "Epoch 1911/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.7216e-07 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.9788\n",
            "Epoch 1912/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6065e-07 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.9789\n",
            "Epoch 1913/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.4798e-07 - accuracy: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.9789\n",
            "Epoch 1914/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3773e-07 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.9789\n",
            "Epoch 1915/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2762e-07 - accuracy: 1.0000 - val_loss: 0.2704 - val_accuracy: 0.9789\n",
            "Epoch 1916/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1809e-07 - accuracy: 1.0000 - val_loss: 0.2715 - val_accuracy: 0.9790\n",
            "Epoch 1917/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0990e-07 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9789\n",
            "Epoch 1918/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0194e-07 - accuracy: 1.0000 - val_loss: 0.2731 - val_accuracy: 0.9791\n",
            "Epoch 1919/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.4190e-08 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9791\n",
            "Epoch 1920/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.7337e-08 - accuracy: 1.0000 - val_loss: 0.2750 - val_accuracy: 0.9791\n",
            "Epoch 1921/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.0606e-08 - accuracy: 1.0000 - val_loss: 0.2759 - val_accuracy: 0.9791\n",
            "Epoch 1922/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3989e-08 - accuracy: 1.0000 - val_loss: 0.2772 - val_accuracy: 0.9791\n",
            "Epoch 1923/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.8063e-08 - accuracy: 1.0000 - val_loss: 0.2782 - val_accuracy: 0.9790\n",
            "Epoch 1924/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2531e-08 - accuracy: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.9791\n",
            "Epoch 1925/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.7289e-08 - accuracy: 1.0000 - val_loss: 0.2807 - val_accuracy: 0.9789\n",
            "Epoch 1926/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.2523e-08 - accuracy: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.9789\n",
            "Epoch 1927/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.8065e-08 - accuracy: 1.0000 - val_loss: 0.2831 - val_accuracy: 0.9788\n",
            "Epoch 1928/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.4271e-08 - accuracy: 1.0000 - val_loss: 0.2841 - val_accuracy: 0.9787\n",
            "Epoch 1929/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.0875e-08 - accuracy: 1.0000 - val_loss: 0.2852 - val_accuracy: 0.9789\n",
            "Epoch 1930/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.7712e-08 - accuracy: 1.0000 - val_loss: 0.2861 - val_accuracy: 0.9789\n",
            "Epoch 1931/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.4719e-08 - accuracy: 1.0000 - val_loss: 0.2872 - val_accuracy: 0.9789\n",
            "Epoch 1932/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.2107e-08 - accuracy: 1.0000 - val_loss: 0.2883 - val_accuracy: 0.9789\n",
            "Epoch 1933/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9688e-08 - accuracy: 1.0000 - val_loss: 0.2893 - val_accuracy: 0.9788\n",
            "Epoch 1934/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7389e-08 - accuracy: 1.0000 - val_loss: 0.2904 - val_accuracy: 0.9789\n",
            "Epoch 1935/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5198e-08 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9788\n",
            "Epoch 1936/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.3259e-08 - accuracy: 1.0000 - val_loss: 0.2925 - val_accuracy: 0.9789\n",
            "Epoch 1937/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.1460e-08 - accuracy: 1.0000 - val_loss: 0.2935 - val_accuracy: 0.9789\n",
            "Epoch 1938/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.9911e-08 - accuracy: 1.0000 - val_loss: 0.2945 - val_accuracy: 0.9789\n",
            "Epoch 1939/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8263e-08 - accuracy: 1.0000 - val_loss: 0.2955 - val_accuracy: 0.9789\n",
            "Epoch 1940/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.6983e-08 - accuracy: 1.0000 - val_loss: 0.2964 - val_accuracy: 0.9789\n",
            "Epoch 1941/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5765e-08 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.9790\n",
            "Epoch 1942/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4578e-08 - accuracy: 1.0000 - val_loss: 0.2980 - val_accuracy: 0.9790\n",
            "Epoch 1943/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.3563e-08 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.9790\n",
            "Epoch 1944/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.2599e-08 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 0.9791\n",
            "Epoch 1945/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.1696e-08 - accuracy: 1.0000 - val_loss: 0.3006 - val_accuracy: 0.9791\n",
            "Epoch 1946/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0829e-08 - accuracy: 1.0000 - val_loss: 0.3014 - val_accuracy: 0.9791\n",
            "Epoch 1947/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.0082e-08 - accuracy: 1.0000 - val_loss: 0.3022 - val_accuracy: 0.9790\n",
            "Epoch 1948/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 9.4069e-09 - accuracy: 1.0000 - val_loss: 0.3030 - val_accuracy: 0.9790\n",
            "Epoch 1949/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.7606e-09 - accuracy: 1.0000 - val_loss: 0.3038 - val_accuracy: 0.9789\n",
            "Epoch 1950/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.1857e-09 - accuracy: 1.0000 - val_loss: 0.3045 - val_accuracy: 0.9789\n",
            "Epoch 1951/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.6479e-09 - accuracy: 1.0000 - val_loss: 0.3051 - val_accuracy: 0.9788\n",
            "Epoch 1952/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 7.1737e-09 - accuracy: 1.0000 - val_loss: 0.3058 - val_accuracy: 0.9789\n",
            "Epoch 1953/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.6572e-09 - accuracy: 1.0000 - val_loss: 0.3065 - val_accuracy: 0.9788\n",
            "Epoch 1954/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.2625e-09 - accuracy: 1.0000 - val_loss: 0.3071 - val_accuracy: 0.9788\n",
            "Epoch 1955/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.8545e-09 - accuracy: 1.0000 - val_loss: 0.3078 - val_accuracy: 0.9788\n",
            "Epoch 1956/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.4757e-09 - accuracy: 1.0000 - val_loss: 0.3085 - val_accuracy: 0.9789\n",
            "Epoch 1957/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.1313e-09 - accuracy: 1.0000 - val_loss: 0.3091 - val_accuracy: 0.9789\n",
            "Epoch 1958/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.8372e-09 - accuracy: 1.0000 - val_loss: 0.3097 - val_accuracy: 0.9789\n",
            "Epoch 1959/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5167e-09 - accuracy: 1.0000 - val_loss: 0.3103 - val_accuracy: 0.9789\n",
            "Epoch 1960/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.2571e-09 - accuracy: 1.0000 - val_loss: 0.3108 - val_accuracy: 0.9790\n",
            "Epoch 1961/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.9842e-09 - accuracy: 1.0000 - val_loss: 0.3114 - val_accuracy: 0.9790\n",
            "Epoch 1962/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.7352e-09 - accuracy: 1.0000 - val_loss: 0.3120 - val_accuracy: 0.9789\n",
            "Epoch 1963/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 3.5312e-09 - accuracy: 1.0000 - val_loss: 0.3125 - val_accuracy: 0.9789\n",
            "Epoch 1964/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.2981e-09 - accuracy: 1.0000 - val_loss: 0.3131 - val_accuracy: 0.9789\n",
            "Epoch 1965/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.0862e-09 - accuracy: 1.0000 - val_loss: 0.3136 - val_accuracy: 0.9790\n",
            "Epoch 1966/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.9034e-09 - accuracy: 1.0000 - val_loss: 0.3142 - val_accuracy: 0.9790\n",
            "Epoch 1967/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.7233e-09 - accuracy: 1.0000 - val_loss: 0.3147 - val_accuracy: 0.9791\n",
            "Epoch 1968/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.5325e-09 - accuracy: 1.0000 - val_loss: 0.3154 - val_accuracy: 0.9791\n",
            "Epoch 1969/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.3683e-09 - accuracy: 1.0000 - val_loss: 0.3160 - val_accuracy: 0.9791\n",
            "Epoch 1970/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 2.2226e-09 - accuracy: 1.0000 - val_loss: 0.3166 - val_accuracy: 0.9791\n",
            "Epoch 1971/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 2.0689e-09 - accuracy: 1.0000 - val_loss: 0.3173 - val_accuracy: 0.9791\n",
            "Epoch 1972/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.9683e-09 - accuracy: 1.0000 - val_loss: 0.3180 - val_accuracy: 0.9791\n",
            "Epoch 1973/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.8544e-09 - accuracy: 1.0000 - val_loss: 0.3186 - val_accuracy: 0.9790\n",
            "Epoch 1974/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.7272e-09 - accuracy: 1.0000 - val_loss: 0.3193 - val_accuracy: 0.9790\n",
            "Epoch 1975/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.6292e-09 - accuracy: 1.0000 - val_loss: 0.3199 - val_accuracy: 0.9790\n",
            "Epoch 1976/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.5365e-09 - accuracy: 1.0000 - val_loss: 0.3206 - val_accuracy: 0.9790\n",
            "Epoch 1977/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.4623e-09 - accuracy: 1.0000 - val_loss: 0.3212 - val_accuracy: 0.9790\n",
            "Epoch 1978/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.3722e-09 - accuracy: 1.0000 - val_loss: 0.3218 - val_accuracy: 0.9790\n",
            "Epoch 1979/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2954e-09 - accuracy: 1.0000 - val_loss: 0.3224 - val_accuracy: 0.9790\n",
            "Epoch 1980/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.2080e-09 - accuracy: 1.0000 - val_loss: 0.3230 - val_accuracy: 0.9789\n",
            "Epoch 1981/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1.1471e-09 - accuracy: 1.0000 - val_loss: 0.3237 - val_accuracy: 0.9790\n",
            "Epoch 1982/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0676e-09 - accuracy: 1.0000 - val_loss: 0.3243 - val_accuracy: 0.9790\n",
            "Epoch 1983/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 1.0093e-09 - accuracy: 1.0000 - val_loss: 0.3249 - val_accuracy: 0.9790\n",
            "Epoch 1984/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 9.5103e-10 - accuracy: 1.0000 - val_loss: 0.3256 - val_accuracy: 0.9790\n",
            "Epoch 1985/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 8.9804e-10 - accuracy: 1.0000 - val_loss: 0.3263 - val_accuracy: 0.9790\n",
            "Epoch 1986/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 8.6096e-10 - accuracy: 1.0000 - val_loss: 0.3270 - val_accuracy: 0.9790\n",
            "Epoch 1987/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8413e-10 - accuracy: 1.0000 - val_loss: 0.3278 - val_accuracy: 0.9789\n",
            "Epoch 1988/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.8413e-10 - accuracy: 1.0000 - val_loss: 0.3284 - val_accuracy: 0.9789\n",
            "Epoch 1989/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 7.3115e-10 - accuracy: 1.0000 - val_loss: 0.3291 - val_accuracy: 0.9789\n",
            "Epoch 1990/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.8347e-10 - accuracy: 1.0000 - val_loss: 0.3299 - val_accuracy: 0.9789\n",
            "Epoch 1991/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 6.5433e-10 - accuracy: 1.0000 - val_loss: 0.3306 - val_accuracy: 0.9789\n",
            "Epoch 1992/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 6.1194e-10 - accuracy: 1.0000 - val_loss: 0.3314 - val_accuracy: 0.9790\n",
            "Epoch 1993/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 5.6691e-10 - accuracy: 1.0000 - val_loss: 0.3322 - val_accuracy: 0.9790\n",
            "Epoch 1994/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.1657e-10 - accuracy: 1.0000 - val_loss: 0.3331 - val_accuracy: 0.9790\n",
            "Epoch 1995/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 5.0863e-10 - accuracy: 1.0000 - val_loss: 0.3340 - val_accuracy: 0.9789\n",
            "Epoch 1996/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.9538e-10 - accuracy: 1.0000 - val_loss: 0.3348 - val_accuracy: 0.9790\n",
            "Epoch 1997/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.5829e-10 - accuracy: 1.0000 - val_loss: 0.3356 - val_accuracy: 0.9790\n",
            "Epoch 1998/2000\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 4.4770e-10 - accuracy: 1.0000 - val_loss: 0.3365 - val_accuracy: 0.9790\n",
            "Epoch 1999/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 4.0001e-10 - accuracy: 1.0000 - val_loss: 0.3374 - val_accuracy: 0.9789\n",
            "Epoch 2000/2000\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 3.8677e-10 - accuracy: 1.0000 - val_loss: 0.3385 - val_accuracy: 0.9791\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0846 - accuracy: 0.9948\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2585 - accuracy: 0.9842\n",
            "train accuracy :  0.9947666525840759 train loss :  0.08461669832468033\n",
            "test accuracy :  0.9842000007629395  test loss :  0.25848591327667236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCAlKST3P3zu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ff36db4-daab-4736-c5ea-9f86ada8ee6d"
      },
      "source": [
        "#정리\n",
        "print(\"=========== total evaluatation ===========\")\n",
        "print(\"\")\n",
        "\n",
        "print(\"########### initializer option = default ###########\")\n",
        "print(\"\")\n",
        "\n",
        "print(\"=========== [은닉층 2개] ===========\")\n",
        "print(\"=========== epochs = 12 ===========\")\n",
        "print(\"train accuracy : \", sc_train2_1[1], \"train loss : \", sc_train2_1[0])\n",
        "print(\"test accuracy : \", sc_test2_1[1], \" test loss : \", sc_test2_1[0])\n",
        "print(\"\")\n",
        "\n",
        "print(\"=========== epochs = 120 ===========\")\n",
        "print(\"train accuracy : \", sc_train2_1_2[1], \"train loss : \", sc_train2_1_2[0])\n",
        "print(\"test accuracy : \", sc_test2_1_2[1], \" test loss : \", sc_test2_1_2[0])\n",
        "print(\"\")\n",
        "\n",
        "print(\"=========== epochs = 1000 ===========\")\n",
        "print(\"train accuracy : \", sc_train2_1_4[1], \"train loss : \", sc_train2_1_4[0])\n",
        "print(\"test accuracy : \", sc_test2_1_4[1], \" test loss : \", sc_test2_1_4[0])\n",
        "print(\"\")\n",
        "\n",
        "print(\"=========== epochs = 2000 ===========\")\n",
        "print(\"train accuracy : \", sc_train2_1_5[1], \"train loss : \", sc_train2_1_5[0])\n",
        "print(\"test accuracy : \", sc_test2_1_5[1], \" test loss : \", sc_test2_1_5[0])\n",
        "print(\"\")\n",
        "print(\"########### initializer option = HeNormal() ###########\")\n",
        "print(\"\")\n",
        "\n",
        "print(\"=========== [은닉층 2개 & 512/512]==+=========\")\n",
        "print(\"=========== epochs = 12 ===========\")\n",
        "print(\"train accuracy : \", sc_train3_1[1], \"train loss : \", sc_train3_1[0])\n",
        "print(\"test accuracy : \", sc_test3_1[1], \" test loss : \", sc_test3_1[0])\n",
        "print(\"\")\n",
        "\n",
        "print(\"=========== epochs = 120 ===========\")\n",
        "print(\"train accuracy : \", sc_train3_2[1], \"train loss : \", sc_train3_2[0])\n",
        "print(\"test accuracy : \", sc_test3_2[1], \" test loss : \", sc_test3_2[0])\n",
        "print(\"\")\n",
        "\n",
        "print(\"=========== epochs = 1000 ===========\")\n",
        "print(\"train accuracy : \", sc_train3_3[1], \"train loss : \", sc_train3_3[0])\n",
        "print(\"test accuracy : \", sc_test3_3[1], \" test loss : \", sc_test3_3[0])\n",
        "print(\"\")\n",
        "\n",
        "print(\"=========== epochs = 2000 ===========\")\n",
        "print(\"train accuracy : \", sc_train3_4[1], \"train loss : \", sc_train3_4[0])\n",
        "print(\"test accuracy : \", sc_test3_4[1], \" test loss : \", sc_test3_4[0])\n",
        "print(\"\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========== total evaluatation ===========\n",
            "\n",
            "########### initializer option = default ###########\n",
            "\n",
            "=========== [은닉층 2개] ===========\n",
            "=========== epochs = 12 ===========\n",
            "train accuracy :  0.9912999868392944 train loss :  0.034651078283786774\n",
            "test accuracy :  0.9800999760627747  test loss :  0.08432424813508987\n",
            "\n",
            "=========== epochs = 120 ===========\n",
            "train accuracy :  0.9954833388328552 train loss :  0.04640447348356247\n",
            "test accuracy :  0.9842000007629395  test loss :  0.14507167041301727\n",
            "\n",
            "=========== epochs = 1000 ===========\n",
            "train accuracy :  0.9952499866485596 train loss :  0.08460886776447296\n",
            "test accuracy :  0.982200026512146  test loss :  0.2703184485435486\n",
            "\n",
            "=========== epochs = 2000 ===========\n",
            "train accuracy :  0.9950833320617676 train loss :  0.06054401770234108\n",
            "test accuracy :  0.9828000068664551  test loss :  0.18144270777702332\n",
            "\n",
            "########### initializer option = HeNormal() ###########\n",
            "\n",
            "=========== [은닉층 2개 & 512/512]==+=========\n",
            "=========== epochs = 12 ===========\n",
            "train accuracy :  0.9879666566848755 train loss :  0.04692676663398743\n",
            "test accuracy :  0.9729999899864197  test loss :  0.10215163230895996\n",
            "\n",
            "=========== epochs = 120 ===========\n",
            "train accuracy :  0.9955666661262512 train loss :  0.04253648966550827\n",
            "test accuracy :  0.9830999970436096  test loss :  0.14426426589488983\n",
            "\n",
            "=========== epochs = 1000 ===========\n",
            "train accuracy :  0.9948166608810425 train loss :  0.07356633991003036\n",
            "test accuracy :  0.9814000129699707  test loss :  0.22297894954681396\n",
            "\n",
            "=========== epochs = 2000 ===========\n",
            "train accuracy :  0.9947666525840759 train loss :  0.08461669832468033\n",
            "test accuracy :  0.9842000007629395  test loss :  0.25848591327667236\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rt456pdDFty"
      },
      "source": [
        "test 정확도로 봤을 때 he 초기값을 적용한 모델은 epochs = 2000회를 적용했을 때 테스트 셋의 정확도가 98.42%로 he 초기값을 적용하지 않은 모델은 epochs = 2000회 적용 했을 때 결과보다 좋다. 하지만 epochs = 120일때는 he 초기값을 적용하지 않은 모델의 테스트셋의 정확도가 98.42로 he 초기값을 적용했을 때 보다 결과가 좋다\n",
        "신경망은 같은 결과라면 단순한 모형이 더 좋은 모형이므로 은닉층이 2개이고, 각 은닉층별 뉴런의 수는 각각 512, 512, epoch = 120일때 가장 결과가 좋은 모형이다."
      ]
    }
  ]
}