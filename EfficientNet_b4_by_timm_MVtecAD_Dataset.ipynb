{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNet_MVtecAD_Dataset",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seunghee0518/AI_python/blob/main/EfficientNet_b4_by_timm_MVtecAD_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## trina/ test 나눠서 학습"
      ],
      "metadata": {
        "id": "lynhGDxilbRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "torch.hub : Pytorch Hub는 연구 재현성을 촉진하도록 설계된 사전 훈련 된 모델 저장소\n",
        "nvidia_efficientnet_b4 사전 모델 가져옴\n",
        "'''\n",
        "# import torch\n",
        "# model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b4', pretrained=True)\n",
        "!pip install timm\n",
        "import timm\n",
        "model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=88)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ-ytfDpoKMH",
        "outputId": "7a78fcb7-85cc-419c-9ec7-c3d9d772eb30"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 46.1 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 46.8 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 48.6 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 30.7 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 51 kB 34.2 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 61 kB 38.4 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 27.9 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 29.8 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 102 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 112 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 122 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 153 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 163 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 174 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 184 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 194 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 204 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 215 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 225 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 235 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 245 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 256 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 266 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 276 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 286 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 307 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 317 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 327 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 348 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 358 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 368 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 378 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 389 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 399 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 409 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 419 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 430 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 431 kB 31.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.12.0+cu113)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.5.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b4_ra2_320-7eb33cd5.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b4_ra2_320-7eb33cd5.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from pprint import pprint\n",
        "# model_names = timm.list_models(pretrained=True)\n",
        "# pprint(model_names)"
      ],
      "metadata": {
        "id": "invECZxkPTyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKXv22Yk6zus",
        "outputId": "69833f2b-662f-4ed6-cd99-344b6aac1547"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 학습 코드\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "#import timm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import transforms, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "from PIL import Image\n",
        "# from efficientnet_pytorch import EfficientNet\n",
        "# model_name = 'efficientnet-b0'  # b5\n",
        "\n",
        "# image_size = EfficientNet.get_image_size(model_name)\n",
        "# print(image_size)\n",
        "# model = EfficientNet.from_pretrained(model_name, num_classes=88)"
      ],
      "metadata": {
        "id": "Gjs-R_R5lUKg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 기본 설정\n",
        "device = torch.device('cuda')\n",
        "batch_size  = 32\n",
        "random_seed = 1234\n",
        "img_size = 224\n",
        "random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZHMCtAvlDOp",
        "outputId": "e456c7b8-afa8-4636-f2ae-a2f6858e338a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fbe88d90e50>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## transforms 함수 정리\n",
        "* transforms.ToPILImage() - csv 파일로 데이터셋을 받을 경우, PIL image로 바꿔준다.\n",
        "* transforms.CenterCrop(size) - 가운데 부분을 size 크기로 자른다.\n",
        "* transforms.Grayscale(num_output_channels=1) - grayscale로 변환한다.\n",
        "* transforms.RandomAffine(degrees) - 랜덤으로 affine 변형을 한다.\n",
        "* transforms.RandomCrop(size) -이미지를 랜덤으로 아무데나 잘라 size 크기로 출력한다.\n",
        "* transforms.RandomResizedCrop(size) - 이미지 사이즈를 size로 변경한다\n",
        "* transforms.Resize(size) - 이미지 사이즈를 size로 변경한다\n",
        "* transforms.RandomRotation(degrees) 이미지를 랜덤으로 degrees 각도로 회전한다.\n",
        "* transforms.RandomResizedCrop(size, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333)) - 이미지를 랜덤으로 변형한다.\n",
        "* transforms.RandomVerticalFlip(p=0.5) - 이미지를 랜덤으로 수직으로 뒤집는다. p =0이면 뒤집지 않는다.\n",
        "* transforms.RandomHorizontalFlip(p=0.5) - 이미지를 랜덤으로 수평으로 뒤집는다.\n",
        "* transforms.ToTensor() - 이미지 데이터를 tensor로 바꿔준다.\n",
        "* transforms.Normalize(mean, std, inplace=False) - 이미지를 정규화한다."
      ],
      "metadata": {
        "id": "fTgH3bYzN7RA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 데이터 전처리 함수\n",
        "# make dataset\n",
        "#data_path = 'president/president_data'  # class 별 폴더로 나누어진 걸 가져와서 라벨도 달아준다\n",
        "# train_dataset = datasets.ImageFolder(data_path,\n",
        "#                                      transforms.Compose([\n",
        "#                                      transforms.Resize((224, 224)),\n",
        "#                                      transforms.RandomCrop(224),\n",
        "#                                      transforms.RandomRotation(90, expand=True),\n",
        "#                                      transforms.RandomVerticalFlip(),\n",
        "#                                      transforms.RandomHorizontalFlip(),\n",
        "#                                      transforms.ToTensor(), # 이미지 데이터를 tensor로 바꿔준다.\n",
        "#                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])) # Normalize는 많은 이미지의 평균, 표준편차로 정함(보통 많이 하는 값이라고함)\n",
        "\n",
        "\n",
        "### 이미지 전처리 함수 & 클래스\n",
        "## 이미지  > 넘파이 배열로 변환\n",
        "def img_load(path):\n",
        "    img = cv2.imread(path)[:,:,::-1] # Return type:\tnumpy.ndarray / 기본적으로 BGR로 불러옴, RGB 변환함\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    return img\n",
        "\n",
        "class Custom_dataset_1(Dataset): # 기본\n",
        "    def __init__(self, img_paths, labels, mode='train'):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode = mode\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.img_paths[idx]\n",
        "        img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "        img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "        ## 레이블 > 원-핫 인코딩 하기 \n",
        "        label = self.labels[idx]# (원핫인코딩 안할거면 해당 코드만 필요)\n",
        "        return img, label\n",
        "\n",
        "class Custom_dataset_2(Dataset): # 변형\n",
        "    def __init__(self, img_paths, labels, mode='train'):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode = mode\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.img_paths[idx]\n",
        "        if self.mode == 'train':\n",
        "          img = Image.fromarray(img)\n",
        "          #img = transforms.Resize((img_size, img_size))(img) # 처음 이미지 불러올때 resize 했으므로 생략\n",
        "          #img = transforms.RandomCrop(img_size)(img)\n",
        "          img = transforms.RandomRotation(90, expand=False)(img)\n",
        "          img = transforms.RandomVerticalFlip()(img)\n",
        "          img = transforms.RandomHorizontalFlip()(img)\n",
        "          img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "          img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "        if self.mode=='test':\n",
        "          img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "        ## 레이블\n",
        "        label = self.labels[idx]# (원핫인코딩 안할거면 해당 코드만 필요)\n",
        "        return img, label\n",
        "\n",
        "class Custom_dataset_3(Dataset): # 기본이미지 + 변형이미지 (train 시 2배 증량됨)\n",
        "    def __init__(self, img_paths, labels, mode='train'):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode=mode\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.mode=='train':\n",
        "          if idx < 4277: # 변경 없는 이미지\n",
        "            img = self.img_paths[idx]\n",
        "            img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "            img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "            label = self.labels[idx]\n",
        "            return img, label\n",
        "\n",
        "          else : # 랜덤 변경된 이미지 추가됨 \n",
        "            img = self.img_paths[idx]\n",
        "            img = Image.fromarray(img)\n",
        "            #img = transforms.Resize((img_size, img_size))(img) # 처음 이미지 불러올때 resize 했으므로 생략\n",
        "            #img = transforms.RandomCrop(img_size)(img)\n",
        "            img = transforms.RandomRotation(90, expand=False)(img)\n",
        "            img = transforms.RandomVerticalFlip()(img)\n",
        "            img = transforms.RandomHorizontalFlip()(img)\n",
        "            img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "            img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "            label = self.labels[idx]\n",
        "            return img, label\n",
        "\n",
        "        if self.mode=='test':\n",
        "          img = self.img_paths[idx]\n",
        "          img = transforms.ToTensor()(img)\n",
        "          img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "          label = self.labels[idx]\n",
        "          return img, label\n",
        "            "
      ],
      "metadata": {
        "id": "ORqFbwLXpSeu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 이미지 로드 및 전처리\n",
        "# 이미지 경로\n",
        "train_png = sorted(glob('/content/drive/Othercomputers/내 MacBook Pro/open/train/*.png'))\n",
        "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
        "\n",
        "#train_imgs = np.load('/content/drive/MyDrive/DACON_이상치 탐지 알고리즘 경진대회/train_imgs_224.npy')\n",
        "train_y = pd.read_csv(\"/content/drive/Othercomputers/내 MacBook Pro/open/train_df.csv\")\n",
        "\n",
        "train_labels = train_y[\"label\"] # 레이블순서는 이미지 파일 순서대로임\n",
        "\n",
        "label_unique = sorted(np.unique(train_labels))\n",
        "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))} # 오름차순으로 레이블별로 숫자 부여(0부터 시작)\n",
        "\n",
        "train_labels = [label_unique[k] for k in train_labels]\n",
        "train_dataset = Custom_dataset_1(np.array(train_imgs), np.array(train_labels), mode='train')\n",
        "train_idx, vaild_idx = train_test_split(list(range(len(train_dataset))), stratify=train_labels, test_size=0.3, random_state=random_seed)\n",
        "\n",
        "# ## 이미지 증량 시만 사용\n",
        "# train_imgs = train_imgs + train_imgs\n",
        "# train_labels = train_labels+train_labels\n",
        "\n",
        "# train_dataset = Custom_dataset_3(np.array(train_imgs), np.array(train_labels), mode='train')\n",
        "\n",
        "# ### 데이터셋 분리 > 층화추출 & 테스터 데이터 비율 : 0.3, 시드 : 1234, 셔플 = True(default)\n",
        "# train_idx, vaild_idx = train_test_split(list(range(len(train_dataset))), stratify=train_labels, test_size=0.3, random_state=random_seed)\n",
        "\n",
        "datasets = {} # 데이터셋을 담을 딕셔너리\n",
        "datasets['train'] = Subset(train_dataset, train_idx)\n",
        "datasets['vaild']  = Subset(train_dataset, vaild_idx)\n",
        "\n",
        "## data loader 선언\n",
        "dataloaders, batch_num = {}, {}\n",
        "dataloaders['train'] = torch.utils.data.DataLoader(datasets['train'],\n",
        "                                                  batch_size=batch_size, shuffle=True,\n",
        "                                                  num_workers=0)\n",
        "dataloaders['vaild']  = torch.utils.data.DataLoader(datasets['vaild'],\n",
        "                                                    batch_size=batch_size, shuffle=False,\n",
        "                                                    num_workers=0)\n",
        "'''\n",
        "데이터 변형 코드를 추가한 후 아래 오류코드가 나와\n",
        "Caught TypeError in DataLoader worker process 0\n",
        "DataLoader > num_workers 를 4 -> 0 로 낮춤\n",
        "'''\n",
        "\n",
        "batch_num['train'], batch_num['vaild'] = len(dataloaders['train']), len(dataloaders['vaild'])\n",
        "print('batch_size : %d,  train/vaild(데이터셋개수/배치사이즈) : %d / %d' % (batch_size, batch_num['train'],batch_num['vaild']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItvLP1Y3k-OW",
        "outputId": "af612781-9996-473e-df15-ec13bdf2e0ae"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4277/4277 [06:38<00:00, 10.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_size : 32,  train/vaild(데이터셋개수/배치사이즈) : 94 / 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 참고 블로그 : https://keep-steady.tistory.com/35\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "### f1 스코어 함수 \n",
        "def score_function(real, pred): # 라이브러리 > sklearn.metrics \n",
        "    score = f1_score(real, pred, average=\"macro\")\n",
        "    return score\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    #train_loss, train_acc, valid_loss, valid_acc = [], [], [], []\n",
        "    train_loss, train_acc, valid_loss, valid_acc, train_f1, valid_f1 = [], [], [], [], [], []\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))# - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'vaild']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
        "            \n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device) # device = torch.device('cuda')\n",
        "                labels = labels.to(device) # device = torch.device('cuda')\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                num_cnt += len(labels)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "            \n",
        "            epoch_loss = float(running_loss / num_cnt)\n",
        "            epoch_acc  = float((running_corrects.double() / num_cnt).cpu()*100)\n",
        "            f1 = score_function(labels.cpu().data, preds.cpu()) # score_function or f1_score\n",
        "\n",
        "            if phase == 'train':\n",
        "                train_loss.append(epoch_loss)\n",
        "                train_acc.append(epoch_acc)\n",
        "                train_f1.append(f1)\n",
        "            else:\n",
        "                valid_loss.append(epoch_loss)\n",
        "                valid_acc.append(epoch_acc)\n",
        "                valid_f1.append(f1)\n",
        "\n",
        "            print('{} Loss: {:.5f} Acc: {:.5f} macro-f1: {:.5f}'.format(phase, epoch_loss, epoch_acc, f1))\n",
        "           \n",
        "            # deep copy the model(최적모델 저장)\n",
        "            if phase == 'vaild' and epoch_acc > best_acc:\n",
        "                best_idx = epoch\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "#                 best_model_wts = copy.deepcopy(model.module.state_dict())\n",
        "                print('==> best model saved - %d / %.1f'%(best_idx, best_acc))\n",
        "        # 한 에포크마다 실행 시간 출력하기(누적 시간으로 출력됨)\n",
        "        time_elapsed = time.time() - since\n",
        "        print('each epochs training time : {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "        print('\\n')\n",
        "\n",
        "        # 한 에포크마다 필요없는 메모리 지우기 : 지우기 효과는 아직 확인 못해봄\n",
        "        try:      \n",
        "          gc.collect() # cpu 비움\n",
        "          torch.cuda.empty_cache() # gpu 비움\n",
        "        except:\n",
        "          pass\n",
        "          \n",
        "    ## 학습 마무리 후\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best valid Acc: %d - %.1f' %(best_idx, best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    '''\n",
        "    한 에포크 마다 저장된 최적의 모델 가중치로 조정 후 다음 에포크가 돌아감\n",
        "    '''\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    torch.save(model.state_dict(), 'president_model.pt')\n",
        "    print('model saved')\n",
        "    return model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc, train_f1, valid_f1\n",
        "\n",
        "# 설정\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # set gpu\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_ft = optim.SGD(model.parameters(), \n",
        "                         lr = 0.05,\n",
        "                         momentum=0.9,\n",
        "                         weight_decay=1e-4)\n",
        "\n",
        "lmbda = lambda epoch: 0.98739\n",
        "exp_lr_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer_ft, lr_lambda=lmbda)\n",
        "\n",
        "# 사전학습된 가중치와 모델을 가져와 데이터셋으로 추가 모델 학습\n",
        "model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc, train_f1, valid_f1 = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDNj4Yarkx-R",
        "outputId": "eac367c0-5147-4995-daa5-bc73dd5bc15a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/100\n",
            "----------\n",
            "train Loss: 1.30392 Acc: 80.35416 macro-f1: 0.73810\n",
            "vaild Loss: 0.70335 Acc: 85.35826 macro-f1: 1.00000\n",
            "==> best model saved - 0 / 85.4\n",
            "each epochs training time : 0m 47s\n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "----------\n",
            "train Loss: 0.55954 Acc: 86.26796 macro-f1: 0.87879\n",
            "vaild Loss: 0.52692 Acc: 86.76012 macro-f1: 1.00000\n",
            "==> best model saved - 1 / 86.8\n",
            "each epochs training time : 1m 35s\n",
            "\n",
            "\n",
            "Epoch 2/100\n",
            "----------\n",
            "train Loss: 0.38391 Acc: 89.87638 macro-f1: 0.70588\n",
            "vaild Loss: 0.40612 Acc: 89.48598 macro-f1: 1.00000\n",
            "==> best model saved - 2 / 89.5\n",
            "each epochs training time : 2m 24s\n",
            "\n",
            "\n",
            "Epoch 3/100\n",
            "----------\n",
            "train Loss: 0.26642 Acc: 92.14835 macro-f1: 0.67619\n",
            "vaild Loss: 0.37226 Acc: 89.95327 macro-f1: 1.00000\n",
            "==> best model saved - 3 / 90.0\n",
            "each epochs training time : 3m 14s\n",
            "\n",
            "\n",
            "Epoch 4/100\n",
            "----------\n",
            "train Loss: 0.17658 Acc: 94.75443 macro-f1: 1.00000\n",
            "vaild Loss: 0.35663 Acc: 89.71963 macro-f1: 1.00000\n",
            "each epochs training time : 4m 4s\n",
            "\n",
            "\n",
            "Epoch 5/100\n",
            "----------\n",
            "train Loss: 0.12126 Acc: 96.49181 macro-f1: 1.00000\n",
            "vaild Loss: 0.27996 Acc: 91.82243 macro-f1: 1.00000\n",
            "==> best model saved - 5 / 91.8\n",
            "each epochs training time : 4m 55s\n",
            "\n",
            "\n",
            "Epoch 6/100\n",
            "----------\n",
            "train Loss: 0.07037 Acc: 97.86168 macro-f1: 1.00000\n",
            "vaild Loss: 0.25119 Acc: 92.05607 macro-f1: 1.00000\n",
            "==> best model saved - 6 / 92.1\n",
            "each epochs training time : 5m 45s\n",
            "\n",
            "\n",
            "Epoch 7/100\n",
            "----------\n",
            "train Loss: 0.05615 Acc: 98.39626 macro-f1: 1.00000\n",
            "vaild Loss: 0.27703 Acc: 92.13396 macro-f1: 1.00000\n",
            "==> best model saved - 7 / 92.1\n",
            "each epochs training time : 6m 36s\n",
            "\n",
            "\n",
            "Epoch 8/100\n",
            "----------\n",
            "train Loss: 0.04176 Acc: 98.93084 macro-f1: 0.84615\n",
            "vaild Loss: 0.25656 Acc: 93.61371 macro-f1: 1.00000\n",
            "==> best model saved - 8 / 93.6\n",
            "each epochs training time : 7m 27s\n",
            "\n",
            "\n",
            "Epoch 9/100\n",
            "----------\n",
            "train Loss: 0.03201 Acc: 99.19813 macro-f1: 1.00000\n",
            "vaild Loss: 0.25687 Acc: 93.06854 macro-f1: 1.00000\n",
            "each epochs training time : 8m 18s\n",
            "\n",
            "\n",
            "Epoch 10/100\n",
            "----------\n",
            "train Loss: 0.02558 Acc: 99.43201 macro-f1: 0.70909\n",
            "vaild Loss: 0.29813 Acc: 91.74455 macro-f1: 1.00000\n",
            "each epochs training time : 9m 9s\n",
            "\n",
            "\n",
            "Epoch 11/100\n",
            "----------\n",
            "train Loss: 0.03756 Acc: 98.99766 macro-f1: 0.84615\n",
            "vaild Loss: 0.25148 Acc: 93.38006 macro-f1: 1.00000\n",
            "each epochs training time : 10m 0s\n",
            "\n",
            "\n",
            "Epoch 12/100\n",
            "----------\n",
            "train Loss: 0.02176 Acc: 99.33177 macro-f1: 0.86667\n",
            "vaild Loss: 0.24441 Acc: 93.84735 macro-f1: 1.00000\n",
            "==> best model saved - 12 / 93.8\n",
            "each epochs training time : 10m 51s\n",
            "\n",
            "\n",
            "Epoch 13/100\n",
            "----------\n",
            "train Loss: 0.00870 Acc: 99.83294 macro-f1: 1.00000\n",
            "vaild Loss: 0.26657 Acc: 93.30218 macro-f1: 1.00000\n",
            "each epochs training time : 11m 42s\n",
            "\n",
            "\n",
            "Epoch 14/100\n",
            "----------\n",
            "train Loss: 0.00663 Acc: 99.83294 macro-f1: 1.00000\n",
            "vaild Loss: 0.25952 Acc: 93.53583 macro-f1: 1.00000\n",
            "each epochs training time : 12m 33s\n",
            "\n",
            "\n",
            "Epoch 15/100\n",
            "----------\n",
            "train Loss: 0.01308 Acc: 99.63248 macro-f1: 1.00000\n",
            "vaild Loss: 0.28118 Acc: 93.38006 macro-f1: 1.00000\n",
            "each epochs training time : 13m 24s\n",
            "\n",
            "\n",
            "Epoch 16/100\n",
            "----------\n",
            "train Loss: 0.00921 Acc: 99.66589 macro-f1: 0.85714\n",
            "vaild Loss: 0.26313 Acc: 93.53583 macro-f1: 1.00000\n",
            "each epochs training time : 14m 15s\n",
            "\n",
            "\n",
            "Epoch 17/100\n",
            "----------\n",
            "train Loss: 0.00515 Acc: 99.93318 macro-f1: 1.00000\n",
            "vaild Loss: 0.29613 Acc: 93.53583 macro-f1: 1.00000\n",
            "each epochs training time : 15m 6s\n",
            "\n",
            "\n",
            "Epoch 18/100\n",
            "----------\n",
            "train Loss: 0.00599 Acc: 99.79953 macro-f1: 1.00000\n",
            "vaild Loss: 0.27763 Acc: 93.76947 macro-f1: 1.00000\n",
            "each epochs training time : 15m 57s\n",
            "\n",
            "\n",
            "Epoch 19/100\n",
            "----------\n",
            "train Loss: 0.00792 Acc: 99.76612 macro-f1: 1.00000\n",
            "vaild Loss: 0.31162 Acc: 93.69159 macro-f1: 1.00000\n",
            "each epochs training time : 16m 48s\n",
            "\n",
            "\n",
            "Epoch 20/100\n",
            "----------\n",
            "train Loss: 0.00403 Acc: 99.93318 macro-f1: 1.00000\n",
            "vaild Loss: 0.25898 Acc: 93.92523 macro-f1: 1.00000\n",
            "==> best model saved - 20 / 93.9\n",
            "each epochs training time : 17m 39s\n",
            "\n",
            "\n",
            "Epoch 21/100\n",
            "----------\n",
            "train Loss: 0.00144 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.27536 Acc: 94.23676 macro-f1: 1.00000\n",
            "==> best model saved - 21 / 94.2\n",
            "each epochs training time : 18m 30s\n",
            "\n",
            "\n",
            "Epoch 22/100\n",
            "----------\n",
            "train Loss: 0.00131 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.27680 Acc: 94.08100 macro-f1: 1.00000\n",
            "each epochs training time : 19m 21s\n",
            "\n",
            "\n",
            "Epoch 23/100\n",
            "----------\n",
            "train Loss: 0.00283 Acc: 99.89977 macro-f1: 1.00000\n",
            "vaild Loss: 0.30156 Acc: 93.92523 macro-f1: 1.00000\n",
            "each epochs training time : 20m 12s\n",
            "\n",
            "\n",
            "Epoch 24/100\n",
            "----------\n",
            "train Loss: 0.00155 Acc: 99.96659 macro-f1: 1.00000\n",
            "vaild Loss: 0.31922 Acc: 93.53583 macro-f1: 1.00000\n",
            "each epochs training time : 21m 3s\n",
            "\n",
            "\n",
            "Epoch 25/100\n",
            "----------\n",
            "train Loss: 0.00177 Acc: 99.96659 macro-f1: 1.00000\n",
            "vaild Loss: 0.34432 Acc: 93.38006 macro-f1: 1.00000\n",
            "each epochs training time : 21m 54s\n",
            "\n",
            "\n",
            "Epoch 26/100\n",
            "----------\n",
            "train Loss: 0.00555 Acc: 99.89977 macro-f1: 1.00000\n",
            "vaild Loss: 0.25684 Acc: 94.08100 macro-f1: 1.00000\n",
            "each epochs training time : 22m 45s\n",
            "\n",
            "\n",
            "Epoch 27/100\n",
            "----------\n",
            "train Loss: 0.00398 Acc: 99.93318 macro-f1: 0.81818\n",
            "vaild Loss: 0.28570 Acc: 94.00312 macro-f1: 1.00000\n",
            "each epochs training time : 23m 36s\n",
            "\n",
            "\n",
            "Epoch 28/100\n",
            "----------\n",
            "train Loss: 0.01698 Acc: 99.66589 macro-f1: 0.80000\n",
            "vaild Loss: 0.26024 Acc: 94.00312 macro-f1: 1.00000\n",
            "each epochs training time : 24m 27s\n",
            "\n",
            "\n",
            "Epoch 29/100\n",
            "----------\n",
            "train Loss: 0.00762 Acc: 99.79953 macro-f1: 1.00000\n",
            "vaild Loss: 0.26960 Acc: 94.23676 macro-f1: 1.00000\n",
            "each epochs training time : 25m 18s\n",
            "\n",
            "\n",
            "Epoch 30/100\n",
            "----------\n",
            "train Loss: 0.00233 Acc: 99.93318 macro-f1: 1.00000\n",
            "vaild Loss: 0.27942 Acc: 93.92523 macro-f1: 1.00000\n",
            "each epochs training time : 26m 9s\n",
            "\n",
            "\n",
            "Epoch 31/100\n",
            "----------\n",
            "train Loss: 0.00117 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.28237 Acc: 94.23676 macro-f1: 1.00000\n",
            "each epochs training time : 26m 60s\n",
            "\n",
            "\n",
            "Epoch 32/100\n",
            "----------\n",
            "train Loss: 0.00075 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.27269 Acc: 94.47040 macro-f1: 1.00000\n",
            "==> best model saved - 32 / 94.5\n",
            "each epochs training time : 27m 51s\n",
            "\n",
            "\n",
            "Epoch 33/100\n",
            "----------\n",
            "train Loss: 0.00113 Acc: 99.96659 macro-f1: 0.83333\n",
            "vaild Loss: 0.27265 Acc: 94.31464 macro-f1: 1.00000\n",
            "each epochs training time : 28m 42s\n",
            "\n",
            "\n",
            "Epoch 34/100\n",
            "----------\n",
            "train Loss: 0.00513 Acc: 99.83294 macro-f1: 1.00000\n",
            "vaild Loss: 0.27688 Acc: 93.69159 macro-f1: 1.00000\n",
            "each epochs training time : 29m 33s\n",
            "\n",
            "\n",
            "Epoch 35/100\n",
            "----------\n",
            "train Loss: 0.00189 Acc: 99.96659 macro-f1: 1.00000\n",
            "vaild Loss: 0.27876 Acc: 94.00312 macro-f1: 1.00000\n",
            "each epochs training time : 30m 24s\n",
            "\n",
            "\n",
            "Epoch 36/100\n",
            "----------\n",
            "train Loss: 0.00150 Acc: 99.96659 macro-f1: 1.00000\n",
            "vaild Loss: 0.27191 Acc: 94.47040 macro-f1: 1.00000\n",
            "each epochs training time : 31m 14s\n",
            "\n",
            "\n",
            "Epoch 37/100\n",
            "----------\n",
            "train Loss: 0.00205 Acc: 99.93318 macro-f1: 1.00000\n",
            "vaild Loss: 0.29489 Acc: 93.84735 macro-f1: 1.00000\n",
            "each epochs training time : 32m 5s\n",
            "\n",
            "\n",
            "Epoch 38/100\n",
            "----------\n",
            "train Loss: 0.00109 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.28147 Acc: 94.31464 macro-f1: 1.00000\n",
            "each epochs training time : 32m 56s\n",
            "\n",
            "\n",
            "Epoch 39/100\n",
            "----------\n",
            "train Loss: 0.00096 Acc: 99.96659 macro-f1: 1.00000\n",
            "vaild Loss: 0.27095 Acc: 94.31464 macro-f1: 1.00000\n",
            "each epochs training time : 33m 47s\n",
            "\n",
            "\n",
            "Epoch 40/100\n",
            "----------\n",
            "train Loss: 0.00055 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.29220 Acc: 94.00312 macro-f1: 1.00000\n",
            "each epochs training time : 34m 38s\n",
            "\n",
            "\n",
            "Epoch 41/100\n",
            "----------\n",
            "train Loss: 0.00030 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.30077 Acc: 94.23676 macro-f1: 1.00000\n",
            "each epochs training time : 35m 29s\n",
            "\n",
            "\n",
            "Epoch 42/100\n",
            "----------\n",
            "train Loss: 0.00045 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.31026 Acc: 94.15888 macro-f1: 1.00000\n",
            "each epochs training time : 36m 20s\n",
            "\n",
            "\n",
            "Epoch 43/100\n",
            "----------\n",
            "train Loss: 0.00093 Acc: 99.96659 macro-f1: 0.89091\n",
            "vaild Loss: 0.30527 Acc: 94.23676 macro-f1: 1.00000\n",
            "each epochs training time : 37m 11s\n",
            "\n",
            "\n",
            "Epoch 44/100\n",
            "----------\n",
            "train Loss: 0.00245 Acc: 99.96659 macro-f1: 1.00000\n",
            "vaild Loss: 0.30820 Acc: 94.23676 macro-f1: 1.00000\n",
            "each epochs training time : 38m 2s\n",
            "\n",
            "\n",
            "Epoch 45/100\n",
            "----------\n",
            "train Loss: 0.00175 Acc: 99.89977 macro-f1: 1.00000\n",
            "vaild Loss: 0.32273 Acc: 93.76947 macro-f1: 1.00000\n",
            "each epochs training time : 38m 53s\n",
            "\n",
            "\n",
            "Epoch 46/100\n",
            "----------\n",
            "train Loss: 0.00240 Acc: 99.93318 macro-f1: 1.00000\n",
            "vaild Loss: 0.32295 Acc: 94.15888 macro-f1: 1.00000\n",
            "each epochs training time : 39m 44s\n",
            "\n",
            "\n",
            "Epoch 47/100\n",
            "----------\n",
            "train Loss: 0.00071 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.31858 Acc: 93.76947 macro-f1: 1.00000\n",
            "each epochs training time : 40m 35s\n",
            "\n",
            "\n",
            "Epoch 48/100\n",
            "----------\n",
            "train Loss: 0.00088 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.30541 Acc: 94.23676 macro-f1: 1.00000\n",
            "each epochs training time : 41m 25s\n",
            "\n",
            "\n",
            "Epoch 49/100\n",
            "----------\n",
            "train Loss: 0.00130 Acc: 99.96659 macro-f1: 1.00000\n",
            "vaild Loss: 0.37512 Acc: 92.91277 macro-f1: 1.00000\n",
            "each epochs training time : 42m 16s\n",
            "\n",
            "\n",
            "Epoch 50/100\n",
            "----------\n",
            "train Loss: 0.00078 Acc: 99.96659 macro-f1: 1.00000\n",
            "vaild Loss: 0.32671 Acc: 94.23676 macro-f1: 1.00000\n",
            "each epochs training time : 43m 7s\n",
            "\n",
            "\n",
            "Epoch 51/100\n",
            "----------\n",
            "train Loss: 0.00041 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.32180 Acc: 94.23676 macro-f1: 1.00000\n",
            "each epochs training time : 43m 58s\n",
            "\n",
            "\n",
            "Epoch 52/100\n",
            "----------\n",
            "train Loss: 0.00061 Acc: 99.96659 macro-f1: 1.00000\n",
            "vaild Loss: 0.31498 Acc: 93.84735 macro-f1: 1.00000\n",
            "each epochs training time : 44m 49s\n",
            "\n",
            "\n",
            "Epoch 53/100\n",
            "----------\n",
            "train Loss: 0.00173 Acc: 99.96659 macro-f1: 1.00000\n",
            "vaild Loss: 0.29999 Acc: 94.39252 macro-f1: 1.00000\n",
            "each epochs training time : 45m 40s\n",
            "\n",
            "\n",
            "Epoch 54/100\n",
            "----------\n",
            "train Loss: 0.00045 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.30417 Acc: 94.39252 macro-f1: 1.00000\n",
            "each epochs training time : 46m 31s\n",
            "\n",
            "\n",
            "Epoch 55/100\n",
            "----------\n",
            "train Loss: 0.00042 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.30747 Acc: 94.31464 macro-f1: 1.00000\n",
            "each epochs training time : 47m 22s\n",
            "\n",
            "\n",
            "Epoch 56/100\n",
            "----------\n",
            "train Loss: 0.00036 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.29768 Acc: 94.54829 macro-f1: 1.00000\n",
            "==> best model saved - 56 / 94.5\n",
            "each epochs training time : 48m 12s\n",
            "\n",
            "\n",
            "Epoch 57/100\n",
            "----------\n",
            "train Loss: 0.00044 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.30903 Acc: 94.31464 macro-f1: 1.00000\n",
            "each epochs training time : 49m 3s\n",
            "\n",
            "\n",
            "Epoch 58/100\n",
            "----------\n",
            "train Loss: 0.00034 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.31798 Acc: 94.23676 macro-f1: 1.00000\n",
            "each epochs training time : 49m 54s\n",
            "\n",
            "\n",
            "Epoch 59/100\n",
            "----------\n",
            "train Loss: 0.00042 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.30079 Acc: 94.31464 macro-f1: 1.00000\n",
            "each epochs training time : 50m 45s\n",
            "\n",
            "\n",
            "Epoch 60/100\n",
            "----------\n",
            "train Loss: 0.00033 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.32098 Acc: 94.31464 macro-f1: 1.00000\n",
            "each epochs training time : 51m 36s\n",
            "\n",
            "\n",
            "Epoch 61/100\n",
            "----------\n",
            "train Loss: 0.00022 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.31090 Acc: 94.54829 macro-f1: 1.00000\n",
            "each epochs training time : 52m 27s\n",
            "\n",
            "\n",
            "Epoch 62/100\n",
            "----------\n",
            "train Loss: 0.00028 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.31184 Acc: 94.62617 macro-f1: 1.00000\n",
            "==> best model saved - 62 / 94.6\n",
            "each epochs training time : 53m 18s\n",
            "\n",
            "\n",
            "Epoch 63/100\n",
            "----------\n",
            "train Loss: 0.00029 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.31836 Acc: 94.31464 macro-f1: 1.00000\n",
            "each epochs training time : 54m 9s\n",
            "\n",
            "\n",
            "Epoch 64/100\n",
            "----------\n",
            "train Loss: 0.00049 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.30660 Acc: 94.47040 macro-f1: 1.00000\n",
            "each epochs training time : 54m 60s\n",
            "\n",
            "\n",
            "Epoch 65/100\n",
            "----------\n",
            "train Loss: 0.00030 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.31436 Acc: 94.54829 macro-f1: 1.00000\n",
            "each epochs training time : 55m 50s\n",
            "\n",
            "\n",
            "Epoch 66/100\n",
            "----------\n",
            "train Loss: 0.00030 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.33371 Acc: 94.31464 macro-f1: 1.00000\n",
            "each epochs training time : 56m 41s\n",
            "\n",
            "\n",
            "Epoch 67/100\n",
            "----------\n",
            "train Loss: 0.00029 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.31340 Acc: 94.54829 macro-f1: 1.00000\n",
            "each epochs training time : 57m 32s\n",
            "\n",
            "\n",
            "Epoch 68/100\n",
            "----------\n",
            "train Loss: 0.00034 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.33213 Acc: 94.31464 macro-f1: 1.00000\n",
            "each epochs training time : 58m 23s\n",
            "\n",
            "\n",
            "Epoch 69/100\n",
            "----------\n",
            "train Loss: 0.00022 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.33738 Acc: 94.39252 macro-f1: 1.00000\n",
            "each epochs training time : 59m 14s\n",
            "\n",
            "\n",
            "Epoch 70/100\n",
            "----------\n",
            "train Loss: 0.00026 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.32662 Acc: 94.47040 macro-f1: 1.00000\n",
            "each epochs training time : 60m 5s\n",
            "\n",
            "\n",
            "Epoch 71/100\n",
            "----------\n",
            "train Loss: 0.00019 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.32033 Acc: 94.54829 macro-f1: 1.00000\n",
            "each epochs training time : 60m 55s\n",
            "\n",
            "\n",
            "Epoch 72/100\n",
            "----------\n",
            "train Loss: 0.00015 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.31562 Acc: 94.39252 macro-f1: 1.00000\n",
            "each epochs training time : 61m 46s\n",
            "\n",
            "\n",
            "Epoch 73/100\n",
            "----------\n",
            "train Loss: 0.00020 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.32229 Acc: 94.54829 macro-f1: 1.00000\n",
            "each epochs training time : 62m 37s\n",
            "\n",
            "\n",
            "Epoch 74/100\n",
            "----------\n",
            "train Loss: 0.00020 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.32634 Acc: 94.39252 macro-f1: 1.00000\n",
            "each epochs training time : 63m 28s\n",
            "\n",
            "\n",
            "Epoch 75/100\n",
            "----------\n",
            "train Loss: 0.00023 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.32158 Acc: 94.39252 macro-f1: 1.00000\n",
            "each epochs training time : 64m 19s\n",
            "\n",
            "\n",
            "Epoch 76/100\n",
            "----------\n",
            "train Loss: 0.00028 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.31364 Acc: 94.39252 macro-f1: 1.00000\n",
            "each epochs training time : 65m 10s\n",
            "\n",
            "\n",
            "Epoch 77/100\n",
            "----------\n",
            "train Loss: 0.00026 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.32580 Acc: 94.31464 macro-f1: 1.00000\n",
            "each epochs training time : 66m 1s\n",
            "\n",
            "\n",
            "Epoch 78/100\n",
            "----------\n",
            "train Loss: 0.00058 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.33061 Acc: 94.31464 macro-f1: 1.00000\n",
            "each epochs training time : 66m 52s\n",
            "\n",
            "\n",
            "Epoch 79/100\n",
            "----------\n",
            "train Loss: 0.00036 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.32520 Acc: 94.08100 macro-f1: 1.00000\n",
            "each epochs training time : 67m 43s\n",
            "\n",
            "\n",
            "Epoch 80/100\n",
            "----------\n",
            "train Loss: 0.00073 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.29606 Acc: 94.70405 macro-f1: 1.00000\n",
            "==> best model saved - 80 / 94.7\n",
            "each epochs training time : 68m 34s\n",
            "\n",
            "\n",
            "Epoch 81/100\n",
            "----------\n",
            "train Loss: 0.00031 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.31820 Acc: 94.23676 macro-f1: 1.00000\n",
            "each epochs training time : 69m 24s\n",
            "\n",
            "\n",
            "Epoch 82/100\n",
            "----------\n",
            "train Loss: 0.00018 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.31152 Acc: 94.54829 macro-f1: 1.00000\n",
            "each epochs training time : 70m 15s\n",
            "\n",
            "\n",
            "Epoch 83/100\n",
            "----------\n",
            "train Loss: 0.00056 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.31546 Acc: 94.08100 macro-f1: 1.00000\n",
            "each epochs training time : 71m 6s\n",
            "\n",
            "\n",
            "Epoch 84/100\n",
            "----------\n",
            "train Loss: 0.00030 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.31336 Acc: 94.23676 macro-f1: 1.00000\n",
            "each epochs training time : 71m 57s\n",
            "\n",
            "\n",
            "Epoch 85/100\n",
            "----------\n",
            "train Loss: 0.00115 Acc: 99.96659 macro-f1: 0.89744\n",
            "vaild Loss: 0.33038 Acc: 94.00312 macro-f1: 1.00000\n",
            "each epochs training time : 72m 48s\n",
            "\n",
            "\n",
            "Epoch 86/100\n",
            "----------\n",
            "train Loss: 0.00126 Acc: 99.93318 macro-f1: 0.87879\n",
            "vaild Loss: 0.33633 Acc: 94.00312 macro-f1: 1.00000\n",
            "each epochs training time : 73m 39s\n",
            "\n",
            "\n",
            "Epoch 87/100\n",
            "----------\n",
            "train Loss: 0.00386 Acc: 99.89977 macro-f1: 1.00000\n",
            "vaild Loss: 0.33875 Acc: 93.69159 macro-f1: 1.00000\n",
            "each epochs training time : 74m 30s\n",
            "\n",
            "\n",
            "Epoch 88/100\n",
            "----------\n",
            "train Loss: 0.00378 Acc: 99.89977 macro-f1: 1.00000\n",
            "vaild Loss: 0.30566 Acc: 94.23676 macro-f1: 1.00000\n",
            "each epochs training time : 75m 21s\n",
            "\n",
            "\n",
            "Epoch 89/100\n",
            "----------\n",
            "train Loss: 0.00043 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.31922 Acc: 94.47040 macro-f1: 1.00000\n",
            "each epochs training time : 76m 12s\n",
            "\n",
            "\n",
            "Epoch 90/100\n",
            "----------\n",
            "train Loss: 0.00123 Acc: 99.96659 macro-f1: 0.90769\n",
            "vaild Loss: 0.30530 Acc: 94.15888 macro-f1: 1.00000\n",
            "each epochs training time : 77m 3s\n",
            "\n",
            "\n",
            "Epoch 91/100\n",
            "----------\n",
            "train Loss: 0.00084 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.30100 Acc: 93.92523 macro-f1: 1.00000\n",
            "each epochs training time : 77m 54s\n",
            "\n",
            "\n",
            "Epoch 92/100\n",
            "----------\n",
            "train Loss: 0.00047 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.31044 Acc: 94.00312 macro-f1: 1.00000\n",
            "each epochs training time : 78m 45s\n",
            "\n",
            "\n",
            "Epoch 93/100\n",
            "----------\n",
            "train Loss: 0.00068 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.31598 Acc: 94.31464 macro-f1: 1.00000\n",
            "each epochs training time : 79m 36s\n",
            "\n",
            "\n",
            "Epoch 94/100\n",
            "----------\n",
            "train Loss: 0.00058 Acc: 99.96659 macro-f1: 1.00000\n",
            "vaild Loss: 0.30697 Acc: 94.31464 macro-f1: 1.00000\n",
            "each epochs training time : 80m 27s\n",
            "\n",
            "\n",
            "Epoch 95/100\n",
            "----------\n",
            "train Loss: 0.00036 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.30447 Acc: 94.15888 macro-f1: 1.00000\n",
            "each epochs training time : 81m 18s\n",
            "\n",
            "\n",
            "Epoch 96/100\n",
            "----------\n",
            "train Loss: 0.00097 Acc: 99.96659 macro-f1: 1.00000\n",
            "vaild Loss: 0.28506 Acc: 94.39252 macro-f1: 1.00000\n",
            "each epochs training time : 82m 9s\n",
            "\n",
            "\n",
            "Epoch 97/100\n",
            "----------\n",
            "train Loss: 0.00033 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.28288 Acc: 94.70405 macro-f1: 1.00000\n",
            "each epochs training time : 82m 60s\n",
            "\n",
            "\n",
            "Epoch 98/100\n",
            "----------\n",
            "train Loss: 0.00051 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.28825 Acc: 94.31464 macro-f1: 1.00000\n",
            "each epochs training time : 83m 50s\n",
            "\n",
            "\n",
            "Epoch 99/100\n",
            "----------\n",
            "train Loss: 0.00026 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.29631 Acc: 94.54829 macro-f1: 1.00000\n",
            "each epochs training time : 84m 41s\n",
            "\n",
            "\n",
            "Training complete in 84m 42s\n",
            "Best valid Acc: 80 - 94.7\n",
            "model saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 결과 그래프 그리기\n",
        "print('best model : %d - %1.f / %.1f'%(best_idx, valid_acc[best_idx], valid_loss[best_idx]))\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(train_acc, 'b-')\n",
        "ax1.plot(valid_acc, 'r-')\n",
        "plt.plot(best_idx, valid_acc[best_idx], 'ro')\n",
        "ax1.set_xlabel('epoch')\n",
        "# Make the y-axis label, ticks and tick labels match the line color.\n",
        "ax1.set_ylabel('acc', color='k')\n",
        "ax1.tick_params('y', colors='k')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(train_loss, 'g-')\n",
        "ax2.plot(valid_loss, 'k-')\n",
        "plt.plot(best_idx, valid_loss[best_idx], 'ro')\n",
        "ax2.set_ylabel('loss', color='k')\n",
        "ax2.tick_params('y', colors='k')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "5kJPLUuEU1pH",
        "outputId": "e51b1832-7625-49a1-95c5-2f23ea976030"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best model : 80 - 95 / 0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JJdS3MynU1rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ## 학습 결과 검수\n",
        "# def test_and_visualize_model(model, phase = 'test', num_images=4):\n",
        "#     # phase = 'train', 'valid', 'test'\n",
        "    \n",
        "#     was_training = model.training\n",
        "#     model.eval()\n",
        "#     fig = plt.figure()\n",
        "    \n",
        "#     running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
        "#             inputs = inputs.to(device)\n",
        "#             labels = labels.to(device)\n",
        "\n",
        "#             outputs = model(inputs)\n",
        "#             _, preds = torch.max(outputs, 1)\n",
        "#             loss = criterion(outputs, labels)  # batch의 평균 loss 출력\n",
        "\n",
        "#             running_loss    += loss.item() * inputs.size(0)\n",
        "#             running_corrects+= torch.sum(preds == labels.data)\n",
        "#             num_cnt += inputs.size(0)  # batch size\n",
        "\n",
        "#     #         if i == 2: break\n",
        "\n",
        "#         test_loss = running_loss / num_cnt\n",
        "#         test_acc  = running_corrects.double() / num_cnt       \n",
        "#         print('test done : loss/acc : %.2f / %.1f' % (test_loss, test_acc*100))\n",
        "\n",
        "#     # 예시 그림 plot\n",
        "#     with torch.no_grad():\n",
        "#         for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
        "#             inputs = inputs.to(device)\n",
        "#             labels = labels.to(device)\n",
        "\n",
        "#             outputs = model(inputs)\n",
        "#             _, preds = torch.max(outputs, 1)        \n",
        "\n",
        "#             # 예시 그림 plot\n",
        "#             for j in range(1, num_images+1):\n",
        "#                 ax = plt.subplot(num_images//2, 2, j)\n",
        "#                 ax.axis('off')\n",
        "#                 ax.set_title('%s : %s -> %s'%(\n",
        "#                     'True' if class_names[str(labels[j].cpu().numpy())]==class_names[str(preds[j].cpu().numpy())] else 'False',\n",
        "#                     class_names[str(labels[j].cpu().numpy())], class_names[str(preds[j].cpu().numpy())]))\n",
        "#                 imshow(inputs.cpu().data[j])          \n",
        "#             if i == 0 : break\n",
        "\n",
        "\n",
        "#     model.train(mode=was_training);  # 다시 train모드로\n",
        "    \n",
        "#     ## TEST!\n",
        "#     test_and_visualize_model(model, phase = 'test')"
      ],
      "metadata": {
        "id": "bZK4jMWoU1tQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LedsQjpUU1vI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "X2jIgWqSU1w9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-o1YRRNYU1zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 추론"
      ],
      "metadata": {
        "id": "WQR1RKgTpKk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 모델을 평가 모드로 변경하고 test 데이터 분류\n",
        "test_png = sorted(glob('/content/drive/Othercomputers/내 MacBook Pro/open/test/*.png'))\n",
        "test_imgs = [img_load(n) for n in tqdm(test_png)]\n",
        "test_dataset = Custom_dataset_3(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "model.eval()\n",
        "f_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in (test_loader):\n",
        "        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            pred = model(x)\n",
        "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
      ],
      "metadata": {
        "id": "gj7gTQv6U11P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1c85530-9950-42f4-d3bd-c498950b281e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2154/2154 [04:25<00:00,  8.12it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 숫자로된 레이블을 문자열 레이블로 변경\n",
        "label_decoder = {value:key for key, value in label_unique.items()}\n",
        "f_result = [label_decoder[result] for result in f_pred]"
      ],
      "metadata": {
        "id": "30_rcMw4U13G"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime as dt \n",
        "today = dt.today().strftime('%Y-%m-%d')\n",
        "version = f'efficientNet_b4_by_timm_data_ver1_{today}'\n",
        "submission = pd.read_csv(f\"/content/drive/MyDrive/DACON_이상치 탐지 알고리즘 경진대회/open/sample_submission.csv\")\n",
        "\n",
        "## 시각적 확인을 위해 문자열 레이블로 이루어진 된 label 필드 생성\n",
        "submission[\"label\"] = f_result\n",
        "display(submission)\n",
        "submission.to_csv(f\"/content/drive/MyDrive/DACON_이상치 탐지 알고리즘 경진대회/open/sample_submission_{version}.csv\", index = False)"
      ],
      "metadata": {
        "id": "1zWu-D7WdRmQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "cef35b9f-ead9-463e-ff7f-60946d075d9c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      index             label\n",
              "0         0   tile-glue_strip\n",
              "1         1         grid-good\n",
              "2         2   transistor-good\n",
              "3         3         tile-good\n",
              "4         4         tile-good\n",
              "...     ...               ...\n",
              "2149   2149  tile-gray_stroke\n",
              "2150   2150        screw-good\n",
              "2151   2151         grid-good\n",
              "2152   2152        cable-good\n",
              "2153   2153       zipper-good\n",
              "\n",
              "[2154 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4eb498c5-cfe3-40f9-8a25-ba4b3824c33a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>tile-glue_strip</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>grid-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>transistor-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>tile-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>tile-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2149</th>\n",
              "      <td>2149</td>\n",
              "      <td>tile-gray_stroke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2150</th>\n",
              "      <td>2150</td>\n",
              "      <td>screw-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2151</th>\n",
              "      <td>2151</td>\n",
              "      <td>grid-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2152</th>\n",
              "      <td>2152</td>\n",
              "      <td>cable-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2153</th>\n",
              "      <td>2153</td>\n",
              "      <td>zipper-good</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2154 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4eb498c5-cfe3-40f9-8a25-ba4b3824c33a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4eb498c5-cfe3-40f9-8a25-ba4b3824c33a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4eb498c5-cfe3-40f9-8a25-ba4b3824c33a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cG_tNWs2zxh8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}