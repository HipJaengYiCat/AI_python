{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNet_MVtecAD_DatasetVer2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seunghee0518/AI_python/blob/main/EfficientNet_b4_by_timm_MVtecAD_agumentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## trina/ test 나눠서 학습"
      ],
      "metadata": {
        "id": "lynhGDxilbRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "torch.hub : Pytorch Hub는 연구 재현성을 촉진하도록 설계된 사전 훈련 된 모델 저장소\n",
        "nvidia_efficientnet_b4 사전 모델 가져옴\n",
        "'''\n",
        "# import torch\n",
        "# model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b4', pretrained=True)\n",
        "!pip install timm\n",
        "import timm\n",
        "model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=88)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ-ytfDpoKMH",
        "outputId": "70696376-f161-4f49-d639-b0e96a5c708f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 43.1 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 49.6 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 53.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 35.1 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 51 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 61 kB 38.1 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 30.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 35.1 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 102 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 112 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 122 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 153 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 163 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 174 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 184 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 194 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 204 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 215 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 225 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 235 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 245 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 256 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 266 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 276 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 286 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 307 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 317 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 327 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 348 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 358 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 368 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 378 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 389 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 399 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 409 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 419 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 430 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 431 kB 34.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.12.0+cu113)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2021.10.8)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.5.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b4_ra2_320-7eb33cd5.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b4_ra2_320-7eb33cd5.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from pprint import pprint\n",
        "# model_names = timm.list_models(pretrained=True)\n",
        "# pprint(model_names)"
      ],
      "metadata": {
        "id": "invECZxkPTyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKXv22Yk6zus",
        "outputId": "bc75a668-48bc-4fb0-c1ee-39aa5ce95159"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 학습 코드\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "#import timm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import transforms, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "from PIL import Image\n",
        "# from efficientnet_pytorch import EfficientNet\n",
        "# model_name = 'efficientnet-b0'  # b5\n",
        "\n",
        "# image_size = EfficientNet.get_image_size(model_name)\n",
        "# print(image_size)\n",
        "# model = EfficientNet.from_pretrained(model_name, num_classes=88)"
      ],
      "metadata": {
        "id": "Gjs-R_R5lUKg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 기본 설정\n",
        "device = torch.device('cuda')\n",
        "batch_size  = 32\n",
        "random_seed = 1234\n",
        "img_size = 224\n",
        "random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZHMCtAvlDOp",
        "outputId": "212e5874-cb8f-42f1-c6b0-a41ec823615c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f5cef660070>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## transforms 함수 정리\n",
        "* transforms.ToPILImage() - csv 파일로 데이터셋을 받을 경우, PIL image로 바꿔준다.\n",
        "* transforms.CenterCrop(size) - 가운데 부분을 size 크기로 자른다.\n",
        "* transforms.Grayscale(num_output_channels=1) - grayscale로 변환한다.\n",
        "* transforms.RandomAffine(degrees) - 랜덤으로 affine 변형을 한다.\n",
        "* transforms.RandomCrop(size) -이미지를 랜덤으로 아무데나 잘라 size 크기로 출력한다.\n",
        "* transforms.RandomResizedCrop(size) - 이미지 사이즈를 size로 변경한다\n",
        "* transforms.Resize(size) - 이미지 사이즈를 size로 변경한다\n",
        "* transforms.RandomRotation(degrees) 이미지를 랜덤으로 degrees 각도로 회전한다.\n",
        "* transforms.RandomResizedCrop(size, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333)) - 이미지를 랜덤으로 변형한다.\n",
        "* transforms.RandomVerticalFlip(p=0.5) - 이미지를 랜덤으로 수직으로 뒤집는다. p =0이면 뒤집지 않는다.\n",
        "* transforms.RandomHorizontalFlip(p=0.5) - 이미지를 랜덤으로 수평으로 뒤집는다.\n",
        "* transforms.ToTensor() - 이미지 데이터를 tensor로 바꿔준다.\n",
        "* transforms.Normalize(mean, std, inplace=False) - 이미지를 정규화한다."
      ],
      "metadata": {
        "id": "fTgH3bYzN7RA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 데이터 전처리 함수\n",
        "# make dataset\n",
        "#data_path = 'president/president_data'  # class 별 폴더로 나누어진 걸 가져와서 라벨도 달아준다\n",
        "# train_dataset = datasets.ImageFolder(data_path,\n",
        "#                                      transforms.Compose([\n",
        "#                                      transforms.Resize((224, 224)),\n",
        "#                                      transforms.RandomCrop(224),\n",
        "#                                      transforms.RandomRotation(90, expand=True),\n",
        "#                                      transforms.RandomVerticalFlip(),\n",
        "#                                      transforms.RandomHorizontalFlip(),\n",
        "#                                      transforms.ToTensor(), # 이미지 데이터를 tensor로 바꿔준다.\n",
        "#                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])) # Normalize는 많은 이미지의 평균, 표준편차로 정함(보통 많이 하는 값이라고함)\n",
        "\n",
        "\n",
        "### 이미지 전처리 함수 & 클래스\n",
        "## 이미지  > 넘파이 배열로 변환\n",
        "def img_load(path):\n",
        "    img = cv2.imread(path)[:,:,::-1] # Return type:\tnumpy.ndarray / 기본적으로 BGR로 불러옴, RGB 변환함\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    return img\n",
        "\n",
        "class Custom_dataset_1(Dataset): # 기본\n",
        "    def __init__(self, img_paths, labels, mode='train'):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode = mode\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.img_paths[idx]\n",
        "        img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "        img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "        ## 레이블 > 원-핫 인코딩 하기 \n",
        "        label = self.labels[idx]# (원핫인코딩 안할거면 해당 코드만 필요)\n",
        "        return img, label\n",
        "\n",
        "class Custom_dataset_2(Dataset): # 변형\n",
        "    def __init__(self, img_paths, labels, mode='train'):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode = mode\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.img_paths[idx]\n",
        "        if self.mode == 'train':\n",
        "          img = Image.fromarray(img)\n",
        "          #img = transforms.Resize((img_size, img_size))(img) # 처음 이미지 불러올때 resize 했으므로 생략\n",
        "          #img = transforms.RandomCrop(img_size)(img)\n",
        "          img = transforms.RandomRotation(90, expand=False)(img)\n",
        "          img = transforms.RandomVerticalFlip()(img)\n",
        "          img = transforms.RandomHorizontalFlip()(img)\n",
        "          img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "          img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "        if self.mode=='test':\n",
        "          img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "          img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "        ## 레이블\n",
        "        label = self.labels[idx]# (원핫인코딩 안할거면 해당 코드만 필요)\n",
        "        return img, label\n",
        "\n",
        "class Custom_dataset_3(Dataset): # 기본이미지 + 변형이미지 (train 시 2배 증량됨)\n",
        "    def __init__(self, img_paths, labels, mode='train'):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode=mode\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.mode=='train':\n",
        "          if idx < 4277: # 변경 없는 이미지\n",
        "            img = self.img_paths[idx]\n",
        "            img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "            img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "            label = self.labels[idx]\n",
        "            return img, label\n",
        "\n",
        "          else : # 랜덤 변경된 이미지 추가됨 \n",
        "            img = self.img_paths[idx]\n",
        "            img = Image.fromarray(img)\n",
        "            #img = transforms.Resize((img_size, img_size))(img) # 처음 이미지 불러올때 resize 했으므로 생략\n",
        "            #img = transforms.RandomCrop(img_size)(img)\n",
        "            img = transforms.RandomRotation(90, expand=False)(img)\n",
        "            img = transforms.RandomVerticalFlip()(img)\n",
        "            img = transforms.RandomHorizontalFlip()(img)\n",
        "            img = transforms.ToTensor()(img) # PIL or ndarray -> tensor\n",
        "            img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "            label = self.labels[idx]\n",
        "            return img, label\n",
        "\n",
        "        if self.mode=='test':\n",
        "          img = self.img_paths[idx]\n",
        "          img = transforms.ToTensor()(img)\n",
        "          img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "          label = self.labels[idx]\n",
        "          return img, label\n",
        "            "
      ],
      "metadata": {
        "id": "ORqFbwLXpSeu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 이미지 로드 및 전처리\n",
        "# 이미지 경로\n",
        "train_png = sorted(glob('/content/drive/Othercomputers/내 MacBook Pro/open/train/*.png'))\n",
        "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
        "\n",
        "#train_imgs = np.load('/content/drive/MyDrive/DACON_이상치 탐지 알고리즘 경진대회/train_imgs_224.npy')\n",
        "train_y = pd.read_csv(\"/content/drive/Othercomputers/내 MacBook Pro/open/train_df.csv\")\n",
        "\n",
        "train_labels = train_y[\"label\"] # 레이블순서는 이미지 파일 순서대로임\n",
        "\n",
        "label_unique = sorted(np.unique(train_labels))\n",
        "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))} # 오름차순으로 레이블별로 숫자 부여(0부터 시작)\n",
        "\n",
        "train_labels = [label_unique[k] for k in train_labels]\n",
        "train_dataset = Custom_dataset_2(np.array(train_imgs), np.array(train_labels), mode='train')\n",
        "train_idx, vaild_idx = train_test_split(list(range(len(train_dataset))), stratify=train_labels, test_size=0.3, random_state=random_seed)\n",
        "\n",
        "# ## 이미지 증량 시만 사용\n",
        "# train_imgs = train_imgs + train_imgs\n",
        "# train_labels = train_labels+train_labels\n",
        "\n",
        "# train_dataset = Custom_dataset_3(np.array(train_imgs), np.array(train_labels), mode='train')\n",
        "\n",
        "# ### 데이터셋 분리 > 층화추출 & 테스터 데이터 비율 : 0.3, 시드 : 1234, 셔플 = True(default)\n",
        "# train_idx, vaild_idx = train_test_split(list(range(len(train_dataset))), stratify=train_labels, test_size=0.3, random_state=random_seed)\n",
        "\n",
        "datasets = {} # 데이터셋을 담을 딕셔너리\n",
        "datasets['train'] = Subset(train_dataset, train_idx)\n",
        "datasets['vaild']  = Subset(train_dataset, vaild_idx)\n",
        "\n",
        "## data loader 선언\n",
        "dataloaders, batch_num = {}, {}\n",
        "dataloaders['train'] = torch.utils.data.DataLoader(datasets['train'],\n",
        "                                                  batch_size=batch_size, shuffle=True,\n",
        "                                                  num_workers=0)\n",
        "dataloaders['vaild']  = torch.utils.data.DataLoader(datasets['vaild'],\n",
        "                                                    batch_size=batch_size, shuffle=False,\n",
        "                                                    num_workers=0)\n",
        "'''\n",
        "데이터 변형 코드를 추가한 후 아래 오류코드가 나와\n",
        "Caught TypeError in DataLoader worker process 0\n",
        "DataLoader > num_workers 를 4 -> 0 로 낮춤\n",
        "'''\n",
        "\n",
        "batch_num['train'], batch_num['vaild'] = len(dataloaders['train']), len(dataloaders['vaild'])\n",
        "print('batch_size : %d,  train/vaild(데이터셋개수/배치사이즈) : %d / %d' % (batch_size, batch_num['train'],batch_num['vaild']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItvLP1Y3k-OW",
        "outputId": "e8891b45-3bd7-4900-be9b-9a4ff93c7225"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4277/4277 [07:09<00:00,  9.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_size : 32,  train/vaild(데이터셋개수/배치사이즈) : 94 / 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 참고 블로그 : https://keep-steady.tistory.com/35\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "### f1 스코어 함수 \n",
        "def score_function(real, pred): # 라이브러리 > sklearn.metrics \n",
        "    score = f1_score(real, pred, average=\"macro\")\n",
        "    return score\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    #train_loss, train_acc, valid_loss, valid_acc = [], [], [], []\n",
        "    train_loss, train_acc, valid_loss, valid_acc, train_f1, valid_f1 = [], [], [], [], [], []\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))# - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'vaild']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
        "            \n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device) # device = torch.device('cuda')\n",
        "                labels = labels.to(device) # device = torch.device('cuda')\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                num_cnt += len(labels)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "            \n",
        "            epoch_loss = float(running_loss / num_cnt)\n",
        "            epoch_acc  = float((running_corrects.double() / num_cnt).cpu()*100)\n",
        "            f1 = score_function(labels.cpu().data, preds.cpu()) # score_function or f1_score\n",
        "\n",
        "            if phase == 'train':\n",
        "                train_loss.append(epoch_loss)\n",
        "                train_acc.append(epoch_acc)\n",
        "                train_f1.append(f1)\n",
        "            else:\n",
        "                valid_loss.append(epoch_loss)\n",
        "                valid_acc.append(epoch_acc)\n",
        "                valid_f1.append(f1)\n",
        "\n",
        "            print('{} Loss: {:.5f} Acc: {:.5f} macro-f1: {:.5f}'.format(phase, epoch_loss, epoch_acc, f1))\n",
        "           \n",
        "            # deep copy the model(최적모델 저장)\n",
        "            if phase == 'vaild' and epoch_acc > best_acc:\n",
        "                best_idx = epoch\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "#                 best_model_wts = copy.deepcopy(model.module.state_dict())\n",
        "                print('==> best model saved - %d / %.1f'%(best_idx, best_acc))\n",
        "        # 한 에포크마다 실행 시간 출력하기(누적 시간으로 출력됨)\n",
        "        time_elapsed = time.time() - since\n",
        "        print('each epochs training time : {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "        print('\\n')\n",
        "\n",
        "        # 한 에포크마다 필요없는 메모리 지우기 : 지우기 효과는 아직 확인 못해봄\n",
        "        try:      \n",
        "          gc.collect() # cpu 비움\n",
        "          torch.cuda.empty_cache() # gpu 비움\n",
        "        except:\n",
        "          pass\n",
        "          \n",
        "    ## 학습 마무리 후\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best valid Acc: %d - %.1f' %(best_idx, best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    '''\n",
        "    한 에포크 마다 저장된 최적의 모델 가중치로 조정 후 다음 에포크가 돌아감\n",
        "    '''\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    torch.save(model.state_dict(), 'president_model.pt')\n",
        "    print('model saved')\n",
        "    return model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc, train_f1, valid_f1\n",
        "\n",
        "# 설정\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # set gpu\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_ft = optim.SGD(model.parameters(), \n",
        "                         lr = 0.05,\n",
        "                         momentum=0.9,\n",
        "                         weight_decay=1e-4)\n",
        "\n",
        "lmbda = lambda epoch: 0.98739\n",
        "exp_lr_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer_ft, lr_lambda=lmbda)\n",
        "\n",
        "# 사전학습된 가중치와 모델을 가져와 데이터셋으로 추가 모델 학습\n",
        "model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc, train_f1, valid_f1 = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDNj4Yarkx-R",
        "outputId": "7913bc84-197d-4901-d7ff-506532141aef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/100\n",
            "----------\n",
            "train Loss: 1.44344 Acc: 76.91280 macro-f1: 0.73810\n",
            "vaild Loss: 0.80629 Acc: 84.81308 macro-f1: 1.00000\n",
            "==> best model saved - 0 / 84.8\n",
            "each epochs training time : 0m 50s\n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "----------\n",
            "train Loss: 0.67743 Acc: 85.36585 macro-f1: 0.51111\n",
            "vaild Loss: 0.56410 Acc: 87.07165 macro-f1: 1.00000\n",
            "==> best model saved - 1 / 87.1\n",
            "each epochs training time : 1m 40s\n",
            "\n",
            "\n",
            "Epoch 2/100\n",
            "----------\n",
            "train Loss: 0.51855 Acc: 87.43735 macro-f1: 0.84615\n",
            "vaild Loss: 0.67371 Acc: 85.82555 macro-f1: 0.50000\n",
            "each epochs training time : 2m 31s\n",
            "\n",
            "\n",
            "Epoch 3/100\n",
            "----------\n",
            "train Loss: 0.44722 Acc: 88.94086 macro-f1: 0.84615\n",
            "vaild Loss: 0.44180 Acc: 89.48598 macro-f1: 1.00000\n",
            "==> best model saved - 3 / 89.5\n",
            "each epochs training time : 3m 23s\n",
            "\n",
            "\n",
            "Epoch 4/100\n",
            "----------\n",
            "train Loss: 0.39417 Acc: 90.17708 macro-f1: 0.84615\n",
            "vaild Loss: 0.38427 Acc: 90.18692 macro-f1: 1.00000\n",
            "==> best model saved - 4 / 90.2\n",
            "each epochs training time : 4m 15s\n",
            "\n",
            "\n",
            "Epoch 5/100\n",
            "----------\n",
            "train Loss: 0.34106 Acc: 91.34648 macro-f1: 0.80513\n",
            "vaild Loss: 0.35659 Acc: 90.57632 macro-f1: 1.00000\n",
            "==> best model saved - 5 / 90.6\n",
            "each epochs training time : 5m 7s\n",
            "\n",
            "\n",
            "Epoch 6/100\n",
            "----------\n",
            "train Loss: 0.29118 Acc: 91.91447 macro-f1: 0.84615\n",
            "vaild Loss: 0.33346 Acc: 91.19938 macro-f1: 1.00000\n",
            "==> best model saved - 6 / 91.2\n",
            "each epochs training time : 5m 60s\n",
            "\n",
            "\n",
            "Epoch 7/100\n",
            "----------\n",
            "train Loss: 0.25734 Acc: 93.08386 macro-f1: 1.00000\n",
            "vaild Loss: 0.30176 Acc: 92.13396 macro-f1: 1.00000\n",
            "==> best model saved - 7 / 92.1\n",
            "each epochs training time : 6m 52s\n",
            "\n",
            "\n",
            "Epoch 8/100\n",
            "----------\n",
            "train Loss: 0.23958 Acc: 93.38456 macro-f1: 0.88889\n",
            "vaild Loss: 0.26152 Acc: 92.91277 macro-f1: 1.00000\n",
            "==> best model saved - 8 / 92.9\n",
            "each epochs training time : 7m 45s\n",
            "\n",
            "\n",
            "Epoch 9/100\n",
            "----------\n",
            "train Loss: 0.20801 Acc: 94.38690 macro-f1: 0.81818\n",
            "vaild Loss: 0.25287 Acc: 92.21184 macro-f1: 1.00000\n",
            "each epochs training time : 8m 37s\n",
            "\n",
            "\n",
            "Epoch 10/100\n",
            "----------\n",
            "train Loss: 0.19004 Acc: 94.35349 macro-f1: 0.74359\n",
            "vaild Loss: 0.26264 Acc: 92.91277 macro-f1: 1.00000\n",
            "each epochs training time : 9m 30s\n",
            "\n",
            "\n",
            "Epoch 11/100\n",
            "----------\n",
            "train Loss: 0.16238 Acc: 94.88807 macro-f1: 0.72222\n",
            "vaild Loss: 0.25034 Acc: 93.84735 macro-f1: 1.00000\n",
            "==> best model saved - 11 / 93.8\n",
            "each epochs training time : 10m 22s\n",
            "\n",
            "\n",
            "Epoch 12/100\n",
            "----------\n",
            "train Loss: 0.12936 Acc: 96.05747 macro-f1: 0.71429\n",
            "vaild Loss: 0.21509 Acc: 94.15888 macro-f1: 1.00000\n",
            "==> best model saved - 12 / 94.2\n",
            "each epochs training time : 11m 15s\n",
            "\n",
            "\n",
            "Epoch 13/100\n",
            "----------\n",
            "train Loss: 0.12359 Acc: 95.99064 macro-f1: 0.88889\n",
            "vaild Loss: 0.21102 Acc: 93.92523 macro-f1: 1.00000\n",
            "each epochs training time : 12m 7s\n",
            "\n",
            "\n",
            "Epoch 14/100\n",
            "----------\n",
            "train Loss: 0.12209 Acc: 96.62546 macro-f1: 1.00000\n",
            "vaild Loss: 0.20173 Acc: 94.47040 macro-f1: 1.00000\n",
            "==> best model saved - 14 / 94.5\n",
            "each epochs training time : 12m 60s\n",
            "\n",
            "\n",
            "Epoch 15/100\n",
            "----------\n",
            "train Loss: 0.09803 Acc: 97.19345 macro-f1: 0.86667\n",
            "vaild Loss: 0.21019 Acc: 93.84735 macro-f1: 1.00000\n",
            "each epochs training time : 13m 52s\n",
            "\n",
            "\n",
            "Epoch 16/100\n",
            "----------\n",
            "train Loss: 0.09359 Acc: 97.29369 macro-f1: 1.00000\n",
            "vaild Loss: 0.18811 Acc: 95.09346 macro-f1: 1.00000\n",
            "==> best model saved - 16 / 95.1\n",
            "each epochs training time : 14m 45s\n",
            "\n",
            "\n",
            "Epoch 17/100\n",
            "----------\n",
            "train Loss: 0.07247 Acc: 98.02873 macro-f1: 1.00000\n",
            "vaild Loss: 0.20473 Acc: 94.85981 macro-f1: 1.00000\n",
            "each epochs training time : 15m 37s\n",
            "\n",
            "\n",
            "Epoch 18/100\n",
            "----------\n",
            "train Loss: 0.08293 Acc: 97.66121 macro-f1: 0.84615\n",
            "vaild Loss: 0.19808 Acc: 95.17134 macro-f1: 1.00000\n",
            "==> best model saved - 18 / 95.2\n",
            "each epochs training time : 16m 30s\n",
            "\n",
            "\n",
            "Epoch 19/100\n",
            "----------\n",
            "train Loss: 0.06979 Acc: 97.69462 macro-f1: 1.00000\n",
            "vaild Loss: 0.20002 Acc: 94.70405 macro-f1: 1.00000\n",
            "each epochs training time : 17m 22s\n",
            "\n",
            "\n",
            "Epoch 20/100\n",
            "----------\n",
            "train Loss: 0.06886 Acc: 97.62780 macro-f1: 1.00000\n",
            "vaild Loss: 0.21347 Acc: 95.09346 macro-f1: 1.00000\n",
            "each epochs training time : 18m 15s\n",
            "\n",
            "\n",
            "Epoch 21/100\n",
            "----------\n",
            "train Loss: 0.05794 Acc: 98.32944 macro-f1: 1.00000\n",
            "vaild Loss: 0.17945 Acc: 95.32710 macro-f1: 1.00000\n",
            "==> best model saved - 21 / 95.3\n",
            "each epochs training time : 19m 8s\n",
            "\n",
            "\n",
            "Epoch 22/100\n",
            "----------\n",
            "train Loss: 0.05687 Acc: 97.99532 macro-f1: 0.85714\n",
            "vaild Loss: 0.21520 Acc: 95.17134 macro-f1: 1.00000\n",
            "each epochs training time : 19m 60s\n",
            "\n",
            "\n",
            "Epoch 23/100\n",
            "----------\n",
            "train Loss: 0.06049 Acc: 98.29602 macro-f1: 0.88889\n",
            "vaild Loss: 0.18646 Acc: 95.32710 macro-f1: 1.00000\n",
            "each epochs training time : 20m 52s\n",
            "\n",
            "\n",
            "Epoch 24/100\n",
            "----------\n",
            "train Loss: 0.04757 Acc: 98.56331 macro-f1: 1.00000\n",
            "vaild Loss: 0.18001 Acc: 95.63863 macro-f1: 1.00000\n",
            "==> best model saved - 24 / 95.6\n",
            "each epochs training time : 21m 45s\n",
            "\n",
            "\n",
            "Epoch 25/100\n",
            "----------\n",
            "train Loss: 0.04445 Acc: 98.63014 macro-f1: 1.00000\n",
            "vaild Loss: 0.21550 Acc: 95.48287 macro-f1: 1.00000\n",
            "each epochs training time : 22m 37s\n",
            "\n",
            "\n",
            "Epoch 26/100\n",
            "----------\n",
            "train Loss: 0.04920 Acc: 98.49649 macro-f1: 1.00000\n",
            "vaild Loss: 0.22748 Acc: 95.09346 macro-f1: 1.00000\n",
            "each epochs training time : 23m 30s\n",
            "\n",
            "\n",
            "Epoch 27/100\n",
            "----------\n",
            "train Loss: 0.04724 Acc: 98.32944 macro-f1: 1.00000\n",
            "vaild Loss: 0.20067 Acc: 95.40498 macro-f1: 1.00000\n",
            "each epochs training time : 24m 22s\n",
            "\n",
            "\n",
            "Epoch 28/100\n",
            "----------\n",
            "train Loss: 0.04110 Acc: 98.76378 macro-f1: 1.00000\n",
            "vaild Loss: 0.18681 Acc: 95.40498 macro-f1: 1.00000\n",
            "each epochs training time : 25m 15s\n",
            "\n",
            "\n",
            "Epoch 29/100\n",
            "----------\n",
            "train Loss: 0.03523 Acc: 99.06448 macro-f1: 1.00000\n",
            "vaild Loss: 0.19935 Acc: 95.87227 macro-f1: 1.00000\n",
            "==> best model saved - 29 / 95.9\n",
            "each epochs training time : 26m 8s\n",
            "\n",
            "\n",
            "Epoch 30/100\n",
            "----------\n",
            "train Loss: 0.04442 Acc: 98.59673 macro-f1: 1.00000\n",
            "vaild Loss: 0.18537 Acc: 95.71651 macro-f1: 1.00000\n",
            "each epochs training time : 27m 0s\n",
            "\n",
            "\n",
            "Epoch 31/100\n",
            "----------\n",
            "train Loss: 0.02800 Acc: 99.16472 macro-f1: 1.00000\n",
            "vaild Loss: 0.24731 Acc: 94.78193 macro-f1: 1.00000\n",
            "each epochs training time : 27m 53s\n",
            "\n",
            "\n",
            "Epoch 32/100\n",
            "----------\n",
            "train Loss: 0.03532 Acc: 98.99766 macro-f1: 1.00000\n",
            "vaild Loss: 0.19524 Acc: 96.02804 macro-f1: 1.00000\n",
            "==> best model saved - 32 / 96.0\n",
            "each epochs training time : 28m 45s\n",
            "\n",
            "\n",
            "Epoch 33/100\n",
            "----------\n",
            "train Loss: 0.02747 Acc: 99.09790 macro-f1: 1.00000\n",
            "vaild Loss: 0.21127 Acc: 95.95016 macro-f1: 1.00000\n",
            "each epochs training time : 29m 38s\n",
            "\n",
            "\n",
            "Epoch 34/100\n",
            "----------\n",
            "train Loss: 0.02477 Acc: 99.33177 macro-f1: 1.00000\n",
            "vaild Loss: 0.19541 Acc: 95.87227 macro-f1: 1.00000\n",
            "each epochs training time : 30m 30s\n",
            "\n",
            "\n",
            "Epoch 35/100\n",
            "----------\n",
            "train Loss: 0.02894 Acc: 98.96425 macro-f1: 1.00000\n",
            "vaild Loss: 0.22161 Acc: 95.71651 macro-f1: 1.00000\n",
            "each epochs training time : 31m 23s\n",
            "\n",
            "\n",
            "Epoch 36/100\n",
            "----------\n",
            "train Loss: 0.02437 Acc: 99.26495 macro-f1: 1.00000\n",
            "vaild Loss: 0.20163 Acc: 95.71651 macro-f1: 1.00000\n",
            "each epochs training time : 32m 15s\n",
            "\n",
            "\n",
            "Epoch 37/100\n",
            "----------\n",
            "train Loss: 0.02394 Acc: 99.19813 macro-f1: 1.00000\n",
            "vaild Loss: 0.19036 Acc: 95.79439 macro-f1: 1.00000\n",
            "each epochs training time : 33m 8s\n",
            "\n",
            "\n",
            "Epoch 38/100\n",
            "----------\n",
            "train Loss: 0.02031 Acc: 99.36519 macro-f1: 1.00000\n",
            "vaild Loss: 0.22536 Acc: 95.17134 macro-f1: 1.00000\n",
            "each epochs training time : 34m 0s\n",
            "\n",
            "\n",
            "Epoch 39/100\n",
            "----------\n",
            "train Loss: 0.01946 Acc: 99.16472 macro-f1: 1.00000\n",
            "vaild Loss: 0.21019 Acc: 95.63863 macro-f1: 1.00000\n",
            "each epochs training time : 34m 53s\n",
            "\n",
            "\n",
            "Epoch 40/100\n",
            "----------\n",
            "train Loss: 0.02049 Acc: 99.26495 macro-f1: 0.76190\n",
            "vaild Loss: 0.20255 Acc: 95.87227 macro-f1: 1.00000\n",
            "each epochs training time : 35m 45s\n",
            "\n",
            "\n",
            "Epoch 41/100\n",
            "----------\n",
            "train Loss: 0.02745 Acc: 99.29836 macro-f1: 1.00000\n",
            "vaild Loss: 0.19766 Acc: 95.56075 macro-f1: 1.00000\n",
            "each epochs training time : 36m 37s\n",
            "\n",
            "\n",
            "Epoch 42/100\n",
            "----------\n",
            "train Loss: 0.02162 Acc: 99.16472 macro-f1: 0.83333\n",
            "vaild Loss: 0.19954 Acc: 96.26168 macro-f1: 1.00000\n",
            "==> best model saved - 42 / 96.3\n",
            "each epochs training time : 37m 30s\n",
            "\n",
            "\n",
            "Epoch 43/100\n",
            "----------\n",
            "train Loss: 0.02857 Acc: 99.29836 macro-f1: 1.00000\n",
            "vaild Loss: 0.19565 Acc: 95.56075 macro-f1: 1.00000\n",
            "each epochs training time : 38m 22s\n",
            "\n",
            "\n",
            "Epoch 44/100\n",
            "----------\n",
            "train Loss: 0.02154 Acc: 99.16472 macro-f1: 1.00000\n",
            "vaild Loss: 0.19776 Acc: 96.10592 macro-f1: 1.00000\n",
            "each epochs training time : 39m 15s\n",
            "\n",
            "\n",
            "Epoch 45/100\n",
            "----------\n",
            "train Loss: 0.02200 Acc: 99.33177 macro-f1: 1.00000\n",
            "vaild Loss: 0.21078 Acc: 95.63863 macro-f1: 1.00000\n",
            "each epochs training time : 40m 7s\n",
            "\n",
            "\n",
            "Epoch 46/100\n",
            "----------\n",
            "train Loss: 0.02201 Acc: 99.49883 macro-f1: 1.00000\n",
            "vaild Loss: 0.16950 Acc: 96.02804 macro-f1: 1.00000\n",
            "each epochs training time : 40m 60s\n",
            "\n",
            "\n",
            "Epoch 47/100\n",
            "----------\n",
            "train Loss: 0.01776 Acc: 99.36519 macro-f1: 1.00000\n",
            "vaild Loss: 0.21331 Acc: 96.02804 macro-f1: 1.00000\n",
            "each epochs training time : 41m 52s\n",
            "\n",
            "\n",
            "Epoch 48/100\n",
            "----------\n",
            "train Loss: 0.01410 Acc: 99.69930 macro-f1: 1.00000\n",
            "vaild Loss: 0.19133 Acc: 96.10592 macro-f1: 1.00000\n",
            "each epochs training time : 42m 45s\n",
            "\n",
            "\n",
            "Epoch 49/100\n",
            "----------\n",
            "train Loss: 0.01094 Acc: 99.73271 macro-f1: 1.00000\n",
            "vaild Loss: 0.21377 Acc: 95.87227 macro-f1: 1.00000\n",
            "each epochs training time : 43m 37s\n",
            "\n",
            "\n",
            "Epoch 50/100\n",
            "----------\n",
            "train Loss: 0.01303 Acc: 99.49883 macro-f1: 1.00000\n",
            "vaild Loss: 0.22222 Acc: 95.87227 macro-f1: 1.00000\n",
            "each epochs training time : 44m 30s\n",
            "\n",
            "\n",
            "Epoch 51/100\n",
            "----------\n",
            "train Loss: 0.01380 Acc: 99.53224 macro-f1: 1.00000\n",
            "vaild Loss: 0.19360 Acc: 96.96262 macro-f1: 1.00000\n",
            "==> best model saved - 51 / 97.0\n",
            "each epochs training time : 45m 22s\n",
            "\n",
            "\n",
            "Epoch 52/100\n",
            "----------\n",
            "train Loss: 0.01549 Acc: 99.43201 macro-f1: 1.00000\n",
            "vaild Loss: 0.23582 Acc: 95.79439 macro-f1: 1.00000\n",
            "each epochs training time : 46m 15s\n",
            "\n",
            "\n",
            "Epoch 53/100\n",
            "----------\n",
            "train Loss: 0.01573 Acc: 99.46542 macro-f1: 1.00000\n",
            "vaild Loss: 0.20734 Acc: 96.18380 macro-f1: 1.00000\n",
            "each epochs training time : 47m 7s\n",
            "\n",
            "\n",
            "Epoch 54/100\n",
            "----------\n",
            "train Loss: 0.01315 Acc: 99.56565 macro-f1: 1.00000\n",
            "vaild Loss: 0.23357 Acc: 94.93769 macro-f1: 1.00000\n",
            "each epochs training time : 47m 60s\n",
            "\n",
            "\n",
            "Epoch 55/100\n",
            "----------\n",
            "train Loss: 0.01141 Acc: 99.56565 macro-f1: 1.00000\n",
            "vaild Loss: 0.19489 Acc: 96.10592 macro-f1: 1.00000\n",
            "each epochs training time : 48m 52s\n",
            "\n",
            "\n",
            "Epoch 56/100\n",
            "----------\n",
            "train Loss: 0.00729 Acc: 99.86635 macro-f1: 1.00000\n",
            "vaild Loss: 0.24503 Acc: 95.32710 macro-f1: 1.00000\n",
            "each epochs training time : 49m 45s\n",
            "\n",
            "\n",
            "Epoch 57/100\n",
            "----------\n",
            "train Loss: 0.00976 Acc: 99.69930 macro-f1: 1.00000\n",
            "vaild Loss: 0.22284 Acc: 95.87227 macro-f1: 1.00000\n",
            "each epochs training time : 50m 37s\n",
            "\n",
            "\n",
            "Epoch 58/100\n",
            "----------\n",
            "train Loss: 0.01633 Acc: 99.39860 macro-f1: 1.00000\n",
            "vaild Loss: 0.24256 Acc: 95.01558 macro-f1: 1.00000\n",
            "each epochs training time : 51m 30s\n",
            "\n",
            "\n",
            "Epoch 59/100\n",
            "----------\n",
            "train Loss: 0.01617 Acc: 99.56565 macro-f1: 1.00000\n",
            "vaild Loss: 0.21583 Acc: 96.02804 macro-f1: 1.00000\n",
            "each epochs training time : 52m 22s\n",
            "\n",
            "\n",
            "Epoch 60/100\n",
            "----------\n",
            "train Loss: 0.00991 Acc: 99.73271 macro-f1: 1.00000\n",
            "vaild Loss: 0.21765 Acc: 95.95016 macro-f1: 1.00000\n",
            "each epochs training time : 53m 15s\n",
            "\n",
            "\n",
            "Epoch 61/100\n",
            "----------\n",
            "train Loss: 0.00874 Acc: 99.63248 macro-f1: 1.00000\n",
            "vaild Loss: 0.22677 Acc: 96.18380 macro-f1: 1.00000\n",
            "each epochs training time : 54m 7s\n",
            "\n",
            "\n",
            "Epoch 62/100\n",
            "----------\n",
            "train Loss: 0.01039 Acc: 99.59906 macro-f1: 1.00000\n",
            "vaild Loss: 0.21539 Acc: 96.02804 macro-f1: 1.00000\n",
            "each epochs training time : 54m 60s\n",
            "\n",
            "\n",
            "Epoch 63/100\n",
            "----------\n",
            "train Loss: 0.00826 Acc: 99.73271 macro-f1: 1.00000\n",
            "vaild Loss: 0.24488 Acc: 95.87227 macro-f1: 1.00000\n",
            "each epochs training time : 55m 52s\n",
            "\n",
            "\n",
            "Epoch 64/100\n",
            "----------\n",
            "train Loss: 0.00980 Acc: 99.63248 macro-f1: 1.00000\n",
            "vaild Loss: 0.20566 Acc: 96.18380 macro-f1: 1.00000\n",
            "each epochs training time : 56m 45s\n",
            "\n",
            "\n",
            "Epoch 65/100\n",
            "----------\n",
            "train Loss: 0.00761 Acc: 99.69930 macro-f1: 0.81818\n",
            "vaild Loss: 0.21809 Acc: 96.18380 macro-f1: 1.00000\n",
            "each epochs training time : 57m 37s\n",
            "\n",
            "\n",
            "Epoch 66/100\n",
            "----------\n",
            "train Loss: 0.01369 Acc: 99.56565 macro-f1: 0.81818\n",
            "vaild Loss: 0.21681 Acc: 95.95016 macro-f1: 1.00000\n",
            "each epochs training time : 58m 30s\n",
            "\n",
            "\n",
            "Epoch 67/100\n",
            "----------\n",
            "train Loss: 0.00882 Acc: 99.66589 macro-f1: 1.00000\n",
            "vaild Loss: 0.24292 Acc: 95.63863 macro-f1: 1.00000\n",
            "each epochs training time : 59m 22s\n",
            "\n",
            "\n",
            "Epoch 68/100\n",
            "----------\n",
            "train Loss: 0.01046 Acc: 99.59906 macro-f1: 1.00000\n",
            "vaild Loss: 0.22793 Acc: 96.18380 macro-f1: 1.00000\n",
            "each epochs training time : 60m 15s\n",
            "\n",
            "\n",
            "Epoch 69/100\n",
            "----------\n",
            "train Loss: 0.00806 Acc: 99.76612 macro-f1: 1.00000\n",
            "vaild Loss: 0.23966 Acc: 95.48287 macro-f1: 1.00000\n",
            "each epochs training time : 61m 7s\n",
            "\n",
            "\n",
            "Epoch 70/100\n",
            "----------\n",
            "train Loss: 0.00839 Acc: 99.83294 macro-f1: 1.00000\n",
            "vaild Loss: 0.20069 Acc: 95.87227 macro-f1: 1.00000\n",
            "each epochs training time : 61m 60s\n",
            "\n",
            "\n",
            "Epoch 71/100\n",
            "----------\n",
            "train Loss: 0.00780 Acc: 99.76612 macro-f1: 1.00000\n",
            "vaild Loss: 0.19487 Acc: 96.02804 macro-f1: 1.00000\n",
            "each epochs training time : 62m 52s\n",
            "\n",
            "\n",
            "Epoch 72/100\n",
            "----------\n",
            "train Loss: 0.00700 Acc: 99.76612 macro-f1: 1.00000\n",
            "vaild Loss: 0.20821 Acc: 96.26168 macro-f1: 1.00000\n",
            "each epochs training time : 63m 45s\n",
            "\n",
            "\n",
            "Epoch 73/100\n",
            "----------\n",
            "train Loss: 0.00908 Acc: 99.69930 macro-f1: 1.00000\n",
            "vaild Loss: 0.23602 Acc: 96.18380 macro-f1: 1.00000\n",
            "each epochs training time : 64m 37s\n",
            "\n",
            "\n",
            "Epoch 74/100\n",
            "----------\n",
            "train Loss: 0.00660 Acc: 99.83294 macro-f1: 1.00000\n",
            "vaild Loss: 0.21668 Acc: 95.95016 macro-f1: 1.00000\n",
            "each epochs training time : 65m 30s\n",
            "\n",
            "\n",
            "Epoch 75/100\n",
            "----------\n",
            "train Loss: 0.00876 Acc: 99.76612 macro-f1: 1.00000\n",
            "vaild Loss: 0.21687 Acc: 96.18380 macro-f1: 1.00000\n",
            "each epochs training time : 66m 22s\n",
            "\n",
            "\n",
            "Epoch 76/100\n",
            "----------\n",
            "train Loss: 0.00765 Acc: 99.76612 macro-f1: 1.00000\n",
            "vaild Loss: 0.22651 Acc: 95.63863 macro-f1: 1.00000\n",
            "each epochs training time : 67m 15s\n",
            "\n",
            "\n",
            "Epoch 77/100\n",
            "----------\n",
            "train Loss: 0.00413 Acc: 99.83294 macro-f1: 1.00000\n",
            "vaild Loss: 0.21374 Acc: 96.57321 macro-f1: 1.00000\n",
            "each epochs training time : 68m 7s\n",
            "\n",
            "\n",
            "Epoch 78/100\n",
            "----------\n",
            "train Loss: 0.00807 Acc: 99.76612 macro-f1: 1.00000\n",
            "vaild Loss: 0.23086 Acc: 95.79439 macro-f1: 1.00000\n",
            "each epochs training time : 68m 60s\n",
            "\n",
            "\n",
            "Epoch 79/100\n",
            "----------\n",
            "train Loss: 0.01318 Acc: 99.59906 macro-f1: 1.00000\n",
            "vaild Loss: 0.22820 Acc: 95.79439 macro-f1: 1.00000\n",
            "each epochs training time : 69m 52s\n",
            "\n",
            "\n",
            "Epoch 80/100\n",
            "----------\n",
            "train Loss: 0.00901 Acc: 99.76612 macro-f1: 0.85714\n",
            "vaild Loss: 0.23751 Acc: 95.56075 macro-f1: 1.00000\n",
            "each epochs training time : 70m 45s\n",
            "\n",
            "\n",
            "Epoch 81/100\n",
            "----------\n",
            "train Loss: 0.00833 Acc: 99.69930 macro-f1: 1.00000\n",
            "vaild Loss: 0.24916 Acc: 96.10592 macro-f1: 1.00000\n",
            "each epochs training time : 71m 37s\n",
            "\n",
            "\n",
            "Epoch 82/100\n",
            "----------\n",
            "train Loss: 0.00876 Acc: 99.76612 macro-f1: 1.00000\n",
            "vaild Loss: 0.22200 Acc: 96.26168 macro-f1: 1.00000\n",
            "each epochs training time : 72m 29s\n",
            "\n",
            "\n",
            "Epoch 83/100\n",
            "----------\n",
            "train Loss: 0.00573 Acc: 99.83294 macro-f1: 1.00000\n",
            "vaild Loss: 0.21928 Acc: 95.71651 macro-f1: 1.00000\n",
            "each epochs training time : 73m 22s\n",
            "\n",
            "\n",
            "Epoch 84/100\n",
            "----------\n",
            "train Loss: 0.00556 Acc: 99.86635 macro-f1: 1.00000\n",
            "vaild Loss: 0.20493 Acc: 96.10592 macro-f1: 1.00000\n",
            "each epochs training time : 74m 14s\n",
            "\n",
            "\n",
            "Epoch 85/100\n",
            "----------\n",
            "train Loss: 0.00715 Acc: 99.79953 macro-f1: 1.00000\n",
            "vaild Loss: 0.21712 Acc: 96.18380 macro-f1: 1.00000\n",
            "each epochs training time : 75m 7s\n",
            "\n",
            "\n",
            "Epoch 86/100\n",
            "----------\n",
            "train Loss: 0.00715 Acc: 99.86635 macro-f1: 1.00000\n",
            "vaild Loss: 0.23114 Acc: 95.79439 macro-f1: 1.00000\n",
            "each epochs training time : 75m 59s\n",
            "\n",
            "\n",
            "Epoch 87/100\n",
            "----------\n",
            "train Loss: 0.00284 Acc: 99.93318 macro-f1: 1.00000\n",
            "vaild Loss: 0.21449 Acc: 96.18380 macro-f1: 1.00000\n",
            "each epochs training time : 76m 52s\n",
            "\n",
            "\n",
            "Epoch 88/100\n",
            "----------\n",
            "train Loss: 0.00172 Acc: 100.00000 macro-f1: 1.00000\n",
            "vaild Loss: 0.24034 Acc: 96.10592 macro-f1: 1.00000\n",
            "each epochs training time : 77m 44s\n",
            "\n",
            "\n",
            "Epoch 89/100\n",
            "----------\n",
            "train Loss: 0.00522 Acc: 99.79953 macro-f1: 1.00000\n",
            "vaild Loss: 0.25355 Acc: 96.02804 macro-f1: 1.00000\n",
            "each epochs training time : 78m 37s\n",
            "\n",
            "\n",
            "Epoch 90/100\n",
            "----------\n",
            "train Loss: 0.00821 Acc: 99.69930 macro-f1: 1.00000\n",
            "vaild Loss: 0.24057 Acc: 95.95016 macro-f1: 1.00000\n",
            "each epochs training time : 79m 29s\n",
            "\n",
            "\n",
            "Epoch 91/100\n",
            "----------\n",
            "train Loss: 0.00913 Acc: 99.66589 macro-f1: 1.00000\n",
            "vaild Loss: 0.21655 Acc: 96.10592 macro-f1: 1.00000\n",
            "each epochs training time : 80m 22s\n",
            "\n",
            "\n",
            "Epoch 92/100\n",
            "----------\n",
            "train Loss: 0.00386 Acc: 99.89977 macro-f1: 1.00000\n",
            "vaild Loss: 0.21157 Acc: 96.33956 macro-f1: 1.00000\n",
            "each epochs training time : 81m 14s\n",
            "\n",
            "\n",
            "Epoch 93/100\n",
            "----------\n",
            "train Loss: 0.00328 Acc: 99.96659 macro-f1: 1.00000\n",
            "vaild Loss: 0.26898 Acc: 95.71651 macro-f1: 1.00000\n",
            "each epochs training time : 82m 7s\n",
            "\n",
            "\n",
            "Epoch 94/100\n",
            "----------\n",
            "train Loss: 0.00595 Acc: 99.83294 macro-f1: 1.00000\n",
            "vaild Loss: 0.22696 Acc: 96.10592 macro-f1: 1.00000\n",
            "each epochs training time : 82m 59s\n",
            "\n",
            "\n",
            "Epoch 95/100\n",
            "----------\n",
            "train Loss: 0.00647 Acc: 99.79953 macro-f1: 1.00000\n",
            "vaild Loss: 0.21483 Acc: 96.26168 macro-f1: 1.00000\n",
            "each epochs training time : 83m 52s\n",
            "\n",
            "\n",
            "Epoch 96/100\n",
            "----------\n",
            "train Loss: 0.00413 Acc: 99.89977 macro-f1: 1.00000\n",
            "vaild Loss: 0.23477 Acc: 95.79439 macro-f1: 1.00000\n",
            "each epochs training time : 84m 45s\n",
            "\n",
            "\n",
            "Epoch 97/100\n",
            "----------\n",
            "train Loss: 0.00589 Acc: 99.79953 macro-f1: 1.00000\n",
            "vaild Loss: 0.22195 Acc: 96.33956 macro-f1: 1.00000\n",
            "each epochs training time : 85m 37s\n",
            "\n",
            "\n",
            "Epoch 98/100\n",
            "----------\n",
            "train Loss: 0.00766 Acc: 99.69930 macro-f1: 1.00000\n",
            "vaild Loss: 0.24020 Acc: 96.02804 macro-f1: 1.00000\n",
            "each epochs training time : 86m 30s\n",
            "\n",
            "\n",
            "Epoch 99/100\n",
            "----------\n",
            "train Loss: 0.00692 Acc: 99.83294 macro-f1: 1.00000\n",
            "vaild Loss: 0.21363 Acc: 96.18380 macro-f1: 1.00000\n",
            "each epochs training time : 87m 22s\n",
            "\n",
            "\n",
            "Training complete in 87m 22s\n",
            "Best valid Acc: 51 - 97.0\n",
            "model saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 결과 그래프 그리기\n",
        "print('best model : %d - %1.f / %.1f'%(best_idx, valid_acc[best_idx], valid_loss[best_idx]))\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(train_acc, 'b-')\n",
        "ax1.plot(valid_acc, 'r-')\n",
        "plt.plot(best_idx, valid_acc[best_idx], 'ro')\n",
        "ax1.set_xlabel('epoch')\n",
        "# Make the y-axis label, ticks and tick labels match the line color.\n",
        "ax1.set_ylabel('acc', color='k')\n",
        "ax1.tick_params('y', colors='k')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(train_loss, 'g-')\n",
        "ax2.plot(valid_loss, 'k-')\n",
        "plt.plot(best_idx, valid_loss[best_idx], 'ro')\n",
        "ax2.set_ylabel('loss', color='k')\n",
        "ax2.tick_params('y', colors='k')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "5kJPLUuEU1pH",
        "outputId": "49f33459-cc2b-44e3-e71f-5e69f22b1c67"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best model : 51 - 97 / 0.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JJdS3MynU1rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ## 학습 결과 검수\n",
        "# def test_and_visualize_model(model, phase = 'test', num_images=4):\n",
        "#     # phase = 'train', 'valid', 'test'\n",
        "    \n",
        "#     was_training = model.training\n",
        "#     model.eval()\n",
        "#     fig = plt.figure()\n",
        "    \n",
        "#     running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
        "#             inputs = inputs.to(device)\n",
        "#             labels = labels.to(device)\n",
        "\n",
        "#             outputs = model(inputs)\n",
        "#             _, preds = torch.max(outputs, 1)\n",
        "#             loss = criterion(outputs, labels)  # batch의 평균 loss 출력\n",
        "\n",
        "#             running_loss    += loss.item() * inputs.size(0)\n",
        "#             running_corrects+= torch.sum(preds == labels.data)\n",
        "#             num_cnt += inputs.size(0)  # batch size\n",
        "\n",
        "#     #         if i == 2: break\n",
        "\n",
        "#         test_loss = running_loss / num_cnt\n",
        "#         test_acc  = running_corrects.double() / num_cnt       \n",
        "#         print('test done : loss/acc : %.2f / %.1f' % (test_loss, test_acc*100))\n",
        "\n",
        "#     # 예시 그림 plot\n",
        "#     with torch.no_grad():\n",
        "#         for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
        "#             inputs = inputs.to(device)\n",
        "#             labels = labels.to(device)\n",
        "\n",
        "#             outputs = model(inputs)\n",
        "#             _, preds = torch.max(outputs, 1)        \n",
        "\n",
        "#             # 예시 그림 plot\n",
        "#             for j in range(1, num_images+1):\n",
        "#                 ax = plt.subplot(num_images//2, 2, j)\n",
        "#                 ax.axis('off')\n",
        "#                 ax.set_title('%s : %s -> %s'%(\n",
        "#                     'True' if class_names[str(labels[j].cpu().numpy())]==class_names[str(preds[j].cpu().numpy())] else 'False',\n",
        "#                     class_names[str(labels[j].cpu().numpy())], class_names[str(preds[j].cpu().numpy())]))\n",
        "#                 imshow(inputs.cpu().data[j])          \n",
        "#             if i == 0 : break\n",
        "\n",
        "\n",
        "#     model.train(mode=was_training);  # 다시 train모드로\n",
        "    \n",
        "#     ## TEST!\n",
        "#     test_and_visualize_model(model, phase = 'test')"
      ],
      "metadata": {
        "id": "bZK4jMWoU1tQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LedsQjpUU1vI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "X2jIgWqSU1w9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-o1YRRNYU1zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 추론"
      ],
      "metadata": {
        "id": "WQR1RKgTpKk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 모델을 평가 모드로 변경하고 test 데이터 분류\n",
        "test_png = sorted(glob('/content/drive/Othercomputers/내 MacBook Pro/open/test/*.png'))\n",
        "test_imgs = [img_load(n) for n in tqdm(test_png)]\n",
        "test_dataset = Custom_dataset_3(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "model.eval()\n",
        "f_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in (test_loader):\n",
        "        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            pred = model(x)\n",
        "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
      ],
      "metadata": {
        "id": "gj7gTQv6U11P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "118afc97-6be1-4fd1-bf9a-705135b8a74f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2154/2154 [03:31<00:00, 10.17it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 숫자로된 레이블을 문자열 레이블로 변경\n",
        "label_decoder = {value:key for key, value in label_unique.items()}\n",
        "f_result = [label_decoder[result] for result in f_pred]"
      ],
      "metadata": {
        "id": "30_rcMw4U13G"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime as dt \n",
        "today = dt.today().strftime('%Y-%m-%d')\n",
        "version = f'efficientNet_b4_by_timm_data_ver2_{today}'\n",
        "submission = pd.read_csv(f\"/content/drive/MyDrive/DACON_이상치 탐지 알고리즘 경진대회/open/sample_submission.csv\")\n",
        "\n",
        "## 시각적 확인을 위해 문자열 레이블로 이루어진 된 label 필드 생성\n",
        "submission[\"label\"] = f_result\n",
        "display(submission)\n",
        "submission.to_csv(f\"/content/drive/MyDrive/DACON_이상치 탐지 알고리즘 경진대회/open/sample_submission_{version}.csv\", index = False)"
      ],
      "metadata": {
        "id": "1zWu-D7WdRmQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "bf9af60d-ec93-475c-a141-692e58f99b7a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      index             label\n",
              "0         0   tile-glue_strip\n",
              "1         1         grid-good\n",
              "2         2   transistor-good\n",
              "3         3  tile-gray_stroke\n",
              "4         4         tile-good\n",
              "...     ...               ...\n",
              "2149   2149  tile-gray_stroke\n",
              "2150   2150        screw-good\n",
              "2151   2151         grid-good\n",
              "2152   2152        cable-good\n",
              "2153   2153       zipper-good\n",
              "\n",
              "[2154 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2779aeec-c442-4e42-960b-af1674c5e184\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>tile-glue_strip</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>grid-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>transistor-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>tile-gray_stroke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>tile-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2149</th>\n",
              "      <td>2149</td>\n",
              "      <td>tile-gray_stroke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2150</th>\n",
              "      <td>2150</td>\n",
              "      <td>screw-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2151</th>\n",
              "      <td>2151</td>\n",
              "      <td>grid-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2152</th>\n",
              "      <td>2152</td>\n",
              "      <td>cable-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2153</th>\n",
              "      <td>2153</td>\n",
              "      <td>zipper-good</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2154 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2779aeec-c442-4e42-960b-af1674c5e184')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2779aeec-c442-4e42-960b-af1674c5e184 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2779aeec-c442-4e42-960b-af1674c5e184');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cG_tNWs2zxh8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}